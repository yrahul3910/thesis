running: {'--uuid': 'bd0a3daad88053e8a9b1d89c7a7751e8', '-db-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230815_214848', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random/optimizer.py -c MLP-adam -d breast -o random -u bd0a3daad88053e8a9b1d89c7a7751e8 -m acc -n 45 -p 1 -dir /Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20230815_214848
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/Users/ryedida/miniforge3/lib/python3.9/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 45 1
with data root: None
suggestion time taken 0.001520 iter 0 next_points [{'alpha': 0.00013638059409394043, 'batch_size': 32, 'beta_1': 0.8215194433711591, 'beta_2': 0.9997717627334223, 'epsilon': 1.8438620927599768e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.00018611734099765556, 'tol': 0.03710949613682067, 'validation_fraction': 0.6538326395124218}]
function_evaluation time 0.517184 value -0.547253 suggestion {'alpha': 0.00013638059409394043, 'batch_size': 32, 'beta_1': 0.8215194433711591, 'beta_2': 0.9997717627334223, 'epsilon': 1.8438620927599768e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.00018611734099765556, 'tol': 0.03710949613682067, 'validation_fraction': 0.6538326395124218}
observation time 0.000001, current best -0.547253 at iter 0
suggestion time taken 0.001689 iter 1 next_points [{'alpha': 0.020417442706632122, 'batch_size': 174, 'beta_1': 0.9382712665951649, 'beta_2': 0.9947912056950896, 'epsilon': 6.008205329158936e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.0006943484140361523, 'tol': 0.017044509915500716, 'validation_fraction': 0.8268284501936647}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.447977 value -0.641758 suggestion {'alpha': 0.020417442706632122, 'batch_size': 174, 'beta_1': 0.9382712665951649, 'beta_2': 0.9947912056950896, 'epsilon': 6.008205329158936e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.0006943484140361523, 'tol': 0.017044509915500716, 'validation_fraction': 0.8268284501936647}
observation time 0.000002, current best -0.641758 at iter 1
suggestion time taken 0.002386 iter 2 next_points [{'alpha': 0.005231988374210541, 'batch_size': 213, 'beta_1': 0.7510368859819104, 'beta_2': 0.9999930616551566, 'epsilon': 9.36466637943371e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.015553962728532138, 'tol': 0.0008203305930650367, 'validation_fraction': 0.3431910735997098}]
function_evaluation time 0.341841 value -0.912088 suggestion {'alpha': 0.005231988374210541, 'batch_size': 213, 'beta_1': 0.7510368859819104, 'beta_2': 0.9999930616551566, 'epsilon': 9.36466637943371e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.015553962728532138, 'tol': 0.0008203305930650367, 'validation_fraction': 0.3431910735997098}
observation time 0.000002, current best -0.912088 at iter 2
suggestion time taken 0.004633 iter 3 next_points [{'alpha': 2.4167944675804143, 'batch_size': 79, 'beta_1': 0.8008943637696544, 'beta_2': 0.9942203637244443, 'epsilon': 1.4169165747620838e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.007788082571995502, 'tol': 0.0003759341889236732, 'validation_fraction': 0.8088002001565814}]
function_evaluation time 0.317465 value -0.909890 suggestion {'alpha': 2.4167944675804143, 'batch_size': 79, 'beta_1': 0.8008943637696544, 'beta_2': 0.9942203637244443, 'epsilon': 1.4169165747620838e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.007788082571995502, 'tol': 0.0003759341889236732, 'validation_fraction': 0.8088002001565814}
observation time 0.000001, current best -0.912088 at iter 3
suggestion time taken 0.001682 iter 4 next_points [{'alpha': 0.00804349157596665, 'batch_size': 97, 'beta_1': 0.6222400541004287, 'beta_2': 0.9979476276383035, 'epsilon': 6.459914116357088e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.0021230014304628887, 'tol': 0.0019906145931513, 'validation_fraction': 0.6733153287784577}]
function_evaluation time 0.797298 value -0.892308 suggestion {'alpha': 0.00804349157596665, 'batch_size': 97, 'beta_1': 0.6222400541004287, 'beta_2': 0.9979476276383035, 'epsilon': 6.459914116357088e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.0021230014304628887, 'tol': 0.0019906145931513, 'validation_fraction': 0.6733153287784577}
observation time 0.000001, current best -0.912088 at iter 4
suggestion time taken 0.001663 iter 5 next_points [{'alpha': 0.004154746756860289, 'batch_size': 33, 'beta_1': 0.924867795938873, 'beta_2': 0.9999659809575334, 'epsilon': 1.7363724661294875e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.05578427810844692, 'tol': 0.04243074274118664, 'validation_fraction': 0.3034261086770961}]
function_evaluation time 0.392329 value -0.852747 suggestion {'alpha': 0.004154746756860289, 'batch_size': 33, 'beta_1': 0.924867795938873, 'beta_2': 0.9999659809575334, 'epsilon': 1.7363724661294875e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.05578427810844692, 'tol': 0.04243074274118664, 'validation_fraction': 0.3034261086770961}
observation time 0.000001, current best -0.912088 at iter 5
suggestion time taken 0.006993 iter 6 next_points [{'alpha': 1.733068464756254e-05, 'batch_size': 13, 'beta_1': 0.9400704357827283, 'beta_2': 0.9108943714001703, 'epsilon': 8.929931756353871e-07, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.030286029478140023, 'tol': 0.06260327237857764, 'validation_fraction': 0.2578964692273636}]
function_evaluation time 0.651749 value -0.916484 suggestion {'alpha': 1.733068464756254e-05, 'batch_size': 13, 'beta_1': 0.9400704357827283, 'beta_2': 0.9108943714001703, 'epsilon': 8.929931756353871e-07, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.030286029478140023, 'tol': 0.06260327237857764, 'validation_fraction': 0.2578964692273636}
observation time 0.000001, current best -0.916484 at iter 6
suggestion time taken 0.006008 iter 7 next_points [{'alpha': 0.06904327375027525, 'batch_size': 198, 'beta_1': 0.7663822982927782, 'beta_2': 0.9921418197403427, 'epsilon': 3.6448241905803074e-07, 'hidden_layer_sizes': 162, 'learning_rate_init': 2.5513945558534748e-05, 'tol': 0.05739027085764669, 'validation_fraction': 0.7510400728216304}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.141427 value -0.507692 suggestion {'alpha': 0.06904327375027525, 'batch_size': 198, 'beta_1': 0.7663822982927782, 'beta_2': 0.9921418197403427, 'epsilon': 3.6448241905803074e-07, 'hidden_layer_sizes': 162, 'learning_rate_init': 2.5513945558534748e-05, 'tol': 0.05739027085764669, 'validation_fraction': 0.7510400728216304}
observation time 0.000001, current best -0.916484 at iter 7
suggestion time taken 0.001654 iter 8 next_points [{'alpha': 1.9339371130701633e-05, 'batch_size': 94, 'beta_1': 0.8836561223242889, 'beta_2': 0.9999856674461585, 'epsilon': 4.014039841189118e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0002533187412637741, 'tol': 0.0001870841245123696, 'validation_fraction': 0.7327712579100587}]
function_evaluation time 0.244168 value -0.639560 suggestion {'alpha': 1.9339371130701633e-05, 'batch_size': 94, 'beta_1': 0.8836561223242889, 'beta_2': 0.9999856674461585, 'epsilon': 4.014039841189118e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0002533187412637741, 'tol': 0.0001870841245123696, 'validation_fraction': 0.7327712579100587}
observation time 0.000001, current best -0.916484 at iter 8
suggestion time taken 0.001645 iter 9 next_points [{'alpha': 0.00023878516389451153, 'batch_size': 23, 'beta_1': 0.9859219651752821, 'beta_2': 0.9999878557942244, 'epsilon': 6.7537784527125975e-09, 'hidden_layer_sizes': 107, 'learning_rate_init': 7.259310728072726e-05, 'tol': 0.0006684909712409785, 'validation_fraction': 0.6375988965145998}]
function_evaluation time 0.468626 value -0.556044 suggestion {'alpha': 0.00023878516389451153, 'batch_size': 23, 'beta_1': 0.9859219651752821, 'beta_2': 0.9999878557942244, 'epsilon': 6.7537784527125975e-09, 'hidden_layer_sizes': 107, 'learning_rate_init': 7.259310728072726e-05, 'tol': 0.0006684909712409785, 'validation_fraction': 0.6375988965145998}
observation time 0.000002, current best -0.916484 at iter 9
suggestion time taken 0.004825 iter 10 next_points [{'alpha': 2.293379244519899, 'batch_size': 140, 'beta_1': 0.9887870273506277, 'beta_2': 0.9975161985383444, 'epsilon': 3.581116883758145e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.07742265102373881, 'tol': 0.046368086350763484, 'validation_fraction': 0.6691659005510386}]
function_evaluation time 0.240695 value -0.852747 suggestion {'alpha': 2.293379244519899, 'batch_size': 140, 'beta_1': 0.9887870273506277, 'beta_2': 0.9975161985383444, 'epsilon': 3.581116883758145e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.07742265102373881, 'tol': 0.046368086350763484, 'validation_fraction': 0.6691659005510386}
observation time 0.000002, current best -0.916484 at iter 10
suggestion time taken 0.001798 iter 11 next_points [{'alpha': 0.000959501907463935, 'batch_size': 124, 'beta_1': 0.9898315494980123, 'beta_2': 0.9317197517963844, 'epsilon': 1.383576604498125e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.00140717932344276, 'tol': 0.023431732300088652, 'validation_fraction': 0.555124695339293}]
function_evaluation time 0.283169 value -0.846154 suggestion {'alpha': 0.000959501907463935, 'batch_size': 124, 'beta_1': 0.9898315494980123, 'beta_2': 0.9317197517963844, 'epsilon': 1.383576604498125e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.00140717932344276, 'tol': 0.023431732300088652, 'validation_fraction': 0.555124695339293}
observation time 0.000001, current best -0.916484 at iter 11
suggestion time taken 0.001790 iter 12 next_points [{'alpha': 0.05097624983155313, 'batch_size': 86, 'beta_1': 0.5639155338181661, 'beta_2': 0.9997677929567336, 'epsilon': 4.1752416604074103e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 4.8208657967477706e-05, 'tol': 0.021346236180968377, 'validation_fraction': 0.34198244233589864}]
function_evaluation time 0.126481 value -0.639560 suggestion {'alpha': 0.05097624983155313, 'batch_size': 86, 'beta_1': 0.5639155338181661, 'beta_2': 0.9997677929567336, 'epsilon': 4.1752416604074103e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 4.8208657967477706e-05, 'tol': 0.021346236180968377, 'validation_fraction': 0.34198244233589864}
observation time 0.000002, current best -0.916484 at iter 12
suggestion time taken 0.001913 iter 13 next_points [{'alpha': 2.7304389219864813, 'batch_size': 45, 'beta_1': 0.5905130386838255, 'beta_2': 0.9999892154876548, 'epsilon': 9.949266382507244e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.08453144553924188, 'tol': 4.185358587435739e-05, 'validation_fraction': 0.7577090610934707}]
function_evaluation time 0.368534 value -0.916484 suggestion {'alpha': 2.7304389219864813, 'batch_size': 45, 'beta_1': 0.5905130386838255, 'beta_2': 0.9999892154876548, 'epsilon': 9.949266382507244e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.08453144553924188, 'tol': 4.185358587435739e-05, 'validation_fraction': 0.7577090610934707}
observation time 0.000002, current best -0.916484 at iter 13
suggestion time taken 0.003854 iter 14 next_points [{'alpha': 5.1473182351393065, 'batch_size': 131, 'beta_1': 0.9886105736629313, 'beta_2': 0.9192123021158333, 'epsilon': 1.6442715422007e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.015155968142267473, 'tol': 0.034802612493482925, 'validation_fraction': 0.42623581594542376}]
function_evaluation time 0.229765 value -0.898901 suggestion {'alpha': 5.1473182351393065, 'batch_size': 131, 'beta_1': 0.9886105736629313, 'beta_2': 0.9192123021158333, 'epsilon': 1.6442715422007e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.015155968142267473, 'tol': 0.034802612493482925, 'validation_fraction': 0.42623581594542376}
observation time 0.000002, current best -0.916484 at iter 14
suggestion time taken 0.002905 iter 15 next_points [{'alpha': 0.0027770033161780565, 'batch_size': 116, 'beta_1': 0.9549546431198532, 'beta_2': 0.9871526682329335, 'epsilon': 1.9105250113132375e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.001813103590686219, 'tol': 0.03629830069833145, 'validation_fraction': 0.1385214018370644}]
function_evaluation time 0.534363 value -0.898901 suggestion {'alpha': 0.0027770033161780565, 'batch_size': 116, 'beta_1': 0.9549546431198532, 'beta_2': 0.9871526682329335, 'epsilon': 1.9105250113132375e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.001813103590686219, 'tol': 0.03629830069833145, 'validation_fraction': 0.1385214018370644}
observation time 0.000001, current best -0.916484 at iter 15
suggestion time taken 0.004908 iter 16 next_points [{'alpha': 0.0005280123625036765, 'batch_size': 87, 'beta_1': 0.9306507182943651, 'beta_2': 0.987644225004733, 'epsilon': 6.789483102769979e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.00014178846122556122, 'tol': 0.053033299088684524, 'validation_fraction': 0.14089685117330086}]
function_evaluation time 0.503609 value -0.740659 suggestion {'alpha': 0.0005280123625036765, 'batch_size': 87, 'beta_1': 0.9306507182943651, 'beta_2': 0.987644225004733, 'epsilon': 6.789483102769979e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.00014178846122556122, 'tol': 0.053033299088684524, 'validation_fraction': 0.14089685117330086}
observation time 0.000002, current best -0.916484 at iter 16
suggestion time taken 0.003672 iter 17 next_points [{'alpha': 0.010860586813814998, 'batch_size': 157, 'beta_1': 0.7289886681660219, 'beta_2': 0.9989085395841174, 'epsilon': 1.4681445832088693e-09, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.005565604867215278, 'tol': 0.006552840410520744, 'validation_fraction': 0.2873486824548362}]
function_evaluation time 0.616124 value -0.903297 suggestion {'alpha': 0.010860586813814998, 'batch_size': 157, 'beta_1': 0.7289886681660219, 'beta_2': 0.9989085395841174, 'epsilon': 1.4681445832088693e-09, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.005565604867215278, 'tol': 0.006552840410520744, 'validation_fraction': 0.2873486824548362}
observation time 0.000001, current best -0.916484 at iter 17
suggestion time taken 0.001650 iter 18 next_points [{'alpha': 1.3917932997918279, 'batch_size': 90, 'beta_1': 0.8949127586724477, 'beta_2': 0.999649812056115, 'epsilon': 1.78852056814153e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.00010214258431231823, 'tol': 2.288747073747405e-05, 'validation_fraction': 0.40085830685005935}]
function_evaluation time 0.255485 value -0.626374 suggestion {'alpha': 1.3917932997918279, 'batch_size': 90, 'beta_1': 0.8949127586724477, 'beta_2': 0.999649812056115, 'epsilon': 1.78852056814153e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.00010214258431231823, 'tol': 2.288747073747405e-05, 'validation_fraction': 0.40085830685005935}
observation time 0.000001, current best -0.916484 at iter 18
suggestion time taken 0.001639 iter 19 next_points [{'alpha': 0.00013272445781531991, 'batch_size': 49, 'beta_1': 0.9193456224115913, 'beta_2': 0.9999980383454311, 'epsilon': 1.4391439255151395e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.00018636288430995561, 'tol': 0.00034485518377237197, 'validation_fraction': 0.42669574940818655}]
function_evaluation time 0.651581 value -0.846154 suggestion {'alpha': 0.00013272445781531991, 'batch_size': 49, 'beta_1': 0.9193456224115913, 'beta_2': 0.9999980383454311, 'epsilon': 1.4391439255151395e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.00018636288430995561, 'tol': 0.00034485518377237197, 'validation_fraction': 0.42669574940818655}
observation time 0.000002, current best -0.916484 at iter 19
suggestion time taken 0.002221 iter 20 next_points [{'alpha': 0.0002782379576789466, 'batch_size': 19, 'beta_1': 0.9779273031728585, 'beta_2': 0.9999974570400566, 'epsilon': 2.1022947790007612e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0014918354897449082, 'tol': 0.0641337014768682, 'validation_fraction': 0.8978719622423597}]
function_evaluation time 0.224267 value -0.846154 suggestion {'alpha': 0.0002782379576789466, 'batch_size': 19, 'beta_1': 0.9779273031728585, 'beta_2': 0.9999974570400566, 'epsilon': 2.1022947790007612e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0014918354897449082, 'tol': 0.0641337014768682, 'validation_fraction': 0.8978719622423597}
observation time 0.000001, current best -0.916484 at iter 20
suggestion time taken 0.001638 iter 21 next_points [{'alpha': 0.009121886581479126, 'batch_size': 113, 'beta_1': 0.9401857783181289, 'beta_2': 0.9784827026116861, 'epsilon': 1.5955965377059626e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 1.5231190361886561e-05, 'tol': 0.0011592313645772498, 'validation_fraction': 0.4451780381971749}]
function_evaluation time 0.210951 value -0.417582 suggestion {'alpha': 0.009121886581479126, 'batch_size': 113, 'beta_1': 0.9401857783181289, 'beta_2': 0.9784827026116861, 'epsilon': 1.5955965377059626e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 1.5231190361886561e-05, 'tol': 0.0011592313645772498, 'validation_fraction': 0.4451780381971749}
observation time 0.000001, current best -0.916484 at iter 21
suggestion time taken 0.001772 iter 22 next_points [{'alpha': 0.0002675059545159937, 'batch_size': 106, 'beta_1': 0.6706446911979158, 'beta_2': 0.9580795838139629, 'epsilon': 1.013857527235818e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.039006001113014284, 'tol': 0.08024201391287551, 'validation_fraction': 0.5471987308810004}]
function_evaluation time 0.226668 value -0.894505 suggestion {'alpha': 0.0002675059545159937, 'batch_size': 106, 'beta_1': 0.6706446911979158, 'beta_2': 0.9580795838139629, 'epsilon': 1.013857527235818e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.039006001113014284, 'tol': 0.08024201391287551, 'validation_fraction': 0.5471987308810004}
observation time 0.000002, current best -0.916484 at iter 22
suggestion time taken 0.002901 iter 23 next_points [{'alpha': 0.002000087987845249, 'batch_size': 195, 'beta_1': 0.972576530374843, 'beta_2': 0.9999634142155329, 'epsilon': 8.891674859712441e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.00012946283286516827, 'tol': 2.9279098705184666e-05, 'validation_fraction': 0.8570433227739295}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.091879 value -0.582418 suggestion {'alpha': 0.002000087987845249, 'batch_size': 195, 'beta_1': 0.972576530374843, 'beta_2': 0.9999634142155329, 'epsilon': 8.891674859712441e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.00012946283286516827, 'tol': 2.9279098705184666e-05, 'validation_fraction': 0.8570433227739295}
observation time 0.000002, current best -0.916484 at iter 23
suggestion time taken 0.004995 iter 24 next_points [{'alpha': 0.06764451385901965, 'batch_size': 125, 'beta_1': 0.9756467895020893, 'beta_2': 0.9992552986602002, 'epsilon': 1.1177228455774982e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 5.147968542542221e-05, 'tol': 2.1041284424341837e-05, 'validation_fraction': 0.8064675450288422}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.137241 value -0.573626 suggestion {'alpha': 0.06764451385901965, 'batch_size': 125, 'beta_1': 0.9756467895020893, 'beta_2': 0.9992552986602002, 'epsilon': 1.1177228455774982e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 5.147968542542221e-05, 'tol': 2.1041284424341837e-05, 'validation_fraction': 0.8064675450288422}
observation time 0.000001, current best -0.916484 at iter 24
suggestion time taken 0.001627 iter 25 next_points [{'alpha': 2.5264600956749073, 'batch_size': 105, 'beta_1': 0.8868306648672712, 'beta_2': 0.9578987963310005, 'epsilon': 1.3950385506511995e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0008108666909737568, 'tol': 0.0046456765615623405, 'validation_fraction': 0.6899749050637285}]
function_evaluation time 0.327933 value -0.909890 suggestion {'alpha': 2.5264600956749073, 'batch_size': 105, 'beta_1': 0.8868306648672712, 'beta_2': 0.9578987963310005, 'epsilon': 1.3950385506511995e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0008108666909737568, 'tol': 0.0046456765615623405, 'validation_fraction': 0.6899749050637285}
observation time 0.000002, current best -0.916484 at iter 25
suggestion time taken 0.004781 iter 26 next_points [{'alpha': 0.9815921922677258, 'batch_size': 214, 'beta_1': 0.5819274792399022, 'beta_2': 0.9999776372717977, 'epsilon': 2.722763502362879e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 6.878673751275376e-05, 'tol': 0.0001096037673564698, 'validation_fraction': 0.23624016214408072}]
function_evaluation time 0.168471 value -0.562637 suggestion {'alpha': 0.9815921922677258, 'batch_size': 214, 'beta_1': 0.5819274792399022, 'beta_2': 0.9999776372717977, 'epsilon': 2.722763502362879e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 6.878673751275376e-05, 'tol': 0.0001096037673564698, 'validation_fraction': 0.23624016214408072}
observation time 0.000001, current best -0.916484 at iter 26
suggestion time taken 0.001647 iter 27 next_points [{'alpha': 2.762885861922793e-05, 'batch_size': 122, 'beta_1': 0.9322596484101794, 'beta_2': 0.9956762125701488, 'epsilon': 2.0860395145139072e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.0009848234916403503, 'tol': 1.4343471503285457e-05, 'validation_fraction': 0.325193074264651}]
function_evaluation time 0.209377 value -0.729670 suggestion {'alpha': 2.762885861922793e-05, 'batch_size': 122, 'beta_1': 0.9322596484101794, 'beta_2': 0.9956762125701488, 'epsilon': 2.0860395145139072e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.0009848234916403503, 'tol': 1.4343471503285457e-05, 'validation_fraction': 0.325193074264651}
observation time 0.000001, current best -0.916484 at iter 27
suggestion time taken 0.001643 iter 28 next_points [{'alpha': 0.001554127729545403, 'batch_size': 151, 'beta_1': 0.9271252914273727, 'beta_2': 0.9999977638524508, 'epsilon': 1.7971571532192564e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.00011853812745645596, 'tol': 0.003979893236581199, 'validation_fraction': 0.34292305885606317}]
function_evaluation time 0.533970 value -0.714286 suggestion {'alpha': 0.001554127729545403, 'batch_size': 151, 'beta_1': 0.9271252914273727, 'beta_2': 0.9999977638524508, 'epsilon': 1.7971571532192564e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.00011853812745645596, 'tol': 0.003979893236581199, 'validation_fraction': 0.34292305885606317}
observation time 0.000001, current best -0.916484 at iter 28
suggestion time taken 0.001636 iter 29 next_points [{'alpha': 0.05385160809195608, 'batch_size': 99, 'beta_1': 0.6980452748984054, 'beta_2': 0.9999969802883659, 'epsilon': 1.1566093933529696e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.002359343708327138, 'tol': 0.001826153494235389, 'validation_fraction': 0.8471959906276598}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.327261 value -0.914286 suggestion {'alpha': 0.05385160809195608, 'batch_size': 99, 'beta_1': 0.6980452748984054, 'beta_2': 0.9999969802883659, 'epsilon': 1.1566093933529696e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.002359343708327138, 'tol': 0.001826153494235389, 'validation_fraction': 0.8471959906276598}
observation time 0.000001, current best -0.916484 at iter 29
suggestion time taken 0.001645 iter 30 next_points [{'alpha': 4.477690317307117, 'batch_size': 25, 'beta_1': 0.972358064642151, 'beta_2': 0.9995919298977868, 'epsilon': 1.8949688119508617e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.0005210321460993181, 'tol': 0.00040946884149449796, 'validation_fraction': 0.8163679352571672}]
function_evaluation time 0.565708 value -0.909890 suggestion {'alpha': 4.477690317307117, 'batch_size': 25, 'beta_1': 0.972358064642151, 'beta_2': 0.9995919298977868, 'epsilon': 1.8949688119508617e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.0005210321460993181, 'tol': 0.00040946884149449796, 'validation_fraction': 0.8163679352571672}
observation time 0.000002, current best -0.916484 at iter 30
suggestion time taken 0.003332 iter 31 next_points [{'alpha': 0.0002492997687334057, 'batch_size': 82, 'beta_1': 0.5772392130586194, 'beta_2': 0.9385310542505004, 'epsilon': 3.1780774603186677e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 1.2633107040178175e-05, 'tol': 0.0007464213023609394, 'validation_fraction': 0.10641513774500669}]
function_evaluation time 0.116023 value -0.527473 suggestion {'alpha': 0.0002492997687334057, 'batch_size': 82, 'beta_1': 0.5772392130586194, 'beta_2': 0.9385310542505004, 'epsilon': 3.1780774603186677e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 1.2633107040178175e-05, 'tol': 0.0007464213023609394, 'validation_fraction': 0.10641513774500669}
observation time 0.000001, current best -0.916484 at iter 31
suggestion time taken 0.007738 iter 32 next_points [{'alpha': 0.001339880762147014, 'batch_size': 147, 'beta_1': 0.9807638695899777, 'beta_2': 0.99887213502411, 'epsilon': 2.5519637849629074e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.00021544408439927632, 'tol': 0.00040244949388161354, 'validation_fraction': 0.4239604900582236}]
function_evaluation time 0.209339 value -0.692308 suggestion {'alpha': 0.001339880762147014, 'batch_size': 147, 'beta_1': 0.9807638695899777, 'beta_2': 0.99887213502411, 'epsilon': 2.5519637849629074e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.00021544408439927632, 'tol': 0.00040244949388161354, 'validation_fraction': 0.4239604900582236}
observation time 0.000002, current best -0.916484 at iter 32
suggestion time taken 0.001631 iter 33 next_points [{'alpha': 7.975209776829285, 'batch_size': 204, 'beta_1': 0.928173637978847, 'beta_2': 0.9966252859575778, 'epsilon': 1.7815033003371835e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.006757378234308486, 'tol': 0.03689459687009224, 'validation_fraction': 0.2697724055958825}]
function_evaluation time 0.265077 value -0.916484 suggestion {'alpha': 7.975209776829285, 'batch_size': 204, 'beta_1': 0.928173637978847, 'beta_2': 0.9966252859575778, 'epsilon': 1.7815033003371835e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.006757378234308486, 'tol': 0.03689459687009224, 'validation_fraction': 0.2697724055958825}
observation time 0.000001, current best -0.916484 at iter 33
suggestion time taken 0.001632 iter 34 next_points [{'alpha': 0.00508476398537191, 'batch_size': 245, 'beta_1': 0.944187932895766, 'beta_2': 0.9999954134345843, 'epsilon': 2.1649773727151506e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0016750691605143025, 'tol': 0.00017647033155549882, 'validation_fraction': 0.440804089342564}]
function_evaluation time 0.164198 value -0.747253 suggestion {'alpha': 0.00508476398537191, 'batch_size': 245, 'beta_1': 0.944187932895766, 'beta_2': 0.9999954134345843, 'epsilon': 2.1649773727151506e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0016750691605143025, 'tol': 0.00017647033155549882, 'validation_fraction': 0.440804089342564}
observation time 0.000001, current best -0.916484 at iter 34
suggestion time taken 0.006312 iter 35 next_points [{'alpha': 2.5466131153426383e-05, 'batch_size': 166, 'beta_1': 0.9146659788655861, 'beta_2': 0.9999931574639987, 'epsilon': 1.004099971380139e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0009015984320905883, 'tol': 9.168455073486128e-05, 'validation_fraction': 0.3116068195422354}]
function_evaluation time 0.472915 value -0.885714 suggestion {'alpha': 2.5466131153426383e-05, 'batch_size': 166, 'beta_1': 0.9146659788655861, 'beta_2': 0.9999931574639987, 'epsilon': 1.004099971380139e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0009015984320905883, 'tol': 9.168455073486128e-05, 'validation_fraction': 0.3116068195422354}
observation time 0.000001, current best -0.916484 at iter 35
suggestion time taken 0.001624 iter 36 next_points [{'alpha': 0.0022633887502324923, 'batch_size': 134, 'beta_1': 0.6610022664865128, 'beta_2': 0.9999866371270802, 'epsilon': 7.558421899183056e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.007666417362012013, 'tol': 4.4143010493953695e-05, 'validation_fraction': 0.767350194899569}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.338713 value -0.907692 suggestion {'alpha': 0.0022633887502324923, 'batch_size': 134, 'beta_1': 0.6610022664865128, 'beta_2': 0.9999866371270802, 'epsilon': 7.558421899183056e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.007666417362012013, 'tol': 4.4143010493953695e-05, 'validation_fraction': 0.767350194899569}
observation time 0.000001, current best -0.916484 at iter 36
suggestion time taken 0.001503 iter 37 next_points [{'alpha': 0.0006420607257830652, 'batch_size': 181, 'beta_1': 0.962227452865725, 'beta_2': 0.9297626018395935, 'epsilon': 3.4818461600598465e-08, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.000570673055151875, 'tol': 0.0002123706725965505, 'validation_fraction': 0.25851601200030766}]
function_evaluation time 0.418522 value -0.742857 suggestion {'alpha': 0.0006420607257830652, 'batch_size': 181, 'beta_1': 0.962227452865725, 'beta_2': 0.9297626018395935, 'epsilon': 3.4818461600598465e-08, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.000570673055151875, 'tol': 0.0002123706725965505, 'validation_fraction': 0.25851601200030766}
observation time 0.000001, current best -0.916484 at iter 37
suggestion time taken 0.001650 iter 38 next_points [{'alpha': 0.13446564183969367, 'batch_size': 181, 'beta_1': 0.6605940469506693, 'beta_2': 0.9999688920731871, 'epsilon': 5.747571060263583e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.021646437876513863, 'tol': 0.002455574827391823, 'validation_fraction': 0.841683687398109}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.175844 value -0.909890 suggestion {'alpha': 0.13446564183969367, 'batch_size': 181, 'beta_1': 0.6605940469506693, 'beta_2': 0.9999688920731871, 'epsilon': 5.747571060263583e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.021646437876513863, 'tol': 0.002455574827391823, 'validation_fraction': 0.841683687398109}
observation time 0.000000, current best -0.916484 at iter 38
suggestion time taken 0.001620 iter 39 next_points [{'alpha': 0.005690836702861546, 'batch_size': 95, 'beta_1': 0.656573793803795, 'beta_2': 0.9501942923623183, 'epsilon': 2.8059023822393862e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.0003953297237084037, 'tol': 0.00757830559052678, 'validation_fraction': 0.2756218235856827}]
function_evaluation time 0.665549 value -0.892308 suggestion {'alpha': 0.005690836702861546, 'batch_size': 95, 'beta_1': 0.656573793803795, 'beta_2': 0.9501942923623183, 'epsilon': 2.8059023822393862e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.0003953297237084037, 'tol': 0.00757830559052678, 'validation_fraction': 0.2756218235856827}
observation time 0.000001, current best -0.916484 at iter 39
suggestion time taken 0.001661 iter 40 next_points [{'alpha': 1.7424111946215783, 'batch_size': 161, 'beta_1': 0.9347188979096356, 'beta_2': 0.9999558650439867, 'epsilon': 3.052879281956414e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.00692052052224875, 'tol': 0.06766063125986352, 'validation_fraction': 0.8929299958683891}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.220910 value -0.890110 suggestion {'alpha': 1.7424111946215783, 'batch_size': 161, 'beta_1': 0.9347188979096356, 'beta_2': 0.9999558650439867, 'epsilon': 3.052879281956414e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.00692052052224875, 'tol': 0.06766063125986352, 'validation_fraction': 0.8929299958683891}
observation time 0.000001, current best -0.916484 at iter 40
suggestion time taken 0.001510 iter 41 next_points [{'alpha': 0.0002950336549447096, 'batch_size': 201, 'beta_1': 0.9742113452121304, 'beta_2': 0.9999982951663166, 'epsilon': 3.8020883303605654e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 1.5703457468320497e-05, 'tol': 0.000239555314788422, 'validation_fraction': 0.26118204040736215}]
function_evaluation time 0.182297 value -0.472527 suggestion {'alpha': 0.0002950336549447096, 'batch_size': 201, 'beta_1': 0.9742113452121304, 'beta_2': 0.9999982951663166, 'epsilon': 3.8020883303605654e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 1.5703457468320497e-05, 'tol': 0.000239555314788422, 'validation_fraction': 0.26118204040736215}
observation time 0.000001, current best -0.916484 at iter 41
suggestion time taken 0.001647 iter 42 next_points [{'alpha': 0.8771858123450061, 'batch_size': 70, 'beta_1': 0.8690081183631887, 'beta_2': 0.9979774568867681, 'epsilon': 4.1950413831620645e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 3.17618933133447e-05, 'tol': 0.07803056924341419, 'validation_fraction': 0.818323824459788}]
function_evaluation time 0.137891 value -0.378022 suggestion {'alpha': 0.8771858123450061, 'batch_size': 70, 'beta_1': 0.8690081183631887, 'beta_2': 0.9979774568867681, 'epsilon': 4.1950413831620645e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 3.17618933133447e-05, 'tol': 0.07803056924341419, 'validation_fraction': 0.818323824459788}
observation time 0.000001, current best -0.916484 at iter 42
suggestion time taken 0.001635 iter 43 next_points [{'alpha': 0.1647825183989149, 'batch_size': 14, 'beta_1': 0.9698470837896137, 'beta_2': 0.9987184744570936, 'epsilon': 8.238696366754607e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.006319679787891121, 'tol': 0.00035078169180381344, 'validation_fraction': 0.7134623574583931}]
function_evaluation time 0.534112 value -0.905495 suggestion {'alpha': 0.1647825183989149, 'batch_size': 14, 'beta_1': 0.9698470837896137, 'beta_2': 0.9987184744570936, 'epsilon': 8.238696366754607e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.006319679787891121, 'tol': 0.00035078169180381344, 'validation_fraction': 0.7134623574583931}
observation time 0.000001, current best -0.916484 at iter 43
suggestion time taken 0.001643 iter 44 next_points [{'alpha': 1.3479742048478662, 'batch_size': 112, 'beta_1': 0.7664885054692474, 'beta_2': 0.9999561264019985, 'epsilon': 1.7839783389396504e-08, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.000329524479477328, 'tol': 0.0007705219268285777, 'validation_fraction': 0.6655013604137819}]
function_evaluation time 0.449353 value -0.698901 suggestion {'alpha': 1.3479742048478662, 'batch_size': 112, 'beta_1': 0.7664885054692474, 'beta_2': 0.9999561264019985, 'epsilon': 1.7839783389396504e-08, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.000329524479477328, 'tol': 0.0007705219268285777, 'validation_fraction': 0.6655013604137819}
observation time 0.000001, current best -0.916484 at iter 44
saving meta data: {'args': {'--uuid': 'bd0a3daad88053e8a9b1d89c7a7751e8', '-db-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230815_214848', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

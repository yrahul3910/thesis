running: {'--uuid': '6ce4309bef745bc5b89cd6afba21cfe1', '-db-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230815_214848', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random/optimizer.py -c MLP-adam -d breast -o random -u 6ce4309bef745bc5b89cd6afba21cfe1 -m acc -n 45 -p 1 -dir /Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20230815_214848
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/Users/ryedida/miniforge3/lib/python3.9/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 45 1
with data root: None
suggestion time taken 0.005845 iter 0 next_points [{'alpha': 0.002050506933199817, 'batch_size': 243, 'beta_1': 0.9808527834834402, 'beta_2': 0.9999388332301973, 'epsilon': 6.4210031754604665e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.045212501369529354, 'tol': 0.00015044957395691393, 'validation_fraction': 0.5442369178285}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.315516 value -0.901099 suggestion {'alpha': 0.002050506933199817, 'batch_size': 243, 'beta_1': 0.9808527834834402, 'beta_2': 0.9999388332301973, 'epsilon': 6.4210031754604665e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.045212501369529354, 'tol': 0.00015044957395691393, 'validation_fraction': 0.5442369178285}
observation time 0.000001, current best -0.901099 at iter 0
suggestion time taken 0.001656 iter 1 next_points [{'alpha': 0.1621595249789441, 'batch_size': 36, 'beta_1': 0.9591723916979376, 'beta_2': 0.9932331107939707, 'epsilon': 1.4048688458233436e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 1.0223921672587934e-05, 'tol': 0.011510905910378458, 'validation_fraction': 0.7991063323613367}]
function_evaluation time 0.177189 value -0.597802 suggestion {'alpha': 0.1621595249789441, 'batch_size': 36, 'beta_1': 0.9591723916979376, 'beta_2': 0.9932331107939707, 'epsilon': 1.4048688458233436e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 1.0223921672587934e-05, 'tol': 0.011510905910378458, 'validation_fraction': 0.7991063323613367}
observation time 0.000001, current best -0.901099 at iter 1
suggestion time taken 0.001638 iter 2 next_points [{'alpha': 0.15771476678394966, 'batch_size': 123, 'beta_1': 0.5991201502082739, 'beta_2': 0.9999955880648962, 'epsilon': 6.833937753144009e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 1.8763684941634165e-05, 'tol': 3.1608548972603344e-05, 'validation_fraction': 0.1890439127902026}]
function_evaluation time 0.333668 value -0.582418 suggestion {'alpha': 0.15771476678394966, 'batch_size': 123, 'beta_1': 0.5991201502082739, 'beta_2': 0.9999955880648962, 'epsilon': 6.833937753144009e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 1.8763684941634165e-05, 'tol': 3.1608548972603344e-05, 'validation_fraction': 0.1890439127902026}
observation time 0.000001, current best -0.901099 at iter 2
suggestion time taken 0.001648 iter 3 next_points [{'alpha': 4.250629229029017e-05, 'batch_size': 93, 'beta_1': 0.9754665950500908, 'beta_2': 0.9772981429763884, 'epsilon': 5.509457641538946e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.0008739617463342659, 'tol': 0.00014435425238393067, 'validation_fraction': 0.39505511390096776}]
function_evaluation time 0.542142 value -0.854945 suggestion {'alpha': 4.250629229029017e-05, 'batch_size': 93, 'beta_1': 0.9754665950500908, 'beta_2': 0.9772981429763884, 'epsilon': 5.509457641538946e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.0008739617463342659, 'tol': 0.00014435425238393067, 'validation_fraction': 0.39505511390096776}
observation time 0.000001, current best -0.901099 at iter 3
suggestion time taken 0.001666 iter 4 next_points [{'alpha': 4.930356905761372e-05, 'batch_size': 227, 'beta_1': 0.9875195644760689, 'beta_2': 0.9998971622704985, 'epsilon': 8.281247393024243e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.00025436428850360613, 'tol': 0.0015021101913723623, 'validation_fraction': 0.4374365269378543}]
function_evaluation time 0.285521 value -0.736264 suggestion {'alpha': 4.930356905761372e-05, 'batch_size': 227, 'beta_1': 0.9875195644760689, 'beta_2': 0.9998971622704985, 'epsilon': 8.281247393024243e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.00025436428850360613, 'tol': 0.0015021101913723623, 'validation_fraction': 0.4374365269378543}
observation time 0.000001, current best -0.901099 at iter 4
suggestion time taken 0.008253 iter 5 next_points [{'alpha': 0.03246551139219213, 'batch_size': 152, 'beta_1': 0.6436990612666658, 'beta_2': 0.9988266269647956, 'epsilon': 2.622327306204641e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 8.340370908364112e-05, 'tol': 6.72405439427141e-05, 'validation_fraction': 0.26003504299835595}]
function_evaluation time 0.626968 value -0.523077 suggestion {'alpha': 0.03246551139219213, 'batch_size': 152, 'beta_1': 0.6436990612666658, 'beta_2': 0.9988266269647956, 'epsilon': 2.622327306204641e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 8.340370908364112e-05, 'tol': 6.72405439427141e-05, 'validation_fraction': 0.26003504299835595}
observation time 0.000001, current best -0.901099 at iter 5
suggestion time taken 0.001630 iter 6 next_points [{'alpha': 6.512165713473901e-05, 'batch_size': 199, 'beta_1': 0.828566875464258, 'beta_2': 0.9684568873108622, 'epsilon': 2.8634786237879488e-08, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.00219884490038315, 'tol': 0.004240446580331598, 'validation_fraction': 0.8833806980444978}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.305129 value -0.903297 suggestion {'alpha': 6.512165713473901e-05, 'batch_size': 199, 'beta_1': 0.828566875464258, 'beta_2': 0.9684568873108622, 'epsilon': 2.8634786237879488e-08, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.00219884490038315, 'tol': 0.004240446580331598, 'validation_fraction': 0.8833806980444978}
observation time 0.000001, current best -0.903297 at iter 6
suggestion time taken 0.001755 iter 7 next_points [{'alpha': 0.11253350939352533, 'batch_size': 237, 'beta_1': 0.9893120096540811, 'beta_2': 0.9987015827200347, 'epsilon': 3.9788576260769135e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.0068063931917408185, 'tol': 0.05105048570456203, 'validation_fraction': 0.6655703548041958}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.237700 value -0.813187 suggestion {'alpha': 0.11253350939352533, 'batch_size': 237, 'beta_1': 0.9893120096540811, 'beta_2': 0.9987015827200347, 'epsilon': 3.9788576260769135e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.0068063931917408185, 'tol': 0.05105048570456203, 'validation_fraction': 0.6655703548041958}
observation time 0.000000, current best -0.903297 at iter 7
suggestion time taken 0.005929 iter 8 next_points [{'alpha': 3.79006555329885e-05, 'batch_size': 153, 'beta_1': 0.9332133480387828, 'beta_2': 0.9998249568167535, 'epsilon': 1.1560015876603976e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.01833866459500461, 'tol': 2.0763712529244883e-05, 'validation_fraction': 0.1119110672979297}]
function_evaluation time 0.333628 value -0.896703 suggestion {'alpha': 3.79006555329885e-05, 'batch_size': 153, 'beta_1': 0.9332133480387828, 'beta_2': 0.9998249568167535, 'epsilon': 1.1560015876603976e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.01833866459500461, 'tol': 2.0763712529244883e-05, 'validation_fraction': 0.1119110672979297}
observation time 0.000001, current best -0.903297 at iter 8
suggestion time taken 0.001770 iter 9 next_points [{'alpha': 0.011339952198762738, 'batch_size': 146, 'beta_1': 0.7416068956811483, 'beta_2': 0.9966644608673957, 'epsilon': 2.0815405906106393e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0020106048817581388, 'tol': 0.00028219153137102866, 'validation_fraction': 0.1018908057618573}]
function_evaluation time 0.497799 value -0.881319 suggestion {'alpha': 0.011339952198762738, 'batch_size': 146, 'beta_1': 0.7416068956811483, 'beta_2': 0.9966644608673957, 'epsilon': 2.0815405906106393e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0020106048817581388, 'tol': 0.00028219153137102866, 'validation_fraction': 0.1018908057618573}
observation time 0.000000, current best -0.903297 at iter 9
suggestion time taken 0.001758 iter 10 next_points [{'alpha': 2.681927178064283, 'batch_size': 217, 'beta_1': 0.9855721400214759, 'beta_2': 0.999515292732141, 'epsilon': 1.171480751868558e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0004216854531058473, 'tol': 0.0038810857944284, 'validation_fraction': 0.6052233591141217}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.216914 value -0.707692 suggestion {'alpha': 2.681927178064283, 'batch_size': 217, 'beta_1': 0.9855721400214759, 'beta_2': 0.999515292732141, 'epsilon': 1.171480751868558e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0004216854531058473, 'tol': 0.0038810857944284, 'validation_fraction': 0.6052233591141217}
observation time 0.000000, current best -0.903297 at iter 10
suggestion time taken 0.001664 iter 11 next_points [{'alpha': 2.793353733436722e-05, 'batch_size': 112, 'beta_1': 0.9096059156698472, 'beta_2': 0.9979680068363002, 'epsilon': 1.647167501402933e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.004195578557165444, 'tol': 0.0013420614944874192, 'validation_fraction': 0.8256384102727736}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.271320 value -0.810989 suggestion {'alpha': 2.793353733436722e-05, 'batch_size': 112, 'beta_1': 0.9096059156698472, 'beta_2': 0.9979680068363002, 'epsilon': 1.647167501402933e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.004195578557165444, 'tol': 0.0013420614944874192, 'validation_fraction': 0.8256384102727736}
observation time 0.000001, current best -0.903297 at iter 11
suggestion time taken 0.001787 iter 12 next_points [{'alpha': 0.06622059134937947, 'batch_size': 227, 'beta_1': 0.977609899205729, 'beta_2': 0.9999962637994582, 'epsilon': 1.0449039250015293e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0007967960024488522, 'tol': 0.007139445416103572, 'validation_fraction': 0.8652431306933938}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.196398 value -0.725275 suggestion {'alpha': 0.06622059134937947, 'batch_size': 227, 'beta_1': 0.977609899205729, 'beta_2': 0.9999962637994582, 'epsilon': 1.0449039250015293e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0007967960024488522, 'tol': 0.007139445416103572, 'validation_fraction': 0.8652431306933938}
observation time 0.000001, current best -0.903297 at iter 12
suggestion time taken 0.004760 iter 13 next_points [{'alpha': 0.3179888854251115, 'batch_size': 79, 'beta_1': 0.9624634000861554, 'beta_2': 0.9899551461722795, 'epsilon': 6.662797481594456e-09, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.004799220467680237, 'tol': 0.01770183584006726, 'validation_fraction': 0.8911224892132507}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.229893 value -0.800000 suggestion {'alpha': 0.3179888854251115, 'batch_size': 79, 'beta_1': 0.9624634000861554, 'beta_2': 0.9899551461722795, 'epsilon': 6.662797481594456e-09, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.004799220467680237, 'tol': 0.01770183584006726, 'validation_fraction': 0.8911224892132507}
observation time 0.000002, current best -0.903297 at iter 13
suggestion time taken 0.005953 iter 14 next_points [{'alpha': 0.0019506720856435576, 'batch_size': 188, 'beta_1': 0.9819673883169961, 'beta_2': 0.9408627259780683, 'epsilon': 4.255079369976231e-08, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.0001946770588093693, 'tol': 0.0007896203394629601, 'validation_fraction': 0.2670407468558682}]
function_evaluation time 0.525719 value -0.780220 suggestion {'alpha': 0.0019506720856435576, 'batch_size': 188, 'beta_1': 0.9819673883169961, 'beta_2': 0.9408627259780683, 'epsilon': 4.255079369976231e-08, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.0001946770588093693, 'tol': 0.0007896203394629601, 'validation_fraction': 0.2670407468558682}
observation time 0.000001, current best -0.903297 at iter 14
suggestion time taken 0.001763 iter 15 next_points [{'alpha': 0.02927730915058393, 'batch_size': 28, 'beta_1': 0.9880407539801297, 'beta_2': 0.9999980449646669, 'epsilon': 1.5552354989819902e-09, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.00011880742527176266, 'tol': 0.00012596128892376223, 'validation_fraction': 0.7106195435503464}]
function_evaluation time 0.374398 value -0.718681 suggestion {'alpha': 0.02927730915058393, 'batch_size': 28, 'beta_1': 0.9880407539801297, 'beta_2': 0.9999980449646669, 'epsilon': 1.5552354989819902e-09, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.00011880742527176266, 'tol': 0.00012596128892376223, 'validation_fraction': 0.7106195435503464}
observation time 0.000001, current best -0.903297 at iter 15
suggestion time taken 0.001793 iter 16 next_points [{'alpha': 4.2490403860356505, 'batch_size': 106, 'beta_1': 0.8601842964113596, 'beta_2': 0.9425594010712621, 'epsilon': 8.15645120984063e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 1.0243099429393802e-05, 'tol': 0.027484602643793505, 'validation_fraction': 0.8731128201770879}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.165658 value -0.417582 suggestion {'alpha': 4.2490403860356505, 'batch_size': 106, 'beta_1': 0.8601842964113596, 'beta_2': 0.9425594010712621, 'epsilon': 8.15645120984063e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 1.0243099429393802e-05, 'tol': 0.027484602643793505, 'validation_fraction': 0.8731128201770879}
observation time 0.000001, current best -0.903297 at iter 16
suggestion time taken 0.001769 iter 17 next_points [{'alpha': 2.2788458881510327, 'batch_size': 190, 'beta_1': 0.9608843062359625, 'beta_2': 0.9999856650397985, 'epsilon': 1.6600384359033288e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0005335726286957242, 'tol': 0.0003751396825132884, 'validation_fraction': 0.5260157268779228}]
function_evaluation time 0.304716 value -0.648352 suggestion {'alpha': 2.2788458881510327, 'batch_size': 190, 'beta_1': 0.9608843062359625, 'beta_2': 0.9999856650397985, 'epsilon': 1.6600384359033288e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0005335726286957242, 'tol': 0.0003751396825132884, 'validation_fraction': 0.5260157268779228}
observation time 0.000002, current best -0.903297 at iter 17
suggestion time taken 0.005245 iter 18 next_points [{'alpha': 0.0002238856391796657, 'batch_size': 241, 'beta_1': 0.6925089287759606, 'beta_2': 0.9426517462504549, 'epsilon': 3.6381038543659264e-07, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.001629778459235724, 'tol': 0.0004887924224073282, 'validation_fraction': 0.3066036516124968}]
function_evaluation time 0.424710 value -0.892308 suggestion {'alpha': 0.0002238856391796657, 'batch_size': 241, 'beta_1': 0.6925089287759606, 'beta_2': 0.9426517462504549, 'epsilon': 3.6381038543659264e-07, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.001629778459235724, 'tol': 0.0004887924224073282, 'validation_fraction': 0.3066036516124968}
observation time 0.000001, current best -0.903297 at iter 18
suggestion time taken 0.001768 iter 19 next_points [{'alpha': 0.0030922552052280628, 'batch_size': 198, 'beta_1': 0.5451934934698449, 'beta_2': 0.9169607483892416, 'epsilon': 1.8352915192938867e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.05005775811924255, 'tol': 0.0030290188909237953, 'validation_fraction': 0.15087974012980968}]
function_evaluation time 0.344979 value -0.896703 suggestion {'alpha': 0.0030922552052280628, 'batch_size': 198, 'beta_1': 0.5451934934698449, 'beta_2': 0.9169607483892416, 'epsilon': 1.8352915192938867e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.05005775811924255, 'tol': 0.0030290188909237953, 'validation_fraction': 0.15087974012980968}
observation time 0.000001, current best -0.903297 at iter 19
suggestion time taken 0.001781 iter 20 next_points [{'alpha': 0.6564540143795237, 'batch_size': 211, 'beta_1': 0.9449375606379309, 'beta_2': 0.9571109560032782, 'epsilon': 2.7678734222817066e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.05566462872127519, 'tol': 0.06839006943863533, 'validation_fraction': 0.30900184257783425}]
function_evaluation time 0.278070 value -0.848352 suggestion {'alpha': 0.6564540143795237, 'batch_size': 211, 'beta_1': 0.9449375606379309, 'beta_2': 0.9571109560032782, 'epsilon': 2.7678734222817066e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.05566462872127519, 'tol': 0.06839006943863533, 'validation_fraction': 0.30900184257783425}
observation time 0.000002, current best -0.903297 at iter 20
suggestion time taken 0.002358 iter 21 next_points [{'alpha': 0.3162244967157089, 'batch_size': 174, 'beta_1': 0.8698800898437444, 'beta_2': 0.9999847109753943, 'epsilon': 3.989072583335269e-08, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.02097123872603035, 'tol': 0.02505634118923898, 'validation_fraction': 0.2358886059260622}]
function_evaluation time 0.357897 value -0.896703 suggestion {'alpha': 0.3162244967157089, 'batch_size': 174, 'beta_1': 0.8698800898437444, 'beta_2': 0.9999847109753943, 'epsilon': 3.989072583335269e-08, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.02097123872603035, 'tol': 0.02505634118923898, 'validation_fraction': 0.2358886059260622}
observation time 0.000001, current best -0.903297 at iter 21
suggestion time taken 0.001615 iter 22 next_points [{'alpha': 0.0003384677676740496, 'batch_size': 82, 'beta_1': 0.9720615146868888, 'beta_2': 0.9999986118265259, 'epsilon': 1.3422705646940514e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.0005277437872489879, 'tol': 0.032914414169689814, 'validation_fraction': 0.12352118709134476}]
function_evaluation time 0.210187 value -0.894505 suggestion {'alpha': 0.0003384677676740496, 'batch_size': 82, 'beta_1': 0.9720615146868888, 'beta_2': 0.9999986118265259, 'epsilon': 1.3422705646940514e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.0005277437872489879, 'tol': 0.032914414169689814, 'validation_fraction': 0.12352118709134476}
observation time 0.000001, current best -0.903297 at iter 22
suggestion time taken 0.006358 iter 23 next_points [{'alpha': 0.0010902145976016645, 'batch_size': 166, 'beta_1': 0.9204268810146523, 'beta_2': 0.9993773230258579, 'epsilon': 4.7544121781300747e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.011900023271807064, 'tol': 0.0013050881484586894, 'validation_fraction': 0.3613291153173052}]
function_evaluation time 0.309877 value -0.903297 suggestion {'alpha': 0.0010902145976016645, 'batch_size': 166, 'beta_1': 0.9204268810146523, 'beta_2': 0.9993773230258579, 'epsilon': 4.7544121781300747e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.011900023271807064, 'tol': 0.0013050881484586894, 'validation_fraction': 0.3613291153173052}
observation time 0.000001, current best -0.903297 at iter 23
suggestion time taken 0.001769 iter 24 next_points [{'alpha': 0.004654863366743712, 'batch_size': 19, 'beta_1': 0.9267814360207238, 'beta_2': 0.9886177986439264, 'epsilon': 1.136739858315195e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.00037620455953202205, 'tol': 1.8141624101202505e-05, 'validation_fraction': 0.13874098838683982}]
function_evaluation time 0.519349 value -0.901099 suggestion {'alpha': 0.004654863366743712, 'batch_size': 19, 'beta_1': 0.9267814360207238, 'beta_2': 0.9886177986439264, 'epsilon': 1.136739858315195e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.00037620455953202205, 'tol': 1.8141624101202505e-05, 'validation_fraction': 0.13874098838683982}
observation time 0.000001, current best -0.903297 at iter 24
suggestion time taken 0.001627 iter 25 next_points [{'alpha': 0.0019078802448794759, 'batch_size': 45, 'beta_1': 0.727566813102153, 'beta_2': 0.9999809243131977, 'epsilon': 3.14065201570321e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.00010624840701363341, 'tol': 0.006283104746557889, 'validation_fraction': 0.5000183304575314}]
function_evaluation time 0.367825 value -0.786813 suggestion {'alpha': 0.0019078802448794759, 'batch_size': 45, 'beta_1': 0.727566813102153, 'beta_2': 0.9999809243131977, 'epsilon': 3.14065201570321e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.00010624840701363341, 'tol': 0.006283104746557889, 'validation_fraction': 0.5000183304575314}
observation time 0.000000, current best -0.903297 at iter 25
suggestion time taken 0.001771 iter 26 next_points [{'alpha': 0.009596631213467733, 'batch_size': 47, 'beta_1': 0.7248165891123212, 'beta_2': 0.9992997535301754, 'epsilon': 7.464136459312222e-07, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0008258935387918525, 'tol': 3.038719361688595e-05, 'validation_fraction': 0.8109318534102026}]
function_evaluation time 0.425046 value -0.909890 suggestion {'alpha': 0.009596631213467733, 'batch_size': 47, 'beta_1': 0.7248165891123212, 'beta_2': 0.9992997535301754, 'epsilon': 7.464136459312222e-07, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0008258935387918525, 'tol': 3.038719361688595e-05, 'validation_fraction': 0.8109318534102026}
observation time 0.000001, current best -0.909890 at iter 26
suggestion time taken 0.001796 iter 27 next_points [{'alpha': 3.2058121230761305, 'batch_size': 220, 'beta_1': 0.8876021421991409, 'beta_2': 0.9999987635658698, 'epsilon': 2.1515101317999356e-09, 'hidden_layer_sizes': 164, 'learning_rate_init': 8.324994555487046e-05, 'tol': 0.00015758254645836578, 'validation_fraction': 0.1404813896568853}]
function_evaluation time 0.428649 value -0.549451 suggestion {'alpha': 3.2058121230761305, 'batch_size': 220, 'beta_1': 0.8876021421991409, 'beta_2': 0.9999987635658698, 'epsilon': 2.1515101317999356e-09, 'hidden_layer_sizes': 164, 'learning_rate_init': 8.324994555487046e-05, 'tol': 0.00015758254645836578, 'validation_fraction': 0.1404813896568853}
observation time 0.000001, current best -0.909890 at iter 27
suggestion time taken 0.004806 iter 28 next_points [{'alpha': 3.696136765047782e-05, 'batch_size': 211, 'beta_1': 0.8486379571793965, 'beta_2': 0.9999329529996288, 'epsilon': 8.340084931394942e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 5.941230607151939e-05, 'tol': 0.0005053309900044365, 'validation_fraction': 0.3715365621823801}]
function_evaluation time 0.541354 value -0.516484 suggestion {'alpha': 3.696136765047782e-05, 'batch_size': 211, 'beta_1': 0.8486379571793965, 'beta_2': 0.9999329529996288, 'epsilon': 8.340084931394942e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 5.941230607151939e-05, 'tol': 0.0005053309900044365, 'validation_fraction': 0.3715365621823801}
observation time 0.000002, current best -0.909890 at iter 28
suggestion time taken 0.004797 iter 29 next_points [{'alpha': 0.027087406074366584, 'batch_size': 241, 'beta_1': 0.9890186279931409, 'beta_2': 0.999991954300703, 'epsilon': 6.0744157519712745e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 4.138962122637731e-05, 'tol': 0.00012814609068032413, 'validation_fraction': 0.41129178620540097}]
function_evaluation time 0.217074 value -0.516484 suggestion {'alpha': 0.027087406074366584, 'batch_size': 241, 'beta_1': 0.9890186279931409, 'beta_2': 0.999991954300703, 'epsilon': 6.0744157519712745e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 4.138962122637731e-05, 'tol': 0.00012814609068032413, 'validation_fraction': 0.41129178620540097}
observation time 0.000000, current best -0.909890 at iter 29
suggestion time taken 0.001613 iter 30 next_points [{'alpha': 4.634682041791869, 'batch_size': 185, 'beta_1': 0.864688485965946, 'beta_2': 0.9998957415793572, 'epsilon': 9.578055941587007e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 1.0472449652479206e-05, 'tol': 0.08798169061882716, 'validation_fraction': 0.8885710360226794}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.143020 value -0.417582 suggestion {'alpha': 4.634682041791869, 'batch_size': 185, 'beta_1': 0.864688485965946, 'beta_2': 0.9998957415793572, 'epsilon': 9.578055941587007e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 1.0472449652479206e-05, 'tol': 0.08798169061882716, 'validation_fraction': 0.8885710360226794}
observation time 0.000002, current best -0.909890 at iter 30
suggestion time taken 0.004148 iter 31 next_points [{'alpha': 0.3627780358375038, 'batch_size': 30, 'beta_1': 0.6323893067813521, 'beta_2': 0.9969474497944635, 'epsilon': 3.2794207234360814e-07, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.00021426507761119833, 'tol': 0.005043862296039332, 'validation_fraction': 0.8327556555931829}]
function_evaluation time 0.128974 value -0.470330 suggestion {'alpha': 0.3627780358375038, 'batch_size': 30, 'beta_1': 0.6323893067813521, 'beta_2': 0.9969474497944635, 'epsilon': 3.2794207234360814e-07, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.00021426507761119833, 'tol': 0.005043862296039332, 'validation_fraction': 0.8327556555931829}
observation time 0.000001, current best -0.909890 at iter 31
suggestion time taken 0.001619 iter 32 next_points [{'alpha': 2.935209592335127e-05, 'batch_size': 93, 'beta_1': 0.9099145754054598, 'beta_2': 0.9998432038793814, 'epsilon': 5.054439046756253e-09, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.0031815680395522647, 'tol': 1.2250891509306332e-05, 'validation_fraction': 0.10142064665935269}]
function_evaluation time 0.575939 value -0.892308 suggestion {'alpha': 2.935209592335127e-05, 'batch_size': 93, 'beta_1': 0.9099145754054598, 'beta_2': 0.9998432038793814, 'epsilon': 5.054439046756253e-09, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.0031815680395522647, 'tol': 1.2250891509306332e-05, 'validation_fraction': 0.10142064665935269}
observation time 0.000001, current best -0.909890 at iter 32
suggestion time taken 0.001617 iter 33 next_points [{'alpha': 0.002083727727293132, 'batch_size': 207, 'beta_1': 0.9866396635073622, 'beta_2': 0.9961920780586717, 'epsilon': 7.303775207858452e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.06443662819267883, 'tol': 0.010672670026115197, 'validation_fraction': 0.8958113368470052}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.191335 value -0.745055 suggestion {'alpha': 0.002083727727293132, 'batch_size': 207, 'beta_1': 0.9866396635073622, 'beta_2': 0.9961920780586717, 'epsilon': 7.303775207858452e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.06443662819267883, 'tol': 0.010672670026115197, 'validation_fraction': 0.8958113368470052}
observation time 0.000001, current best -0.909890 at iter 33
suggestion time taken 0.001762 iter 34 next_points [{'alpha': 2.600481831619083e-05, 'batch_size': 155, 'beta_1': 0.9712031888769773, 'beta_2': 0.9999976650258262, 'epsilon': 3.5253542962787125e-08, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00010857519663074382, 'tol': 0.0001355240989266857, 'validation_fraction': 0.210217763272531}]
function_evaluation time 0.387290 value -0.516484 suggestion {'alpha': 2.600481831619083e-05, 'batch_size': 155, 'beta_1': 0.9712031888769773, 'beta_2': 0.9999976650258262, 'epsilon': 3.5253542962787125e-08, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00010857519663074382, 'tol': 0.0001355240989266857, 'validation_fraction': 0.210217763272531}
observation time 0.000001, current best -0.909890 at iter 34
suggestion time taken 0.001665 iter 35 next_points [{'alpha': 6.995161074377037, 'batch_size': 95, 'beta_1': 0.9011663413224174, 'beta_2': 0.9999985414643532, 'epsilon': 8.053580387257423e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0004596668985766141, 'tol': 0.0016155803811329602, 'validation_fraction': 0.14294702945643048}]
function_evaluation time 0.290498 value -0.738462 suggestion {'alpha': 6.995161074377037, 'batch_size': 95, 'beta_1': 0.9011663413224174, 'beta_2': 0.9999985414643532, 'epsilon': 8.053580387257423e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0004596668985766141, 'tol': 0.0016155803811329602, 'validation_fraction': 0.14294702945643048}
observation time 0.000002, current best -0.909890 at iter 35
suggestion time taken 0.006728 iter 36 next_points [{'alpha': 0.003626026668558812, 'batch_size': 242, 'beta_1': 0.7557467261466023, 'beta_2': 0.9930619606807459, 'epsilon': 8.709004209223759e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.004943814175705401, 'tol': 0.004749830973037529, 'validation_fraction': 0.3346471861100104}]
function_evaluation time 0.576711 value -0.898901 suggestion {'alpha': 0.003626026668558812, 'batch_size': 242, 'beta_1': 0.7557467261466023, 'beta_2': 0.9930619606807459, 'epsilon': 8.709004209223759e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.004943814175705401, 'tol': 0.004749830973037529, 'validation_fraction': 0.3346471861100104}
observation time 0.000002, current best -0.909890 at iter 36
suggestion time taken 0.003860 iter 37 next_points [{'alpha': 2.756294824225268e-05, 'batch_size': 131, 'beta_1': 0.6591345928421216, 'beta_2': 0.9948898511853113, 'epsilon': 1.641462763505282e-07, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.011100379758787977, 'tol': 0.0003018559390639493, 'validation_fraction': 0.760201490361703}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.399879 value -0.898901 suggestion {'alpha': 2.756294824225268e-05, 'batch_size': 131, 'beta_1': 0.6591345928421216, 'beta_2': 0.9948898511853113, 'epsilon': 1.641462763505282e-07, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.011100379758787977, 'tol': 0.0003018559390639493, 'validation_fraction': 0.760201490361703}
observation time 0.000001, current best -0.909890 at iter 37
suggestion time taken 0.001639 iter 38 next_points [{'alpha': 1.84988698672892, 'batch_size': 108, 'beta_1': 0.9829648695069104, 'beta_2': 0.9641732312218402, 'epsilon': 7.212814768889024e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 3.058095391691617e-05, 'tol': 0.002622081671688307, 'validation_fraction': 0.5154636561127401}]
function_evaluation time 0.246202 value -0.417582 suggestion {'alpha': 1.84988698672892, 'batch_size': 108, 'beta_1': 0.9829648695069104, 'beta_2': 0.9641732312218402, 'epsilon': 7.212814768889024e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 3.058095391691617e-05, 'tol': 0.002622081671688307, 'validation_fraction': 0.5154636561127401}
observation time 0.000001, current best -0.909890 at iter 38
suggestion time taken 0.007163 iter 39 next_points [{'alpha': 3.9221241034602756, 'batch_size': 68, 'beta_1': 0.9789228156097964, 'beta_2': 0.999994008400261, 'epsilon': 3.453567649600074e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.01322967981134296, 'tol': 1.6007907619397022e-05, 'validation_fraction': 0.8561942554803725}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.661659 value -0.903297 suggestion {'alpha': 3.9221241034602756, 'batch_size': 68, 'beta_1': 0.9789228156097964, 'beta_2': 0.999994008400261, 'epsilon': 3.453567649600074e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.01322967981134296, 'tol': 1.6007907619397022e-05, 'validation_fraction': 0.8561942554803725}
observation time 0.000001, current best -0.909890 at iter 39
suggestion time taken 0.006226 iter 40 next_points [{'alpha': 0.0053681706734435486, 'batch_size': 104, 'beta_1': 0.6880852219252324, 'beta_2': 0.9999766172915338, 'epsilon': 1.0138545122307446e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 6.484093821856731e-05, 'tol': 0.003829992040152713, 'validation_fraction': 0.11384248230418165}]
function_evaluation time 0.583778 value -0.523077 suggestion {'alpha': 0.0053681706734435486, 'batch_size': 104, 'beta_1': 0.6880852219252324, 'beta_2': 0.9999766172915338, 'epsilon': 1.0138545122307446e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 6.484093821856731e-05, 'tol': 0.003829992040152713, 'validation_fraction': 0.11384248230418165}
observation time 0.000002, current best -0.909890 at iter 40
suggestion time taken 0.002596 iter 41 next_points [{'alpha': 2.434626179826976, 'batch_size': 223, 'beta_1': 0.9813469745011161, 'beta_2': 0.9997276579929563, 'epsilon': 5.631447767406763e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.0007103830036042086, 'tol': 0.0011397114264620647, 'validation_fraction': 0.16061963137891128}]
function_evaluation time 0.571380 value -0.821978 suggestion {'alpha': 2.434626179826976, 'batch_size': 223, 'beta_1': 0.9813469745011161, 'beta_2': 0.9997276579929563, 'epsilon': 5.631447767406763e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.0007103830036042086, 'tol': 0.0011397114264620647, 'validation_fraction': 0.16061963137891128}
observation time 0.000001, current best -0.909890 at iter 41
suggestion time taken 0.001627 iter 42 next_points [{'alpha': 0.0008836476854360254, 'batch_size': 164, 'beta_1': 0.9632593008789083, 'beta_2': 0.9992434791203971, 'epsilon': 7.354000625386342e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.058646823711885815, 'tol': 3.5706109767021624e-05, 'validation_fraction': 0.7085391675663913}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.250277 value -0.863736 suggestion {'alpha': 0.0008836476854360254, 'batch_size': 164, 'beta_1': 0.9632593008789083, 'beta_2': 0.9992434791203971, 'epsilon': 7.354000625386342e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.058646823711885815, 'tol': 3.5706109767021624e-05, 'validation_fraction': 0.7085391675663913}
observation time 0.000000, current best -0.909890 at iter 42
suggestion time taken 0.001722 iter 43 next_points [{'alpha': 0.005902828790538171, 'batch_size': 237, 'beta_1': 0.7318615632442727, 'beta_2': 0.9999551515272659, 'epsilon': 6.100570686405266e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0012132840506410957, 'tol': 0.015417181507924647, 'validation_fraction': 0.4553416629549792}]
function_evaluation time 0.305512 value -0.791209 suggestion {'alpha': 0.005902828790538171, 'batch_size': 237, 'beta_1': 0.7318615632442727, 'beta_2': 0.9999551515272659, 'epsilon': 6.100570686405266e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0012132840506410957, 'tol': 0.015417181507924647, 'validation_fraction': 0.4553416629549792}
observation time 0.000001, current best -0.909890 at iter 43
suggestion time taken 0.001615 iter 44 next_points [{'alpha': 0.014682527466586966, 'batch_size': 225, 'beta_1': 0.904529733243575, 'beta_2': 0.9911446406568184, 'epsilon': 6.85103992233098e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.091137617936423, 'tol': 5.533742135908075e-05, 'validation_fraction': 0.45626141811234133}]
function_evaluation time 0.278742 value -0.687912 suggestion {'alpha': 0.014682527466586966, 'batch_size': 225, 'beta_1': 0.904529733243575, 'beta_2': 0.9911446406568184, 'epsilon': 6.85103992233098e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.091137617936423, 'tol': 5.533742135908075e-05, 'validation_fraction': 0.45626141811234133}
observation time 0.000001, current best -0.909890 at iter 44
saving meta data: {'args': {'--uuid': '6ce4309bef745bc5b89cd6afba21cfe1', '-db-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230815_214848', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

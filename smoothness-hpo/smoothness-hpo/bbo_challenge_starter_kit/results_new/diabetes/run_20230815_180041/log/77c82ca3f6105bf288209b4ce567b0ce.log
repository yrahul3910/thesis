running: {'--uuid': '77c82ca3f6105bf288209b4ce567b0ce', '-db-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230815_180041', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d diabetes -o opentuner -u 77c82ca3f6105bf288209b4ce567b0ce -m mae -n 45 -p 1 -dir /Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20230815_180041
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
/Users/ryedida/miniforge3/lib/python3.9/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study opentuner MLP-adam diabetes mae 45 1
with data root: None
suggestion time taken 0.021542 iter 0 next_points [{'hidden_layer_sizes': 85, 'alpha': 8.50859544265573, 'batch_size': 123, 'learning_rate_init': 0.031119128722228263, 'tol': 0.05658510270010269, 'validation_fraction': 0.5770987157328047, 'beta_1': 0.6764293508040572, 'beta_2': 0.9145869391864201, 'epsilon': 8.78875876437173e-07}]
function_evaluation time 0.341374 value 90.424104 suggestion {'hidden_layer_sizes': 85, 'alpha': 8.50859544265573, 'batch_size': 123, 'learning_rate_init': 0.031119128722228263, 'tol': 0.05658510270010269, 'validation_fraction': 0.5770987157328047, 'beta_1': 0.6764293508040572, 'beta_2': 0.9145869391864201, 'epsilon': 8.78875876437173e-07}
observation time 0.002901, current best 90.424104 at iter 0
suggestion time taken 0.051125 iter 1 next_points [{'hidden_layer_sizes': 175, 'alpha': 0.3017386060812614, 'batch_size': 181, 'learning_rate_init': 0.0018180365115187292, 'tol': 0.003338816846442484, 'validation_fraction': 0.8831120593453624, 'beta_1': 0.8123815505497156, 'beta_2': 0.9067927803973982, 'epsilon': 8.384995511864679e-08}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.092600 value 151.285104 suggestion {'hidden_layer_sizes': 175, 'alpha': 0.3017386060812614, 'batch_size': 181, 'learning_rate_init': 0.0018180365115187292, 'tol': 0.003338816846442484, 'validation_fraction': 0.8831120593453624, 'beta_1': 0.8123815505497156, 'beta_2': 0.9067927803973982, 'epsilon': 8.384995511864679e-08}
observation time 0.002129, current best 90.424104 at iter 1
suggestion time taken 0.005204 iter 2 next_points [{'hidden_layer_sizes': 88, 'alpha': 8.50859544265573, 'batch_size': 123, 'learning_rate_init': 0.031119128722228263, 'tol': 0.057264498211465335, 'validation_fraction': 0.6700459782002386, 'beta_1': 0.6050643657382383, 'beta_2': 0.9145869391864201, 'epsilon': 8.78875876437173e-07}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.239613 value 72.837571 suggestion {'hidden_layer_sizes': 88, 'alpha': 8.50859544265573, 'batch_size': 123, 'learning_rate_init': 0.031119128722228263, 'tol': 0.057264498211465335, 'validation_fraction': 0.6700459782002386, 'beta_1': 0.6050643657382383, 'beta_2': 0.9145869391864201, 'epsilon': 8.78875876437173e-07}
observation time 0.001672, current best 72.837571 at iter 2
suggestion time taken 0.017033 iter 3 next_points [{'hidden_layer_sizes': 88, 'alpha': 1.3123101972110751, 'batch_size': 123, 'learning_rate_init': 0.031119128722228263, 'tol': 0.057264498211465335, 'validation_fraction': 0.6700459782002386, 'beta_1': 0.6050643657382383, 'beta_2': 0.9145869391864201, 'epsilon': 8.78875876437173e-07}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.223949 value 70.394219 suggestion {'hidden_layer_sizes': 88, 'alpha': 1.3123101972110751, 'batch_size': 123, 'learning_rate_init': 0.031119128722228263, 'tol': 0.057264498211465335, 'validation_fraction': 0.6700459782002386, 'beta_1': 0.6050643657382383, 'beta_2': 0.9145869391864201, 'epsilon': 8.78875876437173e-07}
observation time 0.001277, current best 70.394219 at iter 3
suggestion time taken 0.004809 iter 4 next_points [{'hidden_layer_sizes': 88, 'alpha': 1.6029896778745023, 'batch_size': 123, 'learning_rate_init': 0.038793130619894915, 'tol': 0.057264498211465335, 'validation_fraction': 0.6700459782002386, 'beta_1': 0.6050643657382383, 'beta_2': 0.9145869391864201, 'epsilon': 8.78875876437173e-07}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.218161 value 52.604207 suggestion {'hidden_layer_sizes': 88, 'alpha': 1.6029896778745023, 'batch_size': 123, 'learning_rate_init': 0.038793130619894915, 'tol': 0.057264498211465335, 'validation_fraction': 0.6700459782002386, 'beta_1': 0.6050643657382383, 'beta_2': 0.9145869391864201, 'epsilon': 8.78875876437173e-07}
observation time 0.001291, current best 52.604207 at iter 4
suggestion time taken 0.005109 iter 5 next_points [{'hidden_layer_sizes': 109, 'alpha': 1.6029896778745023, 'batch_size': 123, 'learning_rate_init': 0.038793130619894915, 'tol': 0.047790001878852566, 'validation_fraction': 0.6700459782002386, 'beta_1': 0.6050643657382383, 'beta_2': 0.9057559372178874, 'epsilon': 8.78875876437173e-07}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.265421 value 51.542063 suggestion {'hidden_layer_sizes': 109, 'alpha': 1.6029896778745023, 'batch_size': 123, 'learning_rate_init': 0.038793130619894915, 'tol': 0.047790001878852566, 'validation_fraction': 0.6700459782002386, 'beta_1': 0.6050643657382383, 'beta_2': 0.9057559372178874, 'epsilon': 8.78875876437173e-07}
observation time 0.001315, current best 51.542063 at iter 5
suggestion time taken 0.006983 iter 6 next_points [{'hidden_layer_sizes': 90, 'alpha': 4.500514576746779, 'batch_size': 96, 'learning_rate_init': 0.024023557113545358, 'tol': 0.08079596032923068, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.6107621338802567, 'beta_2': 0.9953394882840503, 'epsilon': 2.6328973728718664e-09}]
function_evaluation time 0.172480 value 51.344094 suggestion {'hidden_layer_sizes': 90, 'alpha': 4.500514576746779, 'batch_size': 96, 'learning_rate_init': 0.024023557113545358, 'tol': 0.08079596032923068, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.6107621338802567, 'beta_2': 0.9953394882840503, 'epsilon': 2.6328973728718664e-09}
observation time 0.002547, current best 51.344094 at iter 6
suggestion time taken 0.004800 iter 7 next_points [{'hidden_layer_sizes': 90, 'alpha': 4.500514576746779, 'batch_size': 133, 'learning_rate_init': 0.024023557113545358, 'tol': 0.05701620921810429, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.6121494582568587, 'beta_2': 0.9953394882840503, 'epsilon': 2.6328973728718664e-09}]
function_evaluation time 0.276822 value 51.228670 suggestion {'hidden_layer_sizes': 90, 'alpha': 4.500514576746779, 'batch_size': 133, 'learning_rate_init': 0.024023557113545358, 'tol': 0.05701620921810429, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.6121494582568587, 'beta_2': 0.9953394882840503, 'epsilon': 2.6328973728718664e-09}
observation time 0.002708, current best 51.228670 at iter 7
suggestion time taken 0.004347 iter 8 next_points [{'hidden_layer_sizes': 96, 'alpha': 1.4115354518186964, 'batch_size': 150, 'learning_rate_init': 0.017260382136192232, 'tol': 0.09348994381933788, 'validation_fraction': 0.2183319484065895, 'beta_1': 0.8949462339595204, 'beta_2': 0.9083782853774233, 'epsilon': 7.678454673481761e-07}]
function_evaluation time 0.089865 value 142.500960 suggestion {'hidden_layer_sizes': 96, 'alpha': 1.4115354518186964, 'batch_size': 150, 'learning_rate_init': 0.017260382136192232, 'tol': 0.09348994381933788, 'validation_fraction': 0.2183319484065895, 'beta_1': 0.8949462339595204, 'beta_2': 0.9083782853774233, 'epsilon': 7.678454673481761e-07}
observation time 0.002688, current best 51.228670 at iter 8
suggestion time taken 0.007200 iter 9 next_points [{'hidden_layer_sizes': 90, 'alpha': 0.1269333744114562, 'batch_size': 133, 'learning_rate_init': 0.024023557113545358, 'tol': 0.05701620921810429, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.5601741447719587, 'beta_2': 0.9953394882840503, 'epsilon': 2.6328973728718664e-09}]
function_evaluation time 0.280293 value 51.006081 suggestion {'hidden_layer_sizes': 90, 'alpha': 0.1269333744114562, 'batch_size': 133, 'learning_rate_init': 0.024023557113545358, 'tol': 0.05701620921810429, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.5601741447719587, 'beta_2': 0.9953394882840503, 'epsilon': 2.6328973728718664e-09}
observation time 0.001453, current best 51.006081 at iter 9
suggestion time taken 0.004836 iter 10 next_points [{'hidden_layer_sizes': 90, 'alpha': 0.1269333744114562, 'batch_size': 133, 'learning_rate_init': 0.024023557113545358, 'tol': 0.012285118655576733, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.5601741447719587, 'beta_2': 0.9953394882840503, 'epsilon': 2.6328973728718664e-09}]
function_evaluation time 0.331363 value 50.307725 suggestion {'hidden_layer_sizes': 90, 'alpha': 0.1269333744114562, 'batch_size': 133, 'learning_rate_init': 0.024023557113545358, 'tol': 0.012285118655576733, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.5601741447719587, 'beta_2': 0.9953394882840503, 'epsilon': 2.6328973728718664e-09}
observation time 0.001216, current best 50.307725 at iter 10
suggestion time taken 0.013347 iter 11 next_points [{'hidden_layer_sizes': 84, 'alpha': 0.1269333744114562, 'batch_size': 148, 'learning_rate_init': 0.024023557113545358, 'tol': 0.012285118655576733, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}]
function_evaluation time 0.330943 value 50.291012 suggestion {'hidden_layer_sizes': 84, 'alpha': 0.1269333744114562, 'batch_size': 148, 'learning_rate_init': 0.024023557113545358, 'tol': 0.012285118655576733, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}
observation time 0.001357, current best 50.291012 at iter 11
suggestion time taken 0.005588 iter 12 next_points [{'hidden_layer_sizes': 84, 'alpha': 0.1269333744114562, 'batch_size': 148, 'learning_rate_init': 0.024023557113545358, 'tol': 0.012285118655576733, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.5657007466778463, 'beta_2': 0.9818024441852488, 'epsilon': 3.5839967577582345e-08}]
function_evaluation time 0.355381 value 51.464942 suggestion {'hidden_layer_sizes': 84, 'alpha': 0.1269333744114562, 'batch_size': 148, 'learning_rate_init': 0.024023557113545358, 'tol': 0.012285118655576733, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.5657007466778463, 'beta_2': 0.9818024441852488, 'epsilon': 3.5839967577582345e-08}
observation time 0.001291, current best 50.291012 at iter 12
suggestion time taken 0.004696 iter 13 next_points [{'hidden_layer_sizes': 84, 'alpha': 1.7865415441855648, 'batch_size': 148, 'learning_rate_init': 0.024023557113545358, 'tol': 0.012285118655576733, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.5561235345772925, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}]
function_evaluation time 0.385863 value 50.310020 suggestion {'hidden_layer_sizes': 84, 'alpha': 1.7865415441855648, 'batch_size': 148, 'learning_rate_init': 0.024023557113545358, 'tol': 0.012285118655576733, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.5561235345772925, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}
observation time 0.001883, current best 50.291012 at iter 13
suggestion time taken 0.005191 iter 14 next_points [{'hidden_layer_sizes': 169, 'alpha': 4.8276972674150755, 'batch_size': 116, 'learning_rate_init': 0.004988165881049934, 'tol': 0.012285118655576733, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}]
function_evaluation time 1.102499 value 54.590995 suggestion {'hidden_layer_sizes': 169, 'alpha': 4.8276972674150755, 'batch_size': 116, 'learning_rate_init': 0.004988165881049934, 'tol': 0.012285118655576733, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}
observation time 0.001265, current best 50.291012 at iter 14
suggestion time taken 0.004962 iter 15 next_points [{'hidden_layer_sizes': 91, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.012285118655576733, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}]
function_evaluation time 0.336112 value 49.903486 suggestion {'hidden_layer_sizes': 91, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.012285118655576733, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}
observation time 0.003634, current best 49.903486 at iter 15
suggestion time taken 0.005803 iter 16 next_points [{'hidden_layer_sizes': 106, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.014243756771480976, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}]
function_evaluation time 0.432091 value 50.102656 suggestion {'hidden_layer_sizes': 106, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.014243756771480976, 'validation_fraction': 0.13926459821908388, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}
observation time 0.001263, current best 49.903486 at iter 16
suggestion time taken 0.004731 iter 17 next_points [{'hidden_layer_sizes': 91, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}]
function_evaluation time 0.518371 value 45.841891 suggestion {'hidden_layer_sizes': 91, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}
observation time 0.001284, current best 45.841891 at iter 17
suggestion time taken 0.004810 iter 18 next_points [{'hidden_layer_sizes': 92, 'alpha': 0.2808327605790783, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5601741447719587, 'beta_2': 0.9862657095445039, 'epsilon': 4.863284966458059e-08}]
function_evaluation time 0.538346 value 48.184487 suggestion {'hidden_layer_sizes': 92, 'alpha': 0.2808327605790783, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5601741447719587, 'beta_2': 0.9862657095445039, 'epsilon': 4.863284966458059e-08}
observation time 0.001248, current best 45.841891 at iter 18
suggestion time taken 0.004237 iter 19 next_points [{'hidden_layer_sizes': 126, 'alpha': 2.8264906503527394, 'batch_size': 147, 'learning_rate_init': 0.08403407485328633, 'tol': 0.062497841051009244, 'validation_fraction': 0.868510087142535, 'beta_1': 0.6386147284312199, 'beta_2': 0.9306479535306705, 'epsilon': 3.760007189218252e-07}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.139503 value 51.922884 suggestion {'hidden_layer_sizes': 126, 'alpha': 2.8264906503527394, 'batch_size': 147, 'learning_rate_init': 0.08403407485328633, 'tol': 0.062497841051009244, 'validation_fraction': 0.868510087142535, 'beta_1': 0.6386147284312199, 'beta_2': 0.9306479535306705, 'epsilon': 3.760007189218252e-07}
observation time 0.001198, current best 45.841891 at iter 19
suggestion time taken 0.004739 iter 20 next_points [{'hidden_layer_sizes': 50, 'alpha': 0.1480056632160271, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.013044214026516721, 'validation_fraction': 0.21361952267485423, 'beta_1': 0.5430930088698195, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}]
function_evaluation time 0.214546 value 51.332510 suggestion {'hidden_layer_sizes': 50, 'alpha': 0.1480056632160271, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.013044214026516721, 'validation_fraction': 0.21361952267485423, 'beta_1': 0.5430930088698195, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}
observation time 0.001263, current best 45.841891 at iter 20
suggestion time taken 0.004624 iter 21 next_points [{'hidden_layer_sizes': 91, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.7782053156795634, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.304350 value 51.477214 suggestion {'hidden_layer_sizes': 91, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.7782053156795634, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}
observation time 0.001247, current best 45.841891 at iter 21
suggestion time taken 0.011962 iter 22 next_points [{'hidden_layer_sizes': 91, 'alpha': 0.7060127066458494, 'batch_size': 174, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.13996709397088425, 'beta_1': 0.5134689724354747, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}]
function_evaluation time 0.319482 value 47.907179 suggestion {'hidden_layer_sizes': 91, 'alpha': 0.7060127066458494, 'batch_size': 174, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.13996709397088425, 'beta_1': 0.5134689724354747, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}
observation time 0.001207, current best 45.841891 at iter 22
suggestion time taken 0.006568 iter 23 next_points [{'hidden_layer_sizes': 91, 'alpha': 2.333418003579685, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 9.509383435418451e-07}]
function_evaluation time 0.400420 value 46.978549 suggestion {'hidden_layer_sizes': 91, 'alpha': 2.333418003579685, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 9.509383435418451e-07}
observation time 0.001240, current best 45.841891 at iter 23
suggestion time taken 0.010661 iter 24 next_points [{'hidden_layer_sizes': 91, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.022003285156902242, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5601741447719587, 'beta_2': 0.9867069311769778, 'epsilon': 4.863284966458059e-08}]
function_evaluation time 0.471642 value 48.077352 suggestion {'hidden_layer_sizes': 91, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.022003285156902242, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5601741447719587, 'beta_2': 0.9867069311769778, 'epsilon': 4.863284966458059e-08}
observation time 0.003836, current best 45.841891 at iter 24
suggestion time taken 0.010871 iter 25 next_points [{'hidden_layer_sizes': 62, 'alpha': 0.5870159127547055, 'batch_size': 112, 'learning_rate_init': 0.041178581881021685, 'tol': 0.0833682065949976, 'validation_fraction': 0.5533613326156925, 'beta_1': 0.7310867120542717, 'beta_2': 0.9034719080908795, 'epsilon': 6.544408720781925e-07}]
function_evaluation time 0.188687 value 53.346428 suggestion {'hidden_layer_sizes': 62, 'alpha': 0.5870159127547055, 'batch_size': 112, 'learning_rate_init': 0.041178581881021685, 'tol': 0.0833682065949976, 'validation_fraction': 0.5533613326156925, 'beta_1': 0.7310867120542717, 'beta_2': 0.9034719080908795, 'epsilon': 6.544408720781925e-07}
observation time 0.002613, current best 45.841891 at iter 25
suggestion time taken 0.017897 iter 26 next_points [{'hidden_layer_sizes': 91, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.0018792728184590557, 'validation_fraction': 0.24857705615785247, 'beta_1': 0.6155485501175684, 'beta_2': 0.9805876344894222, 'epsilon': 4.863284966458059e-08}]
function_evaluation time 0.538663 value 46.582653 suggestion {'hidden_layer_sizes': 91, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.0018792728184590557, 'validation_fraction': 0.24857705615785247, 'beta_1': 0.6155485501175684, 'beta_2': 0.9805876344894222, 'epsilon': 4.863284966458059e-08}
observation time 0.001248, current best 45.841891 at iter 26
suggestion time taken 0.004725 iter 27 next_points [{'hidden_layer_sizes': 131, 'alpha': 0.6473596275129293, 'batch_size': 17, 'learning_rate_init': 0.026800337247978746, 'tol': 0.002150433501794492, 'validation_fraction': 0.8756539343577806, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}]
function_evaluation time 0.488912 value 50.001412 suggestion {'hidden_layer_sizes': 131, 'alpha': 0.6473596275129293, 'batch_size': 17, 'learning_rate_init': 0.026800337247978746, 'tol': 0.002150433501794492, 'validation_fraction': 0.8756539343577806, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}
observation time 0.001259, current best 45.841891 at iter 27
suggestion time taken 0.004790 iter 28 next_points [{'hidden_layer_sizes': 91, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.013619578386077014, 'validation_fraction': 0.1208222230203806, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 1.293545409958009e-07}]
function_evaluation time 0.288995 value 49.622898 suggestion {'hidden_layer_sizes': 91, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.013619578386077014, 'validation_fraction': 0.1208222230203806, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 1.293545409958009e-07}
observation time 0.002131, current best 45.841891 at iter 28
suggestion time taken 0.005997 iter 29 next_points [{'hidden_layer_sizes': 141, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}]
function_evaluation time 0.601754 value 45.833116 suggestion {'hidden_layer_sizes': 141, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 4.863284966458059e-08}
observation time 0.001252, current best 45.833116 at iter 29
suggestion time taken 0.004989 iter 30 next_points [{'hidden_layer_sizes': 141, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 9.490340523726482e-07}]
function_evaluation time 0.595561 value 45.637627 suggestion {'hidden_layer_sizes': 141, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 9.490340523726482e-07}
observation time 0.001258, current best 45.637627 at iter 30
suggestion time taken 0.004810 iter 31 next_points [{'hidden_layer_sizes': 123, 'alpha': 2.163607779500899, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.10480711849302492, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 2.7611768041499354e-07}]
function_evaluation time 0.497901 value 46.675057 suggestion {'hidden_layer_sizes': 123, 'alpha': 2.163607779500899, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.10480711849302492, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 2.7611768041499354e-07}
observation time 0.002962, current best 45.637627 at iter 31
suggestion time taken 0.008943 iter 32 next_points [{'hidden_layer_sizes': 141, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.035647662197719025, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.7579610012588466, 'beta_2': 0.9850082538919737, 'epsilon': 9.490340523726482e-07}]
function_evaluation time 0.289701 value 50.527455 suggestion {'hidden_layer_sizes': 141, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.035647662197719025, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.7579610012588466, 'beta_2': 0.9850082538919737, 'epsilon': 9.490340523726482e-07}
observation time 0.001236, current best 45.637627 at iter 32
suggestion time taken 0.004573 iter 33 next_points [{'hidden_layer_sizes': 141, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.6757889597105922, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 9.490340523726482e-07}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.366983 value 50.214413 suggestion {'hidden_layer_sizes': 141, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.6757889597105922, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 9.490340523726482e-07}
observation time 0.001256, current best 45.637627 at iter 33
suggestion time taken 0.004710 iter 34 next_points [{'hidden_layer_sizes': 141, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5601741447719587, 'beta_2': 0.9169765230344773, 'epsilon': 9.490340523726482e-07}]
function_evaluation time 0.621310 value 45.819932 suggestion {'hidden_layer_sizes': 141, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5601741447719587, 'beta_2': 0.9169765230344773, 'epsilon': 9.490340523726482e-07}
observation time 0.001231, current best 45.637627 at iter 34
suggestion time taken 0.004666 iter 35 next_points [{'hidden_layer_sizes': 141, 'alpha': 8.535952892317692, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 9.490340523726482e-07}]
function_evaluation time 0.541209 value 46.998349 suggestion {'hidden_layer_sizes': 141, 'alpha': 8.535952892317692, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5601741447719587, 'beta_2': 0.9850082538919737, 'epsilon': 9.490340523726482e-07}
observation time 0.003296, current best 45.637627 at iter 35
suggestion time taken 0.004331 iter 36 next_points [{'hidden_layer_sizes': 170, 'alpha': 5.135011589879554, 'batch_size': 214, 'learning_rate_init': 0.08236873750691125, 'tol': 0.045656132921001395, 'validation_fraction': 0.1375254712748175, 'beta_1': 0.6385558298318599, 'beta_2': 0.9516766690309548, 'epsilon': 4.6518117594093646e-07}]
function_evaluation time 0.212234 value 46.952805 suggestion {'hidden_layer_sizes': 170, 'alpha': 5.135011589879554, 'batch_size': 214, 'learning_rate_init': 0.08236873750691125, 'tol': 0.045656132921001395, 'validation_fraction': 0.1375254712748175, 'beta_1': 0.6385558298318599, 'beta_2': 0.9516766690309548, 'epsilon': 4.6518117594093646e-07}
observation time 0.002824, current best 45.637627 at iter 36
suggestion time taken 0.005115 iter 37 next_points [{'hidden_layer_sizes': 131, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5308321354437688, 'beta_2': 0.975858856112701, 'epsilon': 9.490340523726482e-07}]
function_evaluation time 0.564032 value 45.428947 suggestion {'hidden_layer_sizes': 131, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.5308321354437688, 'beta_2': 0.975858856112701, 'epsilon': 9.490340523726482e-07}
observation time 0.001344, current best 45.428947 at iter 37
suggestion time taken 0.013380 iter 38 next_points [{'hidden_layer_sizes': 131, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.501426506198735, 'beta_2': 0.975858856112701, 'epsilon': 8.21662193978805e-07}]
function_evaluation time 0.479331 value 45.870238 suggestion {'hidden_layer_sizes': 131, 'alpha': 0.6473596275129293, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.16328771744376924, 'beta_1': 0.501426506198735, 'beta_2': 0.975858856112701, 'epsilon': 8.21662193978805e-07}
observation time 0.005007, current best 45.428947 at iter 38
suggestion time taken 0.008261 iter 39 next_points [{'hidden_layer_sizes': 131, 'alpha': 0.41614631342539393, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.20457624606116326, 'beta_1': 0.556363722669447, 'beta_2': 0.9807991740070748, 'epsilon': 8.82017121479033e-07}]
function_evaluation time 1.144966 value 45.417314 suggestion {'hidden_layer_sizes': 131, 'alpha': 0.41614631342539393, 'batch_size': 153, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.20457624606116326, 'beta_1': 0.556363722669447, 'beta_2': 0.9807991740070748, 'epsilon': 8.82017121479033e-07}
observation time 0.005218, current best 45.417314 at iter 39
suggestion time taken 0.005220 iter 40 next_points [{'hidden_layer_sizes': 131, 'alpha': 0.15820880173923418, 'batch_size': 134, 'learning_rate_init': 0.023184289485541566, 'tol': 0.003361376605431833, 'validation_fraction': 0.20457624606116326, 'beta_1': 0.556363722669447, 'beta_2': 0.9825934688272848, 'epsilon': 8.82017121479033e-07}]
function_evaluation time 0.763323 value 47.023842 suggestion {'hidden_layer_sizes': 131, 'alpha': 0.15820880173923418, 'batch_size': 134, 'learning_rate_init': 0.023184289485541566, 'tol': 0.003361376605431833, 'validation_fraction': 0.20457624606116326, 'beta_1': 0.556363722669447, 'beta_2': 0.9825934688272848, 'epsilon': 8.82017121479033e-07}
observation time 0.001300, current best 45.417314 at iter 40
suggestion time taken 0.013326 iter 41 next_points [{'hidden_layer_sizes': 131, 'alpha': 0.21242101383911133, 'batch_size': 203, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.20457624606116326, 'beta_1': 0.556363722669447, 'beta_2': 0.9807991740070748, 'epsilon': 9.327341997938655e-07}]
function_evaluation time 0.813141 value 45.790982 suggestion {'hidden_layer_sizes': 131, 'alpha': 0.21242101383911133, 'batch_size': 203, 'learning_rate_init': 0.026800337247978746, 'tol': 0.003361376605431833, 'validation_fraction': 0.20457624606116326, 'beta_1': 0.556363722669447, 'beta_2': 0.9807991740070748, 'epsilon': 9.327341997938655e-07}
observation time 0.002571, current best 45.417314 at iter 41
suggestion time taken 0.004910 iter 42 next_points [{'hidden_layer_sizes': 131, 'alpha': 0.12508268986433974, 'batch_size': 140, 'learning_rate_init': 0.04098235475303718, 'tol': 0.003361376605431833, 'validation_fraction': 0.20457624606116326, 'beta_1': 0.556363722669447, 'beta_2': 0.9807991740070748, 'epsilon': 8.82017121479033e-07}]
function_evaluation time 0.482434 value 44.442675 suggestion {'hidden_layer_sizes': 131, 'alpha': 0.12508268986433974, 'batch_size': 140, 'learning_rate_init': 0.04098235475303718, 'tol': 0.003361376605431833, 'validation_fraction': 0.20457624606116326, 'beta_1': 0.556363722669447, 'beta_2': 0.9807991740070748, 'epsilon': 8.82017121479033e-07}
observation time 0.001358, current best 44.442675 at iter 42
suggestion time taken 0.012090 iter 43 next_points [{'hidden_layer_sizes': 131, 'alpha': 0.12508268986433974, 'batch_size': 126, 'learning_rate_init': 0.04098235475303718, 'tol': 0.003361376605431833, 'validation_fraction': 0.20457624606116326, 'beta_1': 0.556363722669447, 'beta_2': 0.9807991740070748, 'epsilon': 7.681773929462944e-07}]
function_evaluation time 0.485421 value 44.930677 suggestion {'hidden_layer_sizes': 131, 'alpha': 0.12508268986433974, 'batch_size': 126, 'learning_rate_init': 0.04098235475303718, 'tol': 0.003361376605431833, 'validation_fraction': 0.20457624606116326, 'beta_1': 0.556363722669447, 'beta_2': 0.9807991740070748, 'epsilon': 7.681773929462944e-07}
observation time 0.003608, current best 44.442675 at iter 43
suggestion time taken 0.006315 iter 44 next_points [{'hidden_layer_sizes': 131, 'alpha': 0.12508268986433974, 'batch_size': 121, 'learning_rate_init': 0.061881650144757376, 'tol': 0.003361376605431833, 'validation_fraction': 0.20457624606116326, 'beta_1': 0.556363722669447, 'beta_2': 0.9843748569677113, 'epsilon': 8.82017121479033e-07}]
function_evaluation time 0.454732 value 44.442356 suggestion {'hidden_layer_sizes': 131, 'alpha': 0.12508268986433974, 'batch_size': 121, 'learning_rate_init': 0.061881650144757376, 'tol': 0.003361376605431833, 'validation_fraction': 0.20457624606116326, 'beta_1': 0.556363722669447, 'beta_2': 0.9843748569677113, 'epsilon': 8.82017121479033e-07}
observation time 0.001375, current best 44.442356 at iter 44
saving meta data: {'args': {'--uuid': '77c82ca3f6105bf288209b4ce567b0ce', '-db-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230815_180041', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

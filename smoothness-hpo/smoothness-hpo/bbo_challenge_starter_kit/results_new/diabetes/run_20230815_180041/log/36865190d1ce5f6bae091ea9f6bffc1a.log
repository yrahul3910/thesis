running: {'--uuid': '36865190d1ce5f6bae091ea9f6bffc1a', '-db-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230815_180041', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d diabetes -o opentuner -u 36865190d1ce5f6bae091ea9f6bffc1a -m mae -n 45 -p 1 -dir /Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20230815_180041
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
/Users/ryedida/miniforge3/lib/python3.9/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study opentuner MLP-adam diabetes mae 45 1
with data root: None
suggestion time taken 0.010804 iter 0 next_points [{'hidden_layer_sizes': 195, 'alpha': 0.3100497237645529, 'batch_size': 54, 'learning_rate_init': 0.04491101552951043, 'tol': 0.058469733450414, 'validation_fraction': 0.8143272617758365, 'beta_1': 0.642990986716782, 'beta_2': 0.9261129581796868, 'epsilon': 5.91392358557068e-07}]
function_evaluation time 0.209037 value 53.511903 suggestion {'hidden_layer_sizes': 195, 'alpha': 0.3100497237645529, 'batch_size': 54, 'learning_rate_init': 0.04491101552951043, 'tol': 0.058469733450414, 'validation_fraction': 0.8143272617758365, 'beta_1': 0.642990986716782, 'beta_2': 0.9261129581796868, 'epsilon': 5.91392358557068e-07}
observation time 0.003079, current best 53.511903 at iter 0
suggestion time taken 0.049321 iter 1 next_points [{'learning_rate_init': 0.005766270828619181, 'alpha': 0.41666883848052766, 'beta_2': 0.9885658439173212, 'beta_1': 0.8485175794637347, 'hidden_layer_sizes': 99, 'epsilon': 3.081008347621529e-07, 'tol': 0.014225657115488333, 'batch_size': 178, 'validation_fraction': 0.7722582515395205}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.057780 value 150.555698 suggestion {'learning_rate_init': 0.005766270828619181, 'alpha': 0.41666883848052766, 'beta_2': 0.9885658439173212, 'beta_1': 0.8485175794637347, 'hidden_layer_sizes': 99, 'epsilon': 3.081008347621529e-07, 'tol': 0.014225657115488333, 'batch_size': 178, 'validation_fraction': 0.7722582515395205}
observation time 0.001238, current best 53.511903 at iter 1
suggestion time taken 0.024006 iter 2 next_points [{'learning_rate_init': 0.03925811803660422, 'alpha': 0.9950288436811171, 'beta_2': 0.9646020865472362, 'beta_1': 0.7989675851422033, 'hidden_layer_sizes': 197, 'epsilon': 7.253091366682108e-07, 'tol': 0.056848459358380836, 'batch_size': 163, 'validation_fraction': 0.7120588195448986}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.259882 value 52.395237 suggestion {'learning_rate_init': 0.03925811803660422, 'alpha': 0.9950288436811171, 'beta_2': 0.9646020865472362, 'beta_1': 0.7989675851422033, 'hidden_layer_sizes': 197, 'epsilon': 7.253091366682108e-07, 'tol': 0.056848459358380836, 'batch_size': 163, 'validation_fraction': 0.7120588195448986}
observation time 0.002978, current best 52.395237 at iter 2
suggestion time taken 0.006967 iter 3 next_points [{'learning_rate_init': 0.03272354753413114, 'alpha': 0.9950288436811171, 'beta_2': 0.9646020865472362, 'beta_1': 0.7989675851422033, 'hidden_layer_sizes': 197, 'epsilon': 7.253091366682108e-07, 'tol': 0.056848459358380836, 'batch_size': 163, 'validation_fraction': 0.7120588195448986}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.244899 value 53.508005 suggestion {'learning_rate_init': 0.03272354753413114, 'alpha': 0.9950288436811171, 'beta_2': 0.9646020865472362, 'beta_1': 0.7989675851422033, 'hidden_layer_sizes': 197, 'epsilon': 7.253091366682108e-07, 'tol': 0.056848459358380836, 'batch_size': 163, 'validation_fraction': 0.7120588195448986}
observation time 0.002736, current best 52.395237 at iter 3
suggestion time taken 0.008882 iter 4 next_points [{'learning_rate_init': 0.07545775501805478, 'alpha': 0.8516314136687492, 'beta_2': 0.9683624288086943, 'beta_1': 0.6908982274413019, 'hidden_layer_sizes': 140, 'epsilon': 4.473115106378979e-07, 'tol': 0.05260836625912762, 'batch_size': 188, 'validation_fraction': 0.8427617862551142}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.135773 value 51.747090 suggestion {'learning_rate_init': 0.07545775501805478, 'alpha': 0.8516314136687492, 'beta_2': 0.9683624288086943, 'beta_1': 0.6908982274413019, 'hidden_layer_sizes': 140, 'epsilon': 4.473115106378979e-07, 'tol': 0.05260836625912762, 'batch_size': 188, 'validation_fraction': 0.8427617862551142}
observation time 0.001263, current best 51.747090 at iter 4
suggestion time taken 0.005119 iter 5 next_points [{'learning_rate_init': 0.07545775501805478, 'alpha': 1.0937961418794564, 'beta_2': 0.9683624288086943, 'beta_1': 0.6908982274413019, 'hidden_layer_sizes': 168, 'epsilon': 4.473115106378979e-07, 'tol': 0.05260836625912762, 'batch_size': 188, 'validation_fraction': 0.8427617862551142}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.140368 value 50.750765 suggestion {'learning_rate_init': 0.07545775501805478, 'alpha': 1.0937961418794564, 'beta_2': 0.9683624288086943, 'beta_1': 0.6908982274413019, 'hidden_layer_sizes': 168, 'epsilon': 4.473115106378979e-07, 'tol': 0.05260836625912762, 'batch_size': 188, 'validation_fraction': 0.8427617862551142}
observation time 0.001818, current best 50.750765 at iter 5
suggestion time taken 0.010276 iter 6 next_points [{'learning_rate_init': 0.003522126668480775, 'alpha': 2.097541156142213, 'beta_2': 0.9790883655716214, 'beta_1': 0.5553494944812052, 'hidden_layer_sizes': 58, 'epsilon': 4.5093167414020265e-07, 'tol': 0.026066337311483268, 'batch_size': 154, 'validation_fraction': 0.1295055031674541}]
function_evaluation time 0.053598 value 150.509630 suggestion {'learning_rate_init': 0.003522126668480775, 'alpha': 2.097541156142213, 'beta_2': 0.9790883655716214, 'beta_1': 0.5553494944812052, 'hidden_layer_sizes': 58, 'epsilon': 4.5093167414020265e-07, 'tol': 0.026066337311483268, 'batch_size': 154, 'validation_fraction': 0.1295055031674541}
observation time 0.001238, current best 50.750765 at iter 6
suggestion time taken 0.010217 iter 7 next_points [{'learning_rate_init': 0.07545775501805478, 'alpha': 1.0937961418794564, 'beta_2': 0.9692338814863146, 'beta_1': 0.7496078256724347, 'hidden_layer_sizes': 168, 'epsilon': 5.779769921052014e-08, 'tol': 0.05260836625912762, 'batch_size': 188, 'validation_fraction': 0.8427617862551142}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.138676 value 51.341792 suggestion {'learning_rate_init': 0.07545775501805478, 'alpha': 1.0937961418794564, 'beta_2': 0.9692338814863146, 'beta_1': 0.7496078256724347, 'hidden_layer_sizes': 168, 'epsilon': 5.779769921052014e-08, 'tol': 0.05260836625912762, 'batch_size': 188, 'validation_fraction': 0.8427617862551142}
observation time 0.002770, current best 50.750765 at iter 7
suggestion time taken 0.005143 iter 8 next_points [{'learning_rate_init': 0.07545775501805478, 'alpha': 6.696068248192482, 'beta_2': 0.9683624288086943, 'beta_1': 0.745510816168431, 'hidden_layer_sizes': 168, 'epsilon': 9.750136548419543e-07, 'tol': 0.05260836625912762, 'batch_size': 188, 'validation_fraction': 0.8427617862551142}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.145460 value 51.496493 suggestion {'learning_rate_init': 0.07545775501805478, 'alpha': 6.696068248192482, 'beta_2': 0.9683624288086943, 'beta_1': 0.745510816168431, 'hidden_layer_sizes': 168, 'epsilon': 9.750136548419543e-07, 'tol': 0.05260836625912762, 'batch_size': 188, 'validation_fraction': 0.8427617862551142}
observation time 0.001995, current best 50.750765 at iter 8
suggestion time taken 0.011625 iter 9 next_points [{'learning_rate_init': 0.01793962546680421, 'alpha': 8.9805341364611, 'beta_2': 0.9325112830676895, 'beta_1': 0.8238516118319696, 'hidden_layer_sizes': 153, 'epsilon': 3.6846940801357655e-07, 'tol': 0.0018712005388642938, 'batch_size': 172, 'validation_fraction': 0.7690945040050344}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.538964 value 52.522802 suggestion {'learning_rate_init': 0.01793962546680421, 'alpha': 8.9805341364611, 'beta_2': 0.9325112830676895, 'beta_1': 0.8238516118319696, 'hidden_layer_sizes': 153, 'epsilon': 3.6846940801357655e-07, 'tol': 0.0018712005388642938, 'batch_size': 172, 'validation_fraction': 0.7690945040050344}
observation time 0.001383, current best 50.750765 at iter 9
suggestion time taken 0.004466 iter 10 next_points [{'learning_rate_init': 0.04491954840375827, 'alpha': 0.5145693547300113, 'beta_2': 0.9786172656103757, 'beta_1': 0.6562550762708385, 'hidden_layer_sizes': 52, 'epsilon': 2.5351487900668226e-07, 'tol': 0.08344066457973291, 'batch_size': 231, 'validation_fraction': 0.7436895503479806}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.076774 value 128.381801 suggestion {'learning_rate_init': 0.04491954840375827, 'alpha': 0.5145693547300113, 'beta_2': 0.9786172656103757, 'beta_1': 0.6562550762708385, 'hidden_layer_sizes': 52, 'epsilon': 2.5351487900668226e-07, 'tol': 0.08344066457973291, 'batch_size': 231, 'validation_fraction': 0.7436895503479806}
observation time 0.001231, current best 50.750765 at iter 10
suggestion time taken 0.004911 iter 11 next_points [{'learning_rate_init': 0.07545775501805478, 'alpha': 1.0937961418794564, 'beta_2': 0.9683624288086943, 'beta_1': 0.6908982274413019, 'hidden_layer_sizes': 168, 'epsilon': 4.473115106378979e-07, 'tol': 0.05260836625912762, 'batch_size': 41, 'validation_fraction': 0.8427617862551142}]
function_evaluation time 0.140559 value 53.317933 suggestion {'learning_rate_init': 0.07545775501805478, 'alpha': 1.0937961418794564, 'beta_2': 0.9683624288086943, 'beta_1': 0.6908982274413019, 'hidden_layer_sizes': 168, 'epsilon': 4.473115106378979e-07, 'tol': 0.05260836625912762, 'batch_size': 41, 'validation_fraction': 0.8427617862551142}
observation time 0.001275, current best 50.750765 at iter 11
suggestion time taken 0.004408 iter 12 next_points [{'learning_rate_init': 0.04739332995140926, 'alpha': 1.1819799800177941, 'beta_2': 0.920279271913581, 'beta_1': 0.6842960034952738, 'hidden_layer_sizes': 116, 'epsilon': 7.827350866634598e-07, 'tol': 0.07624006828519507, 'batch_size': 27, 'validation_fraction': 0.7643507855176925}]
function_evaluation time 0.237080 value 49.087309 suggestion {'learning_rate_init': 0.04739332995140926, 'alpha': 1.1819799800177941, 'beta_2': 0.920279271913581, 'beta_1': 0.6842960034952738, 'hidden_layer_sizes': 116, 'epsilon': 7.827350866634598e-07, 'tol': 0.07624006828519507, 'batch_size': 27, 'validation_fraction': 0.7643507855176925}
observation time 0.002644, current best 49.087309 at iter 12
suggestion time taken 0.004609 iter 13 next_points [{'learning_rate_init': 0.09932255858026988, 'alpha': 0.6144669021770685, 'beta_2': 0.9917450681465069, 'beta_1': 0.5651741672619867, 'hidden_layer_sizes': 76, 'epsilon': 1.9078651583623218e-07, 'tol': 0.014060725463365054, 'batch_size': 87, 'validation_fraction': 0.845555858125587}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.114916 value 50.563043 suggestion {'learning_rate_init': 0.09932255858026988, 'alpha': 0.6144669021770685, 'beta_2': 0.9917450681465069, 'beta_1': 0.5651741672619867, 'hidden_layer_sizes': 76, 'epsilon': 1.9078651583623218e-07, 'tol': 0.014060725463365054, 'batch_size': 87, 'validation_fraction': 0.845555858125587}
observation time 0.002367, current best 49.087309 at iter 13
suggestion time taken 0.004860 iter 14 next_points [{'learning_rate_init': 0.06640400966499597, 'alpha': 0.050980934996886766, 'beta_2': 0.9288182769024159, 'beta_1': 0.7485889961326344, 'hidden_layer_sizes': 101, 'epsilon': 2.3870608947870644e-07, 'tol': 0.0500278301272487, 'batch_size': 145, 'validation_fraction': 0.6945086158889066}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.150505 value 51.315374 suggestion {'learning_rate_init': 0.06640400966499597, 'alpha': 0.050980934996886766, 'beta_2': 0.9288182769024159, 'beta_1': 0.7485889961326344, 'hidden_layer_sizes': 101, 'epsilon': 2.3870608947870644e-07, 'tol': 0.0500278301272487, 'batch_size': 145, 'validation_fraction': 0.6945086158889066}
observation time 0.002616, current best 49.087309 at iter 14
suggestion time taken 0.005966 iter 15 next_points [{'learning_rate_init': 0.04429837410821074, 'alpha': 7.093697149234586, 'beta_2': 0.9555648243715208, 'beta_1': 0.5758744873686165, 'hidden_layer_sizes': 153, 'epsilon': 6.671322635714839e-07, 'tol': 0.06652983700517982, 'batch_size': 129, 'validation_fraction': 0.5381135403340815}]
function_evaluation time 0.185035 value 61.936569 suggestion {'learning_rate_init': 0.04429837410821074, 'alpha': 7.093697149234586, 'beta_2': 0.9555648243715208, 'beta_1': 0.5758744873686165, 'hidden_layer_sizes': 153, 'epsilon': 6.671322635714839e-07, 'tol': 0.06652983700517982, 'batch_size': 129, 'validation_fraction': 0.5381135403340815}
observation time 0.001416, current best 49.087309 at iter 15
suggestion time taken 0.005670 iter 16 next_points [{'learning_rate_init': 0.04739332995140926, 'alpha': 1.1819799800177941, 'beta_2': 0.9602473384889375, 'beta_1': 0.6842960034952738, 'hidden_layer_sizes': 116, 'epsilon': 7.827350866634598e-07, 'tol': 0.07624006828519507, 'batch_size': 27, 'validation_fraction': 0.6931116527190799}]
function_evaluation time 0.174965 value 49.152963 suggestion {'learning_rate_init': 0.04739332995140926, 'alpha': 1.1819799800177941, 'beta_2': 0.9602473384889375, 'beta_1': 0.6842960034952738, 'hidden_layer_sizes': 116, 'epsilon': 7.827350866634598e-07, 'tol': 0.07624006828519507, 'batch_size': 27, 'validation_fraction': 0.6931116527190799}
observation time 0.001272, current best 49.087309 at iter 16
suggestion time taken 0.004525 iter 17 next_points [{'learning_rate_init': 0.031724707937382295, 'alpha': 0.4062216275927381, 'beta_2': 0.9967020029012206, 'beta_1': 0.529534431529285, 'hidden_layer_sizes': 85, 'epsilon': 8.25290465217814e-07, 'tol': 0.04100676674928876, 'batch_size': 25, 'validation_fraction': 0.20029045274443533}]
function_evaluation time 0.210036 value 47.049777 suggestion {'learning_rate_init': 0.031724707937382295, 'alpha': 0.4062216275927381, 'beta_2': 0.9967020029012206, 'beta_1': 0.529534431529285, 'hidden_layer_sizes': 85, 'epsilon': 8.25290465217814e-07, 'tol': 0.04100676674928876, 'batch_size': 25, 'validation_fraction': 0.20029045274443533}
observation time 0.001223, current best 47.049777 at iter 17
suggestion time taken 0.041122 iter 18 next_points [{'learning_rate_init': 0.1, 'alpha': 0.5023004299456938, 'beta_2': 0.926710531009016, 'beta_1': 0.877938035324184, 'hidden_layer_sizes': 200, 'epsilon': 5.831926893911921e-07, 'tol': 0.08880691247148402, 'batch_size': 88, 'validation_fraction': 0.9}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.160328 value 52.158691 suggestion {'learning_rate_init': 0.1, 'alpha': 0.5023004299456938, 'beta_2': 0.926710531009016, 'beta_1': 0.877938035324184, 'hidden_layer_sizes': 200, 'epsilon': 5.831926893911921e-07, 'tol': 0.08880691247148402, 'batch_size': 88, 'validation_fraction': 0.9}
observation time 0.001638, current best 47.049777 at iter 18
suggestion time taken 0.015232 iter 19 next_points [{'learning_rate_init': 0.07301558129344314, 'alpha': 0.9120977900027941, 'beta_2': 0.9441698091965511, 'beta_1': 0.7704085217098577, 'hidden_layer_sizes': 156, 'epsilon': 5.391056824571573e-07, 'tol': 0.06747830632716327, 'batch_size': 110, 'validation_fraction': 0.7619964707965593}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.221947 value 50.648979 suggestion {'learning_rate_init': 0.07301558129344314, 'alpha': 0.9120977900027941, 'beta_2': 0.9441698091965511, 'beta_1': 0.7704085217098577, 'hidden_layer_sizes': 156, 'epsilon': 5.391056824571573e-07, 'tol': 0.06747830632716327, 'batch_size': 110, 'validation_fraction': 0.7619964707965593}
observation time 0.001353, current best 47.049777 at iter 19
suggestion time taken 0.023088 iter 20 next_points [{'learning_rate_init': 0.07155912516415756, 'alpha': 4.437022298084962, 'beta_2': 0.9171771640189862, 'beta_1': 0.7406445799135136, 'hidden_layer_sizes': 200, 'epsilon': 9.99999999834993e-07, 'tol': 1e-05, 'batch_size': 10, 'validation_fraction': 0.5743470143721261}]
function_evaluation time 0.742569 value 45.746167 suggestion {'learning_rate_init': 0.07155912516415756, 'alpha': 4.437022298084962, 'beta_2': 0.9171771640189862, 'beta_1': 0.7406445799135136, 'hidden_layer_sizes': 200, 'epsilon': 9.99999999834993e-07, 'tol': 1e-05, 'batch_size': 10, 'validation_fraction': 0.5743470143721261}
observation time 0.001501, current best 45.746167 at iter 20
suggestion time taken 0.013042 iter 21 next_points [{'learning_rate_init': 0.08969509759939036, 'alpha': 10.0, 'beta_2': 0.9, 'beta_1': 0.7969042490086304, 'hidden_layer_sizes': 200, 'epsilon': 9.99999999834993e-07, 'tol': 1e-05, 'batch_size': 10, 'validation_fraction': 0.46145199038822315}]
function_evaluation time 0.717359 value 49.995576 suggestion {'learning_rate_init': 0.08969509759939036, 'alpha': 10.0, 'beta_2': 0.9, 'beta_1': 0.7969042490086304, 'hidden_layer_sizes': 200, 'epsilon': 9.99999999834993e-07, 'tol': 1e-05, 'batch_size': 10, 'validation_fraction': 0.46145199038822315}
observation time 0.001921, current best 45.746167 at iter 21
suggestion time taken 0.025134 iter 22 next_points [{'learning_rate_init': 0.08096748203434971, 'alpha': 1e-05, 'beta_2': 0.9448500160192792, 'beta_1': 0.9267226088107599, 'hidden_layer_sizes': 108, 'epsilon': 4.011892481841907e-07, 'tol': 1e-05, 'batch_size': 60, 'validation_fraction': 0.9}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.187029 value 56.501728 suggestion {'learning_rate_init': 0.08096748203434971, 'alpha': 1e-05, 'beta_2': 0.9448500160192792, 'beta_1': 0.9267226088107599, 'hidden_layer_sizes': 108, 'epsilon': 4.011892481841907e-07, 'tol': 1e-05, 'batch_size': 60, 'validation_fraction': 0.9}
observation time 0.001410, current best 45.746167 at iter 22
suggestion time taken 0.015333 iter 23 next_points [{'learning_rate_init': 0.06860356766536706, 'alpha': 0.6233488636142116, 'beta_2': 0.9484216188033597, 'beta_1': 0.809773234996712, 'hidden_layer_sizes': 123, 'epsilon': 4.898369120603641e-07, 'tol': 0.020951087162866356, 'batch_size': 83, 'validation_fraction': 0.7851538923792217}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.211898 value 49.936986 suggestion {'learning_rate_init': 0.06860356766536706, 'alpha': 0.6233488636142116, 'beta_2': 0.9484216188033597, 'beta_1': 0.809773234996712, 'hidden_layer_sizes': 123, 'epsilon': 4.898369120603641e-07, 'tol': 0.020951087162866356, 'batch_size': 83, 'validation_fraction': 0.7851538923792217}
observation time 0.001985, current best 45.746167 at iter 23
suggestion time taken 0.024569 iter 24 next_points [{'learning_rate_init': 0.1, 'alpha': 1e-05, 'beta_2': 0.9888141369564936, 'beta_1': 0.5009379841724824, 'hidden_layer_sizes': 99, 'epsilon': 9.453264419317643e-07, 'tol': 0.1, 'batch_size': 10, 'validation_fraction': 0.546846451878804}]
function_evaluation time 0.236287 value 44.609272 suggestion {'learning_rate_init': 0.1, 'alpha': 1e-05, 'beta_2': 0.9888141369564936, 'beta_1': 0.5009379841724824, 'hidden_layer_sizes': 99, 'epsilon': 9.453264419317643e-07, 'tol': 0.1, 'batch_size': 10, 'validation_fraction': 0.546846451878804}
observation time 0.001332, current best 44.609272 at iter 24
suggestion time taken 0.019204 iter 25 next_points [{'learning_rate_init': 0.1, 'alpha': 1e-05, 'beta_2': 0.999999, 'beta_1': 0.5, 'hidden_layer_sizes': 63, 'epsilon': 9.99999999834993e-07, 'tol': 0.1, 'batch_size': 10, 'validation_fraction': 0.3986810837946504}]
function_evaluation time 0.225587 value 43.929480 suggestion {'learning_rate_init': 0.1, 'alpha': 1e-05, 'beta_2': 0.999999, 'beta_1': 0.5, 'hidden_layer_sizes': 63, 'epsilon': 9.99999999834993e-07, 'tol': 0.1, 'batch_size': 10, 'validation_fraction': 0.3986810837946504}
observation time 0.001346, current best 43.929480 at iter 25
suggestion time taken 0.023707 iter 26 next_points [{'learning_rate_init': 0.1, 'alpha': 0.42395737377423787, 'beta_2': 0.9448788450770933, 'beta_1': 0.5, 'hidden_layer_sizes': 50, 'epsilon': 4.21106064158432e-07, 'tol': 0.02914121473118574, 'batch_size': 10, 'validation_fraction': 0.5497937947359608}]
function_evaluation time 0.150592 value 44.148255 suggestion {'learning_rate_init': 0.1, 'alpha': 0.42395737377423787, 'beta_2': 0.9448788450770933, 'beta_1': 0.5, 'hidden_layer_sizes': 50, 'epsilon': 4.21106064158432e-07, 'tol': 0.02914121473118574, 'batch_size': 10, 'validation_fraction': 0.5497937947359608}
observation time 0.001329, current best 43.929480 at iter 26
suggestion time taken 0.023588 iter 27 next_points [{'learning_rate_init': 0.06850043607957883, 'alpha': 0.49399980846964614, 'beta_2': 0.9314411881131343, 'beta_1': 0.5799989938615657, 'hidden_layer_sizes': 53, 'epsilon': 8.858404247085994e-07, 'tol': 0.02921343953077209, 'batch_size': 10, 'validation_fraction': 0.23970835387284792}]
function_evaluation time 0.277079 value 44.816121 suggestion {'learning_rate_init': 0.06850043607957883, 'alpha': 0.49399980846964614, 'beta_2': 0.9314411881131343, 'beta_1': 0.5799989938615657, 'hidden_layer_sizes': 53, 'epsilon': 8.858404247085994e-07, 'tol': 0.02921343953077209, 'batch_size': 10, 'validation_fraction': 0.23970835387284792}
observation time 0.001103, current best 43.929480 at iter 27
suggestion time taken 0.007333 iter 28 next_points [{'learning_rate_init': 0.07081452701504036, 'alpha': 0.6047911760631249, 'beta_2': 0.9437482683449876, 'beta_1': 0.6169654050548111, 'hidden_layer_sizes': 82, 'epsilon': 7.396640985540538e-07, 'tol': 0.0369533954569165, 'batch_size': 40, 'validation_fraction': 0.4407261646669367}]
function_evaluation time 0.121924 value 45.770673 suggestion {'learning_rate_init': 0.07081452701504036, 'alpha': 0.6047911760631249, 'beta_2': 0.9437482683449876, 'beta_1': 0.6169654050548111, 'hidden_layer_sizes': 82, 'epsilon': 7.396640985540538e-07, 'tol': 0.0369533954569165, 'batch_size': 40, 'validation_fraction': 0.4407261646669367}
observation time 0.001136, current best 43.929480 at iter 28
suggestion time taken 0.022233 iter 29 next_points [{'learning_rate_init': 0.1, 'alpha': 0.1933026605716796, 'beta_2': 0.9724389225385466, 'beta_1': 0.5, 'hidden_layer_sizes': 56, 'epsilon': 7.105529901413044e-07, 'tol': 0.0639808853592551, 'batch_size': 10, 'validation_fraction': 0.4742374392653056}]
function_evaluation time 0.209224 value 43.762748 suggestion {'learning_rate_init': 0.1, 'alpha': 0.1933026605716796, 'beta_2': 0.9724389225385466, 'beta_1': 0.5, 'hidden_layer_sizes': 56, 'epsilon': 7.105529901413044e-07, 'tol': 0.0639808853592551, 'batch_size': 10, 'validation_fraction': 0.4742374392653056}
observation time 0.002459, current best 43.762748 at iter 29
suggestion time taken 0.006042 iter 30 next_points [{'learning_rate_init': 0.08568643531087188, 'alpha': 1.3317501866599466, 'beta_2': 0.9585880820094931, 'beta_1': 0.6203222899567569, 'hidden_layer_sizes': 132, 'epsilon': 9.99999999834993e-07, 'tol': 0.04881408084637056, 'batch_size': 10, 'validation_fraction': 0.48651404908338824}]
function_evaluation time 0.267443 value 45.226253 suggestion {'learning_rate_init': 0.08568643531087188, 'alpha': 1.3317501866599466, 'beta_2': 0.9585880820094931, 'beta_1': 0.6203222899567569, 'hidden_layer_sizes': 132, 'epsilon': 9.99999999834993e-07, 'tol': 0.04881408084637056, 'batch_size': 10, 'validation_fraction': 0.48651404908338824}
observation time 0.001185, current best 43.762748 at iter 30
suggestion time taken 0.008082 iter 31 next_points [{'learning_rate_init': 0.06531552499460973, 'alpha': 0.1858479432252697, 'beta_2': 0.9983505014506102, 'beta_1': 0.5147672157646426, 'hidden_layer_sizes': 74, 'epsilon': 9.126452286406229e-07, 'tol': 0.07009692799068905, 'batch_size': 18, 'validation_fraction': 0.2994857682695429}]
function_evaluation time 0.169218 value 44.703334 suggestion {'learning_rate_init': 0.06531552499460973, 'alpha': 0.1858479432252697, 'beta_2': 0.9983505014506102, 'beta_1': 0.5147672157646426, 'hidden_layer_sizes': 74, 'epsilon': 9.126452286406229e-07, 'tol': 0.07009692799068905, 'batch_size': 18, 'validation_fraction': 0.2994857682695429}
observation time 0.001471, current best 43.762748 at iter 31
suggestion time taken 0.004296 iter 32 next_points [{'learning_rate_init': 0.07337442512002916, 'alpha': 0.4771592747917505, 'beta_2': 0.9601391359567905, 'beta_1': 0.5921480017476368, 'hidden_layer_sizes': 90, 'epsilon': 8.91367537254022e-07, 'tol': 0.08805517958264579, 'batch_size': 18, 'validation_fraction': 0.5815159346561715}]
function_evaluation time 0.176000 value 45.855174 suggestion {'learning_rate_init': 0.07337442512002916, 'alpha': 0.4771592747917505, 'beta_2': 0.9601391359567905, 'beta_1': 0.5921480017476368, 'hidden_layer_sizes': 90, 'epsilon': 8.91367537254022e-07, 'tol': 0.08805517958264579, 'batch_size': 18, 'validation_fraction': 0.5815159346561715}
observation time 0.001299, current best 43.762748 at iter 32
suggestion time taken 0.004093 iter 33 next_points [{'learning_rate_init': 0.08418813965059606, 'alpha': 0.27411316050711204, 'beta_2': 0.9742103094016799, 'beta_1': 0.6548866174983561, 'hidden_layer_sizes': 93, 'epsilon': 7.449184233071216e-07, 'tol': 0.05973873249161337, 'batch_size': 46, 'validation_fraction': 0.5919174880869361}]
function_evaluation time 0.122581 value 46.260786 suggestion {'learning_rate_init': 0.08418813965059606, 'alpha': 0.27411316050711204, 'beta_2': 0.9742103094016799, 'beta_1': 0.6548866174983561, 'hidden_layer_sizes': 93, 'epsilon': 7.449184233071216e-07, 'tol': 0.05973873249161337, 'batch_size': 46, 'validation_fraction': 0.5919174880869361}
observation time 0.001259, current best 43.762748 at iter 33
suggestion time taken 0.007529 iter 34 next_points [{'learning_rate_init': 0.09966122712281426, 'alpha': 0.2706228057662052, 'beta_2': 0.9958720340732534, 'beta_1': 0.5325870836309934, 'hidden_layer_sizes': 70, 'epsilon': 5.953931760121756e-07, 'tol': 0.05615660795859528, 'batch_size': 48, 'validation_fraction': 0.6221184709601186}]
function_evaluation time 0.096869 value 47.593787 suggestion {'learning_rate_init': 0.09966122712281426, 'alpha': 0.2706228057662052, 'beta_2': 0.9958720340732534, 'beta_1': 0.5325870836309934, 'hidden_layer_sizes': 70, 'epsilon': 5.953931760121756e-07, 'tol': 0.05615660795859528, 'batch_size': 48, 'validation_fraction': 0.6221184709601186}
observation time 0.001124, current best 43.762748 at iter 34
suggestion time taken 0.003891 iter 35 next_points [{'learning_rate_init': 0.08642401379353275, 'alpha': 0.3827926257235061, 'beta_2': 0.9720844045982755, 'beta_1': 0.6352042608549289, 'hidden_layer_sizes': 110, 'epsilon': 7.695528145007225e-07, 'tol': 0.08361715311261035, 'batch_size': 60, 'validation_fraction': 0.5803387772956049}]
function_evaluation time 0.116189 value 47.572615 suggestion {'learning_rate_init': 0.08642401379353275, 'alpha': 0.3827926257235061, 'beta_2': 0.9720844045982755, 'beta_1': 0.6352042608549289, 'hidden_layer_sizes': 110, 'epsilon': 7.695528145007225e-07, 'tol': 0.08361715311261035, 'batch_size': 60, 'validation_fraction': 0.5803387772956049}
observation time 0.001171, current best 43.762748 at iter 35
suggestion time taken 0.004225 iter 36 next_points [{'learning_rate_init': 0.08307174648142694, 'alpha': 0.025178734890450572, 'beta_2': 0.964408638451208, 'beta_1': 0.6242944980663172, 'hidden_layer_sizes': 82, 'epsilon': 6.193529721592862e-07, 'tol': 0.07472350273534405, 'batch_size': 78, 'validation_fraction': 0.5465948498417784}]
function_evaluation time 0.107729 value 48.574908 suggestion {'learning_rate_init': 0.08307174648142694, 'alpha': 0.025178734890450572, 'beta_2': 0.964408638451208, 'beta_1': 0.6242944980663172, 'hidden_layer_sizes': 82, 'epsilon': 6.193529721592862e-07, 'tol': 0.07472350273534405, 'batch_size': 78, 'validation_fraction': 0.5465948498417784}
observation time 0.001189, current best 43.762748 at iter 36
suggestion time taken 0.005373 iter 37 next_points [{'learning_rate_init': 0.08765965684833914, 'alpha': 0.36075296385053907, 'beta_2': 0.9841807144043471, 'beta_1': 0.595449113720651, 'hidden_layer_sizes': 102, 'epsilon': 7.236557170447734e-07, 'tol': 0.07604330659481799, 'batch_size': 99, 'validation_fraction': 0.6207214350248823}]
function_evaluation time 0.122935 value 49.853485 suggestion {'learning_rate_init': 0.08765965684833914, 'alpha': 0.36075296385053907, 'beta_2': 0.9841807144043471, 'beta_1': 0.595449113720651, 'hidden_layer_sizes': 102, 'epsilon': 7.236557170447734e-07, 'tol': 0.07604330659481799, 'batch_size': 99, 'validation_fraction': 0.6207214350248823}
observation time 0.003096, current best 43.762748 at iter 37
suggestion time taken 0.035378 iter 38 next_points [{'learning_rate_init': 0.08413582054998396, 'alpha': 0.2222987582194504, 'beta_2': 0.9657200940565672, 'beta_1': 0.5399994969307828, 'hidden_layer_sizes': 57, 'epsilon': 9.429202102733948e-07, 'tol': 0.0640182196343481, 'batch_size': 10, 'validation_fraction': 0.3191947188337494}]
function_evaluation time 0.248354 value 45.047503 suggestion {'learning_rate_init': 0.08413582054998396, 'alpha': 0.2222987582194504, 'beta_2': 0.9657200940565672, 'beta_1': 0.5399994969307828, 'hidden_layer_sizes': 57, 'epsilon': 9.429202102733948e-07, 'tol': 0.0640182196343481, 'batch_size': 10, 'validation_fraction': 0.3191947188337494}
observation time 0.001261, current best 43.762748 at iter 38
suggestion time taken 0.004516 iter 39 next_points [{'learning_rate_init': 0.1, 'alpha': 0.1933026605716796, 'beta_2': 0.9067897835159706, 'beta_1': 0.9481737076920764, 'hidden_layer_sizes': 56, 'epsilon': 6.990093414377108e-07, 'tol': 0.0639808853592551, 'batch_size': 10, 'validation_fraction': 0.4742374392653056}]
function_evaluation time 0.142274 value 44.292649 suggestion {'learning_rate_init': 0.1, 'alpha': 0.1933026605716796, 'beta_2': 0.9067897835159706, 'beta_1': 0.9481737076920764, 'hidden_layer_sizes': 56, 'epsilon': 6.990093414377108e-07, 'tol': 0.0639808853592551, 'batch_size': 10, 'validation_fraction': 0.4742374392653056}
observation time 0.001004, current best 43.762748 at iter 39
suggestion time taken 0.015136 iter 40 next_points [{'learning_rate_init': 0.08530916229179601, 'alpha': 0.2668095800690515, 'beta_2': 0.9718736341724938, 'beta_1': 0.5584827025274055, 'hidden_layer_sizes': 72, 'epsilon': 8.698320405347838e-07, 'tol': 0.06801157563959352, 'batch_size': 25, 'validation_fraction': 0.41970362423079377}]
function_evaluation time 0.120801 value 44.928695 suggestion {'learning_rate_init': 0.08530916229179601, 'alpha': 0.2668095800690515, 'beta_2': 0.9718736341724938, 'beta_1': 0.5584827025274055, 'hidden_layer_sizes': 72, 'epsilon': 8.698320405347838e-07, 'tol': 0.06801157563959352, 'batch_size': 25, 'validation_fraction': 0.41970362423079377}
observation time 0.001207, current best 43.762748 at iter 40
suggestion time taken 0.025670 iter 41 next_points [{'learning_rate_init': 0.09263074204181147, 'alpha': 1.1077393860291456, 'beta_2': 0.999999, 'beta_1': 0.5, 'hidden_layer_sizes': 88, 'epsilon': 9.99999999834993e-07, 'tol': 0.06423842496988479, 'batch_size': 10, 'validation_fraction': 0.4071425459617303}]
function_evaluation time 0.267911 value 44.356468 suggestion {'learning_rate_init': 0.09263074204181147, 'alpha': 1.1077393860291456, 'beta_2': 0.999999, 'beta_1': 0.5, 'hidden_layer_sizes': 88, 'epsilon': 9.99999999834993e-07, 'tol': 0.06423842496988479, 'batch_size': 10, 'validation_fraction': 0.4071425459617303}
observation time 0.001100, current best 43.762748 at iter 41
suggestion time taken 0.007393 iter 42 next_points [{'learning_rate_init': 0.08943507268815647, 'alpha': 0.657591984514902, 'beta_2': 0.9883977331326175, 'beta_1': 0.5366346335023519, 'hidden_layer_sizes': 86, 'epsilon': 9.056807496471132e-07, 'tol': 0.0677220353138978, 'batch_size': 21, 'validation_fraction': 0.45362664725507973}]
function_evaluation time 0.155066 value 44.657765 suggestion {'learning_rate_init': 0.08943507268815647, 'alpha': 0.657591984514902, 'beta_2': 0.9883977331326175, 'beta_1': 0.5366346335023519, 'hidden_layer_sizes': 86, 'epsilon': 9.056807496471132e-07, 'tol': 0.0677220353138978, 'batch_size': 21, 'validation_fraction': 0.45362664725507973}
observation time 0.001103, current best 43.762748 at iter 42
suggestion time taken 0.022170 iter 43 next_points [{'learning_rate_init': 0.1, 'alpha': 0.09238935744487568, 'beta_2': 0.9862189612692733, 'beta_1': 0.5, 'hidden_layer_sizes': 60, 'epsilon': 8.5527648444103e-07, 'tol': 0.08184054781528831, 'batch_size': 10, 'validation_fraction': 0.43645926152997805}]
function_evaluation time 0.205638 value 44.451110 suggestion {'learning_rate_init': 0.1, 'alpha': 0.09238935744487568, 'beta_2': 0.9862189612692733, 'beta_1': 0.5, 'hidden_layer_sizes': 60, 'epsilon': 8.5527648444103e-07, 'tol': 0.08184054781528831, 'batch_size': 10, 'validation_fraction': 0.43645926152997805}
observation time 0.001268, current best 43.762748 at iter 43
suggestion time taken 0.004764 iter 44 next_points [{'learning_rate_init': 0.1, 'alpha': 0.1933026605716796, 'beta_2': 0.9724389225385466, 'beta_1': 0.5, 'hidden_layer_sizes': 149, 'epsilon': 7.105529901413044e-07, 'tol': 0.07203091236477703, 'batch_size': 10, 'validation_fraction': 0.4742374392653056}]
function_evaluation time 0.269888 value 44.969836 suggestion {'learning_rate_init': 0.1, 'alpha': 0.1933026605716796, 'beta_2': 0.9724389225385466, 'beta_1': 0.5, 'hidden_layer_sizes': 149, 'epsilon': 7.105529901413044e-07, 'tol': 0.07203091236477703, 'batch_size': 10, 'validation_fraction': 0.4742374392653056}
observation time 0.001165, current best 43.762748 at iter 44
saving meta data: {'args': {'--uuid': '36865190d1ce5f6bae091ea9f6bffc1a', '-db-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230815_180041', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

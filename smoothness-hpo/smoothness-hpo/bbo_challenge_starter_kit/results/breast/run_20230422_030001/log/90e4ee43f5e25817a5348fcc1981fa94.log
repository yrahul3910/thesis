running: {'--uuid': '90e4ee43f5e25817a5348fcc1981fa94', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'turbo', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d breast -o turbo -u 90e4ee43f5e25817a5348fcc1981fa94 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230422_030001
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_acc betwen [-0.80659341 -0.56703297 -0.66593407 -0.87912088 -0.85934066] and [-0.67692308 -0.41758242 -0.54505495 -0.78241758 -0.84395604]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_breast_acc  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
max                  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
starting sklearn study turbo MLP-adam breast acc 15 1
with data root: None
suggestion time taken 0.002419 iter 0 next_points [{'alpha': 0.009706771956468697, 'batch_size': 116, 'beta_1': 0.9620101952343427, 'beta_2': 0.9977622517011921, 'epsilon': 3.212376165928428e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.07896441775956765, 'tol': 0.00010356211636524427, 'validation_fraction': 0.8906157268502487}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.132297 value -0.753846 suggestion {'alpha': 0.009706771956468697, 'batch_size': 116, 'beta_1': 0.9620101952343427, 'beta_2': 0.9977622517011921, 'epsilon': 3.212376165928428e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.07896441775956765, 'tol': 0.00010356211636524427, 'validation_fraction': 0.8906157268502487}
observation time 0.001468, current best -0.753846 at iter 0
suggestion time taken 0.001826 iter 1 next_points [{'alpha': 2.891948765891694e-05, 'batch_size': 199, 'beta_1': 0.9459728386022008, 'beta_2': 0.9998404208316669, 'epsilon': 1.0919335975281176e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 5.625648384471782e-05, 'tol': 0.04342401241035723, 'validation_fraction': 0.6314175184358398}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.116640 value -0.586813 suggestion {'alpha': 2.891948765891694e-05, 'batch_size': 199, 'beta_1': 0.9459728386022008, 'beta_2': 0.9998404208316669, 'epsilon': 1.0919335975281176e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 5.625648384471782e-05, 'tol': 0.04342401241035723, 'validation_fraction': 0.6314175184358398}
observation time 0.001443, current best -0.753846 at iter 1
suggestion time taken 0.001749 iter 2 next_points [{'alpha': 1.844711777979815e-05, 'batch_size': 181, 'beta_1': 0.8614605429518738, 'beta_2': 0.9999878007250059, 'epsilon': 6.518692403904858e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.0005625106352807625, 'tol': 0.010186765947602105, 'validation_fraction': 0.5068010534434687}]
function_evaluation time 0.252119 value -0.793407 suggestion {'alpha': 1.844711777979815e-05, 'batch_size': 181, 'beta_1': 0.8614605429518738, 'beta_2': 0.9999878007250059, 'epsilon': 6.518692403904858e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.0005625106352807625, 'tol': 0.010186765947602105, 'validation_fraction': 0.5068010534434687}
observation time 0.001418, current best -0.793407 at iter 2
suggestion time taken 0.001730 iter 3 next_points [{'alpha': 0.0002243210791922385, 'batch_size': 52, 'beta_1': 0.9111417535683864, 'beta_2': 0.913141362787703, 'epsilon': 1.3881616612115698e-07, 'hidden_layer_sizes': 198, 'learning_rate_init': 9.877341778135972e-05, 'tol': 0.002706172311776185, 'validation_fraction': 0.47066372871413154}]
function_evaluation time 0.366395 value -0.690110 suggestion {'alpha': 0.0002243210791922385, 'batch_size': 52, 'beta_1': 0.9111417535683864, 'beta_2': 0.913141362787703, 'epsilon': 1.3881616612115698e-07, 'hidden_layer_sizes': 198, 'learning_rate_init': 9.877341778135972e-05, 'tol': 0.002706172311776185, 'validation_fraction': 0.47066372871413154}
observation time 0.001580, current best -0.793407 at iter 3
suggestion time taken 0.001730 iter 4 next_points [{'alpha': 0.001453365417260273, 'batch_size': 151, 'beta_1': 0.6705270062727978, 'beta_2': 0.9999597912488836, 'epsilon': 1.5402471137529448e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.00016430742735039404, 'tol': 0.0007260926319888091, 'validation_fraction': 0.1747436246082766}]
function_evaluation time 0.238788 value -0.782418 suggestion {'alpha': 0.001453365417260273, 'batch_size': 151, 'beta_1': 0.6705270062727978, 'beta_2': 0.9999597912488836, 'epsilon': 1.5402471137529448e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.00016430742735039404, 'tol': 0.0007260926319888091, 'validation_fraction': 0.1747436246082766}
observation time 0.001387, current best -0.793407 at iter 4
suggestion time taken 0.001771 iter 5 next_points [{'alpha': 0.0026474190128025804, 'batch_size': 168, 'beta_1': 0.7238249487661611, 'beta_2': 0.9999925257417873, 'epsilon': 5.479052718526873e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.016170140769040383, 'tol': 0.03236278471537939, 'validation_fraction': 0.7543103702202244}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.138314 value -0.907692 suggestion {'alpha': 0.0026474190128025804, 'batch_size': 168, 'beta_1': 0.7238249487661611, 'beta_2': 0.9999925257417873, 'epsilon': 5.479052718526873e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.016170140769040383, 'tol': 0.03236278471537939, 'validation_fraction': 0.7543103702202244}
observation time 0.001405, current best -0.907692 at iter 5
suggestion time taken 0.001782 iter 6 next_points [{'alpha': 0.0004216926033257807, 'batch_size': 249, 'beta_1': 0.9755281456776802, 'beta_2': 0.9999232719664469, 'epsilon': 4.724322204889398e-08, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.03756894407960978, 'tol': 0.006201613762608738, 'validation_fraction': 0.40720675073247653}]
function_evaluation time 0.219615 value -0.876923 suggestion {'alpha': 0.0004216926033257807, 'batch_size': 249, 'beta_1': 0.9755281456776802, 'beta_2': 0.9999232719664469, 'epsilon': 4.724322204889398e-08, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.03756894407960978, 'tol': 0.006201613762608738, 'validation_fraction': 0.40720675073247653}
observation time 0.001383, current best -0.907692 at iter 6
suggestion time taken 0.001769 iter 7 next_points [{'alpha': 1.594369869392431, 'batch_size': 64, 'beta_1': 0.8209022855323086, 'beta_2': 0.9747843983014338, 'epsilon': 2.0353868008024465e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 3.8766914737941414e-05, 'tol': 1.0001102592679941e-05, 'validation_fraction': 0.10796160016075713}]
function_evaluation time 0.243411 value -0.545055 suggestion {'alpha': 1.594369869392431, 'batch_size': 64, 'beta_1': 0.8209022855323086, 'beta_2': 0.9747843983014338, 'epsilon': 2.0353868008024465e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 3.8766914737941414e-05, 'tol': 1.0001102592679941e-05, 'validation_fraction': 0.10796160016075713}
observation time 0.001426, current best -0.907692 at iter 7
suggestion time taken 0.001796 iter 8 next_points [{'alpha': 0.08157232041100973, 'batch_size': 38, 'beta_1': 0.9797563841407501, 'beta_2': 0.9963106450499177, 'epsilon': 4.184933280763109e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.01262561399030488, 'tol': 0.0014212211642649335, 'validation_fraction': 0.1425649913909639}]
function_evaluation time 0.347539 value -0.909890 suggestion {'alpha': 0.08157232041100973, 'batch_size': 38, 'beta_1': 0.9797563841407501, 'beta_2': 0.9963106450499177, 'epsilon': 4.184933280763109e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.01262561399030488, 'tol': 0.0014212211642649335, 'validation_fraction': 0.1425649913909639}
observation time 0.001415, current best -0.909890 at iter 8
suggestion time taken 0.001707 iter 9 next_points [{'alpha': 0.032425905749619635, 'batch_size': 225, 'beta_1': 0.8061876405792188, 'beta_2': 0.999998801532587, 'epsilon': 2.7398914846247347e-09, 'hidden_layer_sizes': 132, 'learning_rate_init': 2.5833506386426574e-05, 'tol': 0.07840048870826609, 'validation_fraction': 0.21541848430051996}]
function_evaluation time 0.133596 value -0.472527 suggestion {'alpha': 0.032425905749619635, 'batch_size': 225, 'beta_1': 0.8061876405792188, 'beta_2': 0.999998801532587, 'epsilon': 2.7398914846247347e-09, 'hidden_layer_sizes': 132, 'learning_rate_init': 2.5833506386426574e-05, 'tol': 0.07840048870826609, 'validation_fraction': 0.21541848430051996}
observation time 0.001390, current best -0.909890 at iter 9
suggestion time taken 0.001717 iter 10 next_points [{'alpha': 4.45473753804581, 'batch_size': 208, 'beta_1': 0.9897446226894455, 'beta_2': 0.9596803985106843, 'epsilon': 7.112890168892676e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.00037099315012463155, 'tol': 0.00023231907648934102, 'validation_fraction': 0.32280534046312775}]
function_evaluation time 0.175943 value -0.637363 suggestion {'alpha': 4.45473753804581, 'batch_size': 208, 'beta_1': 0.9897446226894455, 'beta_2': 0.9596803985106843, 'epsilon': 7.112890168892676e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.00037099315012463155, 'tol': 0.00023231907648934102, 'validation_fraction': 0.32280534046312775}
observation time 0.001415, current best -0.909890 at iter 10
suggestion time taken 0.001723 iter 11 next_points [{'alpha': 0.026449186184531133, 'batch_size': 13, 'beta_1': 0.726018768704029, 'beta_2': 0.9992393818550303, 'epsilon': 1.2431765261647304e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.001655463599956691, 'tol': 0.00015192245018311244, 'validation_fraction': 0.6637391144715361}]
function_evaluation time 0.545033 value -0.912088 suggestion {'alpha': 0.026449186184531133, 'batch_size': 13, 'beta_1': 0.726018768704029, 'beta_2': 0.9992393818550303, 'epsilon': 1.2431765261647304e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.001655463599956691, 'tol': 0.00015192245018311244, 'validation_fraction': 0.6637391144715361}
observation time 0.001400, current best -0.912088 at iter 11
suggestion time taken 0.002055 iter 12 next_points [{'alpha': 0.1477251962564143, 'batch_size': 31, 'beta_1': 0.5797630247131713, 'beta_2': 0.9987806846169958, 'epsilon': 1.5701253318469017e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0061466937760436095, 'tol': 0.017116592468991807, 'validation_fraction': 0.8007811200269263}]
function_evaluation time 0.185963 value -0.907692 suggestion {'alpha': 0.1477251962564143, 'batch_size': 31, 'beta_1': 0.5797630247131713, 'beta_2': 0.9987806846169958, 'epsilon': 1.5701253318469017e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0061466937760436095, 'tol': 0.017116592468991807, 'validation_fraction': 0.8007811200269263}
observation time 0.001387, current best -0.912088 at iter 12
suggestion time taken 0.001790 iter 13 next_points [{'alpha': 4.8862697910590994e-05, 'batch_size': 76, 'beta_1': 0.5141803054145357, 'beta_2': 0.9999950093507115, 'epsilon': 1.8296984837614783e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.002806013766236614, 'tol': 3.869404200800017e-05, 'validation_fraction': 0.8628772744491365}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.186153 value -0.892308 suggestion {'alpha': 4.8862697910590994e-05, 'batch_size': 76, 'beta_1': 0.5141803054145357, 'beta_2': 0.9999950093507115, 'epsilon': 1.8296984837614783e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.002806013766236614, 'tol': 3.869404200800017e-05, 'validation_fraction': 0.8628772744491365}
observation time 0.001367, current best -0.912088 at iter 13
suggestion time taken 0.001773 iter 14 next_points [{'alpha': 6.329145587589542, 'batch_size': 105, 'beta_1': 0.9504228612370583, 'beta_2': 0.9895287691887649, 'epsilon': 6.638100318076925e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.0008115189543021647, 'tol': 2.0288089587755654e-05, 'validation_fraction': 0.23735544785984017}]
function_evaluation time 0.348269 value -0.907692 suggestion {'alpha': 6.329145587589542, 'batch_size': 105, 'beta_1': 0.9504228612370583, 'beta_2': 0.9895287691887649, 'epsilon': 6.638100318076925e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.0008115189543021647, 'tol': 2.0288089587755654e-05, 'validation_fraction': 0.23735544785984017}
observation time 0.001673, current best -0.912088 at iter 14
saving meta data: {'args': {'--uuid': '90e4ee43f5e25817a5348fcc1981fa94', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'turbo', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '33e0c6bce3055dccb3f7caa8d4e66904', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d breast -o hyperopt -u 33e0c6bce3055dccb3f7caa8d4e66904 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230422_030001
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_nll betwen [ 4.58589285 14.6438765   8.74044796  0.67466158  3.06872636] and [ 8.10456652 20.07092365 12.33228572  5.26978359  3.49043108]
  warnings.warn(

Signature errors:
                            0         1         2         3         4       max
MLP-adam_breast_nll  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
max                  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
starting sklearn study hyperopt MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.002382 iter 0 next_points [{'alpha': 0.00016338810418321703, 'batch_size': 250, 'beta_1': 0.9668337012435195, 'beta_2': 0.9839672700134705, 'epsilon': 1.6745096100101672e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0004740814101350176, 'tol': 0.016570737582001345, 'validation_fraction': 0.3416819801066722}]
function_evaluation time 0.167478 value 12.330206 suggestion {'alpha': 0.00016338810418321703, 'batch_size': 250, 'beta_1': 0.9668337012435195, 'beta_2': 0.9839672700134705, 'epsilon': 1.6745096100101672e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0004740814101350176, 'tol': 0.016570737582001345, 'validation_fraction': 0.3416819801066722}
observation time 0.000066, current best 12.330206 at iter 0
suggestion time taken 0.002403 iter 1 next_points [{'alpha': 0.02502021315285606, 'batch_size': 63, 'beta_1': 0.9003017252256662, 'beta_2': 0.9679334022731109, 'epsilon': 2.1546508753230027e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.05261129681599045, 'tol': 1.0342187181858135e-05, 'validation_fraction': 0.1310368510081977}]
function_evaluation time 0.223381 value 0.340681 suggestion {'alpha': 0.02502021315285606, 'batch_size': 63, 'beta_1': 0.9003017252256662, 'beta_2': 0.9679334022731109, 'epsilon': 2.1546508753230027e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.05261129681599045, 'tol': 1.0342187181858135e-05, 'validation_fraction': 0.1310368510081977}
observation time 0.000067, current best 0.340681 at iter 1
suggestion time taken 0.002342 iter 2 next_points [{'alpha': 0.1689557083908229, 'batch_size': 22, 'beta_1': 0.6853798286854397, 'beta_2': 0.9287240931139915, 'epsilon': 1.3144894198774743e-08, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.029504136593712708, 'tol': 0.012307552303868928, 'validation_fraction': 0.3767331505303166}]
function_evaluation time 0.415763 value 0.742574 suggestion {'alpha': 0.1689557083908229, 'batch_size': 22, 'beta_1': 0.6853798286854397, 'beta_2': 0.9287240931139915, 'epsilon': 1.3144894198774743e-08, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.029504136593712708, 'tol': 0.012307552303868928, 'validation_fraction': 0.3767331505303166}
observation time 0.000080, current best 0.340681 at iter 2
suggestion time taken 0.002157 iter 3 next_points [{'alpha': 0.06019693954148978, 'batch_size': 75, 'beta_1': 0.6351311583534175, 'beta_2': 0.905498113120938, 'epsilon': 2.0779703377850716e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.011177717196549182, 'tol': 2.433735975126306e-05, 'validation_fraction': 0.2668819953947436}]
function_evaluation time 0.324929 value 1.036754 suggestion {'alpha': 0.06019693954148978, 'batch_size': 75, 'beta_1': 0.6351311583534175, 'beta_2': 0.905498113120938, 'epsilon': 2.0779703377850716e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.011177717196549182, 'tol': 2.433735975126306e-05, 'validation_fraction': 0.2668819953947436}
observation time 0.000079, current best 0.340681 at iter 3
suggestion time taken 0.002141 iter 4 next_points [{'alpha': 0.004544691934516599, 'batch_size': 75, 'beta_1': 0.6602644238653864, 'beta_2': 0.9580920715696669, 'epsilon': 8.35483374078683e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.007952276083190553, 'tol': 0.0039767269618546435, 'validation_fraction': 0.4945470914794537}]
function_evaluation time 0.300045 value 0.517309 suggestion {'alpha': 0.004544691934516599, 'batch_size': 75, 'beta_1': 0.6602644238653864, 'beta_2': 0.9580920715696669, 'epsilon': 8.35483374078683e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.007952276083190553, 'tol': 0.0039767269618546435, 'validation_fraction': 0.4945470914794537}
observation time 0.000067, current best 0.340681 at iter 4
suggestion time taken 0.002113 iter 5 next_points [{'alpha': 3.597159362104221, 'batch_size': 233, 'beta_1': 0.7847052535632799, 'beta_2': 0.9464215478621804, 'epsilon': 3.248048574421603e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.028620275744767526, 'tol': 0.00014984843562661386, 'validation_fraction': 0.38346737745716736}]
function_evaluation time 0.263654 value 0.596316 suggestion {'alpha': 3.597159362104221, 'batch_size': 233, 'beta_1': 0.7847052535632799, 'beta_2': 0.9464215478621804, 'epsilon': 3.248048574421603e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.028620275744767526, 'tol': 0.00014984843562661386, 'validation_fraction': 0.38346737745716736}
observation time 0.000068, current best 0.340681 at iter 5
suggestion time taken 0.002127 iter 6 next_points [{'alpha': 6.329969144117679, 'batch_size': 35, 'beta_1': 0.6619925417370134, 'beta_2': 0.9995821159266629, 'epsilon': 1.5216232762180464e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.061458381359861335, 'tol': 0.04005691558888007, 'validation_fraction': 0.23169670185429034}]
function_evaluation time 0.287154 value 0.502866 suggestion {'alpha': 6.329969144117679, 'batch_size': 35, 'beta_1': 0.6619925417370134, 'beta_2': 0.9995821159266629, 'epsilon': 1.5216232762180464e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.061458381359861335, 'tol': 0.04005691558888007, 'validation_fraction': 0.23169670185429034}
observation time 0.000062, current best 0.340681 at iter 6
suggestion time taken 0.002173 iter 7 next_points [{'alpha': 0.0011645746927036094, 'batch_size': 68, 'beta_1': 0.7990984890218011, 'beta_2': 0.9009775334004299, 'epsilon': 2.8794676675035926e-08, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.009195402105218232, 'tol': 0.005275001459581513, 'validation_fraction': 0.4956398273294289}]
function_evaluation time 0.263860 value 1.151903 suggestion {'alpha': 0.0011645746927036094, 'batch_size': 68, 'beta_1': 0.7990984890218011, 'beta_2': 0.9009775334004299, 'epsilon': 2.8794676675035926e-08, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.009195402105218232, 'tol': 0.005275001459581513, 'validation_fraction': 0.4956398273294289}
observation time 0.000072, current best 0.340681 at iter 7
suggestion time taken 0.002330 iter 8 next_points [{'alpha': 0.019302776698099152, 'batch_size': 50, 'beta_1': 0.7017350536188337, 'beta_2': 0.9166117084950184, 'epsilon': 4.380087763056776e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 2.1001849822114976e-05, 'tol': 4.884027529220361e-05, 'validation_fraction': 0.15808472849240462}]
function_evaluation time 0.165312 value 17.494590 suggestion {'alpha': 0.019302776698099152, 'batch_size': 50, 'beta_1': 0.7017350536188337, 'beta_2': 0.9166117084950184, 'epsilon': 4.380087763056776e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 2.1001849822114976e-05, 'tol': 4.884027529220361e-05, 'validation_fraction': 0.15808472849240462}
observation time 0.000072, current best 0.340681 at iter 8
suggestion time taken 0.002147 iter 9 next_points [{'alpha': 0.01817595048013119, 'batch_size': 45, 'beta_1': 0.5293699022391689, 'beta_2': 0.9669071562707288, 'epsilon': 3.1367207018382623e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.00013433014459294108, 'tol': 2.925201000492565e-05, 'validation_fraction': 0.2684966676626682}]
function_evaluation time 0.250889 value 9.951366 suggestion {'alpha': 0.01817595048013119, 'batch_size': 45, 'beta_1': 0.5293699022391689, 'beta_2': 0.9669071562707288, 'epsilon': 3.1367207018382623e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.00013433014459294108, 'tol': 2.925201000492565e-05, 'validation_fraction': 0.2684966676626682}
observation time 0.000068, current best 0.340681 at iter 9
suggestion time taken 0.002150 iter 10 next_points [{'alpha': 0.10458322253275804, 'batch_size': 51, 'beta_1': 0.5123364413472057, 'beta_2': 0.9261512391430402, 'epsilon': 4.8473113802352846e-08, 'hidden_layer_sizes': 124, 'learning_rate_init': 8.46686281475001e-05, 'tol': 0.007877893428350161, 'validation_fraction': 0.5893099771990954}]
function_evaluation time 0.205186 value 7.274063 suggestion {'alpha': 0.10458322253275804, 'batch_size': 51, 'beta_1': 0.5123364413472057, 'beta_2': 0.9261512391430402, 'epsilon': 4.8473113802352846e-08, 'hidden_layer_sizes': 124, 'learning_rate_init': 8.46686281475001e-05, 'tol': 0.007877893428350161, 'validation_fraction': 0.5893099771990954}
observation time 0.000072, current best 0.340681 at iter 10
suggestion time taken 0.002125 iter 11 next_points [{'alpha': 2.5386259730764955, 'batch_size': 205, 'beta_1': 0.6599626009683321, 'beta_2': 0.9304652786831527, 'epsilon': 9.29156253611895e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.00022464229579685472, 'tol': 6.584459733105235e-05, 'validation_fraction': 0.6620768767246675}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.091849 value 17.029527 suggestion {'alpha': 2.5386259730764955, 'batch_size': 205, 'beta_1': 0.6599626009683321, 'beta_2': 0.9304652786831527, 'epsilon': 9.29156253611895e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.00022464229579685472, 'tol': 6.584459733105235e-05, 'validation_fraction': 0.6620768767246675}
observation time 0.000070, current best 0.340681 at iter 11
suggestion time taken 0.002346 iter 12 next_points [{'alpha': 8.361594476483926, 'batch_size': 181, 'beta_1': 0.6431662179334727, 'beta_2': 0.929940152463502, 'epsilon': 6.993688495080656e-08, 'hidden_layer_sizes': 127, 'learning_rate_init': 1.818397204611973e-05, 'tol': 0.004189232803092894, 'validation_fraction': 0.19047842786973831}]
function_evaluation time 0.142700 value 19.718512 suggestion {'alpha': 8.361594476483926, 'batch_size': 181, 'beta_1': 0.6431662179334727, 'beta_2': 0.929940152463502, 'epsilon': 6.993688495080656e-08, 'hidden_layer_sizes': 127, 'learning_rate_init': 1.818397204611973e-05, 'tol': 0.004189232803092894, 'validation_fraction': 0.19047842786973831}
observation time 0.000074, current best 0.340681 at iter 12
suggestion time taken 0.002386 iter 13 next_points [{'alpha': 0.000409498088749805, 'batch_size': 157, 'beta_1': 0.6335560518545224, 'beta_2': 0.9009512963513099, 'epsilon': 4.283315989552474e-07, 'hidden_layer_sizes': 174, 'learning_rate_init': 9.229071947537515e-05, 'tol': 0.00044022282720567753, 'validation_fraction': 0.8775407026933287}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.107270 value 10.536392 suggestion {'alpha': 0.000409498088749805, 'batch_size': 157, 'beta_1': 0.6335560518545224, 'beta_2': 0.9009512963513099, 'epsilon': 4.283315989552474e-07, 'hidden_layer_sizes': 174, 'learning_rate_init': 9.229071947537515e-05, 'tol': 0.00044022282720567753, 'validation_fraction': 0.8775407026933287}
observation time 0.000075, current best 0.340681 at iter 13
suggestion time taken 0.002150 iter 14 next_points [{'alpha': 4.396127139359363, 'batch_size': 107, 'beta_1': 0.6499474599545297, 'beta_2': 0.9334974577480977, 'epsilon': 4.711517270326917e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 1.061004326325597e-05, 'tol': 0.009747307445033852, 'validation_fraction': 0.2915136842478755}]
function_evaluation time 0.137074 value 15.577014 suggestion {'alpha': 4.396127139359363, 'batch_size': 107, 'beta_1': 0.6499474599545297, 'beta_2': 0.9334974577480977, 'epsilon': 4.711517270326917e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 1.061004326325597e-05, 'tol': 0.009747307445033852, 'validation_fraction': 0.2915136842478755}
observation time 0.000070, current best 0.340681 at iter 14
saving meta data: {'args': {'--uuid': '33e0c6bce3055dccb3f7caa8d4e66904', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])}
saving results
saving timing
saving suggest log
done

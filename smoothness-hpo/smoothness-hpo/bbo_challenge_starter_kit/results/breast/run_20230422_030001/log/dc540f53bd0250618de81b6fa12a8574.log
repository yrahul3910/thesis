running: {'--uuid': 'dc540f53bd0250618de81b6fa12a8574', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'turbo', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d breast -o turbo -u dc540f53bd0250618de81b6fa12a8574 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230422_030001
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_nll betwen [ 4.58589285 14.6438765   8.74044796  0.67466158  3.06872636] and [ 8.10456652 20.07092365 12.33228572  5.26978359  3.49043108]
  warnings.warn(

Signature errors:
                            0         1         2         3         4       max
MLP-adam_breast_nll  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
max                  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
starting sklearn study turbo MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.002392 iter 0 next_points [{'alpha': 3.117539527190507e-05, 'batch_size': 181, 'beta_1': 0.584460700713992, 'beta_2': 0.999995264281994, 'epsilon': 7.027150992926942e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.013213223641224129, 'tol': 0.00010268763477416761, 'validation_fraction': 0.8071228594778069}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.207416 value 0.849501 suggestion {'alpha': 3.117539527190507e-05, 'batch_size': 181, 'beta_1': 0.584460700713992, 'beta_2': 0.999995264281994, 'epsilon': 7.027150992926942e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.013213223641224129, 'tol': 0.00010268763477416761, 'validation_fraction': 0.8071228594778069}
observation time 0.001383, current best 0.849501 at iter 0
suggestion time taken 0.001749 iter 1 next_points [{'alpha': 0.0021078339151741465, 'batch_size': 225, 'beta_1': 0.9618056880000295, 'beta_2': 0.9999808232931062, 'epsilon': 1.757276253662376e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 4.40011564037692e-05, 'tol': 0.011123396531977942, 'validation_fraction': 0.1371257319158559}]
function_evaluation time 0.191761 value 14.271479 suggestion {'alpha': 0.0021078339151741465, 'batch_size': 225, 'beta_1': 0.9618056880000295, 'beta_2': 0.9999808232931062, 'epsilon': 1.757276253662376e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 4.40011564037692e-05, 'tol': 0.011123396531977942, 'validation_fraction': 0.1371257319158559}
observation time 0.001396, current best 0.849501 at iter 1
suggestion time taken 0.001781 iter 2 next_points [{'alpha': 0.00479785981586268, 'batch_size': 72, 'beta_1': 0.9341855099500213, 'beta_2': 0.9964237044824332, 'epsilon': 2.595386802305183e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0005691478480083383, 'tol': 1.4858411579597385e-05, 'validation_fraction': 0.19484882277332044}]
function_evaluation time 0.266745 value 3.193100 suggestion {'alpha': 0.00479785981586268, 'batch_size': 72, 'beta_1': 0.9341855099500213, 'beta_2': 0.9964237044824332, 'epsilon': 2.595386802305183e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0005691478480083383, 'tol': 1.4858411579597385e-05, 'validation_fraction': 0.19484882277332044}
observation time 0.001370, current best 0.849501 at iter 2
suggestion time taken 0.001754 iter 3 next_points [{'alpha': 0.018838879771469353, 'batch_size': 165, 'beta_1': 0.9894827993629279, 'beta_2': 0.9999153089635844, 'epsilon': 6.258983773637218e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.047352368302336995, 'tol': 0.0018141537821983065, 'validation_fraction': 0.10592088284897071}]
function_evaluation time 0.240965 value 4.358977 suggestion {'alpha': 0.018838879771469353, 'batch_size': 165, 'beta_1': 0.9894827993629279, 'beta_2': 0.9999153089635844, 'epsilon': 6.258983773637218e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.047352368302336995, 'tol': 0.0018141537821983065, 'validation_fraction': 0.10592088284897071}
observation time 0.001328, current best 0.849501 at iter 3
suggestion time taken 0.001731 iter 4 next_points [{'alpha': 0.0007598136169823243, 'batch_size': 151, 'beta_1': 0.9390280117892325, 'beta_2': 0.9483648733943045, 'epsilon': 2.7985596034977862e-08, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.008283562504171187, 'tol': 3.092129047775148e-05, 'validation_fraction': 0.4921020721269258}]
function_evaluation time 0.281902 value 0.923134 suggestion {'alpha': 0.0007598136169823243, 'batch_size': 151, 'beta_1': 0.9390280117892325, 'beta_2': 0.9483648733943045, 'epsilon': 2.7985596034977862e-08, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.008283562504171187, 'tol': 3.092129047775148e-05, 'validation_fraction': 0.4921020721269258}
observation time 0.001335, current best 0.849501 at iter 4
suggestion time taken 0.001729 iter 5 next_points [{'alpha': 9.545978732270111, 'batch_size': 145, 'beta_1': 0.9705599935550842, 'beta_2': 0.9226738756767476, 'epsilon': 5.081950608781082e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 2.4720000554854333e-05, 'tol': 0.00022906612530512773, 'validation_fraction': 0.8369286849844354}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.117828 value 14.410227 suggestion {'alpha': 9.545978732270111, 'batch_size': 145, 'beta_1': 0.9705599935550842, 'beta_2': 0.9226738756767476, 'epsilon': 5.081950608781082e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 2.4720000554854333e-05, 'tol': 0.00022906612530512773, 'validation_fraction': 0.8369286849844354}
observation time 0.001376, current best 0.849501 at iter 5
suggestion time taken 0.002040 iter 6 next_points [{'alpha': 0.07738936898099243, 'batch_size': 111, 'beta_1': 0.8094697601829483, 'beta_2': 0.9990525647439628, 'epsilon': 9.550582522811007e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0002040403089889066, 'tol': 0.00014949354153996456, 'validation_fraction': 0.5314245887684503}]
function_evaluation time 0.171296 value 17.031616 suggestion {'alpha': 0.07738936898099243, 'batch_size': 111, 'beta_1': 0.8094697601829483, 'beta_2': 0.9990525647439628, 'epsilon': 9.550582522811007e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0002040403089889066, 'tol': 0.00014949354153996456, 'validation_fraction': 0.5314245887684503}
observation time 0.001335, current best 0.849501 at iter 6
suggestion time taken 0.001982 iter 7 next_points [{'alpha': 9.237298588051079e-05, 'batch_size': 55, 'beta_1': 0.9490856145666515, 'beta_2': 0.9782944982834283, 'epsilon': 9.67581826973367e-07, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.0013374417017631992, 'tol': 0.0011623367972864586, 'validation_fraction': 0.4696004725888328}]
function_evaluation time 0.348108 value 0.465009 suggestion {'alpha': 9.237298588051079e-05, 'batch_size': 55, 'beta_1': 0.9490856145666515, 'beta_2': 0.9782944982834283, 'epsilon': 9.67581826973367e-07, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.0013374417017631992, 'tol': 0.0011623367972864586, 'validation_fraction': 0.4696004725888328}
observation time 0.001316, current best 0.465009 at iter 7
suggestion time taken 0.001719 iter 8 next_points [{'alpha': 0.0002434387378163511, 'batch_size': 42, 'beta_1': 0.8887718293074209, 'beta_2': 0.9995962738155184, 'epsilon': 2.7190271338944636e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.00212325452639319, 'tol': 0.00039428333857187284, 'validation_fraction': 0.2277612625903604}]
function_evaluation time 0.427228 value 0.439623 suggestion {'alpha': 0.0002434387378163511, 'batch_size': 42, 'beta_1': 0.8887718293074209, 'beta_2': 0.9995962738155184, 'epsilon': 2.7190271338944636e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.00212325452639319, 'tol': 0.00039428333857187284, 'validation_fraction': 0.2277612625903604}
observation time 0.001349, current best 0.439623 at iter 8
suggestion time taken 0.001662 iter 9 next_points [{'alpha': 1.8107356077372705, 'batch_size': 211, 'beta_1': 0.9866003333691381, 'beta_2': 0.9999936522354119, 'epsilon': 6.875546047153562e-07, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.020702653462048942, 'tol': 0.002183674412709162, 'validation_fraction': 0.887447058604401}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.233552 value 1.312539 suggestion {'alpha': 1.8107356077372705, 'batch_size': 211, 'beta_1': 0.9866003333691381, 'beta_2': 0.9999936522354119, 'epsilon': 6.875546047153562e-07, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.020702653462048942, 'tol': 0.002183674412709162, 'validation_fraction': 0.887447058604401}
observation time 0.001342, current best 0.439623 at iter 9
suggestion time taken 0.001702 iter 10 next_points [{'alpha': 0.13007021058286075, 'batch_size': 34, 'beta_1': 0.8226069862945856, 'beta_2': 0.9861868640976723, 'epsilon': 4.0273369010785394e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.025299298751507916, 'tol': 0.005965068736321074, 'validation_fraction': 0.35508208191817725}]
function_evaluation time 0.516566 value 0.475137 suggestion {'alpha': 0.13007021058286075, 'batch_size': 34, 'beta_1': 0.8226069862945856, 'beta_2': 0.9861868640976723, 'epsilon': 4.0273369010785394e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.025299298751507916, 'tol': 0.005965068736321074, 'validation_fraction': 0.35508208191817725}
observation time 0.001379, current best 0.439623 at iter 10
suggestion time taken 0.002013 iter 11 next_points [{'alpha': 0.6011800595400784, 'batch_size': 90, 'beta_1': 0.9800243744122198, 'beta_2': 0.9994182830013562, 'epsilon': 1.5658342459286303e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.00011107901908592838, 'tol': 0.019274146097685255, 'validation_fraction': 0.8647665069900644}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.084886 value 13.203819 suggestion {'alpha': 0.6011800595400784, 'batch_size': 90, 'beta_1': 0.9800243744122198, 'beta_2': 0.9994182830013562, 'epsilon': 1.5658342459286303e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.00011107901908592838, 'tol': 0.019274146097685255, 'validation_fraction': 0.8647665069900644}
observation time 0.001334, current best 0.439623 at iter 11
suggestion time taken 0.001705 iter 12 next_points [{'alpha': 1.0637105296350337e-05, 'batch_size': 125, 'beta_1': 0.6890012068614514, 'beta_2': 0.993037915435006, 'epsilon': 1.898845701326403e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.09017337276997431, 'tol': 0.027661415848234613, 'validation_fraction': 0.37679423581278176}]
function_evaluation time 0.171079 value 0.410598 suggestion {'alpha': 1.0637105296350337e-05, 'batch_size': 125, 'beta_1': 0.6890012068614514, 'beta_2': 0.993037915435006, 'epsilon': 1.898845701326403e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.09017337276997431, 'tol': 0.027661415848234613, 'validation_fraction': 0.37679423581278176}
observation time 0.001301, current best 0.410598 at iter 12
suggestion time taken 0.001676 iter 13 next_points [{'alpha': 7.554263568265914e-05, 'batch_size': 231, 'beta_1': 0.9756407893666997, 'beta_2': 0.9999988447676634, 'epsilon': 1.1604218232257923e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.00016478405808573133, 'tol': 0.09073931568132888, 'validation_fraction': 0.16745622255379497}]
function_evaluation time 0.169742 value 7.786596 suggestion {'alpha': 7.554263568265914e-05, 'batch_size': 231, 'beta_1': 0.9756407893666997, 'beta_2': 0.9999988447676634, 'epsilon': 1.1604218232257923e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.00016478405808573133, 'tol': 0.09073931568132888, 'validation_fraction': 0.16745622255379497}
observation time 0.001403, current best 0.410598 at iter 13
suggestion time taken 0.001736 iter 14 next_points [{'alpha': 3.1635818068113872, 'batch_size': 15, 'beta_1': 0.8540140135485694, 'beta_2': 0.9997991153133712, 'epsilon': 5.343922361807505e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 1.2454879503951792e-05, 'tol': 4.3086836323990096e-05, 'validation_fraction': 0.7618278683430295}]
function_evaluation time 0.180268 value 15.107929 suggestion {'alpha': 3.1635818068113872, 'batch_size': 15, 'beta_1': 0.8540140135485694, 'beta_2': 0.9997991153133712, 'epsilon': 5.343922361807505e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 1.2454879503951792e-05, 'tol': 4.3086836323990096e-05, 'validation_fraction': 0.7618278683430295}
observation time 0.001349, current best 0.410598 at iter 14
saving meta data: {'args': {'--uuid': 'dc540f53bd0250618de81b6fa12a8574', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'turbo', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])}
saving results
saving timing
saving suggest log
done

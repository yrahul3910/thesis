running: {'--uuid': 'ffb1624e6b3f57cdb7b79d051b835510', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'smoothness', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d breast -o smoothness -u ffb1624e6b3f57cdb7b79d051b835510 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230422_030001
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_acc betwen [-0.80659341 -0.56703297 -0.66593407 -0.87912088 -0.85934066] and [-0.67692308 -0.41758242 -0.54505495 -0.78241758 -0.84395604]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_breast_acc  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
max                  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
starting sklearn study smoothness MLP-adam breast acc 15 1
with data root: None
suggestion time taken 11.346523 iter 0 next_points [{'alpha': 6.800568920904754e-05, 'batch_size': 13, 'beta_1': 0.719639967379199, 'beta_2': 0.995859989458567, 'epsilon': 1.0843796796945195e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0629832533266279, 'tol': 0.0004031677677244711, 'validation_fraction': 0.13345040275703055}]
function_evaluation time 0.392398 value -0.905495 suggestion {'alpha': 6.800568920904754e-05, 'batch_size': 13, 'beta_1': 0.719639967379199, 'beta_2': 0.995859989458567, 'epsilon': 1.0843796796945195e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0629832533266279, 'tol': 0.0004031677677244711, 'validation_fraction': 0.13345040275703055}
observation time 0.000007, current best -0.905495 at iter 0
suggestion time taken 11.408455 iter 1 next_points [{'alpha': 0.0002523276974805634, 'batch_size': 13, 'beta_1': 0.9217266869020708, 'beta_2': 0.9999979238483855, 'epsilon': 3.3405212602256737e-09, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.000619293415618496, 'tol': 0.002646911044826127, 'validation_fraction': 0.3634485349671088}]
function_evaluation time 0.890496 value -0.909890 suggestion {'alpha': 0.0002523276974805634, 'batch_size': 13, 'beta_1': 0.9217266869020708, 'beta_2': 0.9999979238483855, 'epsilon': 3.3405212602256737e-09, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.000619293415618496, 'tol': 0.002646911044826127, 'validation_fraction': 0.3634485349671088}
observation time 0.000005, current best -0.909890 at iter 1
suggestion time taken 11.178661 iter 2 next_points [{'alpha': 0.005500537308836593, 'batch_size': 13, 'beta_1': 0.8224501048806233, 'beta_2': 0.9957764708949326, 'epsilon': 7.298722131068038e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0068575804018830315, 'tol': 0.03236433953675243, 'validation_fraction': 0.1168934374202888}]
function_evaluation time 0.320291 value -0.901099 suggestion {'alpha': 0.005500537308836593, 'batch_size': 13, 'beta_1': 0.8224501048806233, 'beta_2': 0.9957764708949326, 'epsilon': 7.298722131068038e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0068575804018830315, 'tol': 0.03236433953675243, 'validation_fraction': 0.1168934374202888}
observation time 0.000005, current best -0.909890 at iter 2
suggestion time taken 11.545540 iter 3 next_points [{'alpha': 0.002814217684577247, 'batch_size': 18, 'beta_1': 0.5239312574158148, 'beta_2': 0.9674984489691277, 'epsilon': 1.0848255124431755e-08, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0009453923476766341, 'tol': 0.0016566077605213241, 'validation_fraction': 0.30514239772403595}]
function_evaluation time 0.626866 value -0.912088 suggestion {'alpha': 0.002814217684577247, 'batch_size': 18, 'beta_1': 0.5239312574158148, 'beta_2': 0.9674984489691277, 'epsilon': 1.0848255124431755e-08, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0009453923476766341, 'tol': 0.0016566077605213241, 'validation_fraction': 0.30514239772403595}
observation time 0.000005, current best -0.912088 at iter 3
suggestion time taken 11.204119 iter 4 next_points [{'alpha': 0.00021213349342602385, 'batch_size': 19, 'beta_1': 0.8115451236298362, 'beta_2': 0.9999953293378858, 'epsilon': 1.5900427395362346e-09, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.00019482783916748963, 'tol': 0.00018472311472477262, 'validation_fraction': 0.11129414324829914}]
function_evaluation time 0.623550 value -0.901099 suggestion {'alpha': 0.00021213349342602385, 'batch_size': 19, 'beta_1': 0.8115451236298362, 'beta_2': 0.9999953293378858, 'epsilon': 1.5900427395362346e-09, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.00019482783916748963, 'tol': 0.00018472311472477262, 'validation_fraction': 0.11129414324829914}
observation time 0.000006, current best -0.912088 at iter 4
suggestion time taken 11.475185 iter 5 next_points [{'alpha': 0.3103509974444725, 'batch_size': 15, 'beta_1': 0.7181628542749681, 'beta_2': 0.9999543807654613, 'epsilon': 1.4878919576475956e-08, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.0016682312391659562, 'tol': 2.7348876382166164e-05, 'validation_fraction': 0.8098215733285821}]
function_evaluation time 0.370005 value -0.912088 suggestion {'alpha': 0.3103509974444725, 'batch_size': 15, 'beta_1': 0.7181628542749681, 'beta_2': 0.9999543807654613, 'epsilon': 1.4878919576475956e-08, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.0016682312391659562, 'tol': 2.7348876382166164e-05, 'validation_fraction': 0.8098215733285821}
observation time 0.000005, current best -0.912088 at iter 5
suggestion time taken 11.343538 iter 6 next_points [{'alpha': 0.05309704224164638, 'batch_size': 11, 'beta_1': 0.7016897174316148, 'beta_2': 0.9833409200915383, 'epsilon': 3.4760380002029675e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 1.3253595044187646e-05, 'tol': 0.017349467775973695, 'validation_fraction': 0.6148926396640308}]
function_evaluation time 0.359633 value -0.560440 suggestion {'alpha': 0.05309704224164638, 'batch_size': 11, 'beta_1': 0.7016897174316148, 'beta_2': 0.9833409200915383, 'epsilon': 3.4760380002029675e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 1.3253595044187646e-05, 'tol': 0.017349467775973695, 'validation_fraction': 0.6148926396640308}
observation time 0.000006, current best -0.912088 at iter 6
suggestion time taken 11.492244 iter 7 next_points [{'alpha': 1.2059897969687985, 'batch_size': 16, 'beta_1': 0.9507385934819653, 'beta_2': 0.999977799614758, 'epsilon': 4.510724346585727e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.0001718241397642746, 'tol': 1.3889850691101275e-05, 'validation_fraction': 0.35717667866862135}]
function_evaluation time 0.656332 value -0.894505 suggestion {'alpha': 1.2059897969687985, 'batch_size': 16, 'beta_1': 0.9507385934819653, 'beta_2': 0.999977799614758, 'epsilon': 4.510724346585727e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.0001718241397642746, 'tol': 1.3889850691101275e-05, 'validation_fraction': 0.35717667866862135}
observation time 0.000006, current best -0.912088 at iter 7
suggestion time taken 11.264551 iter 8 next_points [{'alpha': 0.6646811106601215, 'batch_size': 12, 'beta_1': 0.5845369126669875, 'beta_2': 0.9998693603539665, 'epsilon': 1.5588484209855707e-08, 'hidden_layer_sizes': 187, 'learning_rate_init': 9.38667614954412e-05, 'tol': 0.06180657793892442, 'validation_fraction': 0.20731920460816453}]
function_evaluation time 0.640903 value -0.835165 suggestion {'alpha': 0.6646811106601215, 'batch_size': 12, 'beta_1': 0.5845369126669875, 'beta_2': 0.9998693603539665, 'epsilon': 1.5588484209855707e-08, 'hidden_layer_sizes': 187, 'learning_rate_init': 9.38667614954412e-05, 'tol': 0.06180657793892442, 'validation_fraction': 0.20731920460816453}
observation time 0.000005, current best -0.912088 at iter 8
suggestion time taken 11.101270 iter 9 next_points [{'alpha': 0.001259319874514493, 'batch_size': 12, 'beta_1': 0.9708950170814076, 'beta_2': 0.9531431984954539, 'epsilon': 1.6620867736416937e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.007318186194373533, 'tol': 0.0071141818304512475, 'validation_fraction': 0.14583019863386346}]
function_evaluation time 0.636628 value -0.909890 suggestion {'alpha': 0.001259319874514493, 'batch_size': 12, 'beta_1': 0.9708950170814076, 'beta_2': 0.9531431984954539, 'epsilon': 1.6620867736416937e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.007318186194373533, 'tol': 0.0071141818304512475, 'validation_fraction': 0.14583019863386346}
observation time 0.000005, current best -0.912088 at iter 9
suggestion time taken 11.417711 iter 10 next_points [{'alpha': 0.152354605418256, 'batch_size': 39, 'beta_1': 0.8793291498615426, 'beta_2': 0.9999734577911983, 'epsilon': 7.556646229646721e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.00010072150899710605, 'tol': 0.004030157110497759, 'validation_fraction': 0.8722787639974766}]
function_evaluation time 0.175614 value -0.687912 suggestion {'alpha': 0.152354605418256, 'batch_size': 39, 'beta_1': 0.8793291498615426, 'beta_2': 0.9999734577911983, 'epsilon': 7.556646229646721e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.00010072150899710605, 'tol': 0.004030157110497759, 'validation_fraction': 0.8722787639974766}
observation time 0.000005, current best -0.912088 at iter 10
suggestion time taken 11.341057 iter 11 next_points [{'alpha': 0.00015674978208972106, 'batch_size': 16, 'beta_1': 0.7633349036895539, 'beta_2': 0.9999881285168758, 'epsilon': 2.2682847116479324e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.00522996933381708, 'tol': 2.8302144768789375e-05, 'validation_fraction': 0.6569346993535403}]
function_evaluation time 0.410970 value -0.916484 suggestion {'alpha': 0.00015674978208972106, 'batch_size': 16, 'beta_1': 0.7633349036895539, 'beta_2': 0.9999881285168758, 'epsilon': 2.2682847116479324e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.00522996933381708, 'tol': 2.8302144768789375e-05, 'validation_fraction': 0.6569346993535403}
observation time 0.000005, current best -0.916484 at iter 11
suggestion time taken 11.096177 iter 12 next_points [{'alpha': 1.1742702200226771, 'batch_size': 18, 'beta_1': 0.8630725406594523, 'beta_2': 0.9956422793279708, 'epsilon': 8.562780415777248e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.04022057359024397, 'tol': 0.06604936261536255, 'validation_fraction': 0.5366682689916549}]
function_evaluation time 0.322308 value -0.896703 suggestion {'alpha': 1.1742702200226771, 'batch_size': 18, 'beta_1': 0.8630725406594523, 'beta_2': 0.9956422793279708, 'epsilon': 8.562780415777248e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.04022057359024397, 'tol': 0.06604936261536255, 'validation_fraction': 0.5366682689916549}
observation time 0.000006, current best -0.916484 at iter 12
suggestion time taken 11.445374 iter 13 next_points [{'alpha': 0.8259102054219687, 'batch_size': 37, 'beta_1': 0.7104304657940081, 'beta_2': 0.9567655605611214, 'epsilon': 4.300702052508266e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0004781843956954901, 'tol': 0.0008255952841917134, 'validation_fraction': 0.7673963559494225}]
function_evaluation time 0.342927 value -0.797802 suggestion {'alpha': 0.8259102054219687, 'batch_size': 37, 'beta_1': 0.7104304657940081, 'beta_2': 0.9567655605611214, 'epsilon': 4.300702052508266e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0004781843956954901, 'tol': 0.0008255952841917134, 'validation_fraction': 0.7673963559494225}
observation time 0.000005, current best -0.916484 at iter 13
suggestion time taken 11.122616 iter 14 next_points [{'alpha': 7.143316326101782e-05, 'batch_size': 15, 'beta_1': 0.9104254882538257, 'beta_2': 0.9999927124418835, 'epsilon': 2.8167060455212668e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.0032756666180152505, 'tol': 0.017810233032604927, 'validation_fraction': 0.8376884558508971}]
function_evaluation time 0.211535 value -0.901099 suggestion {'alpha': 7.143316326101782e-05, 'batch_size': 15, 'beta_1': 0.9104254882538257, 'beta_2': 0.9999927124418835, 'epsilon': 2.8167060455212668e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.0032756666180152505, 'tol': 0.017810233032604927, 'validation_fraction': 0.8376884558508971}
observation time 0.000004, current best -0.916484 at iter 14
saving meta data: {'args': {'--uuid': 'ffb1624e6b3f57cdb7b79d051b835510', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'smoothness', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

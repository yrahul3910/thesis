running: {'--uuid': 'b931eb0e7a6d52ecbbe3dd39c5ca63c6', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d breast -o hyperopt -u b931eb0e7a6d52ecbbe3dd39c5ca63c6 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230422_030001
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_nll betwen [ 4.58589285 14.6438765   8.74044796  0.67466158  3.06872636] and [ 8.10456652 20.07092365 12.33228572  5.26978359  3.49043108]
  warnings.warn(

Signature errors:
                            0         1         2         3         4       max
MLP-adam_breast_nll  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
max                  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
starting sklearn study hyperopt MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.002355 iter 0 next_points [{'alpha': 0.0002828987506050649, 'batch_size': 26, 'beta_1': 0.5182411651050163, 'beta_2': 0.9952453351720691, 'epsilon': 2.9077235419551258e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 5.2816029208269244e-05, 'tol': 0.03202427698144424, 'validation_fraction': 0.7058019316810428}]
function_evaluation time 0.179971 value 12.601463 suggestion {'alpha': 0.0002828987506050649, 'batch_size': 26, 'beta_1': 0.5182411651050163, 'beta_2': 0.9952453351720691, 'epsilon': 2.9077235419551258e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 5.2816029208269244e-05, 'tol': 0.03202427698144424, 'validation_fraction': 0.7058019316810428}
observation time 0.000061, current best 12.601463 at iter 0
suggestion time taken 0.002512 iter 1 next_points [{'alpha': 0.21275345615711816, 'batch_size': 96, 'beta_1': 0.7088782022686413, 'beta_2': 0.9799592257376263, 'epsilon': 1.3429448548729727e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.004906444137326458, 'tol': 0.00776915741173089, 'validation_fraction': 0.16113266709882076}]
function_evaluation time 0.168989 value 0.559892 suggestion {'alpha': 0.21275345615711816, 'batch_size': 96, 'beta_1': 0.7088782022686413, 'beta_2': 0.9799592257376263, 'epsilon': 1.3429448548729727e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.004906444137326458, 'tol': 0.00776915741173089, 'validation_fraction': 0.16113266709882076}
observation time 0.000066, current best 0.559892 at iter 1
suggestion time taken 0.002118 iter 2 next_points [{'alpha': 0.20076145788662234, 'batch_size': 100, 'beta_1': 0.6351429350235256, 'beta_2': 0.9148393721818058, 'epsilon': 4.4777008895174956e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.01773714628519366, 'tol': 0.0012926781537748475, 'validation_fraction': 0.6853706654680475}]
function_evaluation time 0.197699 value 0.831635 suggestion {'alpha': 0.20076145788662234, 'batch_size': 100, 'beta_1': 0.6351429350235256, 'beta_2': 0.9148393721818058, 'epsilon': 4.4777008895174956e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.01773714628519366, 'tol': 0.0012926781537748475, 'validation_fraction': 0.6853706654680475}
observation time 0.000069, current best 0.559892 at iter 2
suggestion time taken 0.002148 iter 3 next_points [{'alpha': 0.0005554648733786244, 'batch_size': 80, 'beta_1': 0.5275003954614499, 'beta_2': 0.9701893847796309, 'epsilon': 2.9393853702295405e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.00016258545026195942, 'tol': 0.0001216686231293941, 'validation_fraction': 0.17192222244916722}]
function_evaluation time 0.189231 value 8.268844 suggestion {'alpha': 0.0005554648733786244, 'batch_size': 80, 'beta_1': 0.5275003954614499, 'beta_2': 0.9701893847796309, 'epsilon': 2.9393853702295405e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.00016258545026195942, 'tol': 0.0001216686231293941, 'validation_fraction': 0.17192222244916722}
observation time 0.000067, current best 0.559892 at iter 3
suggestion time taken 0.002092 iter 4 next_points [{'alpha': 7.017349318221375, 'batch_size': 232, 'beta_1': 0.9603058469073199, 'beta_2': 0.9108952123512106, 'epsilon': 4.4328356272966035e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 1.8484437038648538e-05, 'tol': 0.00011201641631113767, 'validation_fraction': 0.14930739861385645}]
function_evaluation time 0.114157 value 12.835078 suggestion {'alpha': 7.017349318221375, 'batch_size': 232, 'beta_1': 0.9603058469073199, 'beta_2': 0.9108952123512106, 'epsilon': 4.4328356272966035e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 1.8484437038648538e-05, 'tol': 0.00011201641631113767, 'validation_fraction': 0.14930739861385645}
observation time 0.000068, current best 0.559892 at iter 4
suggestion time taken 0.002092 iter 5 next_points [{'alpha': 4.768661795367595, 'batch_size': 189, 'beta_1': 0.7589747684360008, 'beta_2': 0.99430985546367, 'epsilon': 4.096483425453661e-09, 'hidden_layer_sizes': 168, 'learning_rate_init': 5.1466006092628075e-05, 'tol': 0.00018646843847351137, 'validation_fraction': 0.3574911511703691}]
function_evaluation time 0.142645 value 17.031616 suggestion {'alpha': 4.768661795367595, 'batch_size': 189, 'beta_1': 0.7589747684360008, 'beta_2': 0.99430985546367, 'epsilon': 4.096483425453661e-09, 'hidden_layer_sizes': 168, 'learning_rate_init': 5.1466006092628075e-05, 'tol': 0.00018646843847351137, 'validation_fraction': 0.3574911511703691}
observation time 0.000063, current best 0.559892 at iter 5
suggestion time taken 0.002059 iter 6 next_points [{'alpha': 0.05398496968023738, 'batch_size': 98, 'beta_1': 0.9224427461630266, 'beta_2': 0.9746164954742258, 'epsilon': 2.2854772366357373e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 4.080373194568613e-05, 'tol': 0.0017034842711644738, 'validation_fraction': 0.2545046339420374}]
function_evaluation time 0.091380 value 20.912093 suggestion {'alpha': 0.05398496968023738, 'batch_size': 98, 'beta_1': 0.9224427461630266, 'beta_2': 0.9746164954742258, 'epsilon': 2.2854772366357373e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 4.080373194568613e-05, 'tol': 0.0017034842711644738, 'validation_fraction': 0.2545046339420374}
observation time 0.000069, current best 0.559892 at iter 6
suggestion time taken 0.002373 iter 7 next_points [{'alpha': 0.0007698615007591456, 'batch_size': 248, 'beta_1': 0.8962470581659717, 'beta_2': 0.9525828753832815, 'epsilon': 1.5575919913682613e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 6.267573385597376e-05, 'tol': 0.0015733347387300203, 'validation_fraction': 0.36018458480329274}]
function_evaluation time 0.145963 value 11.421226 suggestion {'alpha': 0.0007698615007591456, 'batch_size': 248, 'beta_1': 0.8962470581659717, 'beta_2': 0.9525828753832815, 'epsilon': 1.5575919913682613e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 6.267573385597376e-05, 'tol': 0.0015733347387300203, 'validation_fraction': 0.36018458480329274}
observation time 0.000075, current best 0.559892 at iter 7
suggestion time taken 0.002149 iter 8 next_points [{'alpha': 0.1870755657399615, 'batch_size': 135, 'beta_1': 0.7605571784414032, 'beta_2': 0.9813593539845893, 'epsilon': 8.26276250497572e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 2.2688382718108612e-05, 'tol': 0.0002165016344863066, 'validation_fraction': 0.3257874679675817}]
function_evaluation time 0.145848 value 19.135922 suggestion {'alpha': 0.1870755657399615, 'batch_size': 135, 'beta_1': 0.7605571784414032, 'beta_2': 0.9813593539845893, 'epsilon': 8.26276250497572e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 2.2688382718108612e-05, 'tol': 0.0002165016344863066, 'validation_fraction': 0.3257874679675817}
observation time 0.000073, current best 0.559892 at iter 8
suggestion time taken 0.002317 iter 9 next_points [{'alpha': 0.00011754975181449881, 'batch_size': 173, 'beta_1': 0.6567125474234725, 'beta_2': 0.930487841304238, 'epsilon': 1.1159860729956388e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 1.409740438378799e-05, 'tol': 0.007262310738602493, 'validation_fraction': 0.16732887631550428}]
function_evaluation time 0.154106 value 13.851638 suggestion {'alpha': 0.00011754975181449881, 'batch_size': 173, 'beta_1': 0.6567125474234725, 'beta_2': 0.930487841304238, 'epsilon': 1.1159860729956388e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 1.409740438378799e-05, 'tol': 0.007262310738602493, 'validation_fraction': 0.16732887631550428}
observation time 0.000064, current best 0.559892 at iter 9
suggestion time taken 0.002099 iter 10 next_points [{'alpha': 1.2542909915024123, 'batch_size': 100, 'beta_1': 0.8861988756463721, 'beta_2': 0.9807004068995587, 'epsilon': 2.0697280031488324e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.009278329039224834, 'tol': 1.54970302829811e-05, 'validation_fraction': 0.2311250953162258}]
function_evaluation time 0.351328 value 0.913076 suggestion {'alpha': 1.2542909915024123, 'batch_size': 100, 'beta_1': 0.8861988756463721, 'beta_2': 0.9807004068995587, 'epsilon': 2.0697280031488324e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.009278329039224834, 'tol': 1.54970302829811e-05, 'validation_fraction': 0.2311250953162258}
observation time 0.000072, current best 0.559892 at iter 10
suggestion time taken 0.002136 iter 11 next_points [{'alpha': 0.00022933493313247457, 'batch_size': 211, 'beta_1': 0.900696532108427, 'beta_2': 0.9209918396563387, 'epsilon': 6.399575652756921e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.05864156720250035, 'tol': 0.00639819250624994, 'validation_fraction': 0.8390331354828405}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.150319 value 3.248631 suggestion {'alpha': 0.00022933493313247457, 'batch_size': 211, 'beta_1': 0.900696532108427, 'beta_2': 0.9209918396563387, 'epsilon': 6.399575652756921e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.05864156720250035, 'tol': 0.00639819250624994, 'validation_fraction': 0.8390331354828405}
observation time 0.000074, current best 0.559892 at iter 11
suggestion time taken 0.002148 iter 12 next_points [{'alpha': 0.2245236200704426, 'batch_size': 239, 'beta_1': 0.9333787157928772, 'beta_2': 0.957218445205031, 'epsilon': 1.3304023096391017e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.005160756985440009, 'tol': 0.016935475479259197, 'validation_fraction': 0.34504815327043337}]
function_evaluation time 0.129370 value 7.328043 suggestion {'alpha': 0.2245236200704426, 'batch_size': 239, 'beta_1': 0.9333787157928772, 'beta_2': 0.957218445205031, 'epsilon': 1.3304023096391017e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.005160756985440009, 'tol': 0.016935475479259197, 'validation_fraction': 0.34504815327043337}
observation time 0.000073, current best 0.559892 at iter 12
suggestion time taken 0.002179 iter 13 next_points [{'alpha': 0.0001769156647847319, 'batch_size': 197, 'beta_1': 0.7234631224984377, 'beta_2': 0.947546800049887, 'epsilon': 6.664865784043075e-08, 'hidden_layer_sizes': 153, 'learning_rate_init': 3.675853736724686e-05, 'tol': 1.3288562777132534e-05, 'validation_fraction': 0.12295272480302534}]
function_evaluation time 0.172406 value 11.329977 suggestion {'alpha': 0.0001769156647847319, 'batch_size': 197, 'beta_1': 0.7234631224984377, 'beta_2': 0.947546800049887, 'epsilon': 6.664865784043075e-08, 'hidden_layer_sizes': 153, 'learning_rate_init': 3.675853736724686e-05, 'tol': 1.3288562777132534e-05, 'validation_fraction': 0.12295272480302534}
observation time 0.000072, current best 0.559892 at iter 13
suggestion time taken 0.002146 iter 14 next_points [{'alpha': 3.7848456472930425, 'batch_size': 120, 'beta_1': 0.6988817888772607, 'beta_2': 0.9244074657974866, 'epsilon': 4.693634529640252e-08, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.00026769319046452696, 'tol': 2.0901372973439976e-05, 'validation_fraction': 0.10340353272804595}]
function_evaluation time 0.387344 value 5.469258 suggestion {'alpha': 3.7848456472930425, 'batch_size': 120, 'beta_1': 0.6988817888772607, 'beta_2': 0.9244074657974866, 'epsilon': 4.693634529640252e-08, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.00026769319046452696, 'tol': 2.0901372973439976e-05, 'validation_fraction': 0.10340353272804595}
observation time 0.000072, current best 0.559892 at iter 14
saving meta data: {'args': {'--uuid': 'b931eb0e7a6d52ecbbe3dd39c5ca63c6', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])}
saving results
saving timing
saving suggest log
done

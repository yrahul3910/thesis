running: {'--uuid': '060d50d5ca00589daf5a1582eaec6a13', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d breast -o hyperopt -u 060d50d5ca00589daf5a1582eaec6a13 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230422_030001
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_acc betwen [-0.80659341 -0.56703297 -0.66593407 -0.87912088 -0.85934066] and [-0.67692308 -0.41758242 -0.54505495 -0.78241758 -0.84395604]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_breast_acc  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
max                  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
starting sklearn study hyperopt MLP-adam breast acc 15 1
with data root: None
suggestion time taken 0.002351 iter 0 next_points [{'alpha': 3.334324888016128e-05, 'batch_size': 17, 'beta_1': 0.9730061611767826, 'beta_2': 0.9746036103606839, 'epsilon': 6.449555454278352e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0060049475963593725, 'tol': 0.0010434098791403518, 'validation_fraction': 0.7618567679188425}]
function_evaluation time 0.395628 value -0.907692 suggestion {'alpha': 3.334324888016128e-05, 'batch_size': 17, 'beta_1': 0.9730061611767826, 'beta_2': 0.9746036103606839, 'epsilon': 6.449555454278352e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0060049475963593725, 'tol': 0.0010434098791403518, 'validation_fraction': 0.7618567679188425}
observation time 0.000071, current best -0.907692 at iter 0
suggestion time taken 0.002333 iter 1 next_points [{'alpha': 1.3120543073403146, 'batch_size': 166, 'beta_1': 0.6626025911822685, 'beta_2': 0.9812390757766895, 'epsilon': 3.269141268796984e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0006348953832673586, 'tol': 0.06868551213405842, 'validation_fraction': 0.6141625256374862}]
function_evaluation time 0.136376 value -0.738462 suggestion {'alpha': 1.3120543073403146, 'batch_size': 166, 'beta_1': 0.6626025911822685, 'beta_2': 0.9812390757766895, 'epsilon': 3.269141268796984e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0006348953832673586, 'tol': 0.06868551213405842, 'validation_fraction': 0.6141625256374862}
observation time 0.000071, current best -0.907692 at iter 1
suggestion time taken 0.002139 iter 2 next_points [{'alpha': 0.2709889315887289, 'batch_size': 116, 'beta_1': 0.8881818001575333, 'beta_2': 0.9141285562356827, 'epsilon': 2.1912195307260145e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.028702055874437422, 'tol': 0.06395503234585671, 'validation_fraction': 0.19613400712631443}]
function_evaluation time 0.127656 value -0.909890 suggestion {'alpha': 0.2709889315887289, 'batch_size': 116, 'beta_1': 0.8881818001575333, 'beta_2': 0.9141285562356827, 'epsilon': 2.1912195307260145e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.028702055874437422, 'tol': 0.06395503234585671, 'validation_fraction': 0.19613400712631443}
observation time 0.000071, current best -0.909890 at iter 2
suggestion time taken 0.002353 iter 3 next_points [{'alpha': 0.20184594256225466, 'batch_size': 184, 'beta_1': 0.7181709241342871, 'beta_2': 0.9947501232067801, 'epsilon': 2.9095006637600165e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.0002580179192342599, 'tol': 1.7514559578073882e-05, 'validation_fraction': 0.19694445719833698}]
function_evaluation time 0.287061 value -0.747253 suggestion {'alpha': 0.20184594256225466, 'batch_size': 184, 'beta_1': 0.7181709241342871, 'beta_2': 0.9947501232067801, 'epsilon': 2.9095006637600165e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.0002580179192342599, 'tol': 1.7514559578073882e-05, 'validation_fraction': 0.19694445719833698}
observation time 0.000068, current best -0.909890 at iter 3
suggestion time taken 0.002089 iter 4 next_points [{'alpha': 0.07338756632271108, 'batch_size': 143, 'beta_1': 0.6192344534498501, 'beta_2': 0.9116291589794716, 'epsilon': 1.0163068307404781e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 1.8708859455489956e-05, 'tol': 5.338616753051923e-05, 'validation_fraction': 0.4606916779205461}]
function_evaluation time 0.160799 value -0.580220 suggestion {'alpha': 0.07338756632271108, 'batch_size': 143, 'beta_1': 0.6192344534498501, 'beta_2': 0.9116291589794716, 'epsilon': 1.0163068307404781e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 1.8708859455489956e-05, 'tol': 5.338616753051923e-05, 'validation_fraction': 0.4606916779205461}
observation time 0.000069, current best -0.909890 at iter 4
suggestion time taken 0.002135 iter 5 next_points [{'alpha': 0.00044483421189803413, 'batch_size': 11, 'beta_1': 0.7615873088156048, 'beta_2': 0.9696195928017215, 'epsilon': 6.001814258777093e-08, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0035225852917807328, 'tol': 0.07068817685585065, 'validation_fraction': 0.1455103094147795}]
function_evaluation time 0.520933 value -0.905495 suggestion {'alpha': 0.00044483421189803413, 'batch_size': 11, 'beta_1': 0.7615873088156048, 'beta_2': 0.9696195928017215, 'epsilon': 6.001814258777093e-08, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0035225852917807328, 'tol': 0.07068817685585065, 'validation_fraction': 0.1455103094147795}
observation time 0.000074, current best -0.909890 at iter 5
suggestion time taken 0.002144 iter 6 next_points [{'alpha': 0.0005864115069150557, 'batch_size': 123, 'beta_1': 0.5536606979009162, 'beta_2': 0.9111572138957833, 'epsilon': 4.273617174331104e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.003249826403206983, 'tol': 0.041334167298368495, 'validation_fraction': 0.4922570586182844}]
function_evaluation time 0.178977 value -0.903297 suggestion {'alpha': 0.0005864115069150557, 'batch_size': 123, 'beta_1': 0.5536606979009162, 'beta_2': 0.9111572138957833, 'epsilon': 4.273617174331104e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.003249826403206983, 'tol': 0.041334167298368495, 'validation_fraction': 0.4922570586182844}
observation time 0.000070, current best -0.909890 at iter 6
suggestion time taken 0.002238 iter 7 next_points [{'alpha': 0.005020057056455506, 'batch_size': 249, 'beta_1': 0.8161468309794705, 'beta_2': 0.9845683984271859, 'epsilon': 2.848438354124901e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 8.85349599919181e-05, 'tol': 0.01343057096223294, 'validation_fraction': 0.35919022321350413}]
function_evaluation time 0.091532 value -0.527473 suggestion {'alpha': 0.005020057056455506, 'batch_size': 249, 'beta_1': 0.8161468309794705, 'beta_2': 0.9845683984271859, 'epsilon': 2.848438354124901e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 8.85349599919181e-05, 'tol': 0.01343057096223294, 'validation_fraction': 0.35919022321350413}
observation time 0.000078, current best -0.909890 at iter 7
suggestion time taken 0.002123 iter 8 next_points [{'alpha': 0.0025321118972876674, 'batch_size': 143, 'beta_1': 0.7798916395199631, 'beta_2': 0.9791882301583462, 'epsilon': 1.580871024804661e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0068570458763735015, 'tol': 0.017276133550609172, 'validation_fraction': 0.31819717255041097}]
function_evaluation time 0.173000 value -0.903297 suggestion {'alpha': 0.0025321118972876674, 'batch_size': 143, 'beta_1': 0.7798916395199631, 'beta_2': 0.9791882301583462, 'epsilon': 1.580871024804661e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0068570458763735015, 'tol': 0.017276133550609172, 'validation_fraction': 0.31819717255041097}
observation time 0.000069, current best -0.909890 at iter 8
suggestion time taken 0.002113 iter 9 next_points [{'alpha': 0.03576203025897823, 'batch_size': 34, 'beta_1': 0.6932266058189414, 'beta_2': 0.9672997044284068, 'epsilon': 3.394598541591482e-08, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.00030168229141101945, 'tol': 0.0002052073433409882, 'validation_fraction': 0.8482492529284414}]
function_evaluation time 0.433732 value -0.848352 suggestion {'alpha': 0.03576203025897823, 'batch_size': 34, 'beta_1': 0.6932266058189414, 'beta_2': 0.9672997044284068, 'epsilon': 3.394598541591482e-08, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.00030168229141101945, 'tol': 0.0002052073433409882, 'validation_fraction': 0.8482492529284414}
observation time 0.000080, current best -0.909890 at iter 9
suggestion time taken 0.002164 iter 10 next_points [{'alpha': 0.2795835414514117, 'batch_size': 200, 'beta_1': 0.5146624253085686, 'beta_2': 0.9717565708522473, 'epsilon': 9.008820678223015e-07, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.000569683560100075, 'tol': 0.05048290111782184, 'validation_fraction': 0.8397640959964368}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.131301 value -0.758242 suggestion {'alpha': 0.2795835414514117, 'batch_size': 200, 'beta_1': 0.5146624253085686, 'beta_2': 0.9717565708522473, 'epsilon': 9.008820678223015e-07, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.000569683560100075, 'tol': 0.05048290111782184, 'validation_fraction': 0.8397640959964368}
observation time 0.000073, current best -0.909890 at iter 10
suggestion time taken 0.002328 iter 11 next_points [{'alpha': 0.00565583247246231, 'batch_size': 149, 'beta_1': 0.5205137823769991, 'beta_2': 0.9107290302777903, 'epsilon': 1.3047227520963634e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.006322875908177984, 'tol': 0.0028166886498799623, 'validation_fraction': 0.21497156368882267}]
function_evaluation time 0.277598 value -0.892308 suggestion {'alpha': 0.00565583247246231, 'batch_size': 149, 'beta_1': 0.5205137823769991, 'beta_2': 0.9107290302777903, 'epsilon': 1.3047227520963634e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.006322875908177984, 'tol': 0.0028166886498799623, 'validation_fraction': 0.21497156368882267}
observation time 0.000071, current best -0.909890 at iter 11
suggestion time taken 0.002138 iter 12 next_points [{'alpha': 1.1708517932958575, 'batch_size': 144, 'beta_1': 0.7179728744290923, 'beta_2': 0.911012433146834, 'epsilon': 9.774011851935674e-09, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.008202662669240855, 'tol': 0.00047209958251901774, 'validation_fraction': 0.8291758130018471}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.213258 value -0.903297 suggestion {'alpha': 1.1708517932958575, 'batch_size': 144, 'beta_1': 0.7179728744290923, 'beta_2': 0.911012433146834, 'epsilon': 9.774011851935674e-09, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.008202662669240855, 'tol': 0.00047209958251901774, 'validation_fraction': 0.8291758130018471}
observation time 0.000079, current best -0.909890 at iter 12
suggestion time taken 0.002436 iter 13 next_points [{'alpha': 0.21854859707268512, 'batch_size': 20, 'beta_1': 0.6858505898355235, 'beta_2': 0.9039603008099512, 'epsilon': 4.076390013145404e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0005122248181917901, 'tol': 0.0034281791292604417, 'validation_fraction': 0.5521143041075298}]
function_evaluation time 0.508346 value -0.894505 suggestion {'alpha': 0.21854859707268512, 'batch_size': 20, 'beta_1': 0.6858505898355235, 'beta_2': 0.9039603008099512, 'epsilon': 4.076390013145404e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0005122248181917901, 'tol': 0.0034281791292604417, 'validation_fraction': 0.5521143041075298}
observation time 0.000069, current best -0.909890 at iter 13
suggestion time taken 0.002130 iter 14 next_points [{'alpha': 0.001043966541926993, 'batch_size': 105, 'beta_1': 0.5947397684475945, 'beta_2': 0.9274591963271064, 'epsilon': 4.3754291913822e-08, 'hidden_layer_sizes': 84, 'learning_rate_init': 1.7600872573670824e-05, 'tol': 0.00013521318636871356, 'validation_fraction': 0.20972252547905756}]
function_evaluation time 0.100593 value -0.527473 suggestion {'alpha': 0.001043966541926993, 'batch_size': 105, 'beta_1': 0.5947397684475945, 'beta_2': 0.9274591963271064, 'epsilon': 4.3754291913822e-08, 'hidden_layer_sizes': 84, 'learning_rate_init': 1.7600872573670824e-05, 'tol': 0.00013521318636871356, 'validation_fraction': 0.20972252547905756}
observation time 0.000075, current best -0.909890 at iter 14
saving meta data: {'args': {'--uuid': '060d50d5ca00589daf5a1582eaec6a13', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': 'c629a622f5de5128aa05e9fc379a85cd', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'random-search', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d breast -o random-search -u c629a622f5de5128aa05e9fc379a85cd -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230422_030001
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_acc betwen [-0.80659341 -0.56703297 -0.66593407 -0.87912088 -0.85934066] and [-0.67692308 -0.41758242 -0.54505495 -0.78241758 -0.84395604]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_breast_acc  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
max                  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
starting sklearn study random-search MLP-adam breast acc 15 1
with data root: None
suggestion time taken 0.002522 iter 0 next_points [{'alpha': 0.0005314385568472585, 'batch_size': 155, 'beta_1': 0.792974891459753, 'beta_2': 0.9999808865517934, 'epsilon': 3.066386463704593e-09, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.004028834209948511, 'tol': 0.00014319360705815375, 'validation_fraction': 0.3399380805375338}]
function_evaluation time 0.254159 value -0.896703 suggestion {'alpha': 0.0005314385568472585, 'batch_size': 155, 'beta_1': 0.792974891459753, 'beta_2': 0.9999808865517934, 'epsilon': 3.066386463704593e-09, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.004028834209948511, 'tol': 0.00014319360705815375, 'validation_fraction': 0.3399380805375338}
observation time 0.000005, current best -0.896703 at iter 0
suggestion time taken 0.002715 iter 1 next_points [{'alpha': 0.011208632637249768, 'batch_size': 208, 'beta_1': 0.9490544320581863, 'beta_2': 0.9999661173195504, 'epsilon': 1.455878440513011e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.0011506016504134748, 'tol': 0.010293024671703777, 'validation_fraction': 0.8862087654027642}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.142057 value -0.778022 suggestion {'alpha': 0.011208632637249768, 'batch_size': 208, 'beta_1': 0.9490544320581863, 'beta_2': 0.9999661173195504, 'epsilon': 1.455878440513011e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.0011506016504134748, 'tol': 0.010293024671703777, 'validation_fraction': 0.8862087654027642}
observation time 0.000003, current best -0.896703 at iter 1
suggestion time taken 0.002420 iter 2 next_points [{'alpha': 0.08047171288347518, 'batch_size': 192, 'beta_1': 0.7584958584206716, 'beta_2': 0.9858455619697827, 'epsilon': 2.3601597053407326e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0008298404859009501, 'tol': 0.0002041827744943914, 'validation_fraction': 0.8447163381561461}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.167541 value -0.843956 suggestion {'alpha': 0.08047171288347518, 'batch_size': 192, 'beta_1': 0.7584958584206716, 'beta_2': 0.9858455619697827, 'epsilon': 2.3601597053407326e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0008298404859009501, 'tol': 0.0002041827744943914, 'validation_fraction': 0.8447163381561461}
observation time 0.000004, current best -0.896703 at iter 2
suggestion time taken 0.002473 iter 3 next_points [{'alpha': 0.007595941022612031, 'batch_size': 167, 'beta_1': 0.6290519795794975, 'beta_2': 0.9999855068998277, 'epsilon': 2.373211853333695e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 3.486146565147176e-05, 'tol': 0.0025994462137368607, 'validation_fraction': 0.12244142478611282}]
function_evaluation time 0.113223 value -0.472527 suggestion {'alpha': 0.007595941022612031, 'batch_size': 167, 'beta_1': 0.6290519795794975, 'beta_2': 0.9999855068998277, 'epsilon': 2.373211853333695e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 3.486146565147176e-05, 'tol': 0.0025994462137368607, 'validation_fraction': 0.12244142478611282}
observation time 0.000004, current best -0.896703 at iter 3
suggestion time taken 0.002492 iter 4 next_points [{'alpha': 0.00017253838542971123, 'batch_size': 69, 'beta_1': 0.9487290057569088, 'beta_2': 0.9989087862798172, 'epsilon': 3.048320132750049e-08, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.012933813378803881, 'tol': 0.007923474906130133, 'validation_fraction': 0.507871415268563}]
function_evaluation time 0.271674 value -0.912088 suggestion {'alpha': 0.00017253838542971123, 'batch_size': 69, 'beta_1': 0.9487290057569088, 'beta_2': 0.9989087862798172, 'epsilon': 3.048320132750049e-08, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.012933813378803881, 'tol': 0.007923474906130133, 'validation_fraction': 0.507871415268563}
observation time 0.000005, current best -0.912088 at iter 4
suggestion time taken 0.002781 iter 5 next_points [{'alpha': 0.0004563150586504098, 'batch_size': 45, 'beta_1': 0.9664329937866603, 'beta_2': 0.9153713676788046, 'epsilon': 6.906385794008153e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.006798067410061776, 'tol': 0.00021467536245721152, 'validation_fraction': 0.3512499209952962}]
function_evaluation time 0.201593 value -0.916484 suggestion {'alpha': 0.0004563150586504098, 'batch_size': 45, 'beta_1': 0.9664329937866603, 'beta_2': 0.9153713676788046, 'epsilon': 6.906385794008153e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.006798067410061776, 'tol': 0.00021467536245721152, 'validation_fraction': 0.3512499209952962}
observation time 0.000005, current best -0.916484 at iter 5
suggestion time taken 0.002493 iter 6 next_points [{'alpha': 0.0013138239740154772, 'batch_size': 229, 'beta_1': 0.7045119127430509, 'beta_2': 0.9999480795229888, 'epsilon': 6.802706030276604e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 2.857529026130304e-05, 'tol': 1.414793279722558e-05, 'validation_fraction': 0.5082341076847319}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.094657 value -0.472527 suggestion {'alpha': 0.0013138239740154772, 'batch_size': 229, 'beta_1': 0.7045119127430509, 'beta_2': 0.9999480795229888, 'epsilon': 6.802706030276604e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 2.857529026130304e-05, 'tol': 1.414793279722558e-05, 'validation_fraction': 0.5082341076847319}
observation time 0.000004, current best -0.916484 at iter 6
suggestion time taken 0.002487 iter 7 next_points [{'alpha': 0.00024941812255544095, 'batch_size': 119, 'beta_1': 0.8766513600148866, 'beta_2': 0.9999981071781151, 'epsilon': 2.8482606441403326e-08, 'hidden_layer_sizes': 168, 'learning_rate_init': 9.078593779054419e-05, 'tol': 0.0011518302110071885, 'validation_fraction': 0.1156120953152949}]
function_evaluation time 0.238093 value -0.527473 suggestion {'alpha': 0.00024941812255544095, 'batch_size': 119, 'beta_1': 0.8766513600148866, 'beta_2': 0.9999981071781151, 'epsilon': 2.8482606441403326e-08, 'hidden_layer_sizes': 168, 'learning_rate_init': 9.078593779054419e-05, 'tol': 0.0011518302110071885, 'validation_fraction': 0.1156120953152949}
observation time 0.000004, current best -0.916484 at iter 7
suggestion time taken 0.002479 iter 8 next_points [{'alpha': 0.01325913843587381, 'batch_size': 213, 'beta_1': 0.81267299737355, 'beta_2': 0.9996113767099982, 'epsilon': 2.1600969854183968e-09, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.0013654323457007456, 'tol': 0.03174624071017076, 'validation_fraction': 0.31934783150478435}]
function_evaluation time 0.220335 value -0.898901 suggestion {'alpha': 0.01325913843587381, 'batch_size': 213, 'beta_1': 0.81267299737355, 'beta_2': 0.9996113767099982, 'epsilon': 2.1600969854183968e-09, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.0013654323457007456, 'tol': 0.03174624071017076, 'validation_fraction': 0.31934783150478435}
observation time 0.000005, current best -0.916484 at iter 8
suggestion time taken 0.002776 iter 9 next_points [{'alpha': 1.5399337155127506e-05, 'batch_size': 215, 'beta_1': 0.8942193624657847, 'beta_2': 0.9991788289055724, 'epsilon': 5.2824866962541456e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0002884889842501872, 'tol': 0.015016172749586918, 'validation_fraction': 0.5142813247278104}]
function_evaluation time 0.116570 value -0.472527 suggestion {'alpha': 1.5399337155127506e-05, 'batch_size': 215, 'beta_1': 0.8942193624657847, 'beta_2': 0.9991788289055724, 'epsilon': 5.2824866962541456e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0002884889842501872, 'tol': 0.015016172749586918, 'validation_fraction': 0.5142813247278104}
observation time 0.000005, current best -0.916484 at iter 9
suggestion time taken 0.002501 iter 10 next_points [{'alpha': 0.015424674534691938, 'batch_size': 16, 'beta_1': 0.9611383258200658, 'beta_2': 0.9999798790101981, 'epsilon': 7.778722698841726e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0002559057570443253, 'tol': 0.0332530897646184, 'validation_fraction': 0.19798984899752572}]
function_evaluation time 0.354486 value -0.839560 suggestion {'alpha': 0.015424674534691938, 'batch_size': 16, 'beta_1': 0.9611383258200658, 'beta_2': 0.9999798790101981, 'epsilon': 7.778722698841726e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0002559057570443253, 'tol': 0.0332530897646184, 'validation_fraction': 0.19798984899752572}
observation time 0.000005, current best -0.916484 at iter 10
suggestion time taken 0.002444 iter 11 next_points [{'alpha': 0.00020224380117698612, 'batch_size': 220, 'beta_1': 0.9814826366885808, 'beta_2': 0.9999956692507337, 'epsilon': 1.6240759131194228e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.004498827247532586, 'tol': 0.00023502958648890105, 'validation_fraction': 0.7776016613951532}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.206068 value -0.835165 suggestion {'alpha': 0.00020224380117698612, 'batch_size': 220, 'beta_1': 0.9814826366885808, 'beta_2': 0.9999956692507337, 'epsilon': 1.6240759131194228e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.004498827247532586, 'tol': 0.00023502958648890105, 'validation_fraction': 0.7776016613951532}
observation time 0.000005, current best -0.916484 at iter 11
suggestion time taken 0.002449 iter 12 next_points [{'alpha': 3.310801209851228, 'batch_size': 13, 'beta_1': 0.6464051479338966, 'beta_2': 0.9137460147376059, 'epsilon': 1.0547963550670423e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0064219010631743475, 'tol': 0.0016149120383282692, 'validation_fraction': 0.706831237247102}]
function_evaluation time 0.412469 value -0.918681 suggestion {'alpha': 3.310801209851228, 'batch_size': 13, 'beta_1': 0.6464051479338966, 'beta_2': 0.9137460147376059, 'epsilon': 1.0547963550670423e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0064219010631743475, 'tol': 0.0016149120383282692, 'validation_fraction': 0.706831237247102}
observation time 0.000004, current best -0.918681 at iter 12
suggestion time taken 0.002465 iter 13 next_points [{'alpha': 0.0013079763478887466, 'batch_size': 66, 'beta_1': 0.7914003975040369, 'beta_2': 0.9999947103462955, 'epsilon': 2.3376345540785556e-09, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.0002806024608520019, 'tol': 0.000754650828614362, 'validation_fraction': 0.45009425472417725}]
function_evaluation time 0.563091 value -0.854945 suggestion {'alpha': 0.0013079763478887466, 'batch_size': 66, 'beta_1': 0.7914003975040369, 'beta_2': 0.9999947103462955, 'epsilon': 2.3376345540785556e-09, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.0002806024608520019, 'tol': 0.000754650828614362, 'validation_fraction': 0.45009425472417725}
observation time 0.000004, current best -0.918681 at iter 13
suggestion time taken 0.002424 iter 14 next_points [{'alpha': 0.17378638756909243, 'batch_size': 219, 'beta_1': 0.9898160069815054, 'beta_2': 0.9995990895621363, 'epsilon': 8.573930702794352e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.05306442977222946, 'tol': 0.0065845499188579215, 'validation_fraction': 0.22081272672376684}]
function_evaluation time 0.271769 value -0.791209 suggestion {'alpha': 0.17378638756909243, 'batch_size': 219, 'beta_1': 0.9898160069815054, 'beta_2': 0.9995990895621363, 'epsilon': 8.573930702794352e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.05306442977222946, 'tol': 0.0065845499188579215, 'validation_fraction': 0.22081272672376684}
observation time 0.000005, current best -0.918681 at iter 14
saving meta data: {'args': {'--uuid': 'c629a622f5de5128aa05e9fc379a85cd', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'random-search', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': 'ed726eb1bdff5625bce16e473f50f7b4', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d breast -o hyperopt -u ed726eb1bdff5625bce16e473f50f7b4 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230422_030001
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_acc betwen [-0.80659341 -0.56703297 -0.66593407 -0.87912088 -0.85934066] and [-0.67692308 -0.41758242 -0.54505495 -0.78241758 -0.84395604]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_breast_acc  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
max                  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
starting sklearn study hyperopt MLP-adam breast acc 15 1
with data root: None
suggestion time taken 0.002376 iter 0 next_points [{'alpha': 0.00032471336241256943, 'batch_size': 133, 'beta_1': 0.6834224468295472, 'beta_2': 0.9285461435615225, 'epsilon': 1.036910787394028e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.0001768759398022799, 'tol': 0.043497825514413155, 'validation_fraction': 0.2942071694685984}]
function_evaluation time 0.134519 value -0.584615 suggestion {'alpha': 0.00032471336241256943, 'batch_size': 133, 'beta_1': 0.6834224468295472, 'beta_2': 0.9285461435615225, 'epsilon': 1.036910787394028e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.0001768759398022799, 'tol': 0.043497825514413155, 'validation_fraction': 0.2942071694685984}
observation time 0.000066, current best -0.584615 at iter 0
suggestion time taken 0.002339 iter 1 next_points [{'alpha': 0.4373877214785117, 'batch_size': 71, 'beta_1': 0.5604282399343292, 'beta_2': 0.9031966570490606, 'epsilon': 3.108819227319703e-07, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.00020394872442108594, 'tol': 0.0006455479801270415, 'validation_fraction': 0.1065176434053833}]
function_evaluation time 0.357243 value -0.821978 suggestion {'alpha': 0.4373877214785117, 'batch_size': 71, 'beta_1': 0.5604282399343292, 'beta_2': 0.9031966570490606, 'epsilon': 3.108819227319703e-07, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.00020394872442108594, 'tol': 0.0006455479801270415, 'validation_fraction': 0.1065176434053833}
observation time 0.000061, current best -0.821978 at iter 1
suggestion time taken 0.002072 iter 2 next_points [{'alpha': 1.951373471756287e-05, 'batch_size': 138, 'beta_1': 0.5614130732861888, 'beta_2': 0.9390546107335541, 'epsilon': 2.9006411913475696e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.004361756192609193, 'tol': 0.0011826310240997723, 'validation_fraction': 0.11693519225450923}]
function_evaluation time 0.294938 value -0.890110 suggestion {'alpha': 1.951373471756287e-05, 'batch_size': 138, 'beta_1': 0.5614130732861888, 'beta_2': 0.9390546107335541, 'epsilon': 2.9006411913475696e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.004361756192609193, 'tol': 0.0011826310240997723, 'validation_fraction': 0.11693519225450923}
observation time 0.000063, current best -0.890110 at iter 2
suggestion time taken 0.002309 iter 3 next_points [{'alpha': 1.491183031944655, 'batch_size': 19, 'beta_1': 0.8851423739070722, 'beta_2': 0.9395485968349562, 'epsilon': 2.858053620827539e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.00019298077396636603, 'tol': 0.006193024285321304, 'validation_fraction': 0.34786586979936085}]
function_evaluation time 0.772925 value -0.920879 suggestion {'alpha': 1.491183031944655, 'batch_size': 19, 'beta_1': 0.8851423739070722, 'beta_2': 0.9395485968349562, 'epsilon': 2.858053620827539e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.00019298077396636603, 'tol': 0.006193024285321304, 'validation_fraction': 0.34786586979936085}
observation time 0.000066, current best -0.920879 at iter 3
suggestion time taken 0.002050 iter 4 next_points [{'alpha': 0.00012603344631591975, 'batch_size': 161, 'beta_1': 0.5140585317695414, 'beta_2': 0.9452406521818456, 'epsilon': 2.97953562471395e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.022819703879281353, 'tol': 5.793513591610096e-05, 'validation_fraction': 0.14617657201345838}]
function_evaluation time 0.238285 value -0.898901 suggestion {'alpha': 0.00012603344631591975, 'batch_size': 161, 'beta_1': 0.5140585317695414, 'beta_2': 0.9452406521818456, 'epsilon': 2.97953562471395e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.022819703879281353, 'tol': 5.793513591610096e-05, 'validation_fraction': 0.14617657201345838}
observation time 0.000061, current best -0.920879 at iter 4
suggestion time taken 0.002107 iter 5 next_points [{'alpha': 0.1432916597097129, 'batch_size': 219, 'beta_1': 0.7475867932899133, 'beta_2': 0.9333275042604547, 'epsilon': 1.0241040158026867e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 2.6334759543824604e-05, 'tol': 0.00668833832115624, 'validation_fraction': 0.29921667312853534}]
function_evaluation time 0.125799 value -0.417582 suggestion {'alpha': 0.1432916597097129, 'batch_size': 219, 'beta_1': 0.7475867932899133, 'beta_2': 0.9333275042604547, 'epsilon': 1.0241040158026867e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 2.6334759543824604e-05, 'tol': 0.00668833832115624, 'validation_fraction': 0.29921667312853534}
observation time 0.000063, current best -0.920879 at iter 5
suggestion time taken 0.002113 iter 6 next_points [{'alpha': 0.03395600065051879, 'batch_size': 104, 'beta_1': 0.7451388153187786, 'beta_2': 0.9837032762463139, 'epsilon': 1.8463383109317284e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 4.071612271200268e-05, 'tol': 1.2312101848537828e-05, 'validation_fraction': 0.16422342638592533}]
function_evaluation time 0.198971 value -0.560440 suggestion {'alpha': 0.03395600065051879, 'batch_size': 104, 'beta_1': 0.7451388153187786, 'beta_2': 0.9837032762463139, 'epsilon': 1.8463383109317284e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 4.071612271200268e-05, 'tol': 1.2312101848537828e-05, 'validation_fraction': 0.16422342638592533}
observation time 0.000070, current best -0.920879 at iter 6
suggestion time taken 0.002158 iter 7 next_points [{'alpha': 0.3825505460452242, 'batch_size': 62, 'beta_1': 0.7925581988565741, 'beta_2': 0.9433096056035746, 'epsilon': 7.901317091849361e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 1.4180423676500814e-05, 'tol': 2.4655221752868564e-05, 'validation_fraction': 0.18711422232270958}]
function_evaluation time 0.111227 value -0.582418 suggestion {'alpha': 0.3825505460452242, 'batch_size': 62, 'beta_1': 0.7925581988565741, 'beta_2': 0.9433096056035746, 'epsilon': 7.901317091849361e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 1.4180423676500814e-05, 'tol': 2.4655221752868564e-05, 'validation_fraction': 0.18711422232270958}
observation time 0.000070, current best -0.920879 at iter 7
suggestion time taken 0.002100 iter 8 next_points [{'alpha': 1.3541616569716745e-05, 'batch_size': 214, 'beta_1': 0.6034421871835381, 'beta_2': 0.9367135377140071, 'epsilon': 1.5047319443054766e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.0006614662595314144, 'tol': 0.006208768193995356, 'validation_fraction': 0.14279331358914593}]
function_evaluation time 0.302759 value -0.896703 suggestion {'alpha': 1.3541616569716745e-05, 'batch_size': 214, 'beta_1': 0.6034421871835381, 'beta_2': 0.9367135377140071, 'epsilon': 1.5047319443054766e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.0006614662595314144, 'tol': 0.006208768193995356, 'validation_fraction': 0.14279331358914593}
observation time 0.000070, current best -0.920879 at iter 8
suggestion time taken 0.002091 iter 9 next_points [{'alpha': 0.0005048724093511767, 'batch_size': 20, 'beta_1': 0.8825376899098825, 'beta_2': 0.9670390838588092, 'epsilon': 1.930879110529526e-07, 'hidden_layer_sizes': 147, 'learning_rate_init': 2.139400612127244e-05, 'tol': 0.0006515075805270763, 'validation_fraction': 0.25955366006022884}]
function_evaluation time 0.558361 value -0.615385 suggestion {'alpha': 0.0005048724093511767, 'batch_size': 20, 'beta_1': 0.8825376899098825, 'beta_2': 0.9670390838588092, 'epsilon': 1.930879110529526e-07, 'hidden_layer_sizes': 147, 'learning_rate_init': 2.139400612127244e-05, 'tol': 0.0006515075805270763, 'validation_fraction': 0.25955366006022884}
observation time 0.000065, current best -0.920879 at iter 9
suggestion time taken 0.002079 iter 10 next_points [{'alpha': 0.005519167940530196, 'batch_size': 186, 'beta_1': 0.8132013149353581, 'beta_2': 0.9131337792538221, 'epsilon': 7.228471295018729e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.09161257531641279, 'tol': 1.354420126114362e-05, 'validation_fraction': 0.2752477791483842}]
function_evaluation time 0.189680 value -0.800000 suggestion {'alpha': 0.005519167940530196, 'batch_size': 186, 'beta_1': 0.8132013149353581, 'beta_2': 0.9131337792538221, 'epsilon': 7.228471295018729e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.09161257531641279, 'tol': 1.354420126114362e-05, 'validation_fraction': 0.2752477791483842}
observation time 0.000074, current best -0.920879 at iter 10
suggestion time taken 0.002115 iter 11 next_points [{'alpha': 0.06769754937581769, 'batch_size': 176, 'beta_1': 0.6706323361308115, 'beta_2': 0.9556271058195793, 'epsilon': 1.1689741435651819e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.00020171061741548955, 'tol': 0.012817695060118152, 'validation_fraction': 0.38826827942900083}]
function_evaluation time 0.175189 value -0.646154 suggestion {'alpha': 0.06769754937581769, 'batch_size': 176, 'beta_1': 0.6706323361308115, 'beta_2': 0.9556271058195793, 'epsilon': 1.1689741435651819e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.00020171061741548955, 'tol': 0.012817695060118152, 'validation_fraction': 0.38826827942900083}
observation time 0.000065, current best -0.920879 at iter 11
suggestion time taken 0.002274 iter 12 next_points [{'alpha': 0.5213122736140149, 'batch_size': 191, 'beta_1': 0.678046177730078, 'beta_2': 0.981854071490875, 'epsilon': 1.8442995268551558e-08, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.001325478509460755, 'tol': 0.0001147352450585279, 'validation_fraction': 0.7071151739037439}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.171433 value -0.727473 suggestion {'alpha': 0.5213122736140149, 'batch_size': 191, 'beta_1': 0.678046177730078, 'beta_2': 0.981854071490875, 'epsilon': 1.8442995268551558e-08, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.001325478509460755, 'tol': 0.0001147352450585279, 'validation_fraction': 0.7071151739037439}
observation time 0.000067, current best -0.920879 at iter 12
suggestion time taken 0.002158 iter 13 next_points [{'alpha': 4.273769923825032, 'batch_size': 83, 'beta_1': 0.7303539590181748, 'beta_2': 0.9844562506047478, 'epsilon': 9.060909563809954e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.006162556994563934, 'tol': 0.022351578515411384, 'validation_fraction': 0.11246637246388176}]
function_evaluation time 0.153549 value -0.916484 suggestion {'alpha': 4.273769923825032, 'batch_size': 83, 'beta_1': 0.7303539590181748, 'beta_2': 0.9844562506047478, 'epsilon': 9.060909563809954e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.006162556994563934, 'tol': 0.022351578515411384, 'validation_fraction': 0.11246637246388176}
observation time 0.000066, current best -0.920879 at iter 13
suggestion time taken 0.002262 iter 14 next_points [{'alpha': 0.00043331134898727265, 'batch_size': 59, 'beta_1': 0.5039957703606017, 'beta_2': 0.9066854182738848, 'epsilon': 5.036666724698353e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.0021314277349238652, 'tol': 0.010255952706125835, 'validation_fraction': 0.2184425148987452}]
function_evaluation time 0.415599 value -0.914286 suggestion {'alpha': 0.00043331134898727265, 'batch_size': 59, 'beta_1': 0.5039957703606017, 'beta_2': 0.9066854182738848, 'epsilon': 5.036666724698353e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.0021314277349238652, 'tol': 0.010255952706125835, 'validation_fraction': 0.2184425148987452}
observation time 0.000071, current best -0.920879 at iter 14
saving meta data: {'args': {'--uuid': 'ed726eb1bdff5625bce16e473f50f7b4', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

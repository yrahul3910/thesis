running: {'--uuid': 'e955fdcee9fe5cfd8dd84c9b304ea9ad', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'turbo', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d breast -o turbo -u e955fdcee9fe5cfd8dd84c9b304ea9ad -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230422_030001
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_acc betwen [-0.80659341 -0.56703297 -0.66593407 -0.87912088 -0.85934066] and [-0.67692308 -0.41758242 -0.54505495 -0.78241758 -0.84395604]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_breast_acc  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
max                  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
starting sklearn study turbo MLP-adam breast acc 15 1
with data root: None
suggestion time taken 0.002390 iter 0 next_points [{'alpha': 6.528471979592726e-05, 'batch_size': 74, 'beta_1': 0.8689726741449776, 'beta_2': 0.9999591518270416, 'epsilon': 5.974220356424195e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.00010908971303350276, 'tol': 0.00728499744169132, 'validation_fraction': 0.552538108264451}]
function_evaluation time 0.183474 value -0.663736 suggestion {'alpha': 6.528471979592726e-05, 'batch_size': 74, 'beta_1': 0.8689726741449776, 'beta_2': 0.9999591518270416, 'epsilon': 5.974220356424195e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.00010908971303350276, 'tol': 0.00728499744169132, 'validation_fraction': 0.552538108264451}
observation time 0.001435, current best -0.663736 at iter 0
suggestion time taken 0.001767 iter 1 next_points [{'alpha': 9.307652664045354e-05, 'batch_size': 201, 'beta_1': 0.5429737767364551, 'beta_2': 0.9995186191148532, 'epsilon': 2.964924483439118e-09, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0023166637838314057, 'tol': 6.550986292958028e-05, 'validation_fraction': 0.10547424478715696}]
function_evaluation time 0.253944 value -0.885714 suggestion {'alpha': 9.307652664045354e-05, 'batch_size': 201, 'beta_1': 0.5429737767364551, 'beta_2': 0.9995186191148532, 'epsilon': 2.964924483439118e-09, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0023166637838314057, 'tol': 6.550986292958028e-05, 'validation_fraction': 0.10547424478715696}
observation time 0.001452, current best -0.885714 at iter 1
suggestion time taken 0.001772 iter 2 next_points [{'alpha': 0.0033067083569697313, 'batch_size': 166, 'beta_1': 0.9898055695720744, 'beta_2': 0.9999972067465265, 'epsilon': 5.106755302759821e-08, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0035963025324232427, 'tol': 0.010082137269805606, 'validation_fraction': 0.46675524416201886}]
function_evaluation time 0.270067 value -0.843956 suggestion {'alpha': 0.0033067083569697313, 'batch_size': 166, 'beta_1': 0.9898055695720744, 'beta_2': 0.9999972067465265, 'epsilon': 5.106755302759821e-08, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0035963025324232427, 'tol': 0.010082137269805606, 'validation_fraction': 0.46675524416201886}
observation time 0.001397, current best -0.885714 at iter 2
suggestion time taken 0.001754 iter 3 next_points [{'alpha': 0.02237457913016101, 'batch_size': 97, 'beta_1': 0.7276277274306768, 'beta_2': 0.9998152345868111, 'epsilon': 8.446561543307758e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0011642013716968874, 'tol': 3.002220896353501e-05, 'validation_fraction': 0.5220523914822746}]
function_evaluation time 0.286353 value -0.914286 suggestion {'alpha': 0.02237457913016101, 'batch_size': 97, 'beta_1': 0.7276277274306768, 'beta_2': 0.9998152345868111, 'epsilon': 8.446561543307758e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0011642013716968874, 'tol': 3.002220896353501e-05, 'validation_fraction': 0.5220523914822746}
observation time 0.001394, current best -0.914286 at iter 3
suggestion time taken 0.001740 iter 4 next_points [{'alpha': 0.0002022324167420331, 'batch_size': 128, 'beta_1': 0.9662244994620997, 'beta_2': 0.9851430926824013, 'epsilon': 2.271887364527579e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.00013770221200893752, 'tol': 0.0006479508942762634, 'validation_fraction': 0.2781045799617737}]
function_evaluation time 0.250338 value -0.709890 suggestion {'alpha': 0.0002022324167420331, 'batch_size': 128, 'beta_1': 0.9662244994620997, 'beta_2': 0.9851430926824013, 'epsilon': 2.271887364527579e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.00013770221200893752, 'tol': 0.0006479508942762634, 'validation_fraction': 0.2781045799617737}
observation time 0.001397, current best -0.914286 at iter 4
suggestion time taken 0.001764 iter 5 next_points [{'alpha': 7.266607159860711, 'batch_size': 28, 'beta_1': 0.8900499979866016, 'beta_2': 0.9996755338459944, 'epsilon': 4.0184539841296657e-07, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.0005476794715770169, 'tol': 0.0004464027514609183, 'validation_fraction': 0.32994829267192355}]
function_evaluation time 0.348769 value -0.907692 suggestion {'alpha': 7.266607159860711, 'batch_size': 28, 'beta_1': 0.8900499979866016, 'beta_2': 0.9996755338459944, 'epsilon': 4.0184539841296657e-07, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.0005476794715770169, 'tol': 0.0004464027514609183, 'validation_fraction': 0.32994829267192355}
observation time 0.001337, current best -0.914286 at iter 5
suggestion time taken 0.001718 iter 6 next_points [{'alpha': 1.7715913242138, 'batch_size': 234, 'beta_1': 0.9161338447068905, 'beta_2': 0.9999768972424625, 'epsilon': 1.3018001499271765e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.08963647739958569, 'tol': 0.01582792535991992, 'validation_fraction': 0.3756513586019494}]
function_evaluation time 0.156853 value -0.839560 suggestion {'alpha': 1.7715913242138, 'batch_size': 234, 'beta_1': 0.9161338447068905, 'beta_2': 0.9999768972424625, 'epsilon': 1.3018001499271765e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.08963647739958569, 'tol': 0.01582792535991992, 'validation_fraction': 0.3756513586019494}
observation time 0.001423, current best -0.914286 at iter 6
suggestion time taken 0.001791 iter 7 next_points [{'alpha': 0.0010011808170787813, 'batch_size': 123, 'beta_1': 0.9307643082204121, 'beta_2': 0.9999989528606448, 'epsilon': 9.816008588101403e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 3.453564659737362e-05, 'tol': 0.07839287074691687, 'validation_fraction': 0.8237655903654656}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.085852 value -0.527473 suggestion {'alpha': 0.0010011808170787813, 'batch_size': 123, 'beta_1': 0.9307643082204121, 'beta_2': 0.9999989528606448, 'epsilon': 9.816008588101403e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 3.453564659737362e-05, 'tol': 0.07839287074691687, 'validation_fraction': 0.8237655903654656}
observation time 0.001409, current best -0.914286 at iter 7
suggestion time taken 0.001714 iter 8 next_points [{'alpha': 0.0035685137280039047, 'batch_size': 193, 'beta_1': 0.6794457682466104, 'beta_2': 0.9990710130864462, 'epsilon': 2.793748964460113e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.018003588964115073, 'tol': 0.00023051706051723057, 'validation_fraction': 0.8077875797750551}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.199793 value -0.909890 suggestion {'alpha': 0.0035685137280039047, 'batch_size': 193, 'beta_1': 0.6794457682466104, 'beta_2': 0.9990710130864462, 'epsilon': 2.793748964460113e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.018003588964115073, 'tol': 0.00023051706051723057, 'validation_fraction': 0.8077875797750551}
observation time 0.001380, current best -0.914286 at iter 8
suggestion time taken 0.001747 iter 9 next_points [{'alpha': 0.0005489647005168286, 'batch_size': 47, 'beta_1': 0.9555960928276405, 'beta_2': 0.9999009529341011, 'epsilon': 1.2436791264430553e-07, 'hidden_layer_sizes': 68, 'learning_rate_init': 4.864224297111721e-05, 'tol': 0.0015508249366579505, 'validation_fraction': 0.12457042126258987}]
function_evaluation time 0.189898 value -0.582418 suggestion {'alpha': 0.0005489647005168286, 'batch_size': 47, 'beta_1': 0.9555960928276405, 'beta_2': 0.9999009529341011, 'epsilon': 1.2436791264430553e-07, 'hidden_layer_sizes': 68, 'learning_rate_init': 4.864224297111721e-05, 'tol': 0.0015508249366579505, 'validation_fraction': 0.12457042126258987}
observation time 0.001347, current best -0.914286 at iter 9
suggestion time taken 0.001754 iter 10 next_points [{'alpha': 1.1225882006897165e-05, 'batch_size': 55, 'beta_1': 0.8008972944134249, 'beta_2': 0.9982448713045913, 'epsilon': 1.733091797132908e-07, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.008250445381150847, 'tol': 0.028288463923804713, 'validation_fraction': 0.5926544771152839}]
function_evaluation time 0.193817 value -0.890110 suggestion {'alpha': 1.1225882006897165e-05, 'batch_size': 55, 'beta_1': 0.8008972944134249, 'beta_2': 0.9982448713045913, 'epsilon': 1.733091797132908e-07, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.008250445381150847, 'tol': 0.028288463923804713, 'validation_fraction': 0.5926544771152839}
observation time 0.001405, current best -0.914286 at iter 10
suggestion time taken 0.001757 iter 11 next_points [{'alpha': 0.8877703179586386, 'batch_size': 151, 'beta_1': 0.9735911840620817, 'beta_2': 0.9999806546104959, 'epsilon': 7.889008230920589e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.010667063116002164, 'tol': 0.002588473247301022, 'validation_fraction': 0.258721536143301}]
function_evaluation time 0.293640 value -0.901099 suggestion {'alpha': 0.8877703179586386, 'batch_size': 151, 'beta_1': 0.9735911840620817, 'beta_2': 0.9999806546104959, 'epsilon': 7.889008230920589e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.010667063116002164, 'tol': 0.002588473247301022, 'validation_fraction': 0.258721536143301}
observation time 0.001350, current best -0.914286 at iter 11
suggestion time taken 0.001718 iter 12 next_points [{'alpha': 0.45708958426596863, 'batch_size': 13, 'beta_1': 0.981341135904268, 'beta_2': 0.999991118723428, 'epsilon': 6.155998633608179e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.0001972605278068609, 'tol': 0.001045133423237775, 'validation_fraction': 0.6575723007860202}]
function_evaluation time 0.631786 value -0.920879 suggestion {'alpha': 0.45708958426596863, 'batch_size': 13, 'beta_1': 0.981341135904268, 'beta_2': 0.999991118723428, 'epsilon': 6.155998633608179e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.0001972605278068609, 'tol': 0.001045133423237775, 'validation_fraction': 0.6575723007860202}
observation time 0.001339, current best -0.920879 at iter 12
suggestion time taken 0.001905 iter 13 next_points [{'alpha': 2.9556538893504296, 'batch_size': 142, 'beta_1': 0.9869683652829816, 'beta_2': 0.9073608334401968, 'epsilon': 1.6534373625507677e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 1.8516817229197316e-05, 'tol': 2.085740854367977e-05, 'validation_fraction': 0.16417562491330237}]
function_evaluation time 0.167594 value -0.518681 suggestion {'alpha': 2.9556538893504296, 'batch_size': 142, 'beta_1': 0.9869683652829816, 'beta_2': 0.9073608334401968, 'epsilon': 1.6534373625507677e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 1.8516817229197316e-05, 'tol': 2.085740854367977e-05, 'validation_fraction': 0.16417562491330237}
observation time 0.001415, current best -0.920879 at iter 13
suggestion time taken 0.001748 iter 14 next_points [{'alpha': 0.01324427957224771, 'batch_size': 224, 'beta_1': 0.9771543768155901, 'beta_2': 0.9967262897085056, 'epsilon': 3.233880633022618e-09, 'hidden_layer_sizes': 155, 'learning_rate_init': 1.1565920405996942e-05, 'tol': 8.782696269913856e-05, 'validation_fraction': 0.2038549303057528}]
function_evaluation time 0.156883 value -0.630769 suggestion {'alpha': 0.01324427957224771, 'batch_size': 224, 'beta_1': 0.9771543768155901, 'beta_2': 0.9967262897085056, 'epsilon': 3.233880633022618e-09, 'hidden_layer_sizes': 155, 'learning_rate_init': 1.1565920405996942e-05, 'tol': 8.782696269913856e-05, 'validation_fraction': 0.2038549303057528}
observation time 0.001420, current best -0.920879 at iter 14
saving meta data: {'args': {'--uuid': 'e955fdcee9fe5cfd8dd84c9b304ea9ad', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'turbo', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

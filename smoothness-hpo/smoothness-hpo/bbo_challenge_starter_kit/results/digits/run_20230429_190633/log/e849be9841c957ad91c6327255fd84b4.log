running: {'--uuid': 'e849be9841c957ad91c6327255fd84b4', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d digits -o random-search -u e849be9841c957ad91c6327255fd84b4 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study random-search MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002618 iter 0 next_points [{'alpha': 2.7300840952259675e-05, 'batch_size': 149, 'beta_1': 0.9880416560540047, 'beta_2': 0.9493780950804604, 'epsilon': 2.4883701402363507e-08, 'hidden_layer_sizes': 139, 'learning_rate_init': 1.2095474720855376e-05, 'tol': 1.5306948615006478e-05, 'validation_fraction': 0.2683883402115459}]
function_evaluation time 3.164656 value -0.360726 suggestion {'alpha': 2.7300840952259675e-05, 'batch_size': 149, 'beta_1': 0.9880416560540047, 'beta_2': 0.9493780950804604, 'epsilon': 2.4883701402363507e-08, 'hidden_layer_sizes': 139, 'learning_rate_init': 1.2095474720855376e-05, 'tol': 1.5306948615006478e-05, 'validation_fraction': 0.2683883402115459}
observation time 0.000007, current best -0.360726 at iter 0
suggestion time taken 0.002488 iter 1 next_points [{'alpha': 0.029433074480268596, 'batch_size': 53, 'beta_1': 0.9861661263694012, 'beta_2': 0.9999862793762386, 'epsilon': 1.1478949663079284e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.02569585207047225, 'tol': 0.0025230519808501915, 'validation_fraction': 0.811203676201898}]
function_evaluation time 0.787026 value -0.879602 suggestion {'alpha': 0.029433074480268596, 'batch_size': 53, 'beta_1': 0.9861661263694012, 'beta_2': 0.9999862793762386, 'epsilon': 1.1478949663079284e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.02569585207047225, 'tol': 0.0025230519808501915, 'validation_fraction': 0.811203676201898}
observation time 0.000005, current best -0.879602 at iter 1
suggestion time taken 0.002494 iter 2 next_points [{'alpha': 0.00018463617989402073, 'batch_size': 143, 'beta_1': 0.5489318374952151, 'beta_2': 0.9862836690023187, 'epsilon': 5.389823086630828e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 5.349584551008402e-05, 'tol': 0.0045221050997797585, 'validation_fraction': 0.8662529246391978}]
function_evaluation time 0.175679 value -0.100237 suggestion {'alpha': 0.00018463617989402073, 'batch_size': 143, 'beta_1': 0.5489318374952151, 'beta_2': 0.9862836690023187, 'epsilon': 5.389823086630828e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 5.349584551008402e-05, 'tol': 0.0045221050997797585, 'validation_fraction': 0.8662529246391978}
observation time 0.000005, current best -0.879602 at iter 2
suggestion time taken 0.002466 iter 3 next_points [{'alpha': 0.4906364931961266, 'batch_size': 112, 'beta_1': 0.8552654384639833, 'beta_2': 0.999991384635622, 'epsilon': 3.353413299049865e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.01747515501778497, 'tol': 0.0002447678302800982, 'validation_fraction': 0.38800259956688915}]
function_evaluation time 0.894879 value -0.962425 suggestion {'alpha': 0.4906364931961266, 'batch_size': 112, 'beta_1': 0.8552654384639833, 'beta_2': 0.999991384635622, 'epsilon': 3.353413299049865e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.01747515501778497, 'tol': 0.0002447678302800982, 'validation_fraction': 0.38800259956688915}
observation time 0.000004, current best -0.962425 at iter 3
suggestion time taken 0.002955 iter 4 next_points [{'alpha': 5.515637532103279e-05, 'batch_size': 247, 'beta_1': 0.9368795802094161, 'beta_2': 0.9939442855650101, 'epsilon': 7.912272156764211e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.000477348579774179, 'tol': 0.03433805500120319, 'validation_fraction': 0.1135659009189119}]
function_evaluation time 0.662552 value -0.810025 suggestion {'alpha': 5.515637532103279e-05, 'batch_size': 247, 'beta_1': 0.9368795802094161, 'beta_2': 0.9939442855650101, 'epsilon': 7.912272156764211e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.000477348579774179, 'tol': 0.03433805500120319, 'validation_fraction': 0.1135659009189119}
observation time 0.000005, current best -0.962425 at iter 4
suggestion time taken 0.002793 iter 5 next_points [{'alpha': 8.993995932590965e-05, 'batch_size': 163, 'beta_1': 0.9008900475629468, 'beta_2': 0.9963502241966008, 'epsilon': 5.0666815916108236e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.000882741173392385, 'tol': 0.0003821678668765454, 'validation_fraction': 0.222728106757528}]
function_evaluation time 1.320990 value -0.940188 suggestion {'alpha': 8.993995932590965e-05, 'batch_size': 163, 'beta_1': 0.9008900475629468, 'beta_2': 0.9963502241966008, 'epsilon': 5.0666815916108236e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.000882741173392385, 'tol': 0.0003821678668765454, 'validation_fraction': 0.222728106757528}
observation time 0.000005, current best -0.962425 at iter 5
suggestion time taken 0.002428 iter 6 next_points [{'alpha': 9.23339688501417, 'batch_size': 206, 'beta_1': 0.9896333276445158, 'beta_2': 0.9980340371040005, 'epsilon': 1.5222834404383148e-07, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.09552344814427488, 'tol': 4.4117923607239325e-05, 'validation_fraction': 0.10246125764214041}]
function_evaluation time 1.124990 value -0.659817 suggestion {'alpha': 9.23339688501417, 'batch_size': 206, 'beta_1': 0.9896333276445158, 'beta_2': 0.9980340371040005, 'epsilon': 1.5222834404383148e-07, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.09552344814427488, 'tol': 4.4117923607239325e-05, 'validation_fraction': 0.10246125764214041}
observation time 0.000004, current best -0.962425 at iter 6
suggestion time taken 0.002440 iter 7 next_points [{'alpha': 0.006758522475872981, 'batch_size': 25, 'beta_1': 0.8424175686566175, 'beta_2': 0.9893628962817412, 'epsilon': 2.0104903129583483e-07, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.05890082226011577, 'tol': 0.0008021926976722735, 'validation_fraction': 0.5434245356060742}]
function_evaluation time 1.360342 value -0.745899 suggestion {'alpha': 0.006758522475872981, 'batch_size': 25, 'beta_1': 0.8424175686566175, 'beta_2': 0.9893628962817412, 'epsilon': 2.0104903129583483e-07, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.05890082226011577, 'tol': 0.0008021926976722735, 'validation_fraction': 0.5434245356060742}
observation time 0.000004, current best -0.962425 at iter 7
suggestion time taken 0.002885 iter 8 next_points [{'alpha': 0.1498485819685388, 'batch_size': 85, 'beta_1': 0.8214956704856914, 'beta_2': 0.9991345139329733, 'epsilon': 6.1446006149948926e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.002569400958773906, 'tol': 6.872390398415535e-05, 'validation_fraction': 0.19958053396316142}]
function_evaluation time 1.480345 value -0.966606 suggestion {'alpha': 0.1498485819685388, 'batch_size': 85, 'beta_1': 0.8214956704856914, 'beta_2': 0.9991345139329733, 'epsilon': 6.1446006149948926e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.002569400958773906, 'tol': 6.872390398415535e-05, 'validation_fraction': 0.19958053396316142}
observation time 0.000005, current best -0.966606 at iter 8
suggestion time taken 0.002476 iter 9 next_points [{'alpha': 1.2501106527957585e-05, 'batch_size': 191, 'beta_1': 0.8314369006585359, 'beta_2': 0.9943169896021081, 'epsilon': 1.1173320708515452e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.03731400030209253, 'tol': 7.423246157178629e-05, 'validation_fraction': 0.8353971935578544}]
function_evaluation time 0.716124 value -0.890067 suggestion {'alpha': 1.2501106527957585e-05, 'batch_size': 191, 'beta_1': 0.8314369006585359, 'beta_2': 0.9943169896021081, 'epsilon': 1.1173320708515452e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.03731400030209253, 'tol': 7.423246157178629e-05, 'validation_fraction': 0.8353971935578544}
observation time 0.000005, current best -0.966606 at iter 9
suggestion time taken 0.002550 iter 10 next_points [{'alpha': 0.0015966670575759327, 'batch_size': 92, 'beta_1': 0.5516830735085722, 'beta_2': 0.9999971748886513, 'epsilon': 1.7668700124294754e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.005228685270088138, 'tol': 0.0010815698592405063, 'validation_fraction': 0.8964897988361846}]
function_evaluation time 0.790449 value -0.887260 suggestion {'alpha': 0.0015966670575759327, 'batch_size': 92, 'beta_1': 0.5516830735085722, 'beta_2': 0.9999971748886513, 'epsilon': 1.7668700124294754e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.005228685270088138, 'tol': 0.0010815698592405063, 'validation_fraction': 0.8964897988361846}
observation time 0.000004, current best -0.966606 at iter 10
suggestion time taken 0.002448 iter 11 next_points [{'alpha': 7.5901243079827845, 'batch_size': 172, 'beta_1': 0.8698103349463391, 'beta_2': 0.9996231662193182, 'epsilon': 1.1348900438655907e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.0026200541843237213, 'tol': 0.0007677533189492465, 'validation_fraction': 0.6890287347562671}]
function_evaluation time 1.198733 value -0.938076 suggestion {'alpha': 7.5901243079827845, 'batch_size': 172, 'beta_1': 0.8698103349463391, 'beta_2': 0.9996231662193182, 'epsilon': 1.1348900438655907e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.0026200541843237213, 'tol': 0.0007677533189492465, 'validation_fraction': 0.6890287347562671}
observation time 0.000004, current best -0.966606 at iter 11
suggestion time taken 0.002454 iter 12 next_points [{'alpha': 1.7984554829914196e-05, 'batch_size': 124, 'beta_1': 0.9778476457326009, 'beta_2': 0.9999596731808524, 'epsilon': 1.4472078522022193e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.0004253291710611464, 'tol': 0.0007233724168283612, 'validation_fraction': 0.35808096369341763}]
function_evaluation time 1.949536 value -0.947099 suggestion {'alpha': 1.7984554829914196e-05, 'batch_size': 124, 'beta_1': 0.9778476457326009, 'beta_2': 0.9999596731808524, 'epsilon': 1.4472078522022193e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.0004253291710611464, 'tol': 0.0007233724168283612, 'validation_fraction': 0.35808096369341763}
observation time 0.000005, current best -0.966606 at iter 12
suggestion time taken 0.002770 iter 13 next_points [{'alpha': 0.15383344561147025, 'batch_size': 57, 'beta_1': 0.9828037755142632, 'beta_2': 0.9964862289216289, 'epsilon': 2.3450687555807996e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.07879398514407183, 'tol': 0.00010579791527481823, 'validation_fraction': 0.6515059440512203}]
function_evaluation time 1.106098 value -0.908873 suggestion {'alpha': 0.15383344561147025, 'batch_size': 57, 'beta_1': 0.9828037755142632, 'beta_2': 0.9964862289216289, 'epsilon': 2.3450687555807996e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.07879398514407183, 'tol': 0.00010579791527481823, 'validation_fraction': 0.6515059440512203}
observation time 0.000005, current best -0.966606 at iter 13
suggestion time taken 0.002493 iter 14 next_points [{'alpha': 0.004487210497751268, 'batch_size': 62, 'beta_1': 0.9515248868971783, 'beta_2': 0.9999929929683656, 'epsilon': 9.117989230451776e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0645522732106007, 'tol': 0.0003016831888883217, 'validation_fraction': 0.7592052750872215}]
function_evaluation time 0.836231 value -0.656777 suggestion {'alpha': 0.004487210497751268, 'batch_size': 62, 'beta_1': 0.9515248868971783, 'beta_2': 0.9999929929683656, 'epsilon': 9.117989230451776e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0645522732106007, 'tol': 0.0003016831888883217, 'validation_fraction': 0.7592052750872215}
observation time 0.000004, current best -0.966606 at iter 14
saving meta data: {'args': {'--uuid': 'e849be9841c957ad91c6327255fd84b4', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

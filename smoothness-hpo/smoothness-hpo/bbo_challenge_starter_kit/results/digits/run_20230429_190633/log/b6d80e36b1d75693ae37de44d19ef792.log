running: {'--uuid': 'b6d80e36b1d75693ae37de44d19ef792', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u b6d80e36b1d75693ae37de44d19ef792 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study turbo MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002237 iter 0 next_points [{'alpha': 0.0006030452159313351, 'batch_size': 36, 'beta_1': 0.9177397001807199, 'beta_2': 0.9999937634760212, 'epsilon': 5.695373461179544e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 7.036560227243418e-05, 'tol': 0.036024123096876304, 'validation_fraction': 0.15097900508690085}]
function_evaluation time 1.906981 value 0.468494 suggestion {'alpha': 0.0006030452159313351, 'batch_size': 36, 'beta_1': 0.9177397001807199, 'beta_2': 0.9999937634760212, 'epsilon': 5.695373461179544e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 7.036560227243418e-05, 'tol': 0.036024123096876304, 'validation_fraction': 0.15097900508690085}
observation time 0.001408, current best 0.468494 at iter 0
suggestion time taken 0.001736 iter 1 next_points [{'alpha': 0.0016092864803598996, 'batch_size': 145, 'beta_1': 0.6032694308371493, 'beta_2': 0.9990597269383336, 'epsilon': 2.9087287010308517e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0002845509807255165, 'tol': 0.0013788571383728761, 'validation_fraction': 0.6586833431518971}]
function_evaluation time 1.760547 value 0.452505 suggestion {'alpha': 0.0016092864803598996, 'batch_size': 145, 'beta_1': 0.6032694308371493, 'beta_2': 0.9990597269383336, 'epsilon': 2.9087287010308517e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0002845509807255165, 'tol': 0.0013788571383728761, 'validation_fraction': 0.6586833431518971}
observation time 0.001432, current best 0.452505 at iter 1
suggestion time taken 0.001799 iter 2 next_points [{'alpha': 2.790632739441015e-05, 'batch_size': 123, 'beta_1': 0.9799974327805875, 'beta_2': 0.993767076575184, 'epsilon': 3.76203844076152e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.0017653122896929276, 'tol': 0.02124552255614573, 'validation_fraction': 0.8434411834681144}]
function_evaluation time 0.352563 value 0.596809 suggestion {'alpha': 2.790632739441015e-05, 'batch_size': 123, 'beta_1': 0.9799974327805875, 'beta_2': 0.993767076575184, 'epsilon': 3.76203844076152e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.0017653122896929276, 'tol': 0.02124552255614573, 'validation_fraction': 0.8434411834681144}
observation time 0.001397, current best 0.452505 at iter 2
suggestion time taken 0.001745 iter 3 next_points [{'alpha': 0.003517558542704764, 'batch_size': 30, 'beta_1': 0.9603519798801654, 'beta_2': 0.9999979951616872, 'epsilon': 1.1785380522026906e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.000773249373518255, 'tol': 0.0991389018674463, 'validation_fraction': 0.19336340511114503}]
function_evaluation time 0.793289 value 0.205721 suggestion {'alpha': 0.003517558542704764, 'batch_size': 30, 'beta_1': 0.9603519798801654, 'beta_2': 0.9999979951616872, 'epsilon': 1.1785380522026906e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.000773249373518255, 'tol': 0.0991389018674463, 'validation_fraction': 0.19336340511114503}
observation time 0.001410, current best 0.205721 at iter 3
suggestion time taken 0.001752 iter 4 next_points [{'alpha': 9.075884665636309e-05, 'batch_size': 83, 'beta_1': 0.9768955905088959, 'beta_2': 0.9998646905768825, 'epsilon': 7.218267664790841e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0004727962377256411, 'tol': 0.006986894073875123, 'validation_fraction': 0.8920537116883942}]
function_evaluation time 0.752626 value 1.884069 suggestion {'alpha': 9.075884665636309e-05, 'batch_size': 83, 'beta_1': 0.9768955905088959, 'beta_2': 0.9998646905768825, 'epsilon': 7.218267664790841e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0004727962377256411, 'tol': 0.006986894073875123, 'validation_fraction': 0.8920537116883942}
observation time 0.001675, current best 0.205721 at iter 4
suggestion time taken 0.001833 iter 5 next_points [{'alpha': 0.2109782299127264, 'batch_size': 98, 'beta_1': 0.8741757705951178, 'beta_2': 0.9993198357235964, 'epsilon': 4.2084317979110844e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.011472737928994448, 'tol': 1.175912180014235e-05, 'validation_fraction': 0.8015629277781048}]
function_evaluation time 0.579253 value 0.290706 suggestion {'alpha': 0.2109782299127264, 'batch_size': 98, 'beta_1': 0.8741757705951178, 'beta_2': 0.9993198357235964, 'epsilon': 4.2084317979110844e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.011472737928994448, 'tol': 1.175912180014235e-05, 'validation_fraction': 0.8015629277781048}
observation time 0.001385, current best 0.205721 at iter 5
suggestion time taken 0.001758 iter 6 next_points [{'alpha': 1.0056750418634193e-05, 'batch_size': 163, 'beta_1': 0.9892392572967282, 'beta_2': 0.9999857437810283, 'epsilon': 9.501957693692917e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.030495373007947104, 'tol': 6.214796405654575e-05, 'validation_fraction': 0.42490356124252565}]
function_evaluation time 1.320150 value 0.673951 suggestion {'alpha': 1.0056750418634193e-05, 'batch_size': 163, 'beta_1': 0.9892392572967282, 'beta_2': 0.9999857437810283, 'epsilon': 9.501957693692917e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.030495373007947104, 'tol': 6.214796405654575e-05, 'validation_fraction': 0.42490356124252565}
observation time 0.001441, current best 0.205721 at iter 6
suggestion time taken 0.001704 iter 7 next_points [{'alpha': 5.82838622442174, 'batch_size': 73, 'beta_1': 0.9449377857409194, 'beta_2': 0.9963331011628108, 'epsilon': 1.0273640630235974e-07, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.005535802394843882, 'tol': 8.570304696943958e-05, 'validation_fraction': 0.5434779574203467}]
function_evaluation time 1.242400 value 0.211900 suggestion {'alpha': 5.82838622442174, 'batch_size': 73, 'beta_1': 0.9449377857409194, 'beta_2': 0.9963331011628108, 'epsilon': 1.0273640630235974e-07, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.005535802394843882, 'tol': 8.570304696943958e-05, 'validation_fraction': 0.5434779574203467}
observation time 0.001354, current best 0.205721 at iter 7
suggestion time taken 0.001781 iter 8 next_points [{'alpha': 7.013011512125936e-05, 'batch_size': 186, 'beta_1': 0.7910021814628453, 'beta_2': 0.9999643111270089, 'epsilon': 4.729696471152619e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.0034736805310177604, 'tol': 0.004403973250263457, 'validation_fraction': 0.6970125180063204}]
function_evaluation time 0.415355 value 0.226236 suggestion {'alpha': 7.013011512125936e-05, 'batch_size': 186, 'beta_1': 0.7910021814628453, 'beta_2': 0.9999643111270089, 'epsilon': 4.729696471152619e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.0034736805310177604, 'tol': 0.004403973250263457, 'validation_fraction': 0.6970125180063204}
observation time 0.001455, current best 0.205721 at iter 8
suggestion time taken 0.001716 iter 9 next_points [{'alpha': 0.05242641565375777, 'batch_size': 132, 'beta_1': 0.9694390988690381, 'beta_2': 0.9997367289429655, 'epsilon': 1.8539742846710595e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 4.0397510399437293e-05, 'tol': 0.010978946102339337, 'validation_fraction': 0.2470070255841748}]
function_evaluation time 1.498634 value 2.221565 suggestion {'alpha': 0.05242641565375777, 'batch_size': 132, 'beta_1': 0.9694390988690381, 'beta_2': 0.9997367289429655, 'epsilon': 1.8539742846710595e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 4.0397510399437293e-05, 'tol': 0.010978946102339337, 'validation_fraction': 0.2470070255841748}
observation time 0.001400, current best 0.205721 at iter 9
suggestion time taken 0.001741 iter 10 next_points [{'alpha': 4.007757067396842, 'batch_size': 158, 'beta_1': 0.7051160146212765, 'beta_2': 0.9999455173295545, 'epsilon': 1.5059852808898104e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 2.562551316767753e-05, 'tol': 4.0906776288013896e-05, 'validation_fraction': 0.4954283208169148}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.043426 value 6.299474 suggestion {'alpha': 4.007757067396842, 'batch_size': 158, 'beta_1': 0.7051160146212765, 'beta_2': 0.9999455173295545, 'epsilon': 1.5059852808898104e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 2.562551316767753e-05, 'tol': 4.0906776288013896e-05, 'validation_fraction': 0.4954283208169148}
observation time 0.001371, current best 0.205721 at iter 10
suggestion time taken 0.001734 iter 11 next_points [{'alpha': 0.024907639959191596, 'batch_size': 210, 'beta_1': 0.7306412427201506, 'beta_2': 0.9511660439209814, 'epsilon': 6.402660538338621e-07, 'hidden_layer_sizes': 144, 'learning_rate_init': 1.1664305489517001e-05, 'tol': 0.00025048888536738985, 'validation_fraction': 0.33691623585563646}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.244572 value 6.740863 suggestion {'alpha': 0.024907639959191596, 'batch_size': 210, 'beta_1': 0.7306412427201506, 'beta_2': 0.9511660439209814, 'epsilon': 6.402660538338621e-07, 'hidden_layer_sizes': 144, 'learning_rate_init': 1.1664305489517001e-05, 'tol': 0.00025048888536738985, 'validation_fraction': 0.33691623585563646}
observation time 0.001370, current best 0.205721 at iter 11
suggestion time taken 0.001720 iter 12 next_points [{'alpha': 0.007484863167597618, 'batch_size': 236, 'beta_1': 0.6304189306355258, 'beta_2': 0.9999988585503035, 'epsilon': 1.0558967531646822e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.07730160637898134, 'tol': 0.0009067050422272106, 'validation_fraction': 0.7732512527535054}]
function_evaluation time 0.875996 value 1.082018 suggestion {'alpha': 0.007484863167597618, 'batch_size': 236, 'beta_1': 0.6304189306355258, 'beta_2': 0.9999988585503035, 'epsilon': 1.0558967531646822e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.07730160637898134, 'tol': 0.0009067050422272106, 'validation_fraction': 0.7732512527535054}
observation time 0.001399, current best 0.205721 at iter 12
suggestion time taken 0.001736 iter 13 next_points [{'alpha': 0.0003696634425918918, 'batch_size': 221, 'beta_1': 0.5105185822002367, 'beta_2': 0.9822967734223839, 'epsilon': 1.4767743264041136e-09, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.0008510936797198828, 'tol': 0.0005485161235471916, 'validation_fraction': 0.11092343264660708}]
function_evaluation time 1.271578 value 0.176395 suggestion {'alpha': 0.0003696634425918918, 'batch_size': 221, 'beta_1': 0.5105185822002367, 'beta_2': 0.9822967734223839, 'epsilon': 1.4767743264041136e-09, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.0008510936797198828, 'tol': 0.0005485161235471916, 'validation_fraction': 0.11092343264660708}
observation time 0.001371, current best 0.176395 at iter 13
suggestion time taken 0.001681 iter 14 next_points [{'alpha': 0.2976912845948542, 'batch_size': 105, 'beta_1': 0.9197752690575195, 'beta_2': 0.9231878956366741, 'epsilon': 2.841063477042858e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.018264300902990544, 'tol': 0.00015711558899870803, 'validation_fraction': 0.3004514244018957}]
function_evaluation time 0.748956 value 0.179688 suggestion {'alpha': 0.2976912845948542, 'batch_size': 105, 'beta_1': 0.9197752690575195, 'beta_2': 0.9231878956366741, 'epsilon': 2.841063477042858e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.018264300902990544, 'tol': 0.00015711558899870803, 'validation_fraction': 0.3004514244018957}
observation time 0.001367, current best 0.176395 at iter 14
saving meta data: {'args': {'--uuid': 'b6d80e36b1d75693ae37de44d19ef792', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': 'daf578d98ae15cdb93cb6c9c30307724', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u daf578d98ae15cdb93cb6c9c30307724 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study hyperopt MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002354 iter 0 next_points [{'alpha': 0.020092761202728654, 'batch_size': 86, 'beta_1': 0.5131623197616253, 'beta_2': 0.9412645089121018, 'epsilon': 6.538719024793783e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0006212438939222037, 'tol': 0.0003818547231871042, 'validation_fraction': 0.6273953337193473}]
function_evaluation time 2.022806 value 0.151849 suggestion {'alpha': 0.020092761202728654, 'batch_size': 86, 'beta_1': 0.5131623197616253, 'beta_2': 0.9412645089121018, 'epsilon': 6.538719024793783e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0006212438939222037, 'tol': 0.0003818547231871042, 'validation_fraction': 0.6273953337193473}
observation time 0.000069, current best 0.151849 at iter 0
suggestion time taken 0.002616 iter 1 next_points [{'alpha': 0.0020862866308694527, 'batch_size': 200, 'beta_1': 0.6322888703995486, 'beta_2': 0.9221145874116214, 'epsilon': 1.0149414215337566e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0011302848004716881, 'tol': 0.0010182393736552057, 'validation_fraction': 0.12117712637828562}]
function_evaluation time 1.387869 value 0.122731 suggestion {'alpha': 0.0020862866308694527, 'batch_size': 200, 'beta_1': 0.6322888703995486, 'beta_2': 0.9221145874116214, 'epsilon': 1.0149414215337566e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0011302848004716881, 'tol': 0.0010182393736552057, 'validation_fraction': 0.12117712637828562}
observation time 0.000070, current best 0.122731 at iter 1
suggestion time taken 0.002108 iter 2 next_points [{'alpha': 0.005341630897567564, 'batch_size': 83, 'beta_1': 0.6625760314194485, 'beta_2': 0.9571816488464175, 'epsilon': 2.634443136543393e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.04309804982980135, 'tol': 0.021247526334317725, 'validation_fraction': 0.31790179109532946}]
function_evaluation time 0.458627 value 0.258415 suggestion {'alpha': 0.005341630897567564, 'batch_size': 83, 'beta_1': 0.6625760314194485, 'beta_2': 0.9571816488464175, 'epsilon': 2.634443136543393e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.04309804982980135, 'tol': 0.021247526334317725, 'validation_fraction': 0.31790179109532946}
observation time 0.000080, current best 0.122731 at iter 2
suggestion time taken 0.002400 iter 3 next_points [{'alpha': 0.10099092203990062, 'batch_size': 139, 'beta_1': 0.801746240748252, 'beta_2': 0.9287968722181019, 'epsilon': 2.904115709747384e-09, 'hidden_layer_sizes': 117, 'learning_rate_init': 2.2550720724966252e-05, 'tol': 0.002434842061033766, 'validation_fraction': 0.12234047734521636}]
function_evaluation time 1.579211 value 9.036433 suggestion {'alpha': 0.10099092203990062, 'batch_size': 139, 'beta_1': 0.801746240748252, 'beta_2': 0.9287968722181019, 'epsilon': 2.904115709747384e-09, 'hidden_layer_sizes': 117, 'learning_rate_init': 2.2550720724966252e-05, 'tol': 0.002434842061033766, 'validation_fraction': 0.12234047734521636}
observation time 0.000072, current best 0.122731 at iter 3
suggestion time taken 0.002110 iter 4 next_points [{'alpha': 0.08896272166679563, 'batch_size': 180, 'beta_1': 0.6336455173822937, 'beta_2': 0.9820646517702379, 'epsilon': 1.320474903982188e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.007956688008717796, 'tol': 0.00861051871061952, 'validation_fraction': 0.13794589513060956}]
function_evaluation time 0.739829 value 0.084573 suggestion {'alpha': 0.08896272166679563, 'batch_size': 180, 'beta_1': 0.6336455173822937, 'beta_2': 0.9820646517702379, 'epsilon': 1.320474903982188e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.007956688008717796, 'tol': 0.00861051871061952, 'validation_fraction': 0.13794589513060956}
observation time 0.000069, current best 0.084573 at iter 4
suggestion time taken 0.002114 iter 5 next_points [{'alpha': 0.12070623281936278, 'batch_size': 156, 'beta_1': 0.5943265962392336, 'beta_2': 0.9498730524752017, 'epsilon': 1.4227471758961156e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.002825547711877557, 'tol': 0.0007211668483912083, 'validation_fraction': 0.7180073464084921}]
function_evaluation time 1.192715 value 0.192120 suggestion {'alpha': 0.12070623281936278, 'batch_size': 156, 'beta_1': 0.5943265962392336, 'beta_2': 0.9498730524752017, 'epsilon': 1.4227471758961156e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.002825547711877557, 'tol': 0.0007211668483912083, 'validation_fraction': 0.7180073464084921}
observation time 0.000072, current best 0.084573 at iter 5
suggestion time taken 0.002134 iter 6 next_points [{'alpha': 0.02096351936689587, 'batch_size': 21, 'beta_1': 0.5252640040831239, 'beta_2': 0.9378166304562086, 'epsilon': 1.0705272866540192e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 1.12160751918518e-05, 'tol': 4.931946877632705e-05, 'validation_fraction': 0.4843814118323155}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 12.776991 value 0.456079 suggestion {'alpha': 0.02096351936689587, 'batch_size': 21, 'beta_1': 0.5252640040831239, 'beta_2': 0.9378166304562086, 'epsilon': 1.0705272866540192e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 1.12160751918518e-05, 'tol': 4.931946877632705e-05, 'validation_fraction': 0.4843814118323155}
observation time 0.000075, current best 0.084573 at iter 6
suggestion time taken 0.002200 iter 7 next_points [{'alpha': 0.0025088386598614548, 'batch_size': 94, 'beta_1': 0.6158425547294493, 'beta_2': 0.9393344391927047, 'epsilon': 1.8615196976003886e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 2.4653213425490445e-05, 'tol': 0.00036019572195467904, 'validation_fraction': 0.49586482944335775}]
function_evaluation time 2.736915 value 4.146196 suggestion {'alpha': 0.0025088386598614548, 'batch_size': 94, 'beta_1': 0.6158425547294493, 'beta_2': 0.9393344391927047, 'epsilon': 1.8615196976003886e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 2.4653213425490445e-05, 'tol': 0.00036019572195467904, 'validation_fraction': 0.49586482944335775}
observation time 0.000084, current best 0.084573 at iter 7
suggestion time taken 0.002144 iter 8 next_points [{'alpha': 5.3870057390197105e-05, 'batch_size': 205, 'beta_1': 0.6130322872589918, 'beta_2': 0.9141855056235234, 'epsilon': 2.4463657716486037e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.00012147033481394796, 'tol': 0.025017188665263385, 'validation_fraction': 0.1966265285723397}]
function_evaluation time 1.286458 value 0.407781 suggestion {'alpha': 5.3870057390197105e-05, 'batch_size': 205, 'beta_1': 0.6130322872589918, 'beta_2': 0.9141855056235234, 'epsilon': 2.4463657716486037e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.00012147033481394796, 'tol': 0.025017188665263385, 'validation_fraction': 0.1966265285723397}
observation time 0.000077, current best 0.084573 at iter 8
suggestion time taken 0.002387 iter 9 next_points [{'alpha': 0.0001497598159867468, 'batch_size': 127, 'beta_1': 0.5447212636071297, 'beta_2': 0.9146835640572571, 'epsilon': 3.4670060515258226e-08, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.0003794417527491546, 'tol': 0.0013709208760723434, 'validation_fraction': 0.3835719937518047}]
function_evaluation time 2.029766 value 0.106211 suggestion {'alpha': 0.0001497598159867468, 'batch_size': 127, 'beta_1': 0.5447212636071297, 'beta_2': 0.9146835640572571, 'epsilon': 3.4670060515258226e-08, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.0003794417527491546, 'tol': 0.0013709208760723434, 'validation_fraction': 0.3835719937518047}
observation time 0.000077, current best 0.084573 at iter 9
suggestion time taken 0.002145 iter 10 next_points [{'alpha': 8.899569663940447, 'batch_size': 77, 'beta_1': 0.535987908650491, 'beta_2': 0.9907013942301384, 'epsilon': 4.5362462697340524e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.05577247973115932, 'tol': 0.0010183438543988356, 'validation_fraction': 0.12669493783207642}]
function_evaluation time 0.534461 value 1.839561 suggestion {'alpha': 8.899569663940447, 'batch_size': 77, 'beta_1': 0.535987908650491, 'beta_2': 0.9907013942301384, 'epsilon': 4.5362462697340524e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.05577247973115932, 'tol': 0.0010183438543988356, 'validation_fraction': 0.12669493783207642}
observation time 0.000078, current best 0.084573 at iter 10
suggestion time taken 0.002171 iter 11 next_points [{'alpha': 1.4216372179766492e-05, 'batch_size': 214, 'beta_1': 0.622464285973247, 'beta_2': 0.9918050068873167, 'epsilon': 3.09486369839586e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 1.5794921814988835e-05, 'tol': 0.04356868238790467, 'validation_fraction': 0.32093581894201156}]
function_evaluation time 0.385575 value 7.997522 suggestion {'alpha': 1.4216372179766492e-05, 'batch_size': 214, 'beta_1': 0.622464285973247, 'beta_2': 0.9918050068873167, 'epsilon': 3.09486369839586e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 1.5794921814988835e-05, 'tol': 0.04356868238790467, 'validation_fraction': 0.32093581894201156}
observation time 0.000074, current best 0.084573 at iter 11
suggestion time taken 0.002108 iter 12 next_points [{'alpha': 0.0014966031612394111, 'batch_size': 242, 'beta_1': 0.6851250854403796, 'beta_2': 0.9649329499111919, 'epsilon': 1.7484990325041192e-07, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.05478496083004296, 'tol': 0.001868735681519205, 'validation_fraction': 0.6593564527645936}]
function_evaluation time 0.729505 value 0.506419 suggestion {'alpha': 0.0014966031612394111, 'batch_size': 242, 'beta_1': 0.6851250854403796, 'beta_2': 0.9649329499111919, 'epsilon': 1.7484990325041192e-07, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.05478496083004296, 'tol': 0.001868735681519205, 'validation_fraction': 0.6593564527645936}
observation time 0.000072, current best 0.084573 at iter 12
suggestion time taken 0.002428 iter 13 next_points [{'alpha': 0.8202190423789, 'batch_size': 246, 'beta_1': 0.5030007335660199, 'beta_2': 0.9618854967774486, 'epsilon': 7.724768795934407e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.0006172066275245053, 'tol': 0.0005502818752283363, 'validation_fraction': 0.17061114714618505}]
function_evaluation time 1.487475 value 0.166822 suggestion {'alpha': 0.8202190423789, 'batch_size': 246, 'beta_1': 0.5030007335660199, 'beta_2': 0.9618854967774486, 'epsilon': 7.724768795934407e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.0006172066275245053, 'tol': 0.0005502818752283363, 'validation_fraction': 0.17061114714618505}
observation time 0.000076, current best 0.084573 at iter 13
suggestion time taken 0.002113 iter 14 next_points [{'alpha': 1.7338244306696298e-05, 'batch_size': 91, 'beta_1': 0.5484255350953893, 'beta_2': 0.9302553715280222, 'epsilon': 2.558257318741669e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 7.537515306927719e-05, 'tol': 0.004488895300702816, 'validation_fraction': 0.4370201459105131}]
function_evaluation time 1.476146 value 4.214949 suggestion {'alpha': 1.7338244306696298e-05, 'batch_size': 91, 'beta_1': 0.5484255350953893, 'beta_2': 0.9302553715280222, 'epsilon': 2.558257318741669e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 7.537515306927719e-05, 'tol': 0.004488895300702816, 'validation_fraction': 0.4370201459105131}
observation time 0.000076, current best 0.084573 at iter 14
saving meta data: {'args': {'--uuid': 'daf578d98ae15cdb93cb6c9c30307724', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

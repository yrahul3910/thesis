running: {'--uuid': '856b9ebc573f5ffb89b8ab1a40b766e4', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u 856b9ebc573f5ffb89b8ab1a40b766e4 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study turbo MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002134 iter 0 next_points [{'alpha': 0.00209299124397114, 'batch_size': 70, 'beta_1': 0.8607735767145711, 'beta_2': 0.9713978970683791, 'epsilon': 1.9917621093709655e-08, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.04716589516848079, 'tol': 0.09075570238813337, 'validation_fraction': 0.7296365194266217}]
function_evaluation time 0.316424 value 0.559624 suggestion {'alpha': 0.00209299124397114, 'batch_size': 70, 'beta_1': 0.8607735767145711, 'beta_2': 0.9713978970683791, 'epsilon': 1.9917621093709655e-08, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.04716589516848079, 'tol': 0.09075570238813337, 'validation_fraction': 0.7296365194266217}
observation time 0.001436, current best 0.559624 at iter 0
suggestion time taken 0.001764 iter 1 next_points [{'alpha': 1.420994109506165, 'batch_size': 84, 'beta_1': 0.7430006972154799, 'beta_2': 0.9993738787042347, 'epsilon': 7.753881198200537e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 4.098361367834779e-05, 'tol': 4.901658461334499e-05, 'validation_fraction': 0.8458282598103509}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.137738 value 3.690527 suggestion {'alpha': 1.420994109506165, 'batch_size': 84, 'beta_1': 0.7430006972154799, 'beta_2': 0.9993738787042347, 'epsilon': 7.753881198200537e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 4.098361367834779e-05, 'tol': 4.901658461334499e-05, 'validation_fraction': 0.8458282598103509}
observation time 0.001420, current best 0.559624 at iter 1
suggestion time taken 0.001744 iter 2 next_points [{'alpha': 7.429888793278537, 'batch_size': 216, 'beta_1': 0.9784553394108131, 'beta_2': 0.9999960717614375, 'epsilon': 1.6853271724358086e-07, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.0904729692231493, 'tol': 0.009570805574711558, 'validation_fraction': 0.598617940475005}]
function_evaluation time 0.582322 value 0.885447 suggestion {'alpha': 7.429888793278537, 'batch_size': 216, 'beta_1': 0.9784553394108131, 'beta_2': 0.9999960717614375, 'epsilon': 1.6853271724358086e-07, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.0904729692231493, 'tol': 0.009570805574711558, 'validation_fraction': 0.598617940475005}
observation time 0.001434, current best 0.559624 at iter 2
suggestion time taken 0.001676 iter 3 next_points [{'alpha': 0.0005909146398355908, 'batch_size': 123, 'beta_1': 0.5357320134456062, 'beta_2': 0.9999988525786317, 'epsilon': 3.897103523128034e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 1.4748747513380425e-05, 'tol': 0.022254393152210707, 'validation_fraction': 0.2714429924856726}]
function_evaluation time 0.315911 value 11.454698 suggestion {'alpha': 0.0005909146398355908, 'batch_size': 123, 'beta_1': 0.5357320134456062, 'beta_2': 0.9999988525786317, 'epsilon': 3.897103523128034e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 1.4748747513380425e-05, 'tol': 0.022254393152210707, 'validation_fraction': 0.2714429924856726}
observation time 0.001698, current best 0.559624 at iter 3
suggestion time taken 0.001825 iter 4 next_points [{'alpha': 3.8283304680804125e-05, 'batch_size': 86, 'beta_1': 0.9860256228412463, 'beta_2': 0.9665744390288948, 'epsilon': 3.302429514017205e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.00014569247047914287, 'tol': 0.004061312898964533, 'validation_fraction': 0.8934740367303001}]
function_evaluation time 0.849961 value 4.286746 suggestion {'alpha': 3.8283304680804125e-05, 'batch_size': 86, 'beta_1': 0.9860256228412463, 'beta_2': 0.9665744390288948, 'epsilon': 3.302429514017205e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.00014569247047914287, 'tol': 0.004061312898964533, 'validation_fraction': 0.8934740367303001}
observation time 0.001352, current best 0.559624 at iter 4
suggestion time taken 0.001733 iter 5 next_points [{'alpha': 1.7289265072677478e-05, 'batch_size': 16, 'beta_1': 0.8151176756887859, 'beta_2': 0.9841374820431472, 'epsilon': 5.075701366147076e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 2.2202662611101484e-05, 'tol': 2.1966815763624738e-05, 'validation_fraction': 0.23538178779940833}]
function_evaluation time 11.920613 value 0.176950 suggestion {'alpha': 1.7289265072677478e-05, 'batch_size': 16, 'beta_1': 0.8151176756887859, 'beta_2': 0.9841374820431472, 'epsilon': 5.075701366147076e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 2.2202662611101484e-05, 'tol': 2.1966815763624738e-05, 'validation_fraction': 0.23538178779940833}
observation time 0.001337, current best 0.176950 at iter 5
suggestion time taken 0.001702 iter 6 next_points [{'alpha': 4.6082091190583415e-05, 'batch_size': 242, 'beta_1': 0.607601645321249, 'beta_2': 0.9975260153036433, 'epsilon': 2.485805259243857e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0004260600572400796, 'tol': 0.000778828844096857, 'validation_fraction': 0.136277308911467}]
function_evaluation time 1.840774 value 0.222808 suggestion {'alpha': 4.6082091190583415e-05, 'batch_size': 242, 'beta_1': 0.607601645321249, 'beta_2': 0.9975260153036433, 'epsilon': 2.485805259243857e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0004260600572400796, 'tol': 0.000778828844096857, 'validation_fraction': 0.136277308911467}
observation time 0.001397, current best 0.176950 at iter 6
suggestion time taken 0.001739 iter 7 next_points [{'alpha': 0.0001618804849954241, 'batch_size': 204, 'beta_1': 0.9310169444354374, 'beta_2': 0.999992394857053, 'epsilon': 7.581294445629101e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.015248618760063141, 'tol': 7.077157174991075e-05, 'validation_fraction': 0.39022341074366157}]
function_evaluation time 0.767124 value 0.170750 suggestion {'alpha': 0.0001618804849954241, 'batch_size': 204, 'beta_1': 0.9310169444354374, 'beta_2': 0.999992394857053, 'epsilon': 7.581294445629101e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.015248618760063141, 'tol': 7.077157174991075e-05, 'validation_fraction': 0.39022341074366157}
observation time 0.001357, current best 0.170750 at iter 7
suggestion time taken 0.001753 iter 8 next_points [{'alpha': 0.6455734804283135, 'batch_size': 235, 'beta_1': 0.9118396017389816, 'beta_2': 0.999968634694741, 'epsilon': 1.3520930526959e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.005677763364984364, 'tol': 0.0017180119403126136, 'validation_fraction': 0.17985176049556414}]
function_evaluation time 1.068813 value 0.149244 suggestion {'alpha': 0.6455734804283135, 'batch_size': 235, 'beta_1': 0.9118396017389816, 'beta_2': 0.999968634694741, 'epsilon': 1.3520930526959e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.005677763364984364, 'tol': 0.0017180119403126136, 'validation_fraction': 0.17985176049556414}
observation time 0.001390, current best 0.149244 at iter 8
suggestion time taken 0.001727 iter 9 next_points [{'alpha': 0.0010740716118036453, 'batch_size': 54, 'beta_1': 0.6557641034355177, 'beta_2': 0.9996592179492546, 'epsilon': 8.83957090531758e-08, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.0027496058280767842, 'tol': 0.006741198108621756, 'validation_fraction': 0.7457940928854413}]
function_evaluation time 0.630894 value 0.218518 suggestion {'alpha': 0.0010740716118036453, 'batch_size': 54, 'beta_1': 0.6557641034355177, 'beta_2': 0.9996592179492546, 'epsilon': 8.83957090531758e-08, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.0027496058280767842, 'tol': 0.006741198108621756, 'validation_fraction': 0.7457940928854413}
observation time 0.001370, current best 0.149244 at iter 9
suggestion time taken 0.001703 iter 10 next_points [{'alpha': 0.051546359812703675, 'batch_size': 35, 'beta_1': 0.79246165528524, 'beta_2': 0.9999845128694286, 'epsilon': 6.248637363682664e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 6.326257102206812e-05, 'tol': 0.0008893329044965219, 'validation_fraction': 0.661454760948868}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 5.786633 value 0.454326 suggestion {'alpha': 0.051546359812703675, 'batch_size': 35, 'beta_1': 0.79246165528524, 'beta_2': 0.9999845128694286, 'epsilon': 6.248637363682664e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 6.326257102206812e-05, 'tol': 0.0008893329044965219, 'validation_fraction': 0.661454760948868}
observation time 0.001437, current best 0.149244 at iter 10
suggestion time taken 0.001726 iter 11 next_points [{'alpha': 0.08030717548388122, 'batch_size': 154, 'beta_1': 0.9637052292473389, 'beta_2': 0.9941850292809459, 'epsilon': 5.907570073921228e-07, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.0011196264005216324, 'tol': 0.0001890523085818883, 'validation_fraction': 0.8695438376716205}]
function_evaluation time 1.112266 value 0.478915 suggestion {'alpha': 0.08030717548388122, 'batch_size': 154, 'beta_1': 0.9637052292473389, 'beta_2': 0.9941850292809459, 'epsilon': 5.907570073921228e-07, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.0011196264005216324, 'tol': 0.0001890523085818883, 'validation_fraction': 0.8695438376716205}
observation time 0.001375, current best 0.149244 at iter 11
suggestion time taken 0.001731 iter 12 next_points [{'alpha': 0.0003256671546769933, 'batch_size': 104, 'beta_1': 0.9892072769015743, 'beta_2': 0.9991535206381051, 'epsilon': 2.132720909941225e-09, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.0005368797789619702, 'tol': 0.002121437543843242, 'validation_fraction': 0.3529856286978079}]
function_evaluation time 1.634820 value 0.208239 suggestion {'alpha': 0.0003256671546769933, 'batch_size': 104, 'beta_1': 0.9892072769015743, 'beta_2': 0.9991535206381051, 'epsilon': 2.132720909941225e-09, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.0005368797789619702, 'tol': 0.002121437543843242, 'validation_fraction': 0.3529856286978079}
observation time 0.001378, current best 0.149244 at iter 12
suggestion time taken 0.001721 iter 13 next_points [{'alpha': 3.281538971779002, 'batch_size': 176, 'beta_1': 0.8777613679231152, 'beta_2': 0.9951746459614941, 'epsilon': 1.4945951731135272e-09, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.02694565779242725, 'tol': 0.0003073230300439368, 'validation_fraction': 0.5667222886622273}]
function_evaluation time 0.771901 value 0.162029 suggestion {'alpha': 3.281538971779002, 'batch_size': 176, 'beta_1': 0.8777613679231152, 'beta_2': 0.9951746459614941, 'epsilon': 1.4945951731135272e-09, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.02694565779242725, 'tol': 0.0003073230300439368, 'validation_fraction': 0.5667222886622273}
observation time 0.001406, current best 0.149244 at iter 13
suggestion time taken 0.001756 iter 14 next_points [{'alpha': 0.009629191662439945, 'batch_size': 174, 'beta_1': 0.94663528629263, 'beta_2': 0.9998810244260915, 'epsilon': 3.3028127108145268e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.0018536068607869077, 'tol': 0.00018302335772724812, 'validation_fraction': 0.10877082233559209}]
function_evaluation time 0.821017 value 0.191738 suggestion {'alpha': 0.009629191662439945, 'batch_size': 174, 'beta_1': 0.94663528629263, 'beta_2': 0.9998810244260915, 'epsilon': 3.3028127108145268e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.0018536068607869077, 'tol': 0.00018302335772724812, 'validation_fraction': 0.10877082233559209}
observation time 0.001419, current best 0.149244 at iter 14
saving meta data: {'args': {'--uuid': '856b9ebc573f5ffb89b8ab1a40b766e4', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

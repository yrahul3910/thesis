running: {'--uuid': '8d1167e8401f5e239fa50b3ebcf731ff', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 8d1167e8401f5e239fa50b3ebcf731ff -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002387 iter 0 next_points [{'alpha': 0.08117867423351116, 'batch_size': 127, 'beta_1': 0.5271913912294709, 'beta_2': 0.9756595928326288, 'epsilon': 1.430083301614976e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.002340284279805758, 'tol': 2.3358910399642455e-05, 'validation_fraction': 0.30809798858345006}]
function_evaluation time 1.343228 value -0.968690 suggestion {'alpha': 0.08117867423351116, 'batch_size': 127, 'beta_1': 0.5271913912294709, 'beta_2': 0.9756595928326288, 'epsilon': 1.430083301614976e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.002340284279805758, 'tol': 2.3358910399642455e-05, 'validation_fraction': 0.30809798858345006}
observation time 0.000068, current best -0.968690 at iter 0
suggestion time taken 0.002368 iter 1 next_points [{'alpha': 0.034483608714217184, 'batch_size': 134, 'beta_1': 0.8613978564231278, 'beta_2': 0.9132684259273385, 'epsilon': 1.0532808900088076e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 3.005157934517685e-05, 'tol': 0.0006857551838383406, 'validation_fraction': 0.2558502020506566}]
function_evaluation time 4.877309 value -0.905369 suggestion {'alpha': 0.034483608714217184, 'batch_size': 134, 'beta_1': 0.8613978564231278, 'beta_2': 0.9132684259273385, 'epsilon': 1.0532808900088076e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 3.005157934517685e-05, 'tol': 0.0006857551838383406, 'validation_fraction': 0.2558502020506566}
observation time 0.000068, current best -0.968690 at iter 1
suggestion time taken 0.002330 iter 2 next_points [{'alpha': 8.32591019142457, 'batch_size': 247, 'beta_1': 0.7657538766715032, 'beta_2': 0.9514038787193797, 'epsilon': 4.15530631611409e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00020204154245218633, 'tol': 0.007288134169716272, 'validation_fraction': 0.5627465915941625}]
function_evaluation time 1.023417 value -0.572055 suggestion {'alpha': 8.32591019142457, 'batch_size': 247, 'beta_1': 0.7657538766715032, 'beta_2': 0.9514038787193797, 'epsilon': 4.15530631611409e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00020204154245218633, 'tol': 0.007288134169716272, 'validation_fraction': 0.5627465915941625}
observation time 0.000069, current best -0.968690 at iter 2
suggestion time taken 0.002144 iter 3 next_points [{'alpha': 0.004747238335409984, 'batch_size': 80, 'beta_1': 0.979789066771058, 'beta_2': 0.992875778876202, 'epsilon': 2.393850057491947e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 5.058109789122196e-05, 'tol': 0.021743073338513202, 'validation_fraction': 0.8639312727978067}]
function_evaluation time 0.185390 value -0.149591 suggestion {'alpha': 0.004747238335409984, 'batch_size': 80, 'beta_1': 0.979789066771058, 'beta_2': 0.992875778876202, 'epsilon': 2.393850057491947e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 5.058109789122196e-05, 'tol': 0.021743073338513202, 'validation_fraction': 0.8639312727978067}
observation time 0.000070, current best -0.968690 at iter 3
suggestion time taken 0.002129 iter 4 next_points [{'alpha': 0.010006900855959592, 'batch_size': 176, 'beta_1': 0.5043615921661402, 'beta_2': 0.9817415428291758, 'epsilon': 2.7680960489268636e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.013515782973119636, 'tol': 0.030221977683481803, 'validation_fraction': 0.17328211908151003}]
function_evaluation time 0.359303 value -0.954769 suggestion {'alpha': 0.010006900855959592, 'batch_size': 176, 'beta_1': 0.5043615921661402, 'beta_2': 0.9817415428291758, 'epsilon': 2.7680960489268636e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.013515782973119636, 'tol': 0.030221977683481803, 'validation_fraction': 0.17328211908151003}
observation time 0.000068, current best -0.968690 at iter 4
suggestion time taken 0.002116 iter 5 next_points [{'alpha': 0.24783024338896179, 'batch_size': 74, 'beta_1': 0.7045898749311383, 'beta_2': 0.9607268351500894, 'epsilon': 3.5723445234221318e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.00023855074351310555, 'tol': 0.0036101229236655324, 'validation_fraction': 0.21617814855590337}]
function_evaluation time 2.558555 value -0.963129 suggestion {'alpha': 0.24783024338896179, 'batch_size': 74, 'beta_1': 0.7045898749311383, 'beta_2': 0.9607268351500894, 'epsilon': 3.5723445234221318e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.00023855074351310555, 'tol': 0.0036101229236655324, 'validation_fraction': 0.21617814855590337}
observation time 0.000068, current best -0.968690 at iter 5
suggestion time taken 0.002285 iter 6 next_points [{'alpha': 0.00011087746746041395, 'batch_size': 165, 'beta_1': 0.5427667548308006, 'beta_2': 0.984701470936931, 'epsilon': 1.3255809126436923e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.02025079086673848, 'tol': 0.003872391949647081, 'validation_fraction': 0.11929868671833352}]
function_evaluation time 0.723352 value -0.963824 suggestion {'alpha': 0.00011087746746041395, 'batch_size': 165, 'beta_1': 0.5427667548308006, 'beta_2': 0.984701470936931, 'epsilon': 1.3255809126436923e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.02025079086673848, 'tol': 0.003872391949647081, 'validation_fraction': 0.11929868671833352}
observation time 0.000073, current best -0.968690 at iter 6
suggestion time taken 0.002213 iter 7 next_points [{'alpha': 0.17206808444748264, 'batch_size': 107, 'beta_1': 0.6975282722068579, 'beta_2': 0.9494758199937798, 'epsilon': 6.775748385909181e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.015480064912676764, 'tol': 0.0002487375972211885, 'validation_fraction': 0.23569950885502888}]
function_evaluation time 1.207111 value -0.961718 suggestion {'alpha': 0.17206808444748264, 'batch_size': 107, 'beta_1': 0.6975282722068579, 'beta_2': 0.9494758199937798, 'epsilon': 6.775748385909181e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.015480064912676764, 'tol': 0.0002487375972211885, 'validation_fraction': 0.23569950885502888}
observation time 0.000070, current best -0.968690 at iter 7
suggestion time taken 0.002150 iter 8 next_points [{'alpha': 0.00030353362984717635, 'batch_size': 202, 'beta_1': 0.8667767689735977, 'beta_2': 0.9885613646796519, 'epsilon': 4.056374952128608e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0006132982655032268, 'tol': 0.02571466276007291, 'validation_fraction': 0.1370875547515357}]
function_evaluation time 0.605383 value -0.894241 suggestion {'alpha': 0.00030353362984717635, 'batch_size': 202, 'beta_1': 0.8667767689735977, 'beta_2': 0.9885613646796519, 'epsilon': 4.056374952128608e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0006132982655032268, 'tol': 0.02571466276007291, 'validation_fraction': 0.1370875547515357}
observation time 0.000071, current best -0.968690 at iter 8
suggestion time taken 0.002171 iter 9 next_points [{'alpha': 0.34285578490043206, 'batch_size': 152, 'beta_1': 0.6706032877457533, 'beta_2': 0.9802715826624814, 'epsilon': 1.1096513531480946e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0313782540584782, 'tol': 7.699105161583537e-05, 'validation_fraction': 0.6873762160811161}]
function_evaluation time 0.944621 value -0.935980 suggestion {'alpha': 0.34285578490043206, 'batch_size': 152, 'beta_1': 0.6706032877457533, 'beta_2': 0.9802715826624814, 'epsilon': 1.1096513531480946e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0313782540584782, 'tol': 7.699105161583537e-05, 'validation_fraction': 0.6873762160811161}
observation time 0.000071, current best -0.968690 at iter 9
suggestion time taken 0.002130 iter 10 next_points [{'alpha': 0.011299217045615845, 'batch_size': 31, 'beta_1': 0.6930057055402219, 'beta_2': 0.9384735522480894, 'epsilon': 2.114114625965787e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.00979079400663759, 'tol': 0.03590939289649274, 'validation_fraction': 0.12904246999024063}]
function_evaluation time 1.131716 value -0.959645 suggestion {'alpha': 0.011299217045615845, 'batch_size': 31, 'beta_1': 0.6930057055402219, 'beta_2': 0.9384735522480894, 'epsilon': 2.114114625965787e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.00979079400663759, 'tol': 0.03590939289649274, 'validation_fraction': 0.12904246999024063}
observation time 0.000071, current best -0.968690 at iter 10
suggestion time taken 0.002126 iter 11 next_points [{'alpha': 0.006279282046261218, 'batch_size': 157, 'beta_1': 0.5275284576128907, 'beta_2': 0.9787168109967413, 'epsilon': 7.48602166031776e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 7.81740827062135e-05, 'tol': 0.00030612976593832636, 'validation_fraction': 0.7090972661611503}]
function_evaluation time 2.133023 value -0.645567 suggestion {'alpha': 0.006279282046261218, 'batch_size': 157, 'beta_1': 0.5275284576128907, 'beta_2': 0.9787168109967413, 'epsilon': 7.48602166031776e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 7.81740827062135e-05, 'tol': 0.00030612976593832636, 'validation_fraction': 0.7090972661611503}
observation time 0.000075, current best -0.968690 at iter 11
suggestion time taken 0.002150 iter 12 next_points [{'alpha': 7.189058601871128e-05, 'batch_size': 26, 'beta_1': 0.6472424577594004, 'beta_2': 0.9768479386928264, 'epsilon': 6.612543600915819e-09, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.00921473668244493, 'tol': 0.0011194664526687874, 'validation_fraction': 0.3479620866590777}]
function_evaluation time 2.627982 value -0.964511 suggestion {'alpha': 7.189058601871128e-05, 'batch_size': 26, 'beta_1': 0.6472424577594004, 'beta_2': 0.9768479386928264, 'epsilon': 6.612543600915819e-09, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.00921473668244493, 'tol': 0.0011194664526687874, 'validation_fraction': 0.3479620866590777}
observation time 0.000074, current best -0.968690 at iter 12
suggestion time taken 0.002459 iter 13 next_points [{'alpha': 3.738620503946949, 'batch_size': 155, 'beta_1': 0.7443466685918458, 'beta_2': 0.9191448673871215, 'epsilon': 4.120339175398017e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 2.0601784235581085e-05, 'tol': 0.0029891468456717894, 'validation_fraction': 0.31632265646904645}]
function_evaluation time 0.360823 value -0.094648 suggestion {'alpha': 3.738620503946949, 'batch_size': 155, 'beta_1': 0.7443466685918458, 'beta_2': 0.9191448673871215, 'epsilon': 4.120339175398017e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 2.0601784235581085e-05, 'tol': 0.0029891468456717894, 'validation_fraction': 0.31632265646904645}
observation time 0.000070, current best -0.968690 at iter 13
suggestion time taken 0.002122 iter 14 next_points [{'alpha': 0.000562169625463546, 'batch_size': 33, 'beta_1': 0.579563305761497, 'beta_2': 0.9242883232792072, 'epsilon': 9.808730966120283e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 2.6319614834735343e-05, 'tol': 0.03204713758637718, 'validation_fraction': 0.5652632560864191}]
function_evaluation time 0.621265 value -0.157274 suggestion {'alpha': 0.000562169625463546, 'batch_size': 33, 'beta_1': 0.579563305761497, 'beta_2': 0.9242883232792072, 'epsilon': 9.808730966120283e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 2.6319614834735343e-05, 'tol': 0.03204713758637718, 'validation_fraction': 0.5652632560864191}
observation time 0.000074, current best -0.968690 at iter 14
saving meta data: {'args': {'--uuid': '8d1167e8401f5e239fa50b3ebcf731ff', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

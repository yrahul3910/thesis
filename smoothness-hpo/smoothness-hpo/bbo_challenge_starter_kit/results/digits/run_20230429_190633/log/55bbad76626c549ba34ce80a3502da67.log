running: {'--uuid': '55bbad76626c549ba34ce80a3502da67', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d digits -o random-search -u 55bbad76626c549ba34ce80a3502da67 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study random-search MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002553 iter 0 next_points [{'alpha': 0.2646326263972304, 'batch_size': 218, 'beta_1': 0.9523173487718407, 'beta_2': 0.9958567337188865, 'epsilon': 1.0478920989889001e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.04358140684655318, 'tol': 0.0072255000089259695, 'validation_fraction': 0.3607547158539023}]
function_evaluation time 0.897515 value 0.379639 suggestion {'alpha': 0.2646326263972304, 'batch_size': 218, 'beta_1': 0.9523173487718407, 'beta_2': 0.9958567337188865, 'epsilon': 1.0478920989889001e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.04358140684655318, 'tol': 0.0072255000089259695, 'validation_fraction': 0.3607547158539023}
observation time 0.000007, current best 0.379639 at iter 0
suggestion time taken 0.002460 iter 1 next_points [{'alpha': 0.7168085944261608, 'batch_size': 101, 'beta_1': 0.8123516237033835, 'beta_2': 0.9666877311855148, 'epsilon': 6.630603084531723e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 8.946989922554138e-05, 'tol': 0.005009462136389418, 'validation_fraction': 0.20130620183278766}]
function_evaluation time 1.511839 value 5.809971 suggestion {'alpha': 0.7168085944261608, 'batch_size': 101, 'beta_1': 0.8123516237033835, 'beta_2': 0.9666877311855148, 'epsilon': 6.630603084531723e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 8.946989922554138e-05, 'tol': 0.005009462136389418, 'validation_fraction': 0.20130620183278766}
observation time 0.000005, current best 0.379639 at iter 1
suggestion time taken 0.002882 iter 2 next_points [{'alpha': 0.27356020324278196, 'batch_size': 179, 'beta_1': 0.9885205775681091, 'beta_2': 0.9999740126587001, 'epsilon': 7.109729052245247e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.00044447264398616047, 'tol': 0.002737642717596095, 'validation_fraction': 0.42573718182278764}]
function_evaluation time 1.420531 value 0.254543 suggestion {'alpha': 0.27356020324278196, 'batch_size': 179, 'beta_1': 0.9885205775681091, 'beta_2': 0.9999740126587001, 'epsilon': 7.109729052245247e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.00044447264398616047, 'tol': 0.002737642717596095, 'validation_fraction': 0.42573718182278764}
observation time 0.000005, current best 0.254543 at iter 2
suggestion time taken 0.002773 iter 3 next_points [{'alpha': 0.00977569235893674, 'batch_size': 244, 'beta_1': 0.6538562312944048, 'beta_2': 0.9831030691553121, 'epsilon': 7.062954898407377e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.0007382296908309974, 'tol': 5.075325899565293e-05, 'validation_fraction': 0.7299338786131783}]
function_evaluation time 1.825212 value 0.423117 suggestion {'alpha': 0.00977569235893674, 'batch_size': 244, 'beta_1': 0.6538562312944048, 'beta_2': 0.9831030691553121, 'epsilon': 7.062954898407377e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.0007382296908309974, 'tol': 5.075325899565293e-05, 'validation_fraction': 0.7299338786131783}
observation time 0.000004, current best 0.254543 at iter 3
suggestion time taken 0.002837 iter 4 next_points [{'alpha': 2.27318781650171e-05, 'batch_size': 128, 'beta_1': 0.97504303903962, 'beta_2': 0.9999945239005452, 'epsilon': 1.983480995308163e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0028268636979779044, 'tol': 0.00045689837985618114, 'validation_fraction': 0.6496954534738935}]
function_evaluation time 0.742600 value 0.282342 suggestion {'alpha': 2.27318781650171e-05, 'batch_size': 128, 'beta_1': 0.97504303903962, 'beta_2': 0.9999945239005452, 'epsilon': 1.983480995308163e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0028268636979779044, 'tol': 0.00045689837985618114, 'validation_fraction': 0.6496954534738935}
observation time 0.000005, current best 0.254543 at iter 4
suggestion time taken 0.002854 iter 5 next_points [{'alpha': 0.0005804479987288587, 'batch_size': 49, 'beta_1': 0.9515405959104084, 'beta_2': 0.9814381806938689, 'epsilon': 2.7057505799956372e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.015557582087530117, 'tol': 0.017152089560645293, 'validation_fraction': 0.6879904330395309}]
function_evaluation time 0.483505 value 0.200895 suggestion {'alpha': 0.0005804479987288587, 'batch_size': 49, 'beta_1': 0.9515405959104084, 'beta_2': 0.9814381806938689, 'epsilon': 2.7057505799956372e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.015557582087530117, 'tol': 0.017152089560645293, 'validation_fraction': 0.6879904330395309}
observation time 0.000005, current best 0.200895 at iter 5
suggestion time taken 0.002479 iter 6 next_points [{'alpha': 0.004876399472504225, 'batch_size': 235, 'beta_1': 0.9796436857930726, 'beta_2': 0.9999532408540349, 'epsilon': 1.0170520557067645e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 7.217944863348967e-05, 'tol': 0.0014125036808280264, 'validation_fraction': 0.4232887910925748}]
function_evaluation time 4.110259 value 2.193233 suggestion {'alpha': 0.004876399472504225, 'batch_size': 235, 'beta_1': 0.9796436857930726, 'beta_2': 0.9999532408540349, 'epsilon': 1.0170520557067645e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 7.217944863348967e-05, 'tol': 0.0014125036808280264, 'validation_fraction': 0.4232887910925748}
observation time 0.000005, current best 0.200895 at iter 6
suggestion time taken 0.002474 iter 7 next_points [{'alpha': 0.0014472842826899104, 'batch_size': 216, 'beta_1': 0.5443417555342078, 'beta_2': 0.9999669500135461, 'epsilon': 6.367437018992992e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.03083670827556459, 'tol': 2.9651815637990865e-05, 'validation_fraction': 0.3893170555180936}]
function_evaluation time 0.904610 value 0.135309 suggestion {'alpha': 0.0014472842826899104, 'batch_size': 216, 'beta_1': 0.5443417555342078, 'beta_2': 0.9999669500135461, 'epsilon': 6.367437018992992e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.03083670827556459, 'tol': 2.9651815637990865e-05, 'validation_fraction': 0.3893170555180936}
observation time 0.000005, current best 0.135309 at iter 7
suggestion time taken 0.002468 iter 8 next_points [{'alpha': 0.0030213423479617816, 'batch_size': 154, 'beta_1': 0.9628888330713229, 'beta_2': 0.9999954852670744, 'epsilon': 3.467880167012329e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.05617028058180017, 'tol': 0.01992574549359358, 'validation_fraction': 0.5259738171984452}]
function_evaluation time 0.482454 value 3.627413 suggestion {'alpha': 0.0030213423479617816, 'batch_size': 154, 'beta_1': 0.9628888330713229, 'beta_2': 0.9999954852670744, 'epsilon': 3.467880167012329e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.05617028058180017, 'tol': 0.01992574549359358, 'validation_fraction': 0.5259738171984452}
observation time 0.000005, current best 0.135309 at iter 8
suggestion time taken 0.002465 iter 9 next_points [{'alpha': 0.061154647009309504, 'batch_size': 110, 'beta_1': 0.9877443632355455, 'beta_2': 0.9999883897011652, 'epsilon': 1.2494501154462994e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0002668912035478944, 'tol': 5.9033376432215174e-05, 'validation_fraction': 0.8597635830805768}]
function_evaluation time 2.217395 value 0.407096 suggestion {'alpha': 0.061154647009309504, 'batch_size': 110, 'beta_1': 0.9877443632355455, 'beta_2': 0.9999883897011652, 'epsilon': 1.2494501154462994e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0002668912035478944, 'tol': 5.9033376432215174e-05, 'validation_fraction': 0.8597635830805768}
observation time 0.000005, current best 0.135309 at iter 9
suggestion time taken 0.002804 iter 10 next_points [{'alpha': 0.001342974889996156, 'batch_size': 73, 'beta_1': 0.7389308309358028, 'beta_2': 0.9980323952108824, 'epsilon': 9.910101700226047e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.06607172311038984, 'tol': 0.0005316522894004657, 'validation_fraction': 0.7048814316204772}]
function_evaluation time 0.918962 value 0.567088 suggestion {'alpha': 0.001342974889996156, 'batch_size': 73, 'beta_1': 0.7389308309358028, 'beta_2': 0.9980323952108824, 'epsilon': 9.910101700226047e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.06607172311038984, 'tol': 0.0005316522894004657, 'validation_fraction': 0.7048814316204772}
observation time 0.000005, current best 0.135309 at iter 10
suggestion time taken 0.002481 iter 11 next_points [{'alpha': 3.080942623376622e-05, 'batch_size': 204, 'beta_1': 0.8646186843301228, 'beta_2': 0.9999799243535984, 'epsilon': 3.950339074008937e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 1.4443444776269253e-05, 'tol': 0.006128596258060689, 'validation_fraction': 0.8940215332669021}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.167820 value 7.717942 suggestion {'alpha': 3.080942623376622e-05, 'batch_size': 204, 'beta_1': 0.8646186843301228, 'beta_2': 0.9999799243535984, 'epsilon': 3.950339074008937e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 1.4443444776269253e-05, 'tol': 0.006128596258060689, 'validation_fraction': 0.8940215332669021}
observation time 0.000005, current best 0.135309 at iter 11
suggestion time taken 0.002835 iter 12 next_points [{'alpha': 0.4500996921508403, 'batch_size': 36, 'beta_1': 0.9881632254853104, 'beta_2': 0.9999823651804283, 'epsilon': 7.180158363552694e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.0034343948797858678, 'tol': 6.709392931977016e-05, 'validation_fraction': 0.8788689921233341}]
function_evaluation time 0.668846 value 0.547755 suggestion {'alpha': 0.4500996921508403, 'batch_size': 36, 'beta_1': 0.9881632254853104, 'beta_2': 0.9999823651804283, 'epsilon': 7.180158363552694e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.0034343948797858678, 'tol': 6.709392931977016e-05, 'validation_fraction': 0.8788689921233341}
observation time 0.000005, current best 0.135309 at iter 12
suggestion time taken 0.002536 iter 13 next_points [{'alpha': 0.03241333214011239, 'batch_size': 146, 'beta_1': 0.5399943973678493, 'beta_2': 0.9997870312793292, 'epsilon': 2.111885656307414e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.0015818345585156028, 'tol': 0.002914994234258193, 'validation_fraction': 0.37743036098827065}]
function_evaluation time 0.907589 value 0.161331 suggestion {'alpha': 0.03241333214011239, 'batch_size': 146, 'beta_1': 0.5399943973678493, 'beta_2': 0.9997870312793292, 'epsilon': 2.111885656307414e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.0015818345585156028, 'tol': 0.002914994234258193, 'validation_fraction': 0.37743036098827065}
observation time 0.000005, current best 0.135309 at iter 13
suggestion time taken 0.002424 iter 14 next_points [{'alpha': 0.013507694542507567, 'batch_size': 57, 'beta_1': 0.7966488334301979, 'beta_2': 0.9999969634563515, 'epsilon': 7.996412223050613e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.00042494344161397255, 'tol': 0.00013481437330555986, 'validation_fraction': 0.6797221901015267}]
function_evaluation time 2.477917 value 0.241051 suggestion {'alpha': 0.013507694542507567, 'batch_size': 57, 'beta_1': 0.7966488334301979, 'beta_2': 0.9999969634563515, 'epsilon': 7.996412223050613e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.00042494344161397255, 'tol': 0.00013481437330555986, 'validation_fraction': 0.6797221901015267}
observation time 0.000005, current best 0.135309 at iter 14
saving meta data: {'args': {'--uuid': '55bbad76626c549ba34ce80a3502da67', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

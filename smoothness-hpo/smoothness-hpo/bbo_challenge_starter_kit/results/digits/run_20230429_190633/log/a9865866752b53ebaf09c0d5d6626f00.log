running: {'--uuid': 'a9865866752b53ebaf09c0d5d6626f00', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'opentuner', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d digits -o opentuner -u a9865866752b53ebaf09c0d5d6626f00 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study opentuner MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.056752 iter 0 next_points [{'hidden_layer_sizes': 156, 'alpha': 1.6677993914031184, 'batch_size': 99, 'learning_rate_init': 0.09896937496190465, 'tol': 0.05561193762702759, 'validation_fraction': 0.24972726017356495, 'beta_1': 0.5428090969382298, 'beta_2': 0.9233646510065306, 'epsilon': 9.503377282066006e-07}]
function_evaluation time 0.486127 value -0.433082 suggestion {'hidden_layer_sizes': 156, 'alpha': 1.6677993914031184, 'batch_size': 99, 'learning_rate_init': 0.09896937496190465, 'tol': 0.05561193762702759, 'validation_fraction': 0.24972726017356495, 'beta_1': 0.5428090969382298, 'beta_2': 0.9233646510065306, 'epsilon': 9.503377282066006e-07}
observation time 0.004223, current best -0.433082 at iter 0
suggestion time taken 0.007777 iter 1 next_points [{'hidden_layer_sizes': 153, 'alpha': 2.4028634964766566, 'batch_size': 99, 'learning_rate_init': 0.09406446090279179, 'tol': 0.05561193762702759, 'validation_fraction': 0.14882180552611085, 'beta_1': 0.5684927652175358, 'beta_2': 0.9233646510065306, 'epsilon': 9.503377282066006e-07}]
function_evaluation time 0.495977 value -0.417552 suggestion {'hidden_layer_sizes': 153, 'alpha': 2.4028634964766566, 'batch_size': 99, 'learning_rate_init': 0.09406446090279179, 'tol': 0.05561193762702759, 'validation_fraction': 0.14882180552611085, 'beta_1': 0.5684927652175358, 'beta_2': 0.9233646510065306, 'epsilon': 9.503377282066006e-07}
observation time 0.002057, current best -0.433082 at iter 1
suggestion time taken 0.021840 iter 2 next_points [{'hidden_layer_sizes': 72, 'epsilon': 8.857883647966625e-07, 'beta_2': 0.9864337765513238, 'alpha': 0.39945333836319125, 'tol': 0.08133476301774116, 'validation_fraction': 0.5299503061601545, 'beta_1': 0.9006531265758486, 'batch_size': 246, 'learning_rate_init': 0.026177187682648807}]
function_evaluation time 0.262951 value -0.919960 suggestion {'hidden_layer_sizes': 72, 'epsilon': 8.857883647966625e-07, 'beta_2': 0.9864337765513238, 'alpha': 0.39945333836319125, 'tol': 0.08133476301774116, 'validation_fraction': 0.5299503061601545, 'beta_1': 0.9006531265758486, 'batch_size': 246, 'learning_rate_init': 0.026177187682648807}
observation time 0.002115, current best -0.919960 at iter 2
suggestion time taken 0.006917 iter 3 next_points [{'hidden_layer_sizes': 72, 'epsilon': 8.857883647966625e-07, 'beta_2': 0.9864337765513238, 'alpha': 0.39945333836319125, 'tol': 0.08133476301774116, 'validation_fraction': 0.5299503061601545, 'beta_1': 0.9006531265758486, 'batch_size': 246, 'learning_rate_init': 0.08341654713494766}]
function_evaluation time 0.272593 value -0.587161 suggestion {'hidden_layer_sizes': 72, 'epsilon': 8.857883647966625e-07, 'beta_2': 0.9864337765513238, 'alpha': 0.39945333836319125, 'tol': 0.08133476301774116, 'validation_fraction': 0.5299503061601545, 'beta_1': 0.9006531265758486, 'batch_size': 246, 'learning_rate_init': 0.08341654713494766}
observation time 0.001828, current best -0.919960 at iter 3
suggestion time taken 0.005804 iter 4 next_points [{'hidden_layer_sizes': 176, 'epsilon': 8.723925563341718e-07, 'beta_2': 0.9755916793344177, 'alpha': 6.324478711708047, 'tol': 0.0720780895265211, 'validation_fraction': 0.25947889938519664, 'beta_1': 0.6514734235803551, 'batch_size': 145, 'learning_rate_init': 0.08284880346898864}]
function_evaluation time 0.525569 value -0.651396 suggestion {'hidden_layer_sizes': 176, 'epsilon': 8.723925563341718e-07, 'beta_2': 0.9755916793344177, 'alpha': 6.324478711708047, 'tol': 0.0720780895265211, 'validation_fraction': 0.25947889938519664, 'beta_1': 0.6514734235803551, 'batch_size': 145, 'learning_rate_init': 0.08284880346898864}
observation time 0.002233, current best -0.919960 at iter 4
suggestion time taken 0.005751 iter 5 next_points [{'hidden_layer_sizes': 68, 'alpha': 0.5363972242170784, 'batch_size': 138, 'learning_rate_init': 0.08993497751755412, 'tol': 0.09110206794056379, 'validation_fraction': 0.40251859460431727, 'beta_1': 0.6913193580339382, 'beta_2': 0.9679069639711371, 'epsilon': 6.753293072034216e-08}]
function_evaluation time 0.291078 value -0.417322 suggestion {'hidden_layer_sizes': 68, 'alpha': 0.5363972242170784, 'batch_size': 138, 'learning_rate_init': 0.08993497751755412, 'tol': 0.09110206794056379, 'validation_fraction': 0.40251859460431727, 'beta_1': 0.6913193580339382, 'beta_2': 0.9679069639711371, 'epsilon': 6.753293072034216e-08}
observation time 0.001901, current best -0.919960 at iter 5
suggestion time taken 0.005842 iter 6 next_points [{'hidden_layer_sizes': 115, 'epsilon': 4.880204808327116e-07, 'beta_2': 0.9390433106905058, 'alpha': 0.5642085909040905, 'tol': 0.036759676699398884, 'validation_fraction': 0.7908625211576008, 'beta_1': 0.9848194087093891, 'batch_size': 127, 'learning_rate_init': 0.06993098460682161}]
function_evaluation time 0.296568 value -0.460905 suggestion {'hidden_layer_sizes': 115, 'epsilon': 4.880204808327116e-07, 'beta_2': 0.9390433106905058, 'alpha': 0.5642085909040905, 'tol': 0.036759676699398884, 'validation_fraction': 0.7908625211576008, 'beta_1': 0.9848194087093891, 'batch_size': 127, 'learning_rate_init': 0.06993098460682161}
observation time 0.001920, current best -0.919960 at iter 6
suggestion time taken 0.005131 iter 7 next_points [{'hidden_layer_sizes': 109, 'alpha': 5.675259551232979, 'batch_size': 174, 'learning_rate_init': 0.04660329450504557, 'tol': 0.025507118957165776, 'validation_fraction': 0.3927684013892301, 'beta_1': 0.5114471543139382, 'beta_2': 0.9962264228717663, 'epsilon': 8.925676712462073e-07}]
function_evaluation time 0.325239 value -0.346617 suggestion {'hidden_layer_sizes': 109, 'alpha': 5.675259551232979, 'batch_size': 174, 'learning_rate_init': 0.04660329450504557, 'tol': 0.025507118957165776, 'validation_fraction': 0.3927684013892301, 'beta_1': 0.5114471543139382, 'beta_2': 0.9962264228717663, 'epsilon': 8.925676712462073e-07}
observation time 0.001904, current best -0.919960 at iter 7
suggestion time taken 0.005084 iter 8 next_points [{'hidden_layer_sizes': 95, 'alpha': 1.1721798839518751, 'batch_size': 247, 'learning_rate_init': 0.046531694702017505, 'tol': 0.009313794981167179, 'validation_fraction': 0.8786172653294813, 'beta_1': 0.9514655400820031, 'beta_2': 0.9668850673286796, 'epsilon': 8.124576159901077e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.292875 value -0.604203 suggestion {'hidden_layer_sizes': 95, 'alpha': 1.1721798839518751, 'batch_size': 247, 'learning_rate_init': 0.046531694702017505, 'tol': 0.009313794981167179, 'validation_fraction': 0.8786172653294813, 'beta_1': 0.9514655400820031, 'beta_2': 0.9668850673286796, 'epsilon': 8.124576159901077e-07}
observation time 0.001837, current best -0.919960 at iter 8
suggestion time taken 0.005935 iter 9 next_points [{'hidden_layer_sizes': 177, 'epsilon': 3.602886301806431e-07, 'beta_2': 0.9519165170369972, 'alpha': 0.6836052826625653, 'tol': 0.026444011120420653, 'validation_fraction': 0.2991914551580102, 'beta_1': 0.5624484427397851, 'batch_size': 131, 'learning_rate_init': 0.0374580788452003}]
function_evaluation time 0.552577 value -0.940846 suggestion {'hidden_layer_sizes': 177, 'epsilon': 3.602886301806431e-07, 'beta_2': 0.9519165170369972, 'alpha': 0.6836052826625653, 'tol': 0.026444011120420653, 'validation_fraction': 0.2991914551580102, 'beta_1': 0.5624484427397851, 'batch_size': 131, 'learning_rate_init': 0.0374580788452003}
observation time 0.002699, current best -0.940846 at iter 9
suggestion time taken 0.006143 iter 10 next_points [{'hidden_layer_sizes': 145, 'epsilon': 4.29041313726979e-07, 'beta_2': 0.9322146589338092, 'alpha': 2.3280420493116263, 'tol': 0.06828018273123664, 'validation_fraction': 0.7816601096295194, 'beta_1': 0.9279614557722833, 'batch_size': 32, 'learning_rate_init': 0.07710459286117304}]
function_evaluation time 0.494767 value -0.861496 suggestion {'hidden_layer_sizes': 145, 'epsilon': 4.29041313726979e-07, 'beta_2': 0.9322146589338092, 'alpha': 2.3280420493116263, 'tol': 0.06828018273123664, 'validation_fraction': 0.7816601096295194, 'beta_1': 0.9279614557722833, 'batch_size': 32, 'learning_rate_init': 0.07710459286117304}
observation time 0.001952, current best -0.940846 at iter 10
suggestion time taken 0.005894 iter 11 next_points [{'hidden_layer_sizes': 140, 'epsilon': 7.895962902687282e-07, 'beta_2': 0.9087924723722843, 'alpha': 6.945738637556942, 'tol': 0.0968116359298165, 'validation_fraction': 0.4550153298826912, 'beta_1': 0.5261049029751103, 'batch_size': 11, 'learning_rate_init': 0.019326741507237722}]
function_evaluation time 1.473337 value -0.812790 suggestion {'hidden_layer_sizes': 140, 'epsilon': 7.895962902687282e-07, 'beta_2': 0.9087924723722843, 'alpha': 6.945738637556942, 'tol': 0.0968116359298165, 'validation_fraction': 0.4550153298826912, 'beta_1': 0.5261049029751103, 'batch_size': 11, 'learning_rate_init': 0.019326741507237722}
observation time 0.002000, current best -0.940846 at iter 11
suggestion time taken 0.006466 iter 12 next_points [{'hidden_layer_sizes': 73, 'epsilon': 8.316186582984764e-07, 'beta_2': 0.9627005307893288, 'alpha': 0.4516470792363491, 'tol': 0.01086903077632122, 'validation_fraction': 0.469745669387552, 'beta_1': 0.7754862030607357, 'batch_size': 97, 'learning_rate_init': 0.09639598925824926}]
function_evaluation time 0.545071 value -0.369699 suggestion {'hidden_layer_sizes': 73, 'epsilon': 8.316186582984764e-07, 'beta_2': 0.9627005307893288, 'alpha': 0.4516470792363491, 'tol': 0.01086903077632122, 'validation_fraction': 0.469745669387552, 'beta_1': 0.7754862030607357, 'batch_size': 97, 'learning_rate_init': 0.09639598925824926}
observation time 0.001852, current best -0.940846 at iter 12
suggestion time taken 0.005824 iter 13 next_points [{'hidden_layer_sizes': 67, 'epsilon': 2.763441123992673e-07, 'beta_2': 0.9820658620573182, 'alpha': 7.9104515918543505, 'tol': 0.05442996877003286, 'validation_fraction': 0.7999187187290876, 'beta_1': 0.7060551784892521, 'batch_size': 168, 'learning_rate_init': 0.0006089738476284146}]
function_evaluation time 0.161809 value -0.304714 suggestion {'hidden_layer_sizes': 67, 'epsilon': 2.763441123992673e-07, 'beta_2': 0.9820658620573182, 'alpha': 7.9104515918543505, 'tol': 0.05442996877003286, 'validation_fraction': 0.7999187187290876, 'beta_1': 0.7060551784892521, 'batch_size': 168, 'learning_rate_init': 0.0006089738476284146}
observation time 0.002272, current best -0.940846 at iter 13
suggestion time taken 0.006057 iter 14 next_points [{'hidden_layer_sizes': 144, 'epsilon': 4.902684382085121e-07, 'beta_2': 0.9710833830695802, 'alpha': 0.15686154322682605, 'tol': 0.014681012176028286, 'validation_fraction': 0.23276615206361564, 'beta_1': 0.8343529978625924, 'batch_size': 158, 'learning_rate_init': 0.06614898504397997}]
function_evaluation time 0.919214 value -0.924828 suggestion {'hidden_layer_sizes': 144, 'epsilon': 4.902684382085121e-07, 'beta_2': 0.9710833830695802, 'alpha': 0.15686154322682605, 'tol': 0.014681012176028286, 'validation_fraction': 0.23276615206361564, 'beta_1': 0.8343529978625924, 'batch_size': 158, 'learning_rate_init': 0.06614898504397997}
observation time 0.001834, current best -0.940846 at iter 14
saving meta data: {'args': {'--uuid': 'a9865866752b53ebaf09c0d5d6626f00', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'opentuner', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': 'f1d85e495c4053a9b539b661fbbaccce', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_161952', '--opt': 'random-search', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d wine -o random-search -u f1d85e495c4053a9b539b661fbbaccce -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_161952
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])
Signature errors:
                     0    1    2    3    4  max
MLP-adam_wine_acc  0.0  0.0  0.0  0.0  0.0  0.0
max                0.0  0.0  0.0  0.0  0.0  0.0
starting sklearn study random-search MLP-adam wine acc 15 1
with data root: None
suggestion time taken 0.002849 iter 0 next_points [{'alpha': 1.4678048464094706, 'batch_size': 65, 'beta_1': 0.6892194068208761, 'beta_2': 0.9997767609679675, 'epsilon': 9.522601992758166e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0010302052531390939, 'tol': 0.00010633840954514428, 'validation_fraction': 0.7852027353681392}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.121480 value -0.640640 suggestion {'alpha': 1.4678048464094706, 'batch_size': 65, 'beta_1': 0.6892194068208761, 'beta_2': 0.9997767609679675, 'epsilon': 9.522601992758166e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0010302052531390939, 'tol': 0.00010633840954514428, 'validation_fraction': 0.7852027353681392}
observation time 0.000006, current best -0.640640 at iter 0
suggestion time taken 0.002484 iter 1 next_points [{'alpha': 0.003051526707291834, 'batch_size': 195, 'beta_1': 0.9842401690661787, 'beta_2': 0.999954367371783, 'epsilon': 3.577379735057312e-08, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0010472694886570755, 'tol': 0.0842835460754638, 'validation_fraction': 0.5847109446970238}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.050028 value -0.330296 suggestion {'alpha': 0.003051526707291834, 'batch_size': 195, 'beta_1': 0.9842401690661787, 'beta_2': 0.999954367371783, 'epsilon': 3.577379735057312e-08, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0010472694886570755, 'tol': 0.0842835460754638, 'validation_fraction': 0.5847109446970238}
observation time 0.000005, current best -0.640640 at iter 1
suggestion time taken 0.002567 iter 2 next_points [{'alpha': 7.653875920716434, 'batch_size': 235, 'beta_1': 0.9746186753049277, 'beta_2': 0.9895066830522801, 'epsilon': 5.6052786609335574e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.009596888973003573, 'tol': 0.0001731424208735428, 'validation_fraction': 0.10586317161116479}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.070889 value -0.416010 suggestion {'alpha': 7.653875920716434, 'batch_size': 235, 'beta_1': 0.9746186753049277, 'beta_2': 0.9895066830522801, 'epsilon': 5.6052786609335574e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.009596888973003573, 'tol': 0.0001731424208735428, 'validation_fraction': 0.10586317161116479}
observation time 0.000004, current best -0.640640 at iter 2
suggestion time taken 0.002567 iter 3 next_points [{'alpha': 0.016306589879378195, 'batch_size': 76, 'beta_1': 0.7120802806653458, 'beta_2': 0.9999230204530457, 'epsilon': 2.9670737333492476e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 2.09804424379286e-05, 'tol': 0.001203765983327557, 'validation_fraction': 0.6840818641601046}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.054499 value -0.303202 suggestion {'alpha': 0.016306589879378195, 'batch_size': 76, 'beta_1': 0.7120802806653458, 'beta_2': 0.9999230204530457, 'epsilon': 2.9670737333492476e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 2.09804424379286e-05, 'tol': 0.001203765983327557, 'validation_fraction': 0.6840818641601046}
observation time 0.000004, current best -0.640640 at iter 3
suggestion time taken 0.002521 iter 4 next_points [{'alpha': 0.000266079200851621, 'batch_size': 59, 'beta_1': 0.9705127878691786, 'beta_2': 0.9999961517011251, 'epsilon': 1.2597571477691113e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.018951383373415887, 'tol': 0.0001193922660907985, 'validation_fraction': 0.21998538927086847}]
function_evaluation time 0.096121 value -0.642611 suggestion {'alpha': 0.000266079200851621, 'batch_size': 59, 'beta_1': 0.9705127878691786, 'beta_2': 0.9999961517011251, 'epsilon': 1.2597571477691113e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.018951383373415887, 'tol': 0.0001193922660907985, 'validation_fraction': 0.21998538927086847}
observation time 0.000004, current best -0.642611 at iter 4
suggestion time taken 0.002493 iter 5 next_points [{'alpha': 0.00032097478851002254, 'batch_size': 67, 'beta_1': 0.9093997230301927, 'beta_2': 0.9473978279418442, 'epsilon': 1.2679723744590443e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 2.642295723599379e-05, 'tol': 2.424257013883198e-05, 'validation_fraction': 0.17986330958854188}]
function_evaluation time 0.054839 value -0.359360 suggestion {'alpha': 0.00032097478851002254, 'batch_size': 67, 'beta_1': 0.9093997230301927, 'beta_2': 0.9473978279418442, 'epsilon': 1.2679723744590443e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 2.642295723599379e-05, 'tol': 2.424257013883198e-05, 'validation_fraction': 0.17986330958854188}
observation time 0.000005, current best -0.642611 at iter 5
suggestion time taken 0.002445 iter 6 next_points [{'alpha': 4.140161317565801e-05, 'batch_size': 219, 'beta_1': 0.9063909021634372, 'beta_2': 0.9972639489921181, 'epsilon': 2.5957489667124608e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.02503144433706463, 'tol': 9.464897841171384e-05, 'validation_fraction': 0.5984947061923339}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.093091 value -0.594581 suggestion {'alpha': 4.140161317565801e-05, 'batch_size': 219, 'beta_1': 0.9063909021634372, 'beta_2': 0.9972639489921181, 'epsilon': 2.5957489667124608e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.02503144433706463, 'tol': 9.464897841171384e-05, 'validation_fraction': 0.5984947061923339}
observation time 0.000005, current best -0.642611 at iter 6
suggestion time taken 0.002527 iter 7 next_points [{'alpha': 0.046950486904698385, 'batch_size': 17, 'beta_1': 0.9695848928945804, 'beta_2': 0.9768721456134936, 'epsilon': 7.543170839997257e-08, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.00019066905346343352, 'tol': 2.4511405849154044e-05, 'validation_fraction': 0.47253882520332374}]
function_evaluation time 0.118254 value -0.423645 suggestion {'alpha': 0.046950486904698385, 'batch_size': 17, 'beta_1': 0.9695848928945804, 'beta_2': 0.9768721456134936, 'epsilon': 7.543170839997257e-08, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.00019066905346343352, 'tol': 2.4511405849154044e-05, 'validation_fraction': 0.47253882520332374}
observation time 0.000005, current best -0.642611 at iter 7
suggestion time taken 0.002514 iter 8 next_points [{'alpha': 5.8593867404303905, 'batch_size': 40, 'beta_1': 0.803029462885484, 'beta_2': 0.9998616706661623, 'epsilon': 9.899267581514423e-08, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.00022457590327955418, 'tol': 0.0007692301845240836, 'validation_fraction': 0.5857760611953867}]
function_evaluation time 0.128859 value -0.444335 suggestion {'alpha': 5.8593867404303905, 'batch_size': 40, 'beta_1': 0.803029462885484, 'beta_2': 0.9998616706661623, 'epsilon': 9.899267581514423e-08, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.00022457590327955418, 'tol': 0.0007692301845240836, 'validation_fraction': 0.5857760611953867}
observation time 0.000005, current best -0.642611 at iter 8
suggestion time taken 0.002569 iter 9 next_points [{'alpha': 1.3682311684798924e-05, 'batch_size': 34, 'beta_1': 0.9735158250228879, 'beta_2': 0.9999896175268173, 'epsilon': 2.275110828521377e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.008645519168635037, 'tol': 0.011790151350699449, 'validation_fraction': 0.4383195670309244}]
function_evaluation time 0.202305 value -0.705665 suggestion {'alpha': 1.3682311684798924e-05, 'batch_size': 34, 'beta_1': 0.9735158250228879, 'beta_2': 0.9999896175268173, 'epsilon': 2.275110828521377e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.008645519168635037, 'tol': 0.011790151350699449, 'validation_fraction': 0.4383195670309244}
observation time 0.000004, current best -0.705665 at iter 9
suggestion time taken 0.002495 iter 10 next_points [{'alpha': 0.6225138689617646, 'batch_size': 117, 'beta_1': 0.9013599939005293, 'beta_2': 0.9997185717816147, 'epsilon': 1.2429039785052696e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 3.443969755368509e-05, 'tol': 0.0018565718760830778, 'validation_fraction': 0.8728842974862244}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.042627 value -0.309360 suggestion {'alpha': 0.6225138689617646, 'batch_size': 117, 'beta_1': 0.9013599939005293, 'beta_2': 0.9997185717816147, 'epsilon': 1.2429039785052696e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 3.443969755368509e-05, 'tol': 0.0018565718760830778, 'validation_fraction': 0.8728842974862244}
observation time 0.000004, current best -0.705665 at iter 10
suggestion time taken 0.002780 iter 11 next_points [{'alpha': 9.631699031540256e-05, 'batch_size': 42, 'beta_1': 0.9860925871254494, 'beta_2': 0.9675727759381543, 'epsilon': 1.40472296111621e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.006596443756314076, 'tol': 0.003039953885359782, 'validation_fraction': 0.10664862808127423}]
function_evaluation time 0.137894 value -0.690640 suggestion {'alpha': 9.631699031540256e-05, 'batch_size': 42, 'beta_1': 0.9860925871254494, 'beta_2': 0.9675727759381543, 'epsilon': 1.40472296111621e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.006596443756314076, 'tol': 0.003039953885359782, 'validation_fraction': 0.10664862808127423}
observation time 0.000005, current best -0.705665 at iter 11
suggestion time taken 0.002471 iter 12 next_points [{'alpha': 0.06703505977163007, 'batch_size': 184, 'beta_1': 0.7591625189410449, 'beta_2': 0.9990533187354611, 'epsilon': 8.939788838511796e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.09862266671081374, 'tol': 1.6618917789567526e-05, 'validation_fraction': 0.13274729382583847}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.082438 value -0.648522 suggestion {'alpha': 0.06703505977163007, 'batch_size': 184, 'beta_1': 0.7591625189410449, 'beta_2': 0.9990533187354611, 'epsilon': 8.939788838511796e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.09862266671081374, 'tol': 1.6618917789567526e-05, 'validation_fraction': 0.13274729382583847}
observation time 0.000004, current best -0.705665 at iter 12
suggestion time taken 0.002464 iter 13 next_points [{'alpha': 0.004068850933713877, 'batch_size': 41, 'beta_1': 0.9351043842938851, 'beta_2': 0.999872462473316, 'epsilon': 9.618267619458351e-07, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.042332875226103434, 'tol': 0.001694208448175193, 'validation_fraction': 0.669326504245562}]
function_evaluation time 0.070828 value -0.564039 suggestion {'alpha': 0.004068850933713877, 'batch_size': 41, 'beta_1': 0.9351043842938851, 'beta_2': 0.999872462473316, 'epsilon': 9.618267619458351e-07, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.042332875226103434, 'tol': 0.001694208448175193, 'validation_fraction': 0.669326504245562}
observation time 0.000004, current best -0.705665 at iter 13
suggestion time taken 0.002464 iter 14 next_points [{'alpha': 0.13327308917699052, 'batch_size': 11, 'beta_1': 0.9752336103299097, 'beta_2': 0.9996815871378887, 'epsilon': 7.339522551664106e-09, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.04066754398141277, 'tol': 0.0017355779903841062, 'validation_fraction': 0.8817260339242264}]
function_evaluation time 0.125165 value -0.562808 suggestion {'alpha': 0.13327308917699052, 'batch_size': 11, 'beta_1': 0.9752336103299097, 'beta_2': 0.9996815871378887, 'epsilon': 7.339522551664106e-09, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.04066754398141277, 'tol': 0.0017355779903841062, 'validation_fraction': 0.8817260339242264}
observation time 0.000004, current best -0.705665 at iter 14
saving meta data: {'args': {'--uuid': 'f1d85e495c4053a9b539b661fbbaccce', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_161952', '--opt': 'random-search', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])}
saving results
saving timing
saving suggest log
done

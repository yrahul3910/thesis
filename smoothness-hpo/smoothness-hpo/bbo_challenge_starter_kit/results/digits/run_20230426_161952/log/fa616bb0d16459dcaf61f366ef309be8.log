running: {'--uuid': 'fa616bb0d16459dcaf61f366ef309be8', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_161952', '--opt': 'hyperopt', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d wine -o hyperopt -u fa616bb0d16459dcaf61f366ef309be8 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_161952
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])
Signature errors:
                     0    1    2    3    4  max
MLP-adam_wine_acc  0.0  0.0  0.0  0.0  0.0  0.0
max                0.0  0.0  0.0  0.0  0.0  0.0
starting sklearn study hyperopt MLP-adam wine acc 15 1
with data root: None
suggestion time taken 0.002410 iter 0 next_points [{'alpha': 5.502095439058555e-05, 'batch_size': 115, 'beta_1': 0.9332122482520961, 'beta_2': 0.9661954426981882, 'epsilon': 6.610844313560095e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0006364846910351707, 'tol': 9.878933261965509e-05, 'validation_fraction': 0.8461963025702628}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.068222 value -0.507635 suggestion {'alpha': 5.502095439058555e-05, 'batch_size': 115, 'beta_1': 0.9332122482520961, 'beta_2': 0.9661954426981882, 'epsilon': 6.610844313560095e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0006364846910351707, 'tol': 9.878933261965509e-05, 'validation_fraction': 0.8461963025702628}
observation time 0.000070, current best -0.507635 at iter 0
suggestion time taken 0.002377 iter 1 next_points [{'alpha': 0.01532828187855043, 'batch_size': 114, 'beta_1': 0.7851281658969648, 'beta_2': 0.9800228903001675, 'epsilon': 3.917589008367475e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 4.283440564352711e-05, 'tol': 0.00036146779343746474, 'validation_fraction': 0.7659628403523715}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.049939 value -0.344581 suggestion {'alpha': 0.01532828187855043, 'batch_size': 114, 'beta_1': 0.7851281658969648, 'beta_2': 0.9800228903001675, 'epsilon': 3.917589008367475e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 4.283440564352711e-05, 'tol': 0.00036146779343746474, 'validation_fraction': 0.7659628403523715}
observation time 0.000071, current best -0.507635 at iter 1
suggestion time taken 0.002146 iter 2 next_points [{'alpha': 0.03899627873274792, 'batch_size': 18, 'beta_1': 0.9893242152086696, 'beta_2': 0.912302271376652, 'epsilon': 1.514600516182219e-08, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.010281675045810337, 'tol': 1.1951163673127758e-05, 'validation_fraction': 0.42774843853874855}]
function_evaluation time 0.188375 value -0.719212 suggestion {'alpha': 0.03899627873274792, 'batch_size': 18, 'beta_1': 0.9893242152086696, 'beta_2': 0.912302271376652, 'epsilon': 1.514600516182219e-08, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.010281675045810337, 'tol': 1.1951163673127758e-05, 'validation_fraction': 0.42774843853874855}
observation time 0.000072, current best -0.719212 at iter 2
suggestion time taken 0.002205 iter 3 next_points [{'alpha': 0.0012278101071908354, 'batch_size': 18, 'beta_1': 0.6260351293784014, 'beta_2': 0.9645388186504898, 'epsilon': 8.968892297914618e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.007323256573593707, 'tol': 0.0034913612112033596, 'validation_fraction': 0.39399965685626553}]
function_evaluation time 0.185518 value -0.817241 suggestion {'alpha': 0.0012278101071908354, 'batch_size': 18, 'beta_1': 0.6260351293784014, 'beta_2': 0.9645388186504898, 'epsilon': 8.968892297914618e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.007323256573593707, 'tol': 0.0034913612112033596, 'validation_fraction': 0.39399965685626553}
observation time 0.000070, current best -0.817241 at iter 3
suggestion time taken 0.002126 iter 4 next_points [{'alpha': 2.2254491919353994, 'batch_size': 52, 'beta_1': 0.7351047784777536, 'beta_2': 0.9289319138923627, 'epsilon': 1.6769452497235926e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 2.1160656995995338e-05, 'tol': 0.001044629760067614, 'validation_fraction': 0.15767392824137938}]
function_evaluation time 0.077409 value -0.338424 suggestion {'alpha': 2.2254491919353994, 'batch_size': 52, 'beta_1': 0.7351047784777536, 'beta_2': 0.9289319138923627, 'epsilon': 1.6769452497235926e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 2.1160656995995338e-05, 'tol': 0.001044629760067614, 'validation_fraction': 0.15767392824137938}
observation time 0.000074, current best -0.817241 at iter 4
suggestion time taken 0.002163 iter 5 next_points [{'alpha': 0.009767305927531136, 'batch_size': 52, 'beta_1': 0.894947870661995, 'beta_2': 0.9087356912705346, 'epsilon': 1.4052133346796886e-08, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0002625292911264213, 'tol': 0.005248822564574445, 'validation_fraction': 0.19033457766482753}]
function_evaluation time 0.118254 value -0.530296 suggestion {'alpha': 0.009767305927531136, 'batch_size': 52, 'beta_1': 0.894947870661995, 'beta_2': 0.9087356912705346, 'epsilon': 1.4052133346796886e-08, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0002625292911264213, 'tol': 0.005248822564574445, 'validation_fraction': 0.19033457766482753}
observation time 0.000075, current best -0.817241 at iter 5
suggestion time taken 0.002170 iter 6 next_points [{'alpha': 0.013737063362086473, 'batch_size': 182, 'beta_1': 0.8298204035881367, 'beta_2': 0.9059047020295733, 'epsilon': 6.602686921525857e-08, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.08105859499940546, 'tol': 5.590924183678172e-05, 'validation_fraction': 0.5530905599701595}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.106471 value -0.646552 suggestion {'alpha': 0.013737063362086473, 'batch_size': 182, 'beta_1': 0.8298204035881367, 'beta_2': 0.9059047020295733, 'epsilon': 6.602686921525857e-08, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.08105859499940546, 'tol': 5.590924183678172e-05, 'validation_fraction': 0.5530905599701595}
observation time 0.000076, current best -0.817241 at iter 6
suggestion time taken 0.002185 iter 7 next_points [{'alpha': 1.0109166383541997e-05, 'batch_size': 185, 'beta_1': 0.8161349357795463, 'beta_2': 0.9556109730828545, 'epsilon': 3.0567568615988803e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.06769927988557332, 'tol': 0.04736703202822649, 'validation_fraction': 0.3373573640467678}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.072639 value -0.590394 suggestion {'alpha': 1.0109166383541997e-05, 'batch_size': 185, 'beta_1': 0.8161349357795463, 'beta_2': 0.9556109730828545, 'epsilon': 3.0567568615988803e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.06769927988557332, 'tol': 0.04736703202822649, 'validation_fraction': 0.3373573640467678}
observation time 0.000074, current best -0.817241 at iter 7
suggestion time taken 0.002156 iter 8 next_points [{'alpha': 0.0006032106658215372, 'batch_size': 221, 'beta_1': 0.8244654707482869, 'beta_2': 0.9749794989150358, 'epsilon': 1.1221692875007172e-09, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.03085063890000019, 'tol': 0.03841214362410649, 'validation_fraction': 0.28807452868453814}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.089315 value -0.648276 suggestion {'alpha': 0.0006032106658215372, 'batch_size': 221, 'beta_1': 0.8244654707482869, 'beta_2': 0.9749794989150358, 'epsilon': 1.1221692875007172e-09, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.03085063890000019, 'tol': 0.03841214362410649, 'validation_fraction': 0.28807452868453814}
observation time 0.000071, current best -0.817241 at iter 8
suggestion time taken 0.002207 iter 9 next_points [{'alpha': 5.943183919398591e-05, 'batch_size': 66, 'beta_1': 0.9188104418106919, 'beta_2': 0.9074490788142451, 'epsilon': 1.898990200139536e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.03698199038941047, 'tol': 0.015020702194015339, 'validation_fraction': 0.1792287205963083}]
function_evaluation time 0.153187 value -0.732759 suggestion {'alpha': 5.943183919398591e-05, 'batch_size': 66, 'beta_1': 0.9188104418106919, 'beta_2': 0.9074490788142451, 'epsilon': 1.898990200139536e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.03698199038941047, 'tol': 0.015020702194015339, 'validation_fraction': 0.1792287205963083}
observation time 0.000073, current best -0.817241 at iter 9
suggestion time taken 0.002150 iter 10 next_points [{'alpha': 0.003974832702575214, 'batch_size': 194, 'beta_1': 0.5399697283071572, 'beta_2': 0.944903087570955, 'epsilon': 1.8557275585039644e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.020582158456382352, 'tol': 0.00012184725272342075, 'validation_fraction': 0.15000972874992027}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.092985 value -0.521675 suggestion {'alpha': 0.003974832702575214, 'batch_size': 194, 'beta_1': 0.5399697283071572, 'beta_2': 0.944903087570955, 'epsilon': 1.8557275585039644e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.020582158456382352, 'tol': 0.00012184725272342075, 'validation_fraction': 0.15000972874992027}
observation time 0.000075, current best -0.817241 at iter 10
suggestion time taken 0.002196 iter 11 next_points [{'alpha': 1.525780274975253, 'batch_size': 20, 'beta_1': 0.6563339560471154, 'beta_2': 0.9751979408386471, 'epsilon': 1.9074643921063884e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.004467792399940268, 'tol': 0.033329223382245116, 'validation_fraction': 0.10506273430895843}]
function_evaluation time 0.169109 value -0.703448 suggestion {'alpha': 1.525780274975253, 'batch_size': 20, 'beta_1': 0.6563339560471154, 'beta_2': 0.9751979408386471, 'epsilon': 1.9074643921063884e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.004467792399940268, 'tol': 0.033329223382245116, 'validation_fraction': 0.10506273430895843}
observation time 0.000076, current best -0.817241 at iter 11
suggestion time taken 0.002166 iter 12 next_points [{'alpha': 0.05763134829172485, 'batch_size': 99, 'beta_1': 0.5839983213188663, 'beta_2': 0.9222579806711254, 'epsilon': 1.9334933787962533e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.00025208404549045344, 'tol': 0.003667028145679168, 'validation_fraction': 0.5677774821008345}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.052184 value -0.449507 suggestion {'alpha': 0.05763134829172485, 'batch_size': 99, 'beta_1': 0.5839983213188663, 'beta_2': 0.9222579806711254, 'epsilon': 1.9334933787962533e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.00025208404549045344, 'tol': 0.003667028145679168, 'validation_fraction': 0.5677774821008345}
observation time 0.000076, current best -0.817241 at iter 12
suggestion time taken 0.002172 iter 13 next_points [{'alpha': 0.3888031321381421, 'batch_size': 59, 'beta_1': 0.8605263592497995, 'beta_2': 0.9892019552025678, 'epsilon': 1.983484698584698e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 1.4173618927664416e-05, 'tol': 0.01225424636660554, 'validation_fraction': 0.34665403396682176}]
function_evaluation time 0.060030 value -0.302709 suggestion {'alpha': 0.3888031321381421, 'batch_size': 59, 'beta_1': 0.8605263592497995, 'beta_2': 0.9892019552025678, 'epsilon': 1.983484698584698e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 1.4173618927664416e-05, 'tol': 0.01225424636660554, 'validation_fraction': 0.34665403396682176}
observation time 0.000081, current best -0.817241 at iter 13
suggestion time taken 0.002153 iter 14 next_points [{'alpha': 0.2329717433720897, 'batch_size': 102, 'beta_1': 0.562503586306076, 'beta_2': 0.9852371748127966, 'epsilon': 2.9711379153803067e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0003375455949153577, 'tol': 3.972607349186305e-05, 'validation_fraction': 0.11356572173599513}]
function_evaluation time 0.051529 value -0.316995 suggestion {'alpha': 0.2329717433720897, 'batch_size': 102, 'beta_1': 0.562503586306076, 'beta_2': 0.9852371748127966, 'epsilon': 2.9711379153803067e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0003375455949153577, 'tol': 3.972607349186305e-05, 'validation_fraction': 0.11356572173599513}
observation time 0.000073, current best -0.817241 at iter 14
saving meta data: {'args': {'--uuid': 'fa616bb0d16459dcaf61f366ef309be8', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_161952', '--opt': 'hyperopt', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])}
saving results
saving timing
saving suggest log
done

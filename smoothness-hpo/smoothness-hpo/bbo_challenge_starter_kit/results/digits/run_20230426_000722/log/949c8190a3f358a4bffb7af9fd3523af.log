running: {'--uuid': '949c8190a3f358a4bffb7af9fd3523af', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d diabetes -o hyperopt -u 949c8190a3f358a4bffb7af9fd3523af -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_000722
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study hyperopt MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002410 iter 0 next_points [{'alpha': 0.00020856597461369814, 'batch_size': 105, 'beta_1': 0.6594621977322291, 'beta_2': 0.9431617314823537, 'epsilon': 7.762625173533477e-07, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.003389716004392333, 'tol': 0.0004083355647857131, 'validation_fraction': 0.13609290383129197}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.497898 value 3565.897293 suggestion {'alpha': 0.00020856597461369814, 'batch_size': 105, 'beta_1': 0.6594621977322291, 'beta_2': 0.9431617314823537, 'epsilon': 7.762625173533477e-07, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.003389716004392333, 'tol': 0.0004083355647857131, 'validation_fraction': 0.13609290383129197}
observation time 0.000069, current best 3565.897293 at iter 0
suggestion time taken 0.002574 iter 1 next_points [{'alpha': 0.07537851615104368, 'batch_size': 59, 'beta_1': 0.7338591211750307, 'beta_2': 0.9374994169551646, 'epsilon': 5.058367675605411e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 3.057804459825631e-05, 'tol': 0.0013164197447061968, 'validation_fraction': 0.7135551981283317}]
function_evaluation time 0.061276 value 29113.255581 suggestion {'alpha': 0.07537851615104368, 'batch_size': 59, 'beta_1': 0.7338591211750307, 'beta_2': 0.9374994169551646, 'epsilon': 5.058367675605411e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 3.057804459825631e-05, 'tol': 0.0013164197447061968, 'validation_fraction': 0.7135551981283317}
observation time 0.000069, current best 3565.897293 at iter 1
suggestion time taken 0.002139 iter 2 next_points [{'alpha': 0.06788540441252873, 'batch_size': 234, 'beta_1': 0.6604707293898454, 'beta_2': 0.9912801718420998, 'epsilon': 3.4681259662545387e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.0036326030213596414, 'tol': 0.013434489454489402, 'validation_fraction': 0.4268792333306173}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.063530 value 28889.599676 suggestion {'alpha': 0.06788540441252873, 'batch_size': 234, 'beta_1': 0.6604707293898454, 'beta_2': 0.9912801718420998, 'epsilon': 3.4681259662545387e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.0036326030213596414, 'tol': 0.013434489454489402, 'validation_fraction': 0.4268792333306173}
observation time 0.000067, current best 3565.897293 at iter 2
suggestion time taken 0.002134 iter 3 next_points [{'alpha': 7.417695198513779, 'batch_size': 51, 'beta_1': 0.7706816138171393, 'beta_2': 0.953530271739854, 'epsilon': 1.6726653984968051e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.0012729754935718192, 'tol': 1.4924949585139343e-05, 'validation_fraction': 0.11779429833760088}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.444741 value 5489.911128 suggestion {'alpha': 7.417695198513779, 'batch_size': 51, 'beta_1': 0.7706816138171393, 'beta_2': 0.953530271739854, 'epsilon': 1.6726653984968051e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.0012729754935718192, 'tol': 1.4924949585139343e-05, 'validation_fraction': 0.11779429833760088}
observation time 0.000064, current best 3565.897293 at iter 3
suggestion time taken 0.002396 iter 4 next_points [{'alpha': 0.06996606277259855, 'batch_size': 163, 'beta_1': 0.9411621652974129, 'beta_2': 0.9549942541024455, 'epsilon': 7.388267857746052e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0004203503766813068, 'tol': 1.147102738286158e-05, 'validation_fraction': 0.16365917950868059}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.011536 value 28308.416469 suggestion {'alpha': 0.06996606277259855, 'batch_size': 163, 'beta_1': 0.9411621652974129, 'beta_2': 0.9549942541024455, 'epsilon': 7.388267857746052e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0004203503766813068, 'tol': 1.147102738286158e-05, 'validation_fraction': 0.16365917950868059}
observation time 0.000072, current best 3565.897293 at iter 4
suggestion time taken 0.002133 iter 5 next_points [{'alpha': 0.05981229439609468, 'batch_size': 15, 'beta_1': 0.6625036310006392, 'beta_2': 0.9366823624296813, 'epsilon': 2.22872779945471e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.00027053045442378723, 'tol': 0.0019962457282752485, 'validation_fraction': 0.10567814868626232}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.096207 value 13710.675099 suggestion {'alpha': 0.05981229439609468, 'batch_size': 15, 'beta_1': 0.6625036310006392, 'beta_2': 0.9366823624296813, 'epsilon': 2.22872779945471e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.00027053045442378723, 'tol': 0.0019962457282752485, 'validation_fraction': 0.10567814868626232}
observation time 0.000067, current best 3565.897293 at iter 5
suggestion time taken 0.002140 iter 6 next_points [{'alpha': 1.5677433311325385e-05, 'batch_size': 191, 'beta_1': 0.7233278613646903, 'beta_2': 0.962389401099007, 'epsilon': 5.656300393692317e-07, 'hidden_layer_sizes': 125, 'learning_rate_init': 6.763033268928415e-05, 'tol': 0.0006602915359450364, 'validation_fraction': 0.10274719109205735}]
function_evaluation time 0.080284 value 29064.852979 suggestion {'alpha': 1.5677433311325385e-05, 'batch_size': 191, 'beta_1': 0.7233278613646903, 'beta_2': 0.962389401099007, 'epsilon': 5.656300393692317e-07, 'hidden_layer_sizes': 125, 'learning_rate_init': 6.763033268928415e-05, 'tol': 0.0006602915359450364, 'validation_fraction': 0.10274719109205735}
observation time 0.000077, current best 3565.897293 at iter 6
suggestion time taken 0.002222 iter 7 next_points [{'alpha': 0.0002509604728337362, 'batch_size': 109, 'beta_1': 0.9833943286187552, 'beta_2': 0.9942917981435252, 'epsilon': 4.18217111855689e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.026784136400048418, 'tol': 0.008936625325588917, 'validation_fraction': 0.45690591719816864}]
function_evaluation time 0.240841 value 4297.007060 suggestion {'alpha': 0.0002509604728337362, 'batch_size': 109, 'beta_1': 0.9833943286187552, 'beta_2': 0.9942917981435252, 'epsilon': 4.18217111855689e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.026784136400048418, 'tol': 0.008936625325588917, 'validation_fraction': 0.45690591719816864}
observation time 0.000073, current best 3565.897293 at iter 7
suggestion time taken 0.002159 iter 8 next_points [{'alpha': 0.0016847107850462197, 'batch_size': 41, 'beta_1': 0.7407805586909972, 'beta_2': 0.9955192081568088, 'epsilon': 7.856788631430851e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.0002931796445213437, 'tol': 0.0328821697162277, 'validation_fraction': 0.1083840446846889}]
function_evaluation time 0.092641 value 29008.137699 suggestion {'alpha': 0.0016847107850462197, 'batch_size': 41, 'beta_1': 0.7407805586909972, 'beta_2': 0.9955192081568088, 'epsilon': 7.856788631430851e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.0002931796445213437, 'tol': 0.0328821697162277, 'validation_fraction': 0.1083840446846889}
observation time 0.000075, current best 3565.897293 at iter 8
suggestion time taken 0.002120 iter 9 next_points [{'alpha': 0.1279328695281836, 'batch_size': 149, 'beta_1': 0.5004919880796906, 'beta_2': 0.944042196705491, 'epsilon': 3.7817901321885245e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 3.841670045962602e-05, 'tol': 0.02770769612488589, 'validation_fraction': 0.2655412791219103}]
function_evaluation time 0.092080 value 29130.262073 suggestion {'alpha': 0.1279328695281836, 'batch_size': 149, 'beta_1': 0.5004919880796906, 'beta_2': 0.944042196705491, 'epsilon': 3.7817901321885245e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 3.841670045962602e-05, 'tol': 0.02770769612488589, 'validation_fraction': 0.2655412791219103}
observation time 0.000074, current best 3565.897293 at iter 9
suggestion time taken 0.002336 iter 10 next_points [{'alpha': 0.0025674949801599593, 'batch_size': 215, 'beta_1': 0.5249658080417076, 'beta_2': 0.9443791819048317, 'epsilon': 4.4194961583199164e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.000891098647587288, 'tol': 0.0020673595801104622, 'validation_fraction': 0.38535308987457095}]
function_evaluation time 0.058417 value 29023.997794 suggestion {'alpha': 0.0025674949801599593, 'batch_size': 215, 'beta_1': 0.5249658080417076, 'beta_2': 0.9443791819048317, 'epsilon': 4.4194961583199164e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.000891098647587288, 'tol': 0.0020673595801104622, 'validation_fraction': 0.38535308987457095}
observation time 0.000071, current best 3565.897293 at iter 10
suggestion time taken 0.002158 iter 11 next_points [{'alpha': 0.007526917497618406, 'batch_size': 216, 'beta_1': 0.9341697954211106, 'beta_2': 0.9976780113089161, 'epsilon': 2.6698108717992335e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 5.053489551892983e-05, 'tol': 0.007210253906163792, 'validation_fraction': 0.3679194376210899}]
function_evaluation time 0.051920 value 29062.328829 suggestion {'alpha': 0.007526917497618406, 'batch_size': 216, 'beta_1': 0.9341697954211106, 'beta_2': 0.9976780113089161, 'epsilon': 2.6698108717992335e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 5.053489551892983e-05, 'tol': 0.007210253906163792, 'validation_fraction': 0.3679194376210899}
observation time 0.000085, current best 3565.897293 at iter 11
suggestion time taken 0.002378 iter 12 next_points [{'alpha': 0.0004892412716590406, 'batch_size': 44, 'beta_1': 0.612458360815984, 'beta_2': 0.9775493449237483, 'epsilon': 9.391077265147542e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0007548556219061426, 'tol': 4.6869414359438445e-05, 'validation_fraction': 0.6107490164766977}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.151267 value 24722.475783 suggestion {'alpha': 0.0004892412716590406, 'batch_size': 44, 'beta_1': 0.612458360815984, 'beta_2': 0.9775493449237483, 'epsilon': 9.391077265147542e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0007548556219061426, 'tol': 4.6869414359438445e-05, 'validation_fraction': 0.6107490164766977}
observation time 0.000072, current best 3565.897293 at iter 12
suggestion time taken 0.002190 iter 13 next_points [{'alpha': 4.593767778552051e-05, 'batch_size': 179, 'beta_1': 0.6102584760925042, 'beta_2': 0.9015241652816528, 'epsilon': 6.33174716395698e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 1.4322490966795306e-05, 'tol': 1.3543658845300679e-05, 'validation_fraction': 0.15486780761579944}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.778373 value 29049.474913 suggestion {'alpha': 4.593767778552051e-05, 'batch_size': 179, 'beta_1': 0.6102584760925042, 'beta_2': 0.9015241652816528, 'epsilon': 6.33174716395698e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 1.4322490966795306e-05, 'tol': 1.3543658845300679e-05, 'validation_fraction': 0.15486780761579944}
observation time 0.000073, current best 3565.897293 at iter 13
suggestion time taken 0.002138 iter 14 next_points [{'alpha': 0.3947139437067046, 'batch_size': 52, 'beta_1': 0.7830501795966939, 'beta_2': 0.9115824567742311, 'epsilon': 1.1119951108054303e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.030197994621495583, 'tol': 1.5611090328181553e-05, 'validation_fraction': 0.3630369485137052}]
function_evaluation time 0.487238 value 2991.031585 suggestion {'alpha': 0.3947139437067046, 'batch_size': 52, 'beta_1': 0.7830501795966939, 'beta_2': 0.9115824567742311, 'epsilon': 1.1119951108054303e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.030197994621495583, 'tol': 1.5611090328181553e-05, 'validation_fraction': 0.3630369485137052}
observation time 0.000074, current best 2991.031585 at iter 14
saving meta data: {'args': {'--uuid': '949c8190a3f358a4bffb7af9fd3523af', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

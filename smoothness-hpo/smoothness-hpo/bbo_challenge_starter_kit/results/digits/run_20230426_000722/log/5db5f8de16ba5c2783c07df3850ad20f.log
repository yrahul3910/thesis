running: {'--uuid': '5db5f8de16ba5c2783c07df3850ad20f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d diabetes -o turbo -u 5db5f8de16ba5c2783c07df3850ad20f -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_000722
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study turbo MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002129 iter 0 next_points [{'alpha': 0.3925971314098022, 'batch_size': 112, 'beta_1': 0.798933232982801, 'beta_2': 0.9999975371782323, 'epsilon': 3.682072852769506e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.006540419656176005, 'tol': 1.7538043740668613e-05, 'validation_fraction': 0.8357983663624688}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.745840 value 51.612673 suggestion {'alpha': 0.3925971314098022, 'batch_size': 112, 'beta_1': 0.798933232982801, 'beta_2': 0.9999975371782323, 'epsilon': 3.682072852769506e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.006540419656176005, 'tol': 1.7538043740668613e-05, 'validation_fraction': 0.8357983663624688}
observation time 0.001406, current best 51.612673 at iter 0
suggestion time taken 0.001803 iter 1 next_points [{'alpha': 1.2929521286065373, 'batch_size': 219, 'beta_1': 0.7360263650137904, 'beta_2': 0.9969233958880533, 'epsilon': 1.6203749570784376e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 1.544729063697462e-05, 'tol': 0.000508085891810501, 'validation_fraction': 0.1167023563665109}]
function_evaluation time 0.074028 value 151.489805 suggestion {'alpha': 1.2929521286065373, 'batch_size': 219, 'beta_1': 0.7360263650137904, 'beta_2': 0.9969233958880533, 'epsilon': 1.6203749570784376e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 1.544729063697462e-05, 'tol': 0.000508085891810501, 'validation_fraction': 0.1167023563665109}
observation time 0.001396, current best 51.612673 at iter 1
suggestion time taken 0.001804 iter 2 next_points [{'alpha': 0.01365634952755682, 'batch_size': 55, 'beta_1': 0.9339225587930904, 'beta_2': 0.9249322729543076, 'epsilon': 5.480215855495364e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.010088950202191648, 'tol': 1.3926095672616422e-05, 'validation_fraction': 0.7875243091265224}]
function_evaluation time 0.594244 value 55.680538 suggestion {'alpha': 0.01365634952755682, 'batch_size': 55, 'beta_1': 0.9339225587930904, 'beta_2': 0.9249322729543076, 'epsilon': 5.480215855495364e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.010088950202191648, 'tol': 1.3926095672616422e-05, 'validation_fraction': 0.7875243091265224}
observation time 0.001428, current best 51.612673 at iter 2
suggestion time taken 0.001786 iter 3 next_points [{'alpha': 0.00012282750668256526, 'batch_size': 91, 'beta_1': 0.8993288969890071, 'beta_2': 0.9978734877408306, 'epsilon': 1.1484131002067926e-09, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0049827502625133645, 'tol': 0.00026431273136450845, 'validation_fraction': 0.3956678921850418}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.060534 value 50.556295 suggestion {'alpha': 0.00012282750668256526, 'batch_size': 91, 'beta_1': 0.8993288969890071, 'beta_2': 0.9978734877408306, 'epsilon': 1.1484131002067926e-09, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0049827502625133645, 'tol': 0.00026431273136450845, 'validation_fraction': 0.3956678921850418}
observation time 0.001472, current best 50.556295 at iter 3
suggestion time taken 0.001702 iter 4 next_points [{'alpha': 0.5703550352786938, 'batch_size': 67, 'beta_1': 0.6059989880477699, 'beta_2': 0.9933177573700525, 'epsilon': 8.788596433351456e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.07774395344604242, 'tol': 0.0008219405785917765, 'validation_fraction': 0.8682060492681763}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.232137 value 45.733293 suggestion {'alpha': 0.5703550352786938, 'batch_size': 67, 'beta_1': 0.6059989880477699, 'beta_2': 0.9933177573700525, 'epsilon': 8.788596433351456e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.07774395344604242, 'tol': 0.0008219405785917765, 'validation_fraction': 0.8682060492681763}
observation time 0.001404, current best 45.733293 at iter 4
suggestion time taken 0.001780 iter 5 next_points [{'alpha': 0.0019577931833080577, 'batch_size': 85, 'beta_1': 0.8160544377197765, 'beta_2': 0.9702876863179785, 'epsilon': 3.484443832047387e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0001517371237688248, 'tol': 0.015294847655692313, 'validation_fraction': 0.22495219339358605}]
function_evaluation time 0.085963 value 151.657235 suggestion {'alpha': 0.0019577931833080577, 'batch_size': 85, 'beta_1': 0.8160544377197765, 'beta_2': 0.9702876863179785, 'epsilon': 3.484443832047387e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0001517371237688248, 'tol': 0.015294847655692313, 'validation_fraction': 0.22495219339358605}
observation time 0.001430, current best 45.733293 at iter 5
suggestion time taken 0.001758 iter 6 next_points [{'alpha': 0.000519740651803892, 'batch_size': 105, 'beta_1': 0.9779379087498592, 'beta_2': 0.9488684949243879, 'epsilon': 3.258802483890261e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 2.800491073223127e-05, 'tol': 0.032595925407303286, 'validation_fraction': 0.6003444122988226}]
function_evaluation time 0.061322 value 151.612112 suggestion {'alpha': 0.000519740651803892, 'batch_size': 105, 'beta_1': 0.9779379087498592, 'beta_2': 0.9488684949243879, 'epsilon': 3.258802483890261e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 2.800491073223127e-05, 'tol': 0.032595925407303286, 'validation_fraction': 0.6003444122988226}
observation time 0.001418, current best 45.733293 at iter 6
suggestion time taken 0.002118 iter 7 next_points [{'alpha': 3.0983438100687706, 'batch_size': 152, 'beta_1': 0.7026813807050476, 'beta_2': 0.9999986221286601, 'epsilon': 3.96004383311392e-08, 'hidden_layer_sizes': 122, 'learning_rate_init': 1.866871702349197e-05, 'tol': 0.039733921680441535, 'validation_fraction': 0.8939920148200815}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.050333 value 151.585538 suggestion {'alpha': 3.0983438100687706, 'batch_size': 152, 'beta_1': 0.7026813807050476, 'beta_2': 0.9999986221286601, 'epsilon': 3.96004383311392e-08, 'hidden_layer_sizes': 122, 'learning_rate_init': 1.866871702349197e-05, 'tol': 0.039733921680441535, 'validation_fraction': 0.8939920148200815}
observation time 0.001391, current best 45.733293 at iter 7
suggestion time taken 0.001788 iter 8 next_points [{'alpha': 0.006135149012666095, 'batch_size': 242, 'beta_1': 0.9544907231944905, 'beta_2': 0.9832678190924756, 'epsilon': 2.2615663642272032e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 4.294296228012981e-05, 'tol': 0.0001004084346523715, 'validation_fraction': 0.15006789619804423}]
function_evaluation time 0.074833 value 151.569924 suggestion {'alpha': 0.006135149012666095, 'batch_size': 242, 'beta_1': 0.9544907231944905, 'beta_2': 0.9832678190924756, 'epsilon': 2.2615663642272032e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 4.294296228012981e-05, 'tol': 0.0001004084346523715, 'validation_fraction': 0.15006789619804423}
observation time 0.001409, current best 45.733293 at iter 8
suggestion time taken 0.001925 iter 9 next_points [{'alpha': 0.07330493815468571, 'batch_size': 177, 'beta_1': 0.8717820431976899, 'beta_2': 0.9994478623547268, 'epsilon': 1.6994676352883316e-08, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0006852968213851276, 'tol': 0.0016272763866221154, 'validation_fraction': 0.7444039079099637}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.057244 value 151.511242 suggestion {'alpha': 0.07330493815468571, 'batch_size': 177, 'beta_1': 0.8717820431976899, 'beta_2': 0.9994478623547268, 'epsilon': 1.6994676352883316e-08, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0006852968213851276, 'tol': 0.0016272763866221154, 'validation_fraction': 0.7444039079099637}
observation time 0.001392, current best 45.733293 at iter 9
suggestion time taken 0.001704 iter 10 next_points [{'alpha': 0.15484194081457073, 'batch_size': 48, 'beta_1': 0.5370735724279186, 'beta_2': 0.9999524603365898, 'epsilon': 5.927922568796412e-08, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.016231262111677754, 'tol': 6.299405437758489e-05, 'validation_fraction': 0.21404086748388107}]
function_evaluation time 0.539210 value 44.202011 suggestion {'alpha': 0.15484194081457073, 'batch_size': 48, 'beta_1': 0.5370735724279186, 'beta_2': 0.9999524603365898, 'epsilon': 5.927922568796412e-08, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.016231262111677754, 'tol': 6.299405437758489e-05, 'validation_fraction': 0.21404086748388107}
observation time 0.001385, current best 44.202011 at iter 10
suggestion time taken 0.001753 iter 11 next_points [{'alpha': 0.02833406651976546, 'batch_size': 149, 'beta_1': 0.9646871587993091, 'beta_2': 0.9999822624797743, 'epsilon': 8.091564230768331e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.047211802838335794, 'tol': 0.0003947822241957635, 'validation_fraction': 0.3356875402681899}]
function_evaluation time 0.208902 value 52.236146 suggestion {'alpha': 0.02833406651976546, 'batch_size': 149, 'beta_1': 0.9646871587993091, 'beta_2': 0.9999822624797743, 'epsilon': 8.091564230768331e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.047211802838335794, 'tol': 0.0003947822241957635, 'validation_fraction': 0.3356875402681899}
observation time 0.001421, current best 44.202011 at iter 11
suggestion time taken 0.001703 iter 12 next_points [{'alpha': 1.7364040250629783e-05, 'batch_size': 27, 'beta_1': 0.9393610602455864, 'beta_2': 0.9999891906268782, 'epsilon': 2.411376238870354e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0003262222910038793, 'tol': 0.00013185822547555505, 'validation_fraction': 0.5588911624795267}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.767251 value 137.050426 suggestion {'alpha': 1.7364040250629783e-05, 'batch_size': 27, 'beta_1': 0.9393610602455864, 'beta_2': 0.9999891906268782, 'epsilon': 2.411376238870354e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0003262222910038793, 'tol': 0.00013185822547555505, 'validation_fraction': 0.5588911624795267}
observation time 0.001393, current best 44.202011 at iter 12
suggestion time taken 0.001749 iter 13 next_points [{'alpha': 0.04279083601318211, 'batch_size': 132, 'beta_1': 0.6622450808188274, 'beta_2': 0.9999774215975381, 'epsilon': 9.143702942976659e-09, 'hidden_layer_sizes': 103, 'learning_rate_init': 9.229044838517755e-05, 'tol': 3.068765010674013e-05, 'validation_fraction': 0.26891030142051403}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.050362 value 151.060604 suggestion {'alpha': 0.04279083601318211, 'batch_size': 132, 'beta_1': 0.6622450808188274, 'beta_2': 0.9999774215975381, 'epsilon': 9.143702942976659e-09, 'hidden_layer_sizes': 103, 'learning_rate_init': 9.229044838517755e-05, 'tol': 3.068765010674013e-05, 'validation_fraction': 0.26891030142051403}
observation time 0.001391, current best 44.202011 at iter 13
suggestion time taken 0.001747 iter 14 next_points [{'alpha': 0.0003339430245873945, 'batch_size': 196, 'beta_1': 0.9863529565325625, 'beta_2': 0.9996164597357797, 'epsilon': 1.4354409018421316e-07, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0020249980922745076, 'tol': 0.06813129304079707, 'validation_fraction': 0.6673084766250443}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.063401 value 151.029357 suggestion {'alpha': 0.0003339430245873945, 'batch_size': 196, 'beta_1': 0.9863529565325625, 'beta_2': 0.9996164597357797, 'epsilon': 1.4354409018421316e-07, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0020249980922745076, 'tol': 0.06813129304079707, 'validation_fraction': 0.6673084766250443}
observation time 0.001374, current best 44.202011 at iter 14
saving meta data: {'args': {'--uuid': '5db5f8de16ba5c2783c07df3850ad20f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

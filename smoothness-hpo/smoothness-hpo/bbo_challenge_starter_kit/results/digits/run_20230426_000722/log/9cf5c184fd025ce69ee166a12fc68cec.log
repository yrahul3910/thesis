running: {'--uuid': '9cf5c184fd025ce69ee166a12fc68cec', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d diabetes -o random-search -u 9cf5c184fd025ce69ee166a12fc68cec -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_000722
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study random-search MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002568 iter 0 next_points [{'alpha': 5.244848471965448, 'batch_size': 97, 'beta_1': 0.9897968215611471, 'beta_2': 0.9999988898982173, 'epsilon': 1.6237844397085012e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.00012347936805906092, 'tol': 0.002956960575610833, 'validation_fraction': 0.4748812426572559}]
function_evaluation time 0.074054 value 29115.828865 suggestion {'alpha': 5.244848471965448, 'batch_size': 97, 'beta_1': 0.9897968215611471, 'beta_2': 0.9999988898982173, 'epsilon': 1.6237844397085012e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.00012347936805906092, 'tol': 0.002956960575610833, 'validation_fraction': 0.4748812426572559}
observation time 0.000006, current best 29115.828865 at iter 0
suggestion time taken 0.002534 iter 1 next_points [{'alpha': 8.30977368233229, 'batch_size': 179, 'beta_1': 0.9045170657191481, 'beta_2': 0.9999011821242549, 'epsilon': 1.6819012408668504e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.006537471813104561, 'tol': 1.9505475667660402e-05, 'validation_fraction': 0.592206096960672}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.914246 value 3774.671206 suggestion {'alpha': 8.30977368233229, 'batch_size': 179, 'beta_1': 0.9045170657191481, 'beta_2': 0.9999011821242549, 'epsilon': 1.6819012408668504e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.006537471813104561, 'tol': 1.9505475667660402e-05, 'validation_fraction': 0.592206096960672}
observation time 0.000004, current best 3774.671206 at iter 1
suggestion time taken 0.002524 iter 2 next_points [{'alpha': 0.05288632185468064, 'batch_size': 19, 'beta_1': 0.9437268472073941, 'beta_2': 0.9999779334970328, 'epsilon': 2.949826655936059e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0007393151263873185, 'tol': 0.005657211947229634, 'validation_fraction': 0.7514829259143447}]
function_evaluation time 0.083389 value 28968.450771 suggestion {'alpha': 0.05288632185468064, 'batch_size': 19, 'beta_1': 0.9437268472073941, 'beta_2': 0.9999779334970328, 'epsilon': 2.949826655936059e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0007393151263873185, 'tol': 0.005657211947229634, 'validation_fraction': 0.7514829259143447}
observation time 0.000004, current best 3774.671206 at iter 2
suggestion time taken 0.002807 iter 3 next_points [{'alpha': 7.4322564099564525, 'batch_size': 23, 'beta_1': 0.8721957441794064, 'beta_2': 0.9999088714933518, 'epsilon': 3.1011641345209244e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 3.643695985318816e-05, 'tol': 0.00015964793352975685, 'validation_fraction': 0.36995263798418115}]
function_evaluation time 0.523028 value 29018.120702 suggestion {'alpha': 7.4322564099564525, 'batch_size': 23, 'beta_1': 0.8721957441794064, 'beta_2': 0.9999088714933518, 'epsilon': 3.1011641345209244e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 3.643695985318816e-05, 'tol': 0.00015964793352975685, 'validation_fraction': 0.36995263798418115}
observation time 0.000005, current best 3774.671206 at iter 3
suggestion time taken 0.002460 iter 4 next_points [{'alpha': 0.09096428331075097, 'batch_size': 25, 'beta_1': 0.9185668421672206, 'beta_2': 0.9999712149201888, 'epsilon': 1.018818495744262e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.008429883627612192, 'tol': 7.67886686732995e-05, 'validation_fraction': 0.12802413081237832}]
function_evaluation time 0.954995 value 2948.002481 suggestion {'alpha': 0.09096428331075097, 'batch_size': 25, 'beta_1': 0.9185668421672206, 'beta_2': 0.9999712149201888, 'epsilon': 1.018818495744262e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.008429883627612192, 'tol': 7.67886686732995e-05, 'validation_fraction': 0.12802413081237832}
observation time 0.000005, current best 2948.002481 at iter 4
suggestion time taken 0.002735 iter 5 next_points [{'alpha': 0.016597946772731482, 'batch_size': 136, 'beta_1': 0.9874587592626826, 'beta_2': 0.9998611262587398, 'epsilon': 6.4741871751076306e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.006833647114073188, 'tol': 0.02525642356195583, 'validation_fraction': 0.1442500875424961}]
function_evaluation time 0.067810 value 28447.283391 suggestion {'alpha': 0.016597946772731482, 'batch_size': 136, 'beta_1': 0.9874587592626826, 'beta_2': 0.9998611262587398, 'epsilon': 6.4741871751076306e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.006833647114073188, 'tol': 0.02525642356195583, 'validation_fraction': 0.1442500875424961}
observation time 0.000005, current best 2948.002481 at iter 5
suggestion time taken 0.002521 iter 6 next_points [{'alpha': 0.01381784348521731, 'batch_size': 203, 'beta_1': 0.8688246469757307, 'beta_2': 0.9104045912692594, 'epsilon': 2.9544519541161786e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.000322773338279614, 'tol': 0.00048037215214158076, 'validation_fraction': 0.7031670588358144}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.055736 value 29061.595183 suggestion {'alpha': 0.01381784348521731, 'batch_size': 203, 'beta_1': 0.8688246469757307, 'beta_2': 0.9104045912692594, 'epsilon': 2.9544519541161786e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.000322773338279614, 'tol': 0.00048037215214158076, 'validation_fraction': 0.7031670588358144}
observation time 0.000005, current best 2948.002481 at iter 6
suggestion time taken 0.002798 iter 7 next_points [{'alpha': 0.055144663195690384, 'batch_size': 243, 'beta_1': 0.9859160250885817, 'beta_2': 0.9999977579408674, 'epsilon': 1.1735116940920676e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0005573033841534351, 'tol': 0.0012957377764614166, 'validation_fraction': 0.7584838115181617}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.049368 value 29116.854761 suggestion {'alpha': 0.055144663195690384, 'batch_size': 243, 'beta_1': 0.9859160250885817, 'beta_2': 0.9999977579408674, 'epsilon': 1.1735116940920676e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0005573033841534351, 'tol': 0.0012957377764614166, 'validation_fraction': 0.7584838115181617}
observation time 0.000005, current best 2948.002481 at iter 7
suggestion time taken 0.002458 iter 8 next_points [{'alpha': 0.679745865177401, 'batch_size': 221, 'beta_1': 0.8587018041956601, 'beta_2': 0.9722519918229827, 'epsilon': 3.4297608337225615e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.01570989392017827, 'tol': 0.004732033053426764, 'validation_fraction': 0.8507091878381272}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.378706 value 4029.856860 suggestion {'alpha': 0.679745865177401, 'batch_size': 221, 'beta_1': 0.8587018041956601, 'beta_2': 0.9722519918229827, 'epsilon': 3.4297608337225615e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.01570989392017827, 'tol': 0.004732033053426764, 'validation_fraction': 0.8507091878381272}
observation time 0.000004, current best 2948.002481 at iter 8
suggestion time taken 0.002547 iter 9 next_points [{'alpha': 1.4403355441618239e-05, 'batch_size': 78, 'beta_1': 0.8742485895154718, 'beta_2': 0.9999980777517701, 'epsilon': 1.0654850089140826e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.007508211467828153, 'tol': 0.000636678683525406, 'validation_fraction': 0.7508705235517709}]
function_evaluation time 0.675018 value 4196.537144 suggestion {'alpha': 1.4403355441618239e-05, 'batch_size': 78, 'beta_1': 0.8742485895154718, 'beta_2': 0.9999980777517701, 'epsilon': 1.0654850089140826e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.007508211467828153, 'tol': 0.000636678683525406, 'validation_fraction': 0.7508705235517709}
observation time 0.000005, current best 2948.002481 at iter 9
suggestion time taken 0.002452 iter 10 next_points [{'alpha': 0.10539494772602497, 'batch_size': 98, 'beta_1': 0.8239002351111823, 'beta_2': 0.9998596902433987, 'epsilon': 1.8004652718463986e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.03268050536563703, 'tol': 0.009439487393022614, 'validation_fraction': 0.37058045262151873}]
function_evaluation time 0.237623 value 3221.920254 suggestion {'alpha': 0.10539494772602497, 'batch_size': 98, 'beta_1': 0.8239002351111823, 'beta_2': 0.9998596902433987, 'epsilon': 1.8004652718463986e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.03268050536563703, 'tol': 0.009439487393022614, 'validation_fraction': 0.37058045262151873}
observation time 0.000003, current best 2948.002481 at iter 10
suggestion time taken 0.002677 iter 11 next_points [{'alpha': 0.044124518426361954, 'batch_size': 83, 'beta_1': 0.8807470641051622, 'beta_2': 0.9999304325001908, 'epsilon': 2.6450727666961955e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.0009222179271759338, 'tol': 0.0032515409398585216, 'validation_fraction': 0.7734233930775566}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.052361 value 29073.717723 suggestion {'alpha': 0.044124518426361954, 'batch_size': 83, 'beta_1': 0.8807470641051622, 'beta_2': 0.9999304325001908, 'epsilon': 2.6450727666961955e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.0009222179271759338, 'tol': 0.0032515409398585216, 'validation_fraction': 0.7734233930775566}
observation time 0.000005, current best 2948.002481 at iter 11
suggestion time taken 0.002441 iter 12 next_points [{'alpha': 0.019813907488818942, 'batch_size': 96, 'beta_1': 0.8302956499105246, 'beta_2': 0.9997981599333898, 'epsilon': 4.3966107925079095e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.006164689769324295, 'tol': 0.020374508606748616, 'validation_fraction': 0.4416483861385933}]
function_evaluation time 0.147621 value 28179.916558 suggestion {'alpha': 0.019813907488818942, 'batch_size': 96, 'beta_1': 0.8302956499105246, 'beta_2': 0.9997981599333898, 'epsilon': 4.3966107925079095e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.006164689769324295, 'tol': 0.020374508606748616, 'validation_fraction': 0.4416483861385933}
observation time 0.000004, current best 2948.002481 at iter 12
suggestion time taken 0.002468 iter 13 next_points [{'alpha': 0.004633266504509067, 'batch_size': 208, 'beta_1': 0.6424005072163885, 'beta_2': 0.9977144251750449, 'epsilon': 2.120347935884465e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0005129243609736032, 'tol': 2.8195842687925997e-05, 'validation_fraction': 0.5926923460196474}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.671502 value 28588.261926 suggestion {'alpha': 0.004633266504509067, 'batch_size': 208, 'beta_1': 0.6424005072163885, 'beta_2': 0.9977144251750449, 'epsilon': 2.120347935884465e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0005129243609736032, 'tol': 2.8195842687925997e-05, 'validation_fraction': 0.5926923460196474}
observation time 0.000005, current best 2948.002481 at iter 13
suggestion time taken 0.002500 iter 14 next_points [{'alpha': 0.016491353235995848, 'batch_size': 73, 'beta_1': 0.7696939466470507, 'beta_2': 0.9999559826836315, 'epsilon': 1.1179546097886232e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.00027299707387711024, 'tol': 0.0007702452966334242, 'validation_fraction': 0.46257365672063616}]
function_evaluation time 0.080089 value 29101.734686 suggestion {'alpha': 0.016491353235995848, 'batch_size': 73, 'beta_1': 0.7696939466470507, 'beta_2': 0.9999559826836315, 'epsilon': 1.1179546097886232e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.00027299707387711024, 'tol': 0.0007702452966334242, 'validation_fraction': 0.46257365672063616}
observation time 0.000005, current best 2948.002481 at iter 14
saving meta data: {'args': {'--uuid': '9cf5c184fd025ce69ee166a12fc68cec', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

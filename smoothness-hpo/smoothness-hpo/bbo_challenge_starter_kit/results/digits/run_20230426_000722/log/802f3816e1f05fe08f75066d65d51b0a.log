running: {'--uuid': '802f3816e1f05fe08f75066d65d51b0a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d diabetes -o hyperopt -u 802f3816e1f05fe08f75066d65d51b0a -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_000722
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study hyperopt MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002362 iter 0 next_points [{'alpha': 3.9529086152425226, 'batch_size': 124, 'beta_1': 0.6759016907698975, 'beta_2': 0.9410658055275889, 'epsilon': 1.592158616195798e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.02235119474739303, 'tol': 0.024230843504935845, 'validation_fraction': 0.18788093864823413}]
function_evaluation time 0.257142 value 3665.847571 suggestion {'alpha': 3.9529086152425226, 'batch_size': 124, 'beta_1': 0.6759016907698975, 'beta_2': 0.9410658055275889, 'epsilon': 1.592158616195798e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.02235119474739303, 'tol': 0.024230843504935845, 'validation_fraction': 0.18788093864823413}
observation time 0.000067, current best 3665.847571 at iter 0
suggestion time taken 0.002613 iter 1 next_points [{'alpha': 0.0002186898715689761, 'batch_size': 148, 'beta_1': 0.8036083635274943, 'beta_2': 0.9938213782772135, 'epsilon': 2.06040099542707e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.000467506745197653, 'tol': 1.0821651237498502e-05, 'validation_fraction': 0.16347230381057662}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.626392 value 28328.577925 suggestion {'alpha': 0.0002186898715689761, 'batch_size': 148, 'beta_1': 0.8036083635274943, 'beta_2': 0.9938213782772135, 'epsilon': 2.06040099542707e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.000467506745197653, 'tol': 1.0821651237498502e-05, 'validation_fraction': 0.16347230381057662}
observation time 0.000071, current best 3665.847571 at iter 1
suggestion time taken 0.002159 iter 2 next_points [{'alpha': 0.5358998802369427, 'batch_size': 240, 'beta_1': 0.703954074506486, 'beta_2': 0.9288530912826339, 'epsilon': 1.6618250116433467e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.00010162571267343211, 'tol': 0.00014656851252463005, 'validation_fraction': 0.24262107502283917}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.287847 value 29057.276074 suggestion {'alpha': 0.5358998802369427, 'batch_size': 240, 'beta_1': 0.703954074506486, 'beta_2': 0.9288530912826339, 'epsilon': 1.6618250116433467e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.00010162571267343211, 'tol': 0.00014656851252463005, 'validation_fraction': 0.24262107502283917}
observation time 0.000071, current best 3665.847571 at iter 2
suggestion time taken 0.002161 iter 3 next_points [{'alpha': 0.011438080408709412, 'batch_size': 198, 'beta_1': 0.8908148317008819, 'beta_2': 0.953188462905538, 'epsilon': 3.5853388512774626e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 6.45359236602675e-05, 'tol': 0.00010078118386042113, 'validation_fraction': 0.8141395698473293}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.054750 value 29100.709447 suggestion {'alpha': 0.011438080408709412, 'batch_size': 198, 'beta_1': 0.8908148317008819, 'beta_2': 0.953188462905538, 'epsilon': 3.5853388512774626e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 6.45359236602675e-05, 'tol': 0.00010078118386042113, 'validation_fraction': 0.8141395698473293}
observation time 0.000070, current best 3665.847571 at iter 3
suggestion time taken 0.002145 iter 4 next_points [{'alpha': 0.7831331285587427, 'batch_size': 133, 'beta_1': 0.8630126043591997, 'beta_2': 0.972088613422131, 'epsilon': 3.114537506609025e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 2.7568589103095343e-05, 'tol': 0.0011323053921227623, 'validation_fraction': 0.1960487187751097}]
function_evaluation time 0.080423 value 29114.803395 suggestion {'alpha': 0.7831331285587427, 'batch_size': 133, 'beta_1': 0.8630126043591997, 'beta_2': 0.972088613422131, 'epsilon': 3.114537506609025e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 2.7568589103095343e-05, 'tol': 0.0011323053921227623, 'validation_fraction': 0.1960487187751097}
observation time 0.000067, current best 3665.847571 at iter 4
suggestion time taken 0.002129 iter 5 next_points [{'alpha': 2.792454016421461, 'batch_size': 109, 'beta_1': 0.7798951585739741, 'beta_2': 0.9689960690806227, 'epsilon': 9.821199100116026e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 3.611828481840121e-05, 'tol': 0.00020484827521712352, 'validation_fraction': 0.13071001321285122}]
function_evaluation time 0.089271 value 29144.048810 suggestion {'alpha': 2.792454016421461, 'batch_size': 109, 'beta_1': 0.7798951585739741, 'beta_2': 0.9689960690806227, 'epsilon': 9.821199100116026e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 3.611828481840121e-05, 'tol': 0.00020484827521712352, 'validation_fraction': 0.13071001321285122}
observation time 0.000068, current best 3665.847571 at iter 5
suggestion time taken 0.002196 iter 6 next_points [{'alpha': 4.465256155473744e-05, 'batch_size': 201, 'beta_1': 0.8804698056928267, 'beta_2': 0.9609353464826003, 'epsilon': 2.230909062713393e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0025385507776490247, 'tol': 0.008626318155732338, 'validation_fraction': 0.2710504637084538}]
function_evaluation time 0.067269 value 28894.739765 suggestion {'alpha': 4.465256155473744e-05, 'batch_size': 201, 'beta_1': 0.8804698056928267, 'beta_2': 0.9609353464826003, 'epsilon': 2.230909062713393e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0025385507776490247, 'tol': 0.008626318155732338, 'validation_fraction': 0.2710504637084538}
observation time 0.000071, current best 3665.847571 at iter 6
suggestion time taken 0.002208 iter 7 next_points [{'alpha': 8.02878042842572e-05, 'batch_size': 70, 'beta_1': 0.7172174924060511, 'beta_2': 0.9541826583592735, 'epsilon': 3.038178016070603e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.01524367362616539, 'tol': 0.009659283402220338, 'validation_fraction': 0.42039952182114615}]
function_evaluation time 0.319994 value 3766.264211 suggestion {'alpha': 8.02878042842572e-05, 'batch_size': 70, 'beta_1': 0.7172174924060511, 'beta_2': 0.9541826583592735, 'epsilon': 3.038178016070603e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.01524367362616539, 'tol': 0.009659283402220338, 'validation_fraction': 0.42039952182114615}
observation time 0.000072, current best 3665.847571 at iter 7
suggestion time taken 0.002189 iter 8 next_points [{'alpha': 0.00029075430211253887, 'batch_size': 163, 'beta_1': 0.848850386584733, 'beta_2': 0.9241713547313999, 'epsilon': 1.0391186482877002e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.0008459027069754261, 'tol': 0.00047960776558076437, 'validation_fraction': 0.889386754133632}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.669877 value 28086.335396 suggestion {'alpha': 0.00029075430211253887, 'batch_size': 163, 'beta_1': 0.848850386584733, 'beta_2': 0.9241713547313999, 'epsilon': 1.0391186482877002e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.0008459027069754261, 'tol': 0.00047960776558076437, 'validation_fraction': 0.889386754133632}
observation time 0.000071, current best 3665.847571 at iter 8
suggestion time taken 0.002119 iter 9 next_points [{'alpha': 0.0001070272379226962, 'batch_size': 156, 'beta_1': 0.7955132070767073, 'beta_2': 0.9358715786624664, 'epsilon': 7.537296826408053e-07, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0016451785704757259, 'tol': 0.0033164727585155455, 'validation_fraction': 0.7547019333278632}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.054125 value 28982.729160 suggestion {'alpha': 0.0001070272379226962, 'batch_size': 156, 'beta_1': 0.7955132070767073, 'beta_2': 0.9358715786624664, 'epsilon': 7.537296826408053e-07, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0016451785704757259, 'tol': 0.0033164727585155455, 'validation_fraction': 0.7547019333278632}
observation time 0.000073, current best 3665.847571 at iter 9
suggestion time taken 0.002129 iter 10 next_points [{'alpha': 0.0002721650992936795, 'batch_size': 101, 'beta_1': 0.8792830886874407, 'beta_2': 0.9390721532524157, 'epsilon': 3.1558356727954696e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 1.8472724294388946e-05, 'tol': 0.005468439900925709, 'validation_fraction': 0.11072220671135848}]
function_evaluation time 0.091408 value 29115.128084 suggestion {'alpha': 0.0002721650992936795, 'batch_size': 101, 'beta_1': 0.8792830886874407, 'beta_2': 0.9390721532524157, 'epsilon': 3.1558356727954696e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 1.8472724294388946e-05, 'tol': 0.005468439900925709, 'validation_fraction': 0.11072220671135848}
observation time 0.000066, current best 3665.847571 at iter 10
suggestion time taken 0.002173 iter 11 next_points [{'alpha': 0.0012410710265753056, 'batch_size': 30, 'beta_1': 0.5758193227072229, 'beta_2': 0.9595399948833154, 'epsilon': 3.927084925015171e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.012134982520939782, 'tol': 0.006785047348237456, 'validation_fraction': 0.2863271767870557}]
function_evaluation time 0.470751 value 3066.529721 suggestion {'alpha': 0.0012410710265753056, 'batch_size': 30, 'beta_1': 0.5758193227072229, 'beta_2': 0.9595399948833154, 'epsilon': 3.927084925015171e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.012134982520939782, 'tol': 0.006785047348237456, 'validation_fraction': 0.2863271767870557}
observation time 0.000075, current best 3066.529721 at iter 11
suggestion time taken 0.002192 iter 12 next_points [{'alpha': 0.0018677974734875693, 'batch_size': 188, 'beta_1': 0.6519918986779872, 'beta_2': 0.934692209565816, 'epsilon': 2.2841247326625088e-08, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.004408685472074729, 'tol': 0.009335763942060088, 'validation_fraction': 0.32385304058036196}]
function_evaluation time 0.672415 value 14474.143143 suggestion {'alpha': 0.0018677974734875693, 'batch_size': 188, 'beta_1': 0.6519918986779872, 'beta_2': 0.934692209565816, 'epsilon': 2.2841247326625088e-08, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.004408685472074729, 'tol': 0.009335763942060088, 'validation_fraction': 0.32385304058036196}
observation time 0.000067, current best 3066.529721 at iter 12
suggestion time taken 0.002221 iter 13 next_points [{'alpha': 0.20780496034870297, 'batch_size': 225, 'beta_1': 0.6644337476606449, 'beta_2': 0.9552198925520251, 'epsilon': 3.4583362950004248e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.03189823536120229, 'tol': 6.733327631109437e-05, 'validation_fraction': 0.46833896550828413}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.655725 value 3035.642208 suggestion {'alpha': 0.20780496034870297, 'batch_size': 225, 'beta_1': 0.6644337476606449, 'beta_2': 0.9552198925520251, 'epsilon': 3.4583362950004248e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.03189823536120229, 'tol': 6.733327631109437e-05, 'validation_fraction': 0.46833896550828413}
observation time 0.000074, current best 3035.642208 at iter 13
suggestion time taken 0.002182 iter 14 next_points [{'alpha': 0.003753219785014633, 'batch_size': 122, 'beta_1': 0.7657316853207413, 'beta_2': 0.9976981462972181, 'epsilon': 6.293349519846533e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 3.727886136377986e-05, 'tol': 0.00343509769606604, 'validation_fraction': 0.8856453274101245}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.041454 value 29065.231775 suggestion {'alpha': 0.003753219785014633, 'batch_size': 122, 'beta_1': 0.7657316853207413, 'beta_2': 0.9976981462972181, 'epsilon': 6.293349519846533e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 3.727886136377986e-05, 'tol': 0.00343509769606604, 'validation_fraction': 0.8856453274101245}
observation time 0.000074, current best 3035.642208 at iter 14
saving meta data: {'args': {'--uuid': '802f3816e1f05fe08f75066d65d51b0a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

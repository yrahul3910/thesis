running: {'--uuid': '23ee893fb95f50c7aac8b250a59b333b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d diabetes -o hyperopt -u 23ee893fb95f50c7aac8b250a59b333b -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_000722
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study hyperopt MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002343 iter 0 next_points [{'alpha': 0.0024264186906888326, 'batch_size': 236, 'beta_1': 0.7896942002086598, 'beta_2': 0.9987331619058585, 'epsilon': 1.378525864407156e-09, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.00034728815965117185, 'tol': 0.012974994444549103, 'validation_fraction': 0.18615821586692166}]
function_evaluation time 0.066250 value 29072.405398 suggestion {'alpha': 0.0024264186906888326, 'batch_size': 236, 'beta_1': 0.7896942002086598, 'beta_2': 0.9987331619058585, 'epsilon': 1.378525864407156e-09, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.00034728815965117185, 'tol': 0.012974994444549103, 'validation_fraction': 0.18615821586692166}
observation time 0.000065, current best 29072.405398 at iter 0
suggestion time taken 0.002399 iter 1 next_points [{'alpha': 0.16174157677147263, 'batch_size': 210, 'beta_1': 0.9300189431874992, 'beta_2': 0.9036507524144178, 'epsilon': 2.539604363016942e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0005679415670847881, 'tol': 0.0002820758304762654, 'validation_fraction': 0.10598275331551497}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.418929 value 26958.203894 suggestion {'alpha': 0.16174157677147263, 'batch_size': 210, 'beta_1': 0.9300189431874992, 'beta_2': 0.9036507524144178, 'epsilon': 2.539604363016942e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0005679415670847881, 'tol': 0.0002820758304762654, 'validation_fraction': 0.10598275331551497}
observation time 0.000072, current best 26958.203894 at iter 1
suggestion time taken 0.002366 iter 2 next_points [{'alpha': 0.6274850669619128, 'batch_size': 96, 'beta_1': 0.756998144045701, 'beta_2': 0.9340481211326941, 'epsilon': 1.6221905612483642e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.039915014768614865, 'tol': 0.0028893588400949913, 'validation_fraction': 0.6370216385456654}]
function_evaluation time 0.404824 value 3268.675722 suggestion {'alpha': 0.6274850669619128, 'batch_size': 96, 'beta_1': 0.756998144045701, 'beta_2': 0.9340481211326941, 'epsilon': 1.6221905612483642e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.039915014768614865, 'tol': 0.0028893588400949913, 'validation_fraction': 0.6370216385456654}
observation time 0.000069, current best 3268.675722 at iter 2
suggestion time taken 0.002127 iter 3 next_points [{'alpha': 0.0002550591550270286, 'batch_size': 72, 'beta_1': 0.7170902927095691, 'beta_2': 0.9534618006351473, 'epsilon': 8.16294522199828e-09, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.03649611442901142, 'tol': 9.915625463663438e-05, 'validation_fraction': 0.20040683631686446}]
function_evaluation time 0.295904 value 2941.115350 suggestion {'alpha': 0.0002550591550270286, 'batch_size': 72, 'beta_1': 0.7170902927095691, 'beta_2': 0.9534618006351473, 'epsilon': 8.16294522199828e-09, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.03649611442901142, 'tol': 9.915625463663438e-05, 'validation_fraction': 0.20040683631686446}
observation time 0.000071, current best 2941.115350 at iter 3
suggestion time taken 0.002366 iter 4 next_points [{'alpha': 1.2404554283084717, 'batch_size': 117, 'beta_1': 0.8782800051721603, 'beta_2': 0.9628687344932796, 'epsilon': 4.75679416746197e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 5.812792491806903e-05, 'tol': 0.0026163432539975094, 'validation_fraction': 0.3397744838335646}]
function_evaluation time 0.078477 value 29084.707220 suggestion {'alpha': 1.2404554283084717, 'batch_size': 117, 'beta_1': 0.8782800051721603, 'beta_2': 0.9628687344932796, 'epsilon': 4.75679416746197e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 5.812792491806903e-05, 'tol': 0.0026163432539975094, 'validation_fraction': 0.3397744838335646}
observation time 0.000072, current best 2941.115350 at iter 4
suggestion time taken 0.002110 iter 5 next_points [{'alpha': 0.010314211922914086, 'batch_size': 184, 'beta_1': 0.5930456614208611, 'beta_2': 0.9391138753014164, 'epsilon': 2.2431497926526452e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.000274961058499486, 'tol': 0.00029957254109218843, 'validation_fraction': 0.5607009760612706}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.199229 value 29029.677521 suggestion {'alpha': 0.010314211922914086, 'batch_size': 184, 'beta_1': 0.5930456614208611, 'beta_2': 0.9391138753014164, 'epsilon': 2.2431497926526452e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.000274961058499486, 'tol': 0.00029957254109218843, 'validation_fraction': 0.5607009760612706}
observation time 0.000073, current best 2941.115350 at iter 5
suggestion time taken 0.002107 iter 6 next_points [{'alpha': 1.554247682051404, 'batch_size': 176, 'beta_1': 0.6007088899589146, 'beta_2': 0.9126175046879595, 'epsilon': 4.074979368465258e-09, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.00012040339228336537, 'tol': 0.002826680571696637, 'validation_fraction': 0.686258096795596}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.055525 value 29080.815022 suggestion {'alpha': 1.554247682051404, 'batch_size': 176, 'beta_1': 0.6007088899589146, 'beta_2': 0.9126175046879595, 'epsilon': 4.074979368465258e-09, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.00012040339228336537, 'tol': 0.002826680571696637, 'validation_fraction': 0.686258096795596}
observation time 0.000071, current best 2941.115350 at iter 6
suggestion time taken 0.002159 iter 7 next_points [{'alpha': 0.0004828811205995472, 'batch_size': 165, 'beta_1': 0.6556570633159987, 'beta_2': 0.9543121101775758, 'epsilon': 6.564163894350365e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.017396363039528642, 'tol': 0.0045443090595796215, 'validation_fraction': 0.2582498692114259}]
function_evaluation time 0.347974 value 3651.237064 suggestion {'alpha': 0.0004828811205995472, 'batch_size': 165, 'beta_1': 0.6556570633159987, 'beta_2': 0.9543121101775758, 'epsilon': 6.564163894350365e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.017396363039528642, 'tol': 0.0045443090595796215, 'validation_fraction': 0.2582498692114259}
observation time 0.000071, current best 2941.115350 at iter 7
suggestion time taken 0.002129 iter 8 next_points [{'alpha': 4.3735758352063614e-05, 'batch_size': 44, 'beta_1': 0.7009429359912832, 'beta_2': 0.9613480494516894, 'epsilon': 3.757498553009897e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 1.826838929474182e-05, 'tol': 0.0048758281175470845, 'validation_fraction': 0.10524095195432699}]
function_evaluation time 0.132782 value 29160.061885 suggestion {'alpha': 4.3735758352063614e-05, 'batch_size': 44, 'beta_1': 0.7009429359912832, 'beta_2': 0.9613480494516894, 'epsilon': 3.757498553009897e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 1.826838929474182e-05, 'tol': 0.0048758281175470845, 'validation_fraction': 0.10524095195432699}
observation time 0.000073, current best 2941.115350 at iter 8
suggestion time taken 0.002358 iter 9 next_points [{'alpha': 1.5359647846485693e-05, 'batch_size': 111, 'beta_1': 0.6871198944399933, 'beta_2': 0.9470043695812943, 'epsilon': 1.1213817175084535e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.00023094220536295704, 'tol': 0.0001366553629544875, 'validation_fraction': 0.7378809224788025}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.847825 value 28835.202296 suggestion {'alpha': 1.5359647846485693e-05, 'batch_size': 111, 'beta_1': 0.6871198944399933, 'beta_2': 0.9470043695812943, 'epsilon': 1.1213817175084535e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.00023094220536295704, 'tol': 0.0001366553629544875, 'validation_fraction': 0.7378809224788025}
observation time 0.000073, current best 2941.115350 at iter 9
suggestion time taken 0.002312 iter 10 next_points [{'alpha': 7.990270593848887e-05, 'batch_size': 28, 'beta_1': 0.7660879229449038, 'beta_2': 0.9109158944366375, 'epsilon': 7.513740176219682e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.3751737182052e-05, 'tol': 0.0002475369128606186, 'validation_fraction': 0.1933799395092676}]
function_evaluation time 0.098796 value 29147.880150 suggestion {'alpha': 7.990270593848887e-05, 'batch_size': 28, 'beta_1': 0.7660879229449038, 'beta_2': 0.9109158944366375, 'epsilon': 7.513740176219682e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.3751737182052e-05, 'tol': 0.0002475369128606186, 'validation_fraction': 0.1933799395092676}
observation time 0.000072, current best 2941.115350 at iter 10
suggestion time taken 0.002126 iter 11 next_points [{'alpha': 0.0011417087163678233, 'batch_size': 66, 'beta_1': 0.5684815366984528, 'beta_2': 0.9563911685656195, 'epsilon': 6.719120882462749e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.04499434491992007, 'tol': 0.006441411976179237, 'validation_fraction': 0.3180341871695086}]
function_evaluation time 0.163575 value 2945.675639 suggestion {'alpha': 0.0011417087163678233, 'batch_size': 66, 'beta_1': 0.5684815366984528, 'beta_2': 0.9563911685656195, 'epsilon': 6.719120882462749e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.04499434491992007, 'tol': 0.006441411976179237, 'validation_fraction': 0.3180341871695086}
observation time 0.000073, current best 2941.115350 at iter 11
suggestion time taken 0.002262 iter 12 next_points [{'alpha': 9.796752761034655e-05, 'batch_size': 195, 'beta_1': 0.634013208120566, 'beta_2': 0.9800433576980409, 'epsilon': 1.1248444965208452e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.011669064769908958, 'tol': 5.3584073556907676e-05, 'validation_fraction': 0.15363431771451969}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.031585 value 3007.741001 suggestion {'alpha': 9.796752761034655e-05, 'batch_size': 195, 'beta_1': 0.634013208120566, 'beta_2': 0.9800433576980409, 'epsilon': 1.1248444965208452e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.011669064769908958, 'tol': 5.3584073556907676e-05, 'validation_fraction': 0.15363431771451969}
observation time 0.000076, current best 2941.115350 at iter 12
suggestion time taken 0.002466 iter 13 next_points [{'alpha': 0.6775680992913741, 'batch_size': 88, 'beta_1': 0.7651438858906633, 'beta_2': 0.938305959837002, 'epsilon': 1.5566438010932682e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.058528126701953946, 'tol': 0.0015118333194502132, 'validation_fraction': 0.3314617278691626}]
function_evaluation time 0.369525 value 2920.242010 suggestion {'alpha': 0.6775680992913741, 'batch_size': 88, 'beta_1': 0.7651438858906633, 'beta_2': 0.938305959837002, 'epsilon': 1.5566438010932682e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.058528126701953946, 'tol': 0.0015118333194502132, 'validation_fraction': 0.3314617278691626}
observation time 0.000084, current best 2920.242010 at iter 13
suggestion time taken 0.002300 iter 14 next_points [{'alpha': 1.629300527476921e-05, 'batch_size': 73, 'beta_1': 0.8205447978051046, 'beta_2': 0.9228186163535531, 'epsilon': 1.3762739277547882e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.00011693579059429434, 'tol': 0.013177251818462899, 'validation_fraction': 0.3563614859316558}]
function_evaluation time 0.087027 value 29107.546817 suggestion {'alpha': 1.629300527476921e-05, 'batch_size': 73, 'beta_1': 0.8205447978051046, 'beta_2': 0.9228186163535531, 'epsilon': 1.3762739277547882e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.00011693579059429434, 'tol': 0.013177251818462899, 'validation_fraction': 0.3563614859316558}
observation time 0.000077, current best 2920.242010 at iter 14
saving meta data: {'args': {'--uuid': '23ee893fb95f50c7aac8b250a59b333b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

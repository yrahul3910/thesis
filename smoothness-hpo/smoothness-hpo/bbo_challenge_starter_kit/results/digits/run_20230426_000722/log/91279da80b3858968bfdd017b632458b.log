running: {'--uuid': '91279da80b3858968bfdd017b632458b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d diabetes -o hyperopt -u 91279da80b3858968bfdd017b632458b -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_000722
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study hyperopt MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002374 iter 0 next_points [{'alpha': 0.0072833659346220134, 'batch_size': 172, 'beta_1': 0.5128970910510827, 'beta_2': 0.9647594024344007, 'epsilon': 4.651638323812443e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 2.1916718179843193e-05, 'tol': 3.5187374056850205e-05, 'validation_fraction': 0.5239048512457571}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.059660 value 151.693581 suggestion {'alpha': 0.0072833659346220134, 'batch_size': 172, 'beta_1': 0.5128970910510827, 'beta_2': 0.9647594024344007, 'epsilon': 4.651638323812443e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 2.1916718179843193e-05, 'tol': 3.5187374056850205e-05, 'validation_fraction': 0.5239048512457571}
observation time 0.000072, current best 151.693581 at iter 0
suggestion time taken 0.002605 iter 1 next_points [{'alpha': 8.468135754506976, 'batch_size': 29, 'beta_1': 0.7278509666125617, 'beta_2': 0.9437214659349731, 'epsilon': 6.659799251351202e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 2.3264469643524197e-05, 'tol': 6.255331589036983e-05, 'validation_fraction': 0.13070924854724855}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.660506 value 151.152749 suggestion {'alpha': 8.468135754506976, 'batch_size': 29, 'beta_1': 0.7278509666125617, 'beta_2': 0.9437214659349731, 'epsilon': 6.659799251351202e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 2.3264469643524197e-05, 'tol': 6.255331589036983e-05, 'validation_fraction': 0.13070924854724855}
observation time 0.000070, current best 151.152749 at iter 1
suggestion time taken 0.002172 iter 2 next_points [{'alpha': 0.015021064676805949, 'batch_size': 141, 'beta_1': 0.5960671896367989, 'beta_2': 0.9900900030193459, 'epsilon': 2.073951340828274e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 2.7611686862428022e-05, 'tol': 0.00027983105618202, 'validation_fraction': 0.22033213447971675}]
function_evaluation time 0.086945 value 151.503208 suggestion {'alpha': 0.015021064676805949, 'batch_size': 141, 'beta_1': 0.5960671896367989, 'beta_2': 0.9900900030193459, 'epsilon': 2.073951340828274e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 2.7611686862428022e-05, 'tol': 0.00027983105618202, 'validation_fraction': 0.22033213447971675}
observation time 0.000067, current best 151.152749 at iter 2
suggestion time taken 0.002159 iter 3 next_points [{'alpha': 0.0859597386654567, 'batch_size': 195, 'beta_1': 0.6713383186197163, 'beta_2': 0.9928554568093737, 'epsilon': 6.058863606828006e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.00021493957496970272, 'tol': 0.00023742141193137486, 'validation_fraction': 0.4586563417669404}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.050902 value 151.589985 suggestion {'alpha': 0.0859597386654567, 'batch_size': 195, 'beta_1': 0.6713383186197163, 'beta_2': 0.9928554568093737, 'epsilon': 6.058863606828006e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.00021493957496970272, 'tol': 0.00023742141193137486, 'validation_fraction': 0.4586563417669404}
observation time 0.000081, current best 151.152749 at iter 3
suggestion time taken 0.002295 iter 4 next_points [{'alpha': 1.608308625461436e-05, 'batch_size': 110, 'beta_1': 0.9641873785537003, 'beta_2': 0.9911493220504444, 'epsilon': 3.5715243781196e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 9.242676196304789e-05, 'tol': 1.1439988201613551e-05, 'validation_fraction': 0.7040431600638419}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.763083 value 151.354260 suggestion {'alpha': 1.608308625461436e-05, 'batch_size': 110, 'beta_1': 0.9641873785537003, 'beta_2': 0.9911493220504444, 'epsilon': 3.5715243781196e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 9.242676196304789e-05, 'tol': 1.1439988201613551e-05, 'validation_fraction': 0.7040431600638419}
observation time 0.000072, current best 151.152749 at iter 4
suggestion time taken 0.002135 iter 5 next_points [{'alpha': 0.0004172067826193377, 'batch_size': 94, 'beta_1': 0.5398591699508055, 'beta_2': 0.9466158289137541, 'epsilon': 6.29459047861938e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0021813762949629343, 'tol': 0.00030603972030585227, 'validation_fraction': 0.2786869591885408}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.756990 value 78.007736 suggestion {'alpha': 0.0004172067826193377, 'batch_size': 94, 'beta_1': 0.5398591699508055, 'beta_2': 0.9466158289137541, 'epsilon': 6.29459047861938e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0021813762949629343, 'tol': 0.00030603972030585227, 'validation_fraction': 0.2786869591885408}
observation time 0.000075, current best 78.007736 at iter 5
suggestion time taken 0.002145 iter 6 next_points [{'alpha': 0.008365259911222807, 'batch_size': 138, 'beta_1': 0.7084151847241276, 'beta_2': 0.9995457779865893, 'epsilon': 9.070423628545918e-07, 'hidden_layer_sizes': 137, 'learning_rate_init': 4.959660028317944e-05, 'tol': 0.02034147338164851, 'validation_fraction': 0.32993481487309056}]
function_evaluation time 0.079250 value 151.583837 suggestion {'alpha': 0.008365259911222807, 'batch_size': 138, 'beta_1': 0.7084151847241276, 'beta_2': 0.9995457779865893, 'epsilon': 9.070423628545918e-07, 'hidden_layer_sizes': 137, 'learning_rate_init': 4.959660028317944e-05, 'tol': 0.02034147338164851, 'validation_fraction': 0.32993481487309056}
observation time 0.000080, current best 78.007736 at iter 6
suggestion time taken 0.002172 iter 7 next_points [{'alpha': 0.018379385661495867, 'batch_size': 183, 'beta_1': 0.8367159761272388, 'beta_2': 0.991054212000646, 'epsilon': 2.5774521798061662e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.007119015882719115, 'tol': 0.008121795770425112, 'validation_fraction': 0.28474607132476176}]
function_evaluation time 0.591589 value 53.187641 suggestion {'alpha': 0.018379385661495867, 'batch_size': 183, 'beta_1': 0.8367159761272388, 'beta_2': 0.991054212000646, 'epsilon': 2.5774521798061662e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.007119015882719115, 'tol': 0.008121795770425112, 'validation_fraction': 0.28474607132476176}
observation time 0.000073, current best 53.187641 at iter 7
suggestion time taken 0.002133 iter 8 next_points [{'alpha': 0.013368341392744391, 'batch_size': 239, 'beta_1': 0.820436835756693, 'beta_2': 0.916898396078172, 'epsilon': 3.3905471993967032e-09, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.02162341907971067, 'tol': 0.0025957793212917787, 'validation_fraction': 0.16531588760434252}]
function_evaluation time 0.573203 value 47.712816 suggestion {'alpha': 0.013368341392744391, 'batch_size': 239, 'beta_1': 0.820436835756693, 'beta_2': 0.916898396078172, 'epsilon': 3.3905471993967032e-09, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.02162341907971067, 'tol': 0.0025957793212917787, 'validation_fraction': 0.16531588760434252}
observation time 0.000077, current best 47.712816 at iter 8
suggestion time taken 0.002123 iter 9 next_points [{'alpha': 0.1186439392597714, 'batch_size': 210, 'beta_1': 0.6484865109070138, 'beta_2': 0.9502379522073094, 'epsilon': 2.966908978722816e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0008476474181641296, 'tol': 0.00023285863386257862, 'validation_fraction': 0.7020197172982612}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.665787 value 149.238825 suggestion {'alpha': 0.1186439392597714, 'batch_size': 210, 'beta_1': 0.6484865109070138, 'beta_2': 0.9502379522073094, 'epsilon': 2.966908978722816e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0008476474181641296, 'tol': 0.00023285863386257862, 'validation_fraction': 0.7020197172982612}
observation time 0.000073, current best 47.712816 at iter 9
suggestion time taken 0.002340 iter 10 next_points [{'alpha': 0.2366729042888123, 'batch_size': 162, 'beta_1': 0.7351754548060251, 'beta_2': 0.9421254067455543, 'epsilon': 4.911348384526367e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.011523680095738658, 'tol': 0.002145777185605976, 'validation_fraction': 0.1275574672542816}]
function_evaluation time 0.906585 value 46.171650 suggestion {'alpha': 0.2366729042888123, 'batch_size': 162, 'beta_1': 0.7351754548060251, 'beta_2': 0.9421254067455543, 'epsilon': 4.911348384526367e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.011523680095738658, 'tol': 0.002145777185605976, 'validation_fraction': 0.1275574672542816}
observation time 0.000068, current best 46.171650 at iter 10
suggestion time taken 0.002164 iter 11 next_points [{'alpha': 8.29423043519176e-05, 'batch_size': 160, 'beta_1': 0.7133403101136647, 'beta_2': 0.9353648442651602, 'epsilon': 9.397980614902565e-08, 'hidden_layer_sizes': 195, 'learning_rate_init': 1.5038746583619014e-05, 'tol': 4.3632791743243455e-05, 'validation_fraction': 0.23995516050630272}]
function_evaluation time 0.092507 value 151.428223 suggestion {'alpha': 8.29423043519176e-05, 'batch_size': 160, 'beta_1': 0.7133403101136647, 'beta_2': 0.9353648442651602, 'epsilon': 9.397980614902565e-08, 'hidden_layer_sizes': 195, 'learning_rate_init': 1.5038746583619014e-05, 'tol': 4.3632791743243455e-05, 'validation_fraction': 0.23995516050630272}
observation time 0.000073, current best 46.171650 at iter 11
suggestion time taken 0.002369 iter 12 next_points [{'alpha': 0.0015542128422722191, 'batch_size': 233, 'beta_1': 0.9219335623629913, 'beta_2': 0.9775836815212119, 'epsilon': 3.004709493709774e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.0003754026987832429, 'tol': 0.0009912011259471127, 'validation_fraction': 0.11464828612505658}]
function_evaluation time 0.071295 value 151.630597 suggestion {'alpha': 0.0015542128422722191, 'batch_size': 233, 'beta_1': 0.9219335623629913, 'beta_2': 0.9775836815212119, 'epsilon': 3.004709493709774e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.0003754026987832429, 'tol': 0.0009912011259471127, 'validation_fraction': 0.11464828612505658}
observation time 0.000076, current best 46.171650 at iter 12
suggestion time taken 0.002236 iter 13 next_points [{'alpha': 0.0008932530869270884, 'batch_size': 23, 'beta_1': 0.6069735603884482, 'beta_2': 0.9239461350932795, 'epsilon': 2.3928119885473826e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.00015245511519163066, 'tol': 0.00911560182756451, 'validation_fraction': 0.4678119073405458}]
function_evaluation time 0.093191 value 151.572303 suggestion {'alpha': 0.0008932530869270884, 'batch_size': 23, 'beta_1': 0.6069735603884482, 'beta_2': 0.9239461350932795, 'epsilon': 2.3928119885473826e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.00015245511519163066, 'tol': 0.00911560182756451, 'validation_fraction': 0.4678119073405458}
observation time 0.000070, current best 46.171650 at iter 13
suggestion time taken 0.002144 iter 14 next_points [{'alpha': 0.004282943002286871, 'batch_size': 106, 'beta_1': 0.5809800575135525, 'beta_2': 0.9917264197909323, 'epsilon': 7.9264082679547e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0011314521295140963, 'tol': 1.3850292393139023e-05, 'validation_fraction': 0.14975253784167558}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.725587 value 126.937791 suggestion {'alpha': 0.004282943002286871, 'batch_size': 106, 'beta_1': 0.5809800575135525, 'beta_2': 0.9917264197909323, 'epsilon': 7.9264082679547e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0011314521295140963, 'tol': 1.3850292393139023e-05, 'validation_fraction': 0.14975253784167558}
observation time 0.000075, current best 46.171650 at iter 14
saving meta data: {'args': {'--uuid': '91279da80b3858968bfdd017b632458b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

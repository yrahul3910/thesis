running: {'--uuid': '91f299254aa75d3f8037c1b3d623b91c', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d diabetes -o turbo -u 91f299254aa75d3f8037c1b3d623b91c -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_000722
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study turbo MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002132 iter 0 next_points [{'alpha': 0.04532507455756455, 'batch_size': 215, 'beta_1': 0.8970619815409279, 'beta_2': 0.9728035894017278, 'epsilon': 2.3805756448084002e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.030335921633795743, 'tol': 0.0004987324925641185, 'validation_fraction': 0.2294679198027676}]
function_evaluation time 0.433010 value 53.964992 suggestion {'alpha': 0.04532507455756455, 'batch_size': 215, 'beta_1': 0.8970619815409279, 'beta_2': 0.9728035894017278, 'epsilon': 2.3805756448084002e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.030335921633795743, 'tol': 0.0004987324925641185, 'validation_fraction': 0.2294679198027676}
observation time 0.001369, current best 53.964992 at iter 0
suggestion time taken 0.001782 iter 1 next_points [{'alpha': 0.09841327588024953, 'batch_size': 233, 'beta_1': 0.9524745112301001, 'beta_2': 0.9987150020062896, 'epsilon': 1.685047609372388e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.01111287681086756, 'tol': 0.009267735163303144, 'validation_fraction': 0.5157917377694292}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.205968 value 113.283447 suggestion {'alpha': 0.09841327588024953, 'batch_size': 233, 'beta_1': 0.9524745112301001, 'beta_2': 0.9987150020062896, 'epsilon': 1.685047609372388e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.01111287681086756, 'tol': 0.009267735163303144, 'validation_fraction': 0.5157917377694292}
observation time 0.001403, current best 53.964992 at iter 1
suggestion time taken 0.001790 iter 2 next_points [{'alpha': 0.016398300169000853, 'batch_size': 22, 'beta_1': 0.9452493346254299, 'beta_2': 0.999957646964344, 'epsilon': 2.2838614428572548e-07, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.07760953281211196, 'tol': 0.004614197913653221, 'validation_fraction': 0.6147523689948885}]
function_evaluation time 0.283694 value 44.427301 suggestion {'alpha': 0.016398300169000853, 'batch_size': 22, 'beta_1': 0.9452493346254299, 'beta_2': 0.999957646964344, 'epsilon': 2.2838614428572548e-07, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.07760953281211196, 'tol': 0.004614197913653221, 'validation_fraction': 0.6147523689948885}
observation time 0.001441, current best 44.427301 at iter 2
suggestion time taken 0.001724 iter 3 next_points [{'alpha': 0.00015487986801585173, 'batch_size': 84, 'beta_1': 0.6228905632237568, 'beta_2': 0.999971968105673, 'epsilon': 4.335332807902277e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 3.883468566156705e-05, 'tol': 0.001283299322508575, 'validation_fraction': 0.8920527757047859}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.051671 value 151.595267 suggestion {'alpha': 0.00015487986801585173, 'batch_size': 84, 'beta_1': 0.6228905632237568, 'beta_2': 0.999971968105673, 'epsilon': 4.335332807902277e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 3.883468566156705e-05, 'tol': 0.001283299322508575, 'validation_fraction': 0.8920527757047859}
observation time 0.001425, current best 44.427301 at iter 3
suggestion time taken 0.001766 iter 4 next_points [{'alpha': 0.010104357302882559, 'batch_size': 112, 'beta_1': 0.9622962575967882, 'beta_2': 0.9999974359443605, 'epsilon': 9.955410037265974e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.0069824459183615885, 'tol': 0.00019537569890892405, 'validation_fraction': 0.7942199390850689}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.784621 value 53.741152 suggestion {'alpha': 0.010104357302882559, 'batch_size': 112, 'beta_1': 0.9622962575967882, 'beta_2': 0.9999974359443605, 'epsilon': 9.955410037265974e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.0069824459183615885, 'tol': 0.00019537569890892405, 'validation_fraction': 0.7942199390850689}
observation time 0.001393, current best 44.427301 at iter 4
suggestion time taken 0.001758 iter 5 next_points [{'alpha': 0.0010045964860231171, 'batch_size': 175, 'beta_1': 0.601873482855252, 'beta_2': 0.9891167749334716, 'epsilon': 2.0248954242654575e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 1.5961519268148356e-05, 'tol': 0.0008597625186749213, 'validation_fraction': 0.42908005404014343}]
function_evaluation time 0.040005 value 151.611007 suggestion {'alpha': 0.0010045964860231171, 'batch_size': 175, 'beta_1': 0.601873482855252, 'beta_2': 0.9891167749334716, 'epsilon': 2.0248954242654575e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 1.5961519268148356e-05, 'tol': 0.0008597625186749213, 'validation_fraction': 0.42908005404014343}
observation time 0.001642, current best 44.427301 at iter 5
suggestion time taken 0.001785 iter 6 next_points [{'alpha': 0.0007182179114188054, 'batch_size': 155, 'beta_1': 0.9003611253388636, 'beta_2': 0.9938983530353402, 'epsilon': 3.76221911361192e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0024375402642100603, 'tol': 0.00803123422497896, 'validation_fraction': 0.27526696527960787}]
function_evaluation time 0.068341 value 150.822553 suggestion {'alpha': 0.0007182179114188054, 'batch_size': 155, 'beta_1': 0.9003611253388636, 'beta_2': 0.9938983530353402, 'epsilon': 3.76221911361192e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0024375402642100603, 'tol': 0.00803123422497896, 'validation_fraction': 0.27526696527960787}
observation time 0.001378, current best 44.427301 at iter 6
suggestion time taken 0.001779 iter 7 next_points [{'alpha': 0.17563062782530198, 'batch_size': 67, 'beta_1': 0.521788764000415, 'beta_2': 0.9444152315477625, 'epsilon': 2.257141434209317e-08, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.00022497358493603952, 'tol': 0.00043110910069264996, 'validation_fraction': 0.762754482204842}]
function_evaluation time 0.083998 value 151.500885 suggestion {'alpha': 0.17563062782530198, 'batch_size': 67, 'beta_1': 0.521788764000415, 'beta_2': 0.9444152315477625, 'epsilon': 2.257141434209317e-08, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.00022497358493603952, 'tol': 0.00043110910069264996, 'validation_fraction': 0.762754482204842}
observation time 0.001389, current best 44.427301 at iter 7
suggestion time taken 0.001785 iter 8 next_points [{'alpha': 0.0020136948799698378, 'batch_size': 240, 'beta_1': 0.9756700684815071, 'beta_2': 0.9953282518997577, 'epsilon': 5.128520240084193e-07, 'hidden_layer_sizes': 184, 'learning_rate_init': 4.506856780013081e-05, 'tol': 0.0030792682227753633, 'validation_fraction': 0.16112018067720704}]
function_evaluation time 0.080878 value 151.536094 suggestion {'alpha': 0.0020136948799698378, 'batch_size': 240, 'beta_1': 0.9756700684815071, 'beta_2': 0.9953282518997577, 'epsilon': 5.128520240084193e-07, 'hidden_layer_sizes': 184, 'learning_rate_init': 4.506856780013081e-05, 'tol': 0.0030792682227753633, 'validation_fraction': 0.16112018067720704}
observation time 0.001410, current best 44.427301 at iter 8
suggestion time taken 0.001678 iter 9 next_points [{'alpha': 7.831644576120637, 'batch_size': 106, 'beta_1': 0.9843470542641505, 'beta_2': 0.9999982991608151, 'epsilon': 6.073299363484201e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.00012481059637656447, 'tol': 0.04778217335712015, 'validation_fraction': 0.3680874182280976}]
function_evaluation time 0.088860 value 151.509139 suggestion {'alpha': 7.831644576120637, 'batch_size': 106, 'beta_1': 0.9843470542641505, 'beta_2': 0.9999982991608151, 'epsilon': 6.073299363484201e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.00012481059637656447, 'tol': 0.04778217335712015, 'validation_fraction': 0.3680874182280976}
observation time 0.001386, current best 44.427301 at iter 9
suggestion time taken 0.001714 iter 10 next_points [{'alpha': 1.431203959453492, 'batch_size': 130, 'beta_1': 0.7975300279176654, 'beta_2': 0.9998269248790949, 'epsilon': 1.0778034814229561e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0007952074665155126, 'tol': 0.06958908678224253, 'validation_fraction': 0.6664693261037958}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.050432 value 151.521628 suggestion {'alpha': 1.431203959453492, 'batch_size': 130, 'beta_1': 0.7975300279176654, 'beta_2': 0.9998269248790949, 'epsilon': 1.0778034814229561e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0007952074665155126, 'tol': 0.06958908678224253, 'validation_fraction': 0.6664693261037958}
observation time 0.001428, current best 44.427301 at iter 10
suggestion time taken 0.001749 iter 11 next_points [{'alpha': 0.004633100453807492, 'batch_size': 90, 'beta_1': 0.8691878207468674, 'beta_2': 0.9996585584965472, 'epsilon': 7.598776227410991e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.001490063515197307, 'tol': 4.840258537239951e-05, 'validation_fraction': 0.1436678062119205}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.342028 value 73.395339 suggestion {'alpha': 0.004633100453807492, 'batch_size': 90, 'beta_1': 0.8691878207468674, 'beta_2': 0.9996585584965472, 'epsilon': 7.598776227410991e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.001490063515197307, 'tol': 4.840258537239951e-05, 'validation_fraction': 0.1436678062119205}
observation time 0.001417, current best 44.427301 at iter 11
suggestion time taken 0.001775 iter 12 next_points [{'alpha': 0.0003341141856258841, 'batch_size': 58, 'beta_1': 0.9738897204773815, 'beta_2': 0.9999824257592806, 'epsilon': 2.3857887546987154e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.004532875714197125, 'tol': 0.03152873258407147, 'validation_fraction': 0.19291265508098224}]
function_evaluation time 0.641266 value 53.867610 suggestion {'alpha': 0.0003341141856258841, 'batch_size': 58, 'beta_1': 0.9738897204773815, 'beta_2': 0.9999824257592806, 'epsilon': 2.3857887546987154e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.004532875714197125, 'tol': 0.03152873258407147, 'validation_fraction': 0.19291265508098224}
observation time 0.001396, current best 44.427301 at iter 12
suggestion time taken 0.001980 iter 13 next_points [{'alpha': 3.320342101178452, 'batch_size': 31, 'beta_1': 0.7536498777915974, 'beta_2': 0.9999940675868396, 'epsilon': 3.943929470080882e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.0006167948541146223, 'tol': 0.021361002429867167, 'validation_fraction': 0.5304575634125485}]
function_evaluation time 0.117850 value 151.001899 suggestion {'alpha': 3.320342101178452, 'batch_size': 31, 'beta_1': 0.7536498777915974, 'beta_2': 0.9999940675868396, 'epsilon': 3.943929470080882e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.0006167948541146223, 'tol': 0.021361002429867167, 'validation_fraction': 0.5304575634125485}
observation time 0.001403, current best 44.427301 at iter 13
suggestion time taken 0.001797 iter 14 next_points [{'alpha': 7.582179916539708e-05, 'batch_size': 145, 'beta_1': 0.9879911598467266, 'beta_2': 0.9992391565710257, 'epsilon': 6.661890278303902e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.049440599320360615, 'tol': 2.2150455795160827e-05, 'validation_fraction': 0.8654925177774537}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.193264 value 60.600463 suggestion {'alpha': 7.582179916539708e-05, 'batch_size': 145, 'beta_1': 0.9879911598467266, 'beta_2': 0.9992391565710257, 'epsilon': 6.661890278303902e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.049440599320360615, 'tol': 2.2150455795160827e-05, 'validation_fraction': 0.8654925177774537}
observation time 0.001405, current best 44.427301 at iter 14
saving meta data: {'args': {'--uuid': '91f299254aa75d3f8037c1b3d623b91c', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

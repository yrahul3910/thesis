running: {'--uuid': '87a2e510fde75473b83e1d2f7c801089', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d diabetes -o turbo -u 87a2e510fde75473b83e1d2f7c801089 -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_000722
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study turbo MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002127 iter 0 next_points [{'alpha': 0.03454375209295631, 'batch_size': 148, 'beta_1': 0.7652656047281347, 'beta_2': 0.9997221352677533, 'epsilon': 4.5920029117580416e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0031559590972309558, 'tol': 0.0003849170125007559, 'validation_fraction': 0.5956560449103306}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.760175 value 103.143299 suggestion {'alpha': 0.03454375209295631, 'batch_size': 148, 'beta_1': 0.7652656047281347, 'beta_2': 0.9997221352677533, 'epsilon': 4.5920029117580416e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0031559590972309558, 'tol': 0.0003849170125007559, 'validation_fraction': 0.5956560449103306}
observation time 0.001405, current best 103.143299 at iter 0
suggestion time taken 0.001762 iter 1 next_points [{'alpha': 5.503634410894201, 'batch_size': 152, 'beta_1': 0.9526255909850906, 'beta_2': 0.9999845026657189, 'epsilon': 6.2422100984917864e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.00011161300874620109, 'tol': 0.000508957583038298, 'validation_fraction': 0.10587266045141447}]
function_evaluation time 0.095341 value 151.543097 suggestion {'alpha': 5.503634410894201, 'batch_size': 152, 'beta_1': 0.9526255909850906, 'beta_2': 0.9999845026657189, 'epsilon': 6.2422100984917864e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.00011161300874620109, 'tol': 0.000508957583038298, 'validation_fraction': 0.10587266045141447}
observation time 0.001637, current best 103.143299 at iter 1
suggestion time taken 0.001817 iter 2 next_points [{'alpha': 3.071988360532224, 'batch_size': 99, 'beta_1': 0.5839700702423816, 'beta_2': 0.999960192103992, 'epsilon': 6.581817498091968e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 6.868412435472963e-05, 'tol': 2.4392713930352363e-05, 'validation_fraction': 0.1896779521101932}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.357095 value 150.880282 suggestion {'alpha': 3.071988360532224, 'batch_size': 99, 'beta_1': 0.5839700702423816, 'beta_2': 0.999960192103992, 'epsilon': 6.581817498091968e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 6.868412435472963e-05, 'tol': 2.4392713930352363e-05, 'validation_fraction': 0.1896779521101932}
observation time 0.001430, current best 103.143299 at iter 2
suggestion time taken 0.001747 iter 3 next_points [{'alpha': 0.0030367714720264736, 'batch_size': 68, 'beta_1': 0.8289903949368177, 'beta_2': 0.9437644430316915, 'epsilon': 1.1074353917803694e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0018124420541678382, 'tol': 0.09430185601118628, 'validation_fraction': 0.2446674766991731}]
function_evaluation time 0.107738 value 149.939412 suggestion {'alpha': 0.0030367714720264736, 'batch_size': 68, 'beta_1': 0.8289903949368177, 'beta_2': 0.9437644430316915, 'epsilon': 1.1074353917803694e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0018124420541678382, 'tol': 0.09430185601118628, 'validation_fraction': 0.2446674766991731}
observation time 0.001439, current best 103.143299 at iter 3
suggestion time taken 0.001709 iter 4 next_points [{'alpha': 0.45136123486439045, 'batch_size': 193, 'beta_1': 0.6986274288861161, 'beta_2': 0.9999975185949913, 'epsilon': 5.618240145692463e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.00021712065496706833, 'tol': 0.0062601720846032, 'validation_fraction': 0.497164175272811}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.056631 value 151.448770 suggestion {'alpha': 0.45136123486439045, 'batch_size': 193, 'beta_1': 0.6986274288861161, 'beta_2': 0.9999975185949913, 'epsilon': 5.618240145692463e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.00021712065496706833, 'tol': 0.0062601720846032, 'validation_fraction': 0.497164175272811}
observation time 0.001436, current best 103.143299 at iter 4
suggestion time taken 0.001700 iter 5 next_points [{'alpha': 5.791759800953218e-05, 'batch_size': 123, 'beta_1': 0.9757769872179863, 'beta_2': 0.9989776587205798, 'epsilon': 5.104953958349455e-09, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.013388449687253827, 'tol': 0.0009886474802692296, 'validation_fraction': 0.6476490211676283}]
function_evaluation time 0.489527 value 53.789672 suggestion {'alpha': 5.791759800953218e-05, 'batch_size': 123, 'beta_1': 0.9757769872179863, 'beta_2': 0.9989776587205798, 'epsilon': 5.104953958349455e-09, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.013388449687253827, 'tol': 0.0009886474802692296, 'validation_fraction': 0.6476490211676283}
observation time 0.001357, current best 53.789672 at iter 5
suggestion time taken 0.001933 iter 6 next_points [{'alpha': 0.23493593955886766, 'batch_size': 248, 'beta_1': 0.9805521513687034, 'beta_2': 0.9705338693442697, 'epsilon': 1.5397116811039677e-07, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0637643492496408, 'tol': 0.0016986287299251882, 'validation_fraction': 0.12529191969164108}]
function_evaluation time 0.222117 value 56.614676 suggestion {'alpha': 0.23493593955886766, 'batch_size': 248, 'beta_1': 0.9805521513687034, 'beta_2': 0.9705338693442697, 'epsilon': 1.5397116811039677e-07, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0637643492496408, 'tol': 0.0016986287299251882, 'validation_fraction': 0.12529191969164108}
observation time 0.001461, current best 53.789672 at iter 6
suggestion time taken 0.001732 iter 7 next_points [{'alpha': 0.006950434751492271, 'batch_size': 18, 'beta_1': 0.9228113394661575, 'beta_2': 0.9997885991704369, 'epsilon': 1.6682586234924904e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0009038852674129812, 'tol': 0.035626675542693526, 'validation_fraction': 0.8749252944857525}]
function_evaluation time 0.062502 value 151.362058 suggestion {'alpha': 0.006950434751492271, 'batch_size': 18, 'beta_1': 0.9228113394661575, 'beta_2': 0.9997885991704369, 'epsilon': 1.6682586234924904e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0009038852674129812, 'tol': 0.035626675542693526, 'validation_fraction': 0.8749252944857525}
observation time 0.001389, current best 53.789672 at iter 7
suggestion time taken 0.001732 iter 8 next_points [{'alpha': 0.02735124038891462, 'batch_size': 164, 'beta_1': 0.9869049188578639, 'beta_2': 0.9880842909663056, 'epsilon': 1.9212883977911307e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0036724496020815968, 'tol': 4.779150736965117e-05, 'validation_fraction': 0.3304935339873649}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.975099 value 83.000202 suggestion {'alpha': 0.02735124038891462, 'batch_size': 164, 'beta_1': 0.9869049188578639, 'beta_2': 0.9880842909663056, 'epsilon': 1.9212883977911307e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0036724496020815968, 'tol': 4.779150736965117e-05, 'validation_fraction': 0.3304935339873649}
observation time 0.001379, current best 53.789672 at iter 8
suggestion time taken 0.001765 iter 9 next_points [{'alpha': 0.009502077464448809, 'batch_size': 182, 'beta_1': 0.9878213634440672, 'beta_2': 0.9999986640189003, 'epsilon': 8.284953390474918e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.005605339997057832, 'tol': 0.015536815699328998, 'validation_fraction': 0.8401858103492098}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.044608 value 150.882214 suggestion {'alpha': 0.009502077464448809, 'batch_size': 182, 'beta_1': 0.9878213634440672, 'beta_2': 0.9999986640189003, 'epsilon': 8.284953390474918e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.005605339997057832, 'tol': 0.015536815699328998, 'validation_fraction': 0.8401858103492098}
observation time 0.001379, current best 53.789672 at iter 9
suggestion time taken 0.001705 iter 10 next_points [{'alpha': 3.863796214211838e-05, 'batch_size': 48, 'beta_1': 0.889302233199652, 'beta_2': 0.9999918701630358, 'epsilon': 9.8710285517249e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 1.1368825498717982e-05, 'tol': 0.055895352849778784, 'validation_fraction': 0.4590001928926857}]
function_evaluation time 0.090181 value 151.622954 suggestion {'alpha': 3.863796214211838e-05, 'batch_size': 48, 'beta_1': 0.889302233199652, 'beta_2': 0.9999918701630358, 'epsilon': 9.8710285517249e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 1.1368825498717982e-05, 'tol': 0.055895352849778784, 'validation_fraction': 0.4590001928926857}
observation time 0.001406, current best 53.789672 at iter 10
suggestion time taken 0.001713 iter 11 next_points [{'alpha': 1.0689994052433804e-05, 'batch_size': 55, 'beta_1': 0.9143876490711972, 'beta_2': 0.9957131931482103, 'epsilon': 3.229958479427367e-07, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.018000098524039995, 'tol': 0.005073036614284199, 'validation_fraction': 0.5509549066229464}]
function_evaluation time 0.328889 value 48.323035 suggestion {'alpha': 1.0689994052433804e-05, 'batch_size': 55, 'beta_1': 0.9143876490711972, 'beta_2': 0.9957131931482103, 'epsilon': 3.229958479427367e-07, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.018000098524039995, 'tol': 0.005073036614284199, 'validation_fraction': 0.5509549066229464}
observation time 0.001378, current best 48.323035 at iter 11
suggestion time taken 0.001720 iter 12 next_points [{'alpha': 0.0002121616578852248, 'batch_size': 134, 'beta_1': 0.9351398009207462, 'beta_2': 0.9999246926995228, 'epsilon': 1.846685352089956e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 2.4089778663209194e-05, 'tol': 7.501864374419382e-05, 'validation_fraction': 0.7424807216925459}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.055872 value 151.612341 suggestion {'alpha': 0.0002121616578852248, 'batch_size': 134, 'beta_1': 0.9351398009207462, 'beta_2': 0.9999246926995228, 'epsilon': 1.846685352089956e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 2.4089778663209194e-05, 'tol': 7.501864374419382e-05, 'validation_fraction': 0.7424807216925459}
observation time 0.001343, current best 48.323035 at iter 12
suggestion time taken 0.001764 iter 13 next_points [{'alpha': 0.11820939917978832, 'batch_size': 25, 'beta_1': 0.8679767852967764, 'beta_2': 0.9999765587208438, 'epsilon': 4.1983570572898975e-08, 'hidden_layer_sizes': 154, 'learning_rate_init': 2.984943389946454e-05, 'tol': 0.011343406807714555, 'validation_fraction': 0.8795269583803027}]
function_evaluation time 0.065820 value 151.552581 suggestion {'alpha': 0.11820939917978832, 'batch_size': 25, 'beta_1': 0.8679767852967764, 'beta_2': 0.9999765587208438, 'epsilon': 4.1983570572898975e-08, 'hidden_layer_sizes': 154, 'learning_rate_init': 2.984943389946454e-05, 'tol': 0.011343406807714555, 'validation_fraction': 0.8795269583803027}
observation time 0.001365, current best 48.323035 at iter 13
suggestion time taken 0.001817 iter 14 next_points [{'alpha': 1.6881763297768746, 'batch_size': 208, 'beta_1': 0.5266179107345643, 'beta_2': 0.9992625792258663, 'epsilon': 9.077774004735163e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.00013455531946545636, 'tol': 0.0002534291385629313, 'validation_fraction': 0.27709331039938084}]
function_evaluation time 0.061249 value 151.698754 suggestion {'alpha': 1.6881763297768746, 'batch_size': 208, 'beta_1': 0.5266179107345643, 'beta_2': 0.9992625792258663, 'epsilon': 9.077774004735163e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.00013455531946545636, 'tol': 0.0002534291385629313, 'validation_fraction': 0.27709331039938084}
observation time 0.001353, current best 48.323035 at iter 14
saving meta data: {'args': {'--uuid': '87a2e510fde75473b83e1d2f7c801089', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

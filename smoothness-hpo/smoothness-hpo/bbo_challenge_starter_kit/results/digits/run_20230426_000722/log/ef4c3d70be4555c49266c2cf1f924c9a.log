running: {'--uuid': 'ef4c3d70be4555c49266c2cf1f924c9a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d diabetes -o random-search -u ef4c3d70be4555c49266c2cf1f924c9a -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_000722
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study random-search MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002513 iter 0 next_points [{'alpha': 0.6488318569663707, 'batch_size': 102, 'beta_1': 0.9284568734061625, 'beta_2': 0.9999322977387478, 'epsilon': 1.4098873481509519e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 1.4039184741729585e-05, 'tol': 2.8127954193535194e-05, 'validation_fraction': 0.13648814779135107}]
function_evaluation time 0.051313 value 29089.193484 suggestion {'alpha': 0.6488318569663707, 'batch_size': 102, 'beta_1': 0.9284568734061625, 'beta_2': 0.9999322977387478, 'epsilon': 1.4098873481509519e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 1.4039184741729585e-05, 'tol': 2.8127954193535194e-05, 'validation_fraction': 0.13648814779135107}
observation time 0.000006, current best 29089.193484 at iter 0
suggestion time taken 0.002831 iter 1 next_points [{'alpha': 0.3128689037420494, 'batch_size': 12, 'beta_1': 0.8346322341009059, 'beta_2': 0.9999939408510843, 'epsilon': 2.463947502020527e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.03151677114106879, 'tol': 0.002320793160371146, 'validation_fraction': 0.19054230115488185}]
function_evaluation time 0.583089 value 2877.713157 suggestion {'alpha': 0.3128689037420494, 'batch_size': 12, 'beta_1': 0.8346322341009059, 'beta_2': 0.9999939408510843, 'epsilon': 2.463947502020527e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.03151677114106879, 'tol': 0.002320793160371146, 'validation_fraction': 0.19054230115488185}
observation time 0.000004, current best 2877.713157 at iter 1
suggestion time taken 0.002764 iter 2 next_points [{'alpha': 3.09036472554527e-05, 'batch_size': 193, 'beta_1': 0.977952752049091, 'beta_2': 0.9906523898844325, 'epsilon': 6.493762204147336e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 2.0697469596512922e-05, 'tol': 0.010265646051121815, 'validation_fraction': 0.66547038453708}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.050755 value 29093.234334 suggestion {'alpha': 3.09036472554527e-05, 'batch_size': 193, 'beta_1': 0.977952752049091, 'beta_2': 0.9906523898844325, 'epsilon': 6.493762204147336e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 2.0697469596512922e-05, 'tol': 0.010265646051121815, 'validation_fraction': 0.66547038453708}
observation time 0.000004, current best 2877.713157 at iter 2
suggestion time taken 0.002504 iter 3 next_points [{'alpha': 0.5968666730784287, 'batch_size': 119, 'beta_1': 0.890687948401721, 'beta_2': 0.9580796174241015, 'epsilon': 1.3279390192785524e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 2.5890753006325162e-05, 'tol': 6.948871722254894e-05, 'validation_fraction': 0.8995910632165345}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.054240 value 29107.917233 suggestion {'alpha': 0.5968666730784287, 'batch_size': 119, 'beta_1': 0.890687948401721, 'beta_2': 0.9580796174241015, 'epsilon': 1.3279390192785524e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 2.5890753006325162e-05, 'tol': 6.948871722254894e-05, 'validation_fraction': 0.8995910632165345}
observation time 0.000005, current best 2877.713157 at iter 3
suggestion time taken 0.002509 iter 4 next_points [{'alpha': 4.69485448414074e-05, 'batch_size': 147, 'beta_1': 0.9809559810185912, 'beta_2': 0.9999383573766515, 'epsilon': 9.957513374984527e-07, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.043202055402798784, 'tol': 0.013747016570405557, 'validation_fraction': 0.31539506191292765}]
function_evaluation time 0.187997 value 4313.736448 suggestion {'alpha': 4.69485448414074e-05, 'batch_size': 147, 'beta_1': 0.9809559810185912, 'beta_2': 0.9999383573766515, 'epsilon': 9.957513374984527e-07, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.043202055402798784, 'tol': 0.013747016570405557, 'validation_fraction': 0.31539506191292765}
observation time 0.000005, current best 2877.713157 at iter 4
suggestion time taken 0.002477 iter 5 next_points [{'alpha': 2.1694354697085016e-05, 'batch_size': 30, 'beta_1': 0.7075040997404454, 'beta_2': 0.9999906589015753, 'epsilon': 1.1294969675899682e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0016995097117093, 'tol': 0.006384302817315124, 'validation_fraction': 0.36337990347470805}]
function_evaluation time 0.972687 value 4486.310936 suggestion {'alpha': 2.1694354697085016e-05, 'batch_size': 30, 'beta_1': 0.7075040997404454, 'beta_2': 0.9999906589015753, 'epsilon': 1.1294969675899682e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0016995097117093, 'tol': 0.006384302817315124, 'validation_fraction': 0.36337990347470805}
observation time 0.000005, current best 2877.713157 at iter 5
suggestion time taken 0.002555 iter 6 next_points [{'alpha': 0.0007369843359302825, 'batch_size': 239, 'beta_1': 0.9482752375359335, 'beta_2': 0.9999500993566375, 'epsilon': 3.791713063188039e-07, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0027297764213663764, 'tol': 0.025193551272346393, 'validation_fraction': 0.7870638299106434}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.053756 value 28938.499944 suggestion {'alpha': 0.0007369843359302825, 'batch_size': 239, 'beta_1': 0.9482752375359335, 'beta_2': 0.9999500993566375, 'epsilon': 3.791713063188039e-07, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0027297764213663764, 'tol': 0.025193551272346393, 'validation_fraction': 0.7870638299106434}
observation time 0.000004, current best 2877.713157 at iter 6
suggestion time taken 0.002511 iter 7 next_points [{'alpha': 0.00047772470600346566, 'batch_size': 43, 'beta_1': 0.7302801942753703, 'beta_2': 0.9999765254052643, 'epsilon': 1.717749191091018e-08, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.02757524924621276, 'tol': 1.2506141886199979e-05, 'validation_fraction': 0.6708190990547068}]
function_evaluation time 0.544255 value 3040.155230 suggestion {'alpha': 0.00047772470600346566, 'batch_size': 43, 'beta_1': 0.7302801942753703, 'beta_2': 0.9999765254052643, 'epsilon': 1.717749191091018e-08, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.02757524924621276, 'tol': 1.2506141886199979e-05, 'validation_fraction': 0.6708190990547068}
observation time 0.000005, current best 2877.713157 at iter 7
suggestion time taken 0.002498 iter 8 next_points [{'alpha': 0.0005068260077344708, 'batch_size': 190, 'beta_1': 0.6662296956395274, 'beta_2': 0.9999069984390014, 'epsilon': 9.958905693166496e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 5.893034619058242e-05, 'tol': 0.009741944737043196, 'validation_fraction': 0.14982653222614054}]
function_evaluation time 0.059860 value 29109.374427 suggestion {'alpha': 0.0005068260077344708, 'batch_size': 190, 'beta_1': 0.6662296956395274, 'beta_2': 0.9999069984390014, 'epsilon': 9.958905693166496e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 5.893034619058242e-05, 'tol': 0.009741944737043196, 'validation_fraction': 0.14982653222614054}
observation time 0.000004, current best 2877.713157 at iter 8
suggestion time taken 0.002511 iter 9 next_points [{'alpha': 9.590870092483665e-05, 'batch_size': 99, 'beta_1': 0.9350499690815995, 'beta_2': 0.9940453018162474, 'epsilon': 1.1044387771481663e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.004281595457371631, 'tol': 0.0004245540645211234, 'validation_fraction': 0.14739204250957452}]
function_evaluation time 1.241564 value 3571.703596 suggestion {'alpha': 9.590870092483665e-05, 'batch_size': 99, 'beta_1': 0.9350499690815995, 'beta_2': 0.9940453018162474, 'epsilon': 1.1044387771481663e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.004281595457371631, 'tol': 0.0004245540645211234, 'validation_fraction': 0.14739204250957452}
observation time 0.000004, current best 2877.713157 at iter 9
suggestion time taken 0.002525 iter 10 next_points [{'alpha': 0.623210779265514, 'batch_size': 138, 'beta_1': 0.9268094370242194, 'beta_2': 0.9999622888138106, 'epsilon': 2.544580950527258e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.00011113011398964941, 'tol': 8.851382636908889e-05, 'validation_fraction': 0.8812198156796269}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.042157 value 29172.100491 suggestion {'alpha': 0.623210779265514, 'batch_size': 138, 'beta_1': 0.9268094370242194, 'beta_2': 0.9999622888138106, 'epsilon': 2.544580950527258e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.00011113011398964941, 'tol': 8.851382636908889e-05, 'validation_fraction': 0.8812198156796269}
observation time 0.000004, current best 2877.713157 at iter 10
suggestion time taken 0.002486 iter 11 next_points [{'alpha': 0.5548265080395611, 'batch_size': 166, 'beta_1': 0.7256691334142694, 'beta_2': 0.9993257218510012, 'epsilon': 3.4070131600482116e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0014717304361189078, 'tol': 0.00016252242044396457, 'validation_fraction': 0.7674076090982082}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.735178 value 25161.151472 suggestion {'alpha': 0.5548265080395611, 'batch_size': 166, 'beta_1': 0.7256691334142694, 'beta_2': 0.9993257218510012, 'epsilon': 3.4070131600482116e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0014717304361189078, 'tol': 0.00016252242044396457, 'validation_fraction': 0.7674076090982082}
observation time 0.000005, current best 2877.713157 at iter 11
suggestion time taken 0.002470 iter 12 next_points [{'alpha': 0.00011381713865078851, 'batch_size': 101, 'beta_1': 0.8644485609075772, 'beta_2': 0.9998890019252927, 'epsilon': 3.4031336126752617e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0025195074525689305, 'tol': 0.004134862734094685, 'validation_fraction': 0.8119482605796033}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.048415 value 28974.565442 suggestion {'alpha': 0.00011381713865078851, 'batch_size': 101, 'beta_1': 0.8644485609075772, 'beta_2': 0.9998890019252927, 'epsilon': 3.4031336126752617e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0025195074525689305, 'tol': 0.004134862734094685, 'validation_fraction': 0.8119482605796033}
observation time 0.000005, current best 2877.713157 at iter 12
suggestion time taken 0.002784 iter 13 next_points [{'alpha': 5.061348827237461, 'batch_size': 155, 'beta_1': 0.9799436090274141, 'beta_2': 0.990258013240676, 'epsilon': 1.0809698038026868e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.07961185195018201, 'tol': 0.0007402616062918048, 'validation_fraction': 0.3381650479610798}]
function_evaluation time 0.220404 value 3396.666587 suggestion {'alpha': 5.061348827237461, 'batch_size': 155, 'beta_1': 0.9799436090274141, 'beta_2': 0.990258013240676, 'epsilon': 1.0809698038026868e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.07961185195018201, 'tol': 0.0007402616062918048, 'validation_fraction': 0.3381650479610798}
observation time 0.000004, current best 2877.713157 at iter 13
suggestion time taken 0.002513 iter 14 next_points [{'alpha': 0.029157347749956795, 'batch_size': 62, 'beta_1': 0.9515845598371628, 'beta_2': 0.9987491993576326, 'epsilon': 7.190129016119626e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.024011655426628198, 'tol': 0.004140287901352443, 'validation_fraction': 0.22342342317660335}]
function_evaluation time 0.354650 value 2975.266052 suggestion {'alpha': 0.029157347749956795, 'batch_size': 62, 'beta_1': 0.9515845598371628, 'beta_2': 0.9987491993576326, 'epsilon': 7.190129016119626e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.024011655426628198, 'tol': 0.004140287901352443, 'validation_fraction': 0.22342342317660335}
observation time 0.000004, current best 2877.713157 at iter 14
saving meta data: {'args': {'--uuid': 'ef4c3d70be4555c49266c2cf1f924c9a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

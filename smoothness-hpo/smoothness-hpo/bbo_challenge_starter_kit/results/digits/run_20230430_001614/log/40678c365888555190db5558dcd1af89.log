running: {'--uuid': '40678c365888555190db5558dcd1af89', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u 40678c365888555190db5558dcd1af89 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study smoothness MLP-adam digits acc 15 1
with data root: None
suggestion time taken 9.423700 iter 0 next_points [{'alpha': 0.002455425818192576, 'batch_size': 36, 'beta_1': 0.9893918180164255, 'beta_2': 0.9898156922020972, 'epsilon': 5.906635902332626e-09, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.00012950976957050244, 'tol': 0.000867530280925274, 'validation_fraction': 0.6219164972126564}]
function_evaluation time 3.913617 value -0.936675 suggestion {'alpha': 0.002455425818192576, 'batch_size': 36, 'beta_1': 0.9893918180164255, 'beta_2': 0.9898156922020972, 'epsilon': 5.906635902332626e-09, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.00012950976957050244, 'tol': 0.000867530280925274, 'validation_fraction': 0.6219164972126564}
observation time 0.000006, current best -0.936675 at iter 0
suggestion time taken 9.234311 iter 1 next_points [{'alpha': 0.11639603145910142, 'batch_size': 20, 'beta_1': 0.9300016644577747, 'beta_2': 0.9590929167003766, 'epsilon': 5.100123733763e-08, 'hidden_layer_sizes': 75, 'learning_rate_init': 1.531083615329266e-05, 'tol': 2.9357952239365325e-05, 'validation_fraction': 0.8858865241256034}]
function_evaluation time 1.453970 value -0.181550 suggestion {'alpha': 0.11639603145910142, 'batch_size': 20, 'beta_1': 0.9300016644577747, 'beta_2': 0.9590929167003766, 'epsilon': 5.100123733763e-08, 'hidden_layer_sizes': 75, 'learning_rate_init': 1.531083615329266e-05, 'tol': 2.9357952239365325e-05, 'validation_fraction': 0.8858865241256034}
observation time 0.000005, current best -0.936675 at iter 1
suggestion time taken 9.297273 iter 2 next_points [{'alpha': 3.3673456182792108, 'batch_size': 28, 'beta_1': 0.927703760576019, 'beta_2': 0.9797301399824299, 'epsilon': 6.620704098962764e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.002742150043393173, 'tol': 1.0322421945402423e-05, 'validation_fraction': 0.8918390426873875}]
function_evaluation time 0.895726 value -0.910942 suggestion {'alpha': 3.3673456182792108, 'batch_size': 28, 'beta_1': 0.927703760576019, 'beta_2': 0.9797301399824299, 'epsilon': 6.620704098962764e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.002742150043393173, 'tol': 1.0322421945402423e-05, 'validation_fraction': 0.8918390426873875}
observation time 0.000006, current best -0.936675 at iter 2
suggestion time taken 9.476581 iter 3 next_points [{'alpha': 3.5591016780159604e-05, 'batch_size': 26, 'beta_1': 0.7018818120134106, 'beta_2': 0.9999979664862149, 'epsilon': 3.318118092028724e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 2.808262164063694e-05, 'tol': 0.01264597892816386, 'validation_fraction': 0.8671943923728334}]
function_evaluation time 0.244168 value -0.112795 suggestion {'alpha': 3.5591016780159604e-05, 'batch_size': 26, 'beta_1': 0.7018818120134106, 'beta_2': 0.9999979664862149, 'epsilon': 3.318118092028724e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 2.808262164063694e-05, 'tol': 0.01264597892816386, 'validation_fraction': 0.8671943923728334}
observation time 0.000005, current best -0.936675 at iter 3
suggestion time taken 9.259200 iter 4 next_points [{'alpha': 0.12171538995125447, 'batch_size': 21, 'beta_1': 0.9880430266530276, 'beta_2': 0.9999028182561409, 'epsilon': 4.202628544200926e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0064121512320937475, 'tol': 3.642553202040093e-05, 'validation_fraction': 0.8296113135393971}]
function_evaluation time 1.086919 value -0.908858 suggestion {'alpha': 0.12171538995125447, 'batch_size': 21, 'beta_1': 0.9880430266530276, 'beta_2': 0.9999028182561409, 'epsilon': 4.202628544200926e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0064121512320937475, 'tol': 3.642553202040093e-05, 'validation_fraction': 0.8296113135393971}
observation time 0.000006, current best -0.936675 at iter 4
suggestion time taken 9.334508 iter 5 next_points [{'alpha': 0.037516359666913066, 'batch_size': 30, 'beta_1': 0.544965009644712, 'beta_2': 0.9998757924355732, 'epsilon': 5.936415772070623e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.0010139096250246478, 'tol': 0.014651107841284712, 'validation_fraction': 0.2685114519700679}]
function_evaluation time 1.097162 value -0.946424 suggestion {'alpha': 0.037516359666913066, 'batch_size': 30, 'beta_1': 0.544965009644712, 'beta_2': 0.9998757924355732, 'epsilon': 5.936415772070623e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.0010139096250246478, 'tol': 0.014651107841284712, 'validation_fraction': 0.2685114519700679}
observation time 0.000006, current best -0.946424 at iter 5
suggestion time taken 9.224366 iter 6 next_points [{'alpha': 8.12838760434952, 'batch_size': 26, 'beta_1': 0.9688828933205996, 'beta_2': 0.9950928975710763, 'epsilon': 1.4221295753866534e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.008669734157243456, 'tol': 0.0003221068428327317, 'validation_fraction': 0.45525638765920584}]
function_evaluation time 1.069494 value -0.919290 suggestion {'alpha': 8.12838760434952, 'batch_size': 26, 'beta_1': 0.9688828933205996, 'beta_2': 0.9950928975710763, 'epsilon': 1.4221295753866534e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.008669734157243456, 'tol': 0.0003221068428327317, 'validation_fraction': 0.45525638765920584}
observation time 0.000006, current best -0.946424 at iter 6
suggestion time taken 9.245523 iter 7 next_points [{'alpha': 0.4022747883258033, 'batch_size': 24, 'beta_1': 0.9232790271899031, 'beta_2': 0.9995663673430959, 'epsilon': 1.9779366683785136e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 9.652053277596945e-05, 'tol': 0.00043628351286052346, 'validation_fraction': 0.14379692240151337}]
function_evaluation time 3.511362 value -0.909558 suggestion {'alpha': 0.4022747883258033, 'batch_size': 24, 'beta_1': 0.9232790271899031, 'beta_2': 0.9995663673430959, 'epsilon': 1.9779366683785136e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 9.652053277596945e-05, 'tol': 0.00043628351286052346, 'validation_fraction': 0.14379692240151337}
observation time 0.000006, current best -0.946424 at iter 7
suggestion time taken 9.356369 iter 8 next_points [{'alpha': 0.054653562531588935, 'batch_size': 19, 'beta_1': 0.9771349120746762, 'beta_2': 0.9999833233162294, 'epsilon': 1.3991197723810064e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.00013921428817335402, 'tol': 0.0004847258349605956, 'validation_fraction': 0.8179737397790596}]
function_evaluation time 4.675799 value -0.842056 suggestion {'alpha': 0.054653562531588935, 'batch_size': 19, 'beta_1': 0.9771349120746762, 'beta_2': 0.9999833233162294, 'epsilon': 1.3991197723810064e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.00013921428817335402, 'tol': 0.0004847258349605956, 'validation_fraction': 0.8179737397790596}
observation time 0.000006, current best -0.946424 at iter 8
suggestion time taken 9.295083 iter 9 next_points [{'alpha': 0.06481245620768308, 'batch_size': 19, 'beta_1': 0.9186182773548287, 'beta_2': 0.9993105746572145, 'epsilon': 2.641847813225179e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 6.760619635265037e-05, 'tol': 0.013299088671495799, 'validation_fraction': 0.24959683067592656}]
function_evaluation time 3.235267 value -0.900491 suggestion {'alpha': 0.06481245620768308, 'batch_size': 19, 'beta_1': 0.9186182773548287, 'beta_2': 0.9993105746572145, 'epsilon': 2.641847813225179e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 6.760619635265037e-05, 'tol': 0.013299088671495799, 'validation_fraction': 0.24959683067592656}
observation time 0.000005, current best -0.946424 at iter 9
suggestion time taken 9.288958 iter 10 next_points [{'alpha': 0.5806477405980093, 'batch_size': 25, 'beta_1': 0.5322941289453684, 'beta_2': 0.9999408395417605, 'epsilon': 7.458016479564073e-09, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.04815134202704893, 'tol': 0.004385459045573874, 'validation_fraction': 0.17036220587647047}]
function_evaluation time 1.332248 value -0.809321 suggestion {'alpha': 0.5806477405980093, 'batch_size': 25, 'beta_1': 0.5322941289453684, 'beta_2': 0.9999408395417605, 'epsilon': 7.458016479564073e-09, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.04815134202704893, 'tol': 0.004385459045573874, 'validation_fraction': 0.17036220587647047}
observation time 0.000006, current best -0.946424 at iter 10
suggestion time taken 9.282149 iter 11 next_points [{'alpha': 1.562852157086082, 'batch_size': 30, 'beta_1': 0.9240263499843528, 'beta_2': 0.9972636203513718, 'epsilon': 4.9917205479601565e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.0001161592643158642, 'tol': 0.00041001190439254854, 'validation_fraction': 0.20032154740236774}]
function_evaluation time 5.293557 value -0.957571 suggestion {'alpha': 1.562852157086082, 'batch_size': 30, 'beta_1': 0.9240263499843528, 'beta_2': 0.9972636203513718, 'epsilon': 4.9917205479601565e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.0001161592643158642, 'tol': 0.00041001190439254854, 'validation_fraction': 0.20032154740236774}
observation time 0.000006, current best -0.957571 at iter 11
suggestion time taken 9.260807 iter 12 next_points [{'alpha': 8.107597253177245, 'batch_size': 31, 'beta_1': 0.9144949347555923, 'beta_2': 0.9320869319515159, 'epsilon': 9.846992852519907e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 2.4648403803013523e-05, 'tol': 0.040843108601294906, 'validation_fraction': 0.11217277984920004}]
function_evaluation time 0.773104 value -0.195633 suggestion {'alpha': 8.107597253177245, 'batch_size': 31, 'beta_1': 0.9144949347555923, 'beta_2': 0.9320869319515159, 'epsilon': 9.846992852519907e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 2.4648403803013523e-05, 'tol': 0.040843108601294906, 'validation_fraction': 0.11217277984920004}
observation time 0.000006, current best -0.957571 at iter 12
suggestion time taken 9.291201 iter 13 next_points [{'alpha': 0.3228151186368273, 'batch_size': 35, 'beta_1': 0.9272905872387563, 'beta_2': 0.9998603414445426, 'epsilon': 1.5993660683275434e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 9.502693857054028e-05, 'tol': 0.008084075964409127, 'validation_fraction': 0.6971922656510772}]
function_evaluation time 1.196247 value -0.448909 suggestion {'alpha': 0.3228151186368273, 'batch_size': 35, 'beta_1': 0.9272905872387563, 'beta_2': 0.9998603414445426, 'epsilon': 1.5993660683275434e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 9.502693857054028e-05, 'tol': 0.008084075964409127, 'validation_fraction': 0.6971922656510772}
observation time 0.000005, current best -0.957571 at iter 13
suggestion time taken 9.355367 iter 14 next_points [{'alpha': 1.6820112945557263e-05, 'batch_size': 12, 'beta_1': 0.536890123509834, 'beta_2': 0.999902915052216, 'epsilon': 1.8296846618071023e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.03444193916135767, 'tol': 0.09562320115322846, 'validation_fraction': 0.2210325126910046}]
function_evaluation time 1.427613 value -0.915793 suggestion {'alpha': 1.6820112945557263e-05, 'batch_size': 12, 'beta_1': 0.536890123509834, 'beta_2': 0.999902915052216, 'epsilon': 1.8296846618071023e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.03444193916135767, 'tol': 0.09562320115322846, 'validation_fraction': 0.2210325126910046}
observation time 0.000006, current best -0.957571 at iter 14
saving meta data: {'args': {'--uuid': '40678c365888555190db5558dcd1af89', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': 'bfb4fc7e5ac55745b073971422cec1db', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u bfb4fc7e5ac55745b073971422cec1db -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study smoothness MLP-adam digits nll 15 1
with data root: None
suggestion time taken 9.406612 iter 0 next_points [{'alpha': 0.2025749497685341, 'batch_size': 28, 'beta_1': 0.8283712092264017, 'beta_2': 0.9368595046176729, 'epsilon': 1.987093530264684e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.001420452078426198, 'tol': 0.00028646546216423577, 'validation_fraction': 0.17671905681455924}]
function_evaluation time 1.873169 value 0.130888 suggestion {'alpha': 0.2025749497685341, 'batch_size': 28, 'beta_1': 0.8283712092264017, 'beta_2': 0.9368595046176729, 'epsilon': 1.987093530264684e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.001420452078426198, 'tol': 0.00028646546216423577, 'validation_fraction': 0.17671905681455924}
observation time 0.000007, current best 0.130888 at iter 0
suggestion time taken 9.318663 iter 1 next_points [{'alpha': 1.4033450664618774, 'batch_size': 13, 'beta_1': 0.771503619433367, 'beta_2': 0.9955154891111382, 'epsilon': 2.3028243017692524e-08, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.02620226182322704, 'tol': 0.048887836667798924, 'validation_fraction': 0.8968993908024515}]
function_evaluation time 0.360429 value 0.590815 suggestion {'alpha': 1.4033450664618774, 'batch_size': 13, 'beta_1': 0.771503619433367, 'beta_2': 0.9955154891111382, 'epsilon': 2.3028243017692524e-08, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.02620226182322704, 'tol': 0.048887836667798924, 'validation_fraction': 0.8968993908024515}
observation time 0.000006, current best 0.130888 at iter 1
suggestion time taken 9.328670 iter 2 next_points [{'alpha': 1.2660006004950004, 'batch_size': 13, 'beta_1': 0.9874916665917975, 'beta_2': 0.9999957533423479, 'epsilon': 4.8547269855321265e-09, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.01737225341077077, 'tol': 0.00022687112802268711, 'validation_fraction': 0.40822634000362235}]
function_evaluation time 2.429932 value 0.212079 suggestion {'alpha': 1.2660006004950004, 'batch_size': 13, 'beta_1': 0.9874916665917975, 'beta_2': 0.9999957533423479, 'epsilon': 4.8547269855321265e-09, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.01737225341077077, 'tol': 0.00022687112802268711, 'validation_fraction': 0.40822634000362235}
observation time 0.000006, current best 0.130888 at iter 2
suggestion time taken 9.536088 iter 3 next_points [{'alpha': 1.926128592640779e-05, 'batch_size': 50, 'beta_1': 0.9775858404252129, 'beta_2': 0.9495286749746712, 'epsilon': 9.778506227922808e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0006420071101736279, 'tol': 0.005117095074631874, 'validation_fraction': 0.8989163388187823}]
function_evaluation time 0.757509 value 2.145670 suggestion {'alpha': 1.926128592640779e-05, 'batch_size': 50, 'beta_1': 0.9775858404252129, 'beta_2': 0.9495286749746712, 'epsilon': 9.778506227922808e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0006420071101736279, 'tol': 0.005117095074631874, 'validation_fraction': 0.8989163388187823}
observation time 0.000007, current best 0.130888 at iter 3
suggestion time taken 9.520852 iter 4 next_points [{'alpha': 0.0012839148155685996, 'batch_size': 23, 'beta_1': 0.9670217948193055, 'beta_2': 0.9887759673136293, 'epsilon': 9.190414917009632e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.0940417520841083, 'tol': 0.06526364584510455, 'validation_fraction': 0.7810649093410994}]
function_evaluation time 0.310491 value 2.446634 suggestion {'alpha': 0.0012839148155685996, 'batch_size': 23, 'beta_1': 0.9670217948193055, 'beta_2': 0.9887759673136293, 'epsilon': 9.190414917009632e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.0940417520841083, 'tol': 0.06526364584510455, 'validation_fraction': 0.7810649093410994}
observation time 0.000005, current best 0.130888 at iter 4
suggestion time taken 9.496140 iter 5 next_points [{'alpha': 2.540746667667142, 'batch_size': 18, 'beta_1': 0.9290418971070357, 'beta_2': 0.9999914711606571, 'epsilon': 1.0608602698221333e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00047193323278514404, 'tol': 0.0008992222992473844, 'validation_fraction': 0.2851703945027476}]
function_evaluation time 3.874949 value 0.204082 suggestion {'alpha': 2.540746667667142, 'batch_size': 18, 'beta_1': 0.9290418971070357, 'beta_2': 0.9999914711606571, 'epsilon': 1.0608602698221333e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00047193323278514404, 'tol': 0.0008992222992473844, 'validation_fraction': 0.2851703945027476}
observation time 0.000006, current best 0.130888 at iter 5
suggestion time taken 9.489476 iter 6 next_points [{'alpha': 0.0004507684775391694, 'batch_size': 25, 'beta_1': 0.9306760217599289, 'beta_2': 0.9973244781233068, 'epsilon': 2.5236347694482403e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 1.5830516685826983e-05, 'tol': 0.002976573492382549, 'validation_fraction': 0.4466202264528769}]
function_evaluation time 9.173278 value 0.513287 suggestion {'alpha': 0.0004507684775391694, 'batch_size': 25, 'beta_1': 0.9306760217599289, 'beta_2': 0.9973244781233068, 'epsilon': 2.5236347694482403e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 1.5830516685826983e-05, 'tol': 0.002976573492382549, 'validation_fraction': 0.4466202264528769}
observation time 0.000006, current best 0.130888 at iter 6
suggestion time taken 9.491079 iter 7 next_points [{'alpha': 2.7950521279160174, 'batch_size': 10, 'beta_1': 0.9849342588087223, 'beta_2': 0.9350606016488416, 'epsilon': 3.303274624676161e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0004779824663249902, 'tol': 1.529726018422926e-05, 'validation_fraction': 0.15945283827274728}]
function_evaluation time 3.311504 value 0.294402 suggestion {'alpha': 2.7950521279160174, 'batch_size': 10, 'beta_1': 0.9849342588087223, 'beta_2': 0.9350606016488416, 'epsilon': 3.303274624676161e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0004779824663249902, 'tol': 1.529726018422926e-05, 'validation_fraction': 0.15945283827274728}
observation time 0.000006, current best 0.130888 at iter 7
suggestion time taken 9.509027 iter 8 next_points [{'alpha': 0.005826668996539665, 'batch_size': 21, 'beta_1': 0.9813745210825294, 'beta_2': 0.9984451354066589, 'epsilon': 8.889502428213818e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 1.1670619767873178e-05, 'tol': 0.01872582277895699, 'validation_fraction': 0.2447619601956541}]
function_evaluation time 1.059650 value 6.064055 suggestion {'alpha': 0.005826668996539665, 'batch_size': 21, 'beta_1': 0.9813745210825294, 'beta_2': 0.9984451354066589, 'epsilon': 8.889502428213818e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 1.1670619767873178e-05, 'tol': 0.01872582277895699, 'validation_fraction': 0.2447619601956541}
observation time 0.000006, current best 0.130888 at iter 8
suggestion time taken 9.539455 iter 9 next_points [{'alpha': 0.0005756018469125389, 'batch_size': 29, 'beta_1': 0.6477790777650438, 'beta_2': 0.9914566615817604, 'epsilon': 6.938994444719283e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.060215096109615694, 'tol': 0.037198127047662934, 'validation_fraction': 0.209403700661691}]
function_evaluation time 0.889905 value 0.495444 suggestion {'alpha': 0.0005756018469125389, 'batch_size': 29, 'beta_1': 0.6477790777650438, 'beta_2': 0.9914566615817604, 'epsilon': 6.938994444719283e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.060215096109615694, 'tol': 0.037198127047662934, 'validation_fraction': 0.209403700661691}
observation time 0.000006, current best 0.130888 at iter 9
suggestion time taken 9.537781 iter 10 next_points [{'alpha': 0.09250565049165975, 'batch_size': 15, 'beta_1': 0.9699723441345691, 'beta_2': 0.9991183843126171, 'epsilon': 1.9960705194297514e-08, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.0003247224203511919, 'tol': 0.0036312788121053673, 'validation_fraction': 0.24949862043129578}]
function_evaluation time 3.625352 value 0.148141 suggestion {'alpha': 0.09250565049165975, 'batch_size': 15, 'beta_1': 0.9699723441345691, 'beta_2': 0.9991183843126171, 'epsilon': 1.9960705194297514e-08, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.0003247224203511919, 'tol': 0.0036312788121053673, 'validation_fraction': 0.24949862043129578}
observation time 0.000006, current best 0.130888 at iter 10
suggestion time taken 9.603180 iter 11 next_points [{'alpha': 4.7651007712803555, 'batch_size': 20, 'beta_1': 0.9874167889267982, 'beta_2': 0.9989140247510286, 'epsilon': 5.657463103817292e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.7554825907859293e-05, 'tol': 0.008644216551641869, 'validation_fraction': 0.7259709744550564}]
function_evaluation time 0.449189 value 9.588824 suggestion {'alpha': 4.7651007712803555, 'batch_size': 20, 'beta_1': 0.9874167889267982, 'beta_2': 0.9989140247510286, 'epsilon': 5.657463103817292e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.7554825907859293e-05, 'tol': 0.008644216551641869, 'validation_fraction': 0.7259709744550564}
observation time 0.000006, current best 0.130888 at iter 11
suggestion time taken 9.658073 iter 12 next_points [{'alpha': 0.12637561121724641, 'batch_size': 17, 'beta_1': 0.9576950336172297, 'beta_2': 0.9999984800622775, 'epsilon': 3.627434019058743e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.00019346404695972272, 'tol': 0.001939770482241884, 'validation_fraction': 0.2205420093068275}]
function_evaluation time 6.315922 value 0.152553 suggestion {'alpha': 0.12637561121724641, 'batch_size': 17, 'beta_1': 0.9576950336172297, 'beta_2': 0.9999984800622775, 'epsilon': 3.627434019058743e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.00019346404695972272, 'tol': 0.001939770482241884, 'validation_fraction': 0.2205420093068275}
observation time 0.000006, current best 0.130888 at iter 12
suggestion time taken 9.599376 iter 13 next_points [{'alpha': 0.004016844969990631, 'batch_size': 19, 'beta_1': 0.6996833939083262, 'beta_2': 0.9844362136592658, 'epsilon': 4.165227632674997e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 1.3670001446385193e-05, 'tol': 0.00017483974016846041, 'validation_fraction': 0.849225508536647}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.844589 value 4.355486 suggestion {'alpha': 0.004016844969990631, 'batch_size': 19, 'beta_1': 0.6996833939083262, 'beta_2': 0.9844362136592658, 'epsilon': 4.165227632674997e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 1.3670001446385193e-05, 'tol': 0.00017483974016846041, 'validation_fraction': 0.849225508536647}
observation time 0.000006, current best 0.130888 at iter 13
suggestion time taken 9.616472 iter 14 next_points [{'alpha': 0.0036752643436028594, 'batch_size': 37, 'beta_1': 0.753654369492054, 'beta_2': 0.9956132145217066, 'epsilon': 1.6889779374520364e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 2.424178175944297e-05, 'tol': 0.00014100610823837353, 'validation_fraction': 0.7771059817981236}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 4.168694 value 1.230306 suggestion {'alpha': 0.0036752643436028594, 'batch_size': 37, 'beta_1': 0.753654369492054, 'beta_2': 0.9956132145217066, 'epsilon': 1.6889779374520364e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 2.424178175944297e-05, 'tol': 0.00014100610823837353, 'validation_fraction': 0.7771059817981236}
observation time 0.000006, current best 0.130888 at iter 14
saving meta data: {'args': {'--uuid': 'bfb4fc7e5ac55745b073971422cec1db', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': 'ebaf67bbe4f15064bcc052ccd719427a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u ebaf67bbe4f15064bcc052ccd719427a -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study smoothness MLP-adam digits nll 15 1
with data root: None
suggestion time taken 9.487350 iter 0 next_points [{'alpha': 0.0002662270053078803, 'batch_size': 26, 'beta_1': 0.7153303284606837, 'beta_2': 0.9999445009685001, 'epsilon': 1.4700329025436414e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 1.3445892434483966e-05, 'tol': 1.9709177091547187e-05, 'validation_fraction': 0.197276621211757}]
function_evaluation time 9.868124 value 2.449676 suggestion {'alpha': 0.0002662270053078803, 'batch_size': 26, 'beta_1': 0.7153303284606837, 'beta_2': 0.9999445009685001, 'epsilon': 1.4700329025436414e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 1.3445892434483966e-05, 'tol': 1.9709177091547187e-05, 'validation_fraction': 0.197276621211757}
observation time 0.000006, current best 2.449676 at iter 0
suggestion time taken 9.208036 iter 1 next_points [{'alpha': 0.0001369216172167461, 'batch_size': 17, 'beta_1': 0.9187891798703742, 'beta_2': 0.9988977982081324, 'epsilon': 2.1049203598298434e-08, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.004347334971872916, 'tol': 0.00023009922270950141, 'validation_fraction': 0.6096488728143235}]
function_evaluation time 1.643147 value 0.166554 suggestion {'alpha': 0.0001369216172167461, 'batch_size': 17, 'beta_1': 0.9187891798703742, 'beta_2': 0.9988977982081324, 'epsilon': 2.1049203598298434e-08, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.004347334971872916, 'tol': 0.00023009922270950141, 'validation_fraction': 0.6096488728143235}
observation time 0.000006, current best 0.166554 at iter 1
suggestion time taken 9.252471 iter 2 next_points [{'alpha': 0.03485215284179058, 'batch_size': 25, 'beta_1': 0.9131150654284275, 'beta_2': 0.9839487942750829, 'epsilon': 4.773881807202354e-07, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.03975255474036589, 'tol': 0.014313444590227452, 'validation_fraction': 0.6445057130299426}]
function_evaluation time 0.815905 value 0.549965 suggestion {'alpha': 0.03485215284179058, 'batch_size': 25, 'beta_1': 0.9131150654284275, 'beta_2': 0.9839487942750829, 'epsilon': 4.773881807202354e-07, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.03975255474036589, 'tol': 0.014313444590227452, 'validation_fraction': 0.6445057130299426}
observation time 0.000005, current best 0.166554 at iter 2
suggestion time taken 9.473122 iter 3 next_points [{'alpha': 1.5668163368429664, 'batch_size': 37, 'beta_1': 0.9893772673384222, 'beta_2': 0.9991615164699554, 'epsilon': 4.072422267843348e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.0005115551377939667, 'tol': 0.01595713336085639, 'validation_fraction': 0.2391254882296804}]
function_evaluation time 1.162758 value 0.183794 suggestion {'alpha': 1.5668163368429664, 'batch_size': 37, 'beta_1': 0.9893772673384222, 'beta_2': 0.9991615164699554, 'epsilon': 4.072422267843348e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.0005115551377939667, 'tol': 0.01595713336085639, 'validation_fraction': 0.2391254882296804}
observation time 0.000005, current best 0.166554 at iter 3
suggestion time taken 9.273125 iter 4 next_points [{'alpha': 0.061349438430662075, 'batch_size': 35, 'beta_1': 0.8889630718448746, 'beta_2': 0.9993296363407367, 'epsilon': 1.8612434755554768e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.051964135574731646, 'tol': 0.012719225356705628, 'validation_fraction': 0.8860776554920298}]
function_evaluation time 0.452183 value 0.842310 suggestion {'alpha': 0.061349438430662075, 'batch_size': 35, 'beta_1': 0.8889630718448746, 'beta_2': 0.9993296363407367, 'epsilon': 1.8612434755554768e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.051964135574731646, 'tol': 0.012719225356705628, 'validation_fraction': 0.8860776554920298}
observation time 0.000006, current best 0.166554 at iter 4
suggestion time taken 9.207460 iter 5 next_points [{'alpha': 0.7429574416771791, 'batch_size': 40, 'beta_1': 0.6324223496631853, 'beta_2': 0.969528247871016, 'epsilon': 1.4454990808269356e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0003619849728079061, 'tol': 0.002550345810456652, 'validation_fraction': 0.1588352202420385}]
function_evaluation time 2.605047 value 0.127518 suggestion {'alpha': 0.7429574416771791, 'batch_size': 40, 'beta_1': 0.6324223496631853, 'beta_2': 0.969528247871016, 'epsilon': 1.4454990808269356e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0003619849728079061, 'tol': 0.002550345810456652, 'validation_fraction': 0.1588352202420385}
observation time 0.000005, current best 0.127518 at iter 5
suggestion time taken 9.211201 iter 6 next_points [{'alpha': 0.17480762541741543, 'batch_size': 13, 'beta_1': 0.6208073621268639, 'beta_2': 0.9380911674433473, 'epsilon': 1.0796178965946844e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.026038338888605038, 'tol': 1.393456205423279e-05, 'validation_fraction': 0.8529533315720025}]
function_evaluation time 0.867794 value 0.524381 suggestion {'alpha': 0.17480762541741543, 'batch_size': 13, 'beta_1': 0.6208073621268639, 'beta_2': 0.9380911674433473, 'epsilon': 1.0796178965946844e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.026038338888605038, 'tol': 1.393456205423279e-05, 'validation_fraction': 0.8529533315720025}
observation time 0.000005, current best 0.127518 at iter 6
suggestion time taken 9.212500 iter 7 next_points [{'alpha': 3.4407184909013373, 'batch_size': 14, 'beta_1': 0.8689142004416035, 'beta_2': 0.9969851107187436, 'epsilon': 3.2569874220733064e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.02889400183794232, 'tol': 0.0005116840615740856, 'validation_fraction': 0.29952761982077336}]
function_evaluation time 1.593708 value 0.435053 suggestion {'alpha': 3.4407184909013373, 'batch_size': 14, 'beta_1': 0.8689142004416035, 'beta_2': 0.9969851107187436, 'epsilon': 3.2569874220733064e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.02889400183794232, 'tol': 0.0005116840615740856, 'validation_fraction': 0.29952761982077336}
observation time 0.000006, current best 0.127518 at iter 7
suggestion time taken 9.208583 iter 8 next_points [{'alpha': 5.0253932272877195, 'batch_size': 18, 'beta_1': 0.9883686033142294, 'beta_2': 0.9999545606225925, 'epsilon': 6.0193599759037355e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 7.180224608369747e-05, 'tol': 4.890127785456335e-05, 'validation_fraction': 0.8696211410789582}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.963229 value 2.412642 suggestion {'alpha': 5.0253932272877195, 'batch_size': 18, 'beta_1': 0.9883686033142294, 'beta_2': 0.9999545606225925, 'epsilon': 6.0193599759037355e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 7.180224608369747e-05, 'tol': 4.890127785456335e-05, 'validation_fraction': 0.8696211410789582}
observation time 0.000005, current best 0.127518 at iter 8
suggestion time taken 9.239703 iter 9 next_points [{'alpha': 5.114024237473006e-05, 'batch_size': 12, 'beta_1': 0.9853649631869886, 'beta_2': 0.9984395620924588, 'epsilon': 7.2399303617106515e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0002805211753940381, 'tol': 0.018449780996771966, 'validation_fraction': 0.8078231018643599}]
function_evaluation time 1.076104 value 0.644205 suggestion {'alpha': 5.114024237473006e-05, 'batch_size': 12, 'beta_1': 0.9853649631869886, 'beta_2': 0.9984395620924588, 'epsilon': 7.2399303617106515e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0002805211753940381, 'tol': 0.018449780996771966, 'validation_fraction': 0.8078231018643599}
observation time 0.000005, current best 0.127518 at iter 9
suggestion time taken 9.277804 iter 10 next_points [{'alpha': 0.000579317224422796, 'batch_size': 23, 'beta_1': 0.8386092292387382, 'beta_2': 0.9999986719034554, 'epsilon': 1.0316006071143229e-07, 'hidden_layer_sizes': 146, 'learning_rate_init': 6.453975396331932e-05, 'tol': 0.002990857634355392, 'validation_fraction': 0.1312925738025536}]
function_evaluation time 6.019904 value 0.239077 suggestion {'alpha': 0.000579317224422796, 'batch_size': 23, 'beta_1': 0.8386092292387382, 'beta_2': 0.9999986719034554, 'epsilon': 1.0316006071143229e-07, 'hidden_layer_sizes': 146, 'learning_rate_init': 6.453975396331932e-05, 'tol': 0.002990857634355392, 'validation_fraction': 0.1312925738025536}
observation time 0.000004, current best 0.127518 at iter 10
suggestion time taken 9.252315 iter 11 next_points [{'alpha': 0.00012732709980866147, 'batch_size': 19, 'beta_1': 0.9751281886525687, 'beta_2': 0.9956220677539958, 'epsilon': 3.553514501125689e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 1.6313146639117337e-05, 'tol': 0.012054664918862234, 'validation_fraction': 0.7156080717868286}]
function_evaluation time 0.481527 value 7.997689 suggestion {'alpha': 0.00012732709980866147, 'batch_size': 19, 'beta_1': 0.9751281886525687, 'beta_2': 0.9956220677539958, 'epsilon': 3.553514501125689e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 1.6313146639117337e-05, 'tol': 0.012054664918862234, 'validation_fraction': 0.7156080717868286}
observation time 0.000005, current best 0.127518 at iter 11
suggestion time taken 9.182585 iter 12 next_points [{'alpha': 0.06307434397650932, 'batch_size': 35, 'beta_1': 0.9652067087790742, 'beta_2': 0.9883893037701377, 'epsilon': 4.3061214362622444e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 1.1354968341531231e-05, 'tol': 4.407961112026501e-05, 'validation_fraction': 0.16877358159318379}]
function_evaluation time 9.628649 value 2.515729 suggestion {'alpha': 0.06307434397650932, 'batch_size': 35, 'beta_1': 0.9652067087790742, 'beta_2': 0.9883893037701377, 'epsilon': 4.3061214362622444e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 1.1354968341531231e-05, 'tol': 4.407961112026501e-05, 'validation_fraction': 0.16877358159318379}
observation time 0.000005, current best 0.127518 at iter 12
suggestion time taken 9.223389 iter 13 next_points [{'alpha': 0.03313299158346729, 'batch_size': 44, 'beta_1': 0.6693602095108886, 'beta_2': 0.9999964351272238, 'epsilon': 1.432342377869456e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0013581977039280133, 'tol': 0.0009681176720449825, 'validation_fraction': 0.1966066909318519}]
function_evaluation time 1.452373 value 0.131276 suggestion {'alpha': 0.03313299158346729, 'batch_size': 44, 'beta_1': 0.6693602095108886, 'beta_2': 0.9999964351272238, 'epsilon': 1.432342377869456e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0013581977039280133, 'tol': 0.0009681176720449825, 'validation_fraction': 0.1966066909318519}
observation time 0.000005, current best 0.127518 at iter 13
suggestion time taken 9.229558 iter 14 next_points [{'alpha': 0.0005179448576404868, 'batch_size': 18, 'beta_1': 0.5716309138363111, 'beta_2': 0.9950396574869145, 'epsilon': 5.777008293419266e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 8.862733459976226e-05, 'tol': 3.7945879774631886e-05, 'validation_fraction': 0.7756017388929201}]
function_evaluation time 5.991459 value 0.264240 suggestion {'alpha': 0.0005179448576404868, 'batch_size': 18, 'beta_1': 0.5716309138363111, 'beta_2': 0.9950396574869145, 'epsilon': 5.777008293419266e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 8.862733459976226e-05, 'tol': 3.7945879774631886e-05, 'validation_fraction': 0.7756017388929201}
observation time 0.000006, current best 0.127518 at iter 14
saving meta data: {'args': {'--uuid': 'ebaf67bbe4f15064bcc052ccd719427a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '59e32c65829a5be89a091f198148d10c', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u 59e32c65829a5be89a091f198148d10c -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002275 iter 0 next_points [{'alpha': 0.24006842790908767, 'batch_size': 210, 'beta_1': 0.9336768364692983, 'beta_2': 0.9999977511558762, 'epsilon': 6.588611593013324e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.04736009135346764, 'tol': 0.00023732415929517673, 'validation_fraction': 0.7286574342720797}]
function_evaluation time 0.604986 value -0.695904 suggestion {'alpha': 0.24006842790908767, 'batch_size': 210, 'beta_1': 0.9336768364692983, 'beta_2': 0.9999977511558762, 'epsilon': 6.588611593013324e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.04736009135346764, 'tol': 0.00023732415929517673, 'validation_fraction': 0.7286574342720797}
observation time 0.001451, current best -0.695904 at iter 0
suggestion time taken 0.001815 iter 1 next_points [{'alpha': 0.005931885794996907, 'batch_size': 48, 'beta_1': 0.8038998516225258, 'beta_2': 0.9999988390914626, 'epsilon': 4.465174552168459e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 1.0292934389572717e-05, 'tol': 6.338572571521678e-05, 'validation_fraction': 0.25892256522021523}]
function_evaluation time 5.038651 value -0.346458 suggestion {'alpha': 0.005931885794996907, 'batch_size': 48, 'beta_1': 0.8038998516225258, 'beta_2': 0.9999988390914626, 'epsilon': 4.465174552168459e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 1.0292934389572717e-05, 'tol': 6.338572571521678e-05, 'validation_fraction': 0.25892256522021523}
observation time 0.001496, current best -0.695904 at iter 1
suggestion time taken 0.001778 iter 2 next_points [{'alpha': 0.0002052534488696816, 'batch_size': 231, 'beta_1': 0.9366345395672664, 'beta_2': 0.9534608527026806, 'epsilon': 3.0304023575793604e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.0014486837202381914, 'tol': 0.02556687883195558, 'validation_fraction': 0.7514567612442092}]
function_evaluation time 0.391481 value -0.846881 suggestion {'alpha': 0.0002052534488696816, 'batch_size': 231, 'beta_1': 0.9366345395672664, 'beta_2': 0.9534608527026806, 'epsilon': 3.0304023575793604e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.0014486837202381914, 'tol': 0.02556687883195558, 'validation_fraction': 0.7514567612442092}
observation time 0.001523, current best -0.846881 at iter 2
suggestion time taken 0.002008 iter 3 next_points [{'alpha': 0.5416671057232566, 'batch_size': 30, 'beta_1': 0.8711584596663312, 'beta_2': 0.9938127482305352, 'epsilon': 1.6846825451340412e-09, 'hidden_layer_sizes': 58, 'learning_rate_init': 6.540603339093466e-05, 'tol': 0.003610166432826469, 'validation_fraction': 0.6375342844714367}]
function_evaluation time 3.058944 value -0.707532 suggestion {'alpha': 0.5416671057232566, 'batch_size': 30, 'beta_1': 0.8711584596663312, 'beta_2': 0.9938127482305352, 'epsilon': 1.6846825451340412e-09, 'hidden_layer_sizes': 58, 'learning_rate_init': 6.540603339093466e-05, 'tol': 0.003610166432826469, 'validation_fraction': 0.6375342844714367}
observation time 0.001431, current best -0.846881 at iter 3
suggestion time taken 0.001769 iter 4 next_points [{'alpha': 0.0015706987915346873, 'batch_size': 157, 'beta_1': 0.988215162965136, 'beta_2': 0.9878926736560107, 'epsilon': 1.7662665300601359e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.007380337882892037, 'tol': 0.00016429007745350613, 'validation_fraction': 0.1880486025718729}]
function_evaluation time 1.213618 value -0.955456 suggestion {'alpha': 0.0015706987915346873, 'batch_size': 157, 'beta_1': 0.988215162965136, 'beta_2': 0.9878926736560107, 'epsilon': 1.7662665300601359e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.007380337882892037, 'tol': 0.00016429007745350613, 'validation_fraction': 0.1880486025718729}
observation time 0.001441, current best -0.955456 at iter 4
suggestion time taken 0.001771 iter 5 next_points [{'alpha': 0.8291305832748743, 'batch_size': 215, 'beta_1': 0.7449459377309626, 'beta_2': 0.9999964418579949, 'epsilon': 2.139317382941454e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.004379932717310113, 'tol': 0.002782968314220761, 'validation_fraction': 0.8692295637206194}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.411094 value -0.894244 suggestion {'alpha': 0.8291305832748743, 'batch_size': 215, 'beta_1': 0.7449459377309626, 'beta_2': 0.9999964418579949, 'epsilon': 2.139317382941454e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.004379932717310113, 'tol': 0.002782968314220761, 'validation_fraction': 0.8692295637206194}
observation time 0.001416, current best -0.955456 at iter 5
suggestion time taken 0.001757 iter 6 next_points [{'alpha': 1.7937912495265345, 'batch_size': 167, 'beta_1': 0.8842042485708687, 'beta_2': 0.913613348419252, 'epsilon': 8.975698523609447e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.0005409121025736147, 'tol': 0.0003433025657822479, 'validation_fraction': 0.28887413566624875}]
function_evaluation time 1.610516 value -0.970766 suggestion {'alpha': 1.7937912495265345, 'batch_size': 167, 'beta_1': 0.8842042485708687, 'beta_2': 0.913613348419252, 'epsilon': 8.975698523609447e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.0005409121025736147, 'tol': 0.0003433025657822479, 'validation_fraction': 0.28887413566624875}
observation time 0.001408, current best -0.970766 at iter 6
suggestion time taken 0.001846 iter 7 next_points [{'alpha': 1.899362200496291e-05, 'batch_size': 174, 'beta_1': 0.5779798871984846, 'beta_2': 0.9999102989293801, 'epsilon': 8.244909783121643e-08, 'hidden_layer_sizes': 195, 'learning_rate_init': 3.4086382717183756e-05, 'tol': 0.009818702801176896, 'validation_fraction': 0.33479130837281645}]
function_evaluation time 1.155040 value -0.188095 suggestion {'alpha': 1.899362200496291e-05, 'batch_size': 174, 'beta_1': 0.5779798871984846, 'beta_2': 0.9999102989293801, 'epsilon': 8.244909783121643e-08, 'hidden_layer_sizes': 195, 'learning_rate_init': 3.4086382717183756e-05, 'tol': 0.009818702801176896, 'validation_fraction': 0.33479130837281645}
observation time 0.001435, current best -0.970766 at iter 7
suggestion time taken 0.001807 iter 8 next_points [{'alpha': 0.00043970690764459175, 'batch_size': 141, 'beta_1': 0.5542118741058683, 'beta_2': 0.9999756699541963, 'epsilon': 6.426244307464939e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.012820200081018562, 'tol': 0.0005771355882020871, 'validation_fraction': 0.44216234017340544}]
function_evaluation time 0.836254 value -0.963110 suggestion {'alpha': 0.00043970690764459175, 'batch_size': 141, 'beta_1': 0.5542118741058683, 'beta_2': 0.9999756699541963, 'epsilon': 6.426244307464939e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.012820200081018562, 'tol': 0.0005771355882020871, 'validation_fraction': 0.44216234017340544}
observation time 0.001473, current best -0.970766 at iter 8
suggestion time taken 0.001861 iter 9 next_points [{'alpha': 9.156214391664058, 'batch_size': 124, 'beta_1': 0.8249264460505569, 'beta_2': 0.9993918647686385, 'epsilon': 3.193313123602719e-09, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.01605290244575524, 'tol': 3.0343756852756937e-05, 'validation_fraction': 0.15177528731456064}]
function_evaluation time 0.858798 value -0.959635 suggestion {'alpha': 9.156214391664058, 'batch_size': 124, 'beta_1': 0.8249264460505569, 'beta_2': 0.9993918647686385, 'epsilon': 3.193313123602719e-09, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.01605290244575524, 'tol': 3.0343756852756937e-05, 'validation_fraction': 0.15177528731456064}
observation time 0.001408, current best -0.970766 at iter 9
suggestion time taken 0.001762 iter 10 next_points [{'alpha': 0.025412220769129235, 'batch_size': 11, 'beta_1': 0.9717129917977473, 'beta_2': 0.9996067302145807, 'epsilon': 2.1117140128806476e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 2.1745298804713587e-05, 'tol': 0.014690059867593384, 'validation_fraction': 0.8064546858545943}]
function_evaluation time 0.624322 value -0.148909 suggestion {'alpha': 0.025412220769129235, 'batch_size': 11, 'beta_1': 0.9717129917977473, 'beta_2': 0.9996067302145807, 'epsilon': 2.1117140128806476e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 2.1745298804713587e-05, 'tol': 0.014690059867593384, 'validation_fraction': 0.8064546858545943}
observation time 0.001416, current best -0.970766 at iter 10
suggestion time taken 0.001854 iter 11 next_points [{'alpha': 0.032108152243377236, 'batch_size': 103, 'beta_1': 0.9178659091525819, 'beta_2': 0.9999475596252262, 'epsilon': 4.957117754777471e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.06162942645633816, 'tol': 0.002066361453634902, 'validation_fraction': 0.8945079330681797}]
function_evaluation time 0.603969 value -0.739114 suggestion {'alpha': 0.032108152243377236, 'batch_size': 103, 'beta_1': 0.9178659091525819, 'beta_2': 0.9999475596252262, 'epsilon': 4.957117754777471e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.06162942645633816, 'tol': 0.002066361453634902, 'validation_fraction': 0.8945079330681797}
observation time 0.001428, current best -0.970766 at iter 11
suggestion time taken 0.001787 iter 12 next_points [{'alpha': 0.0001375347989177753, 'batch_size': 36, 'beta_1': 0.9783235318165553, 'beta_2': 0.999991461001032, 'epsilon': 2.8647627270591944e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.00022970950176557956, 'tol': 1.3792815886780375e-05, 'validation_fraction': 0.8300959148796717}]
function_evaluation time 2.890225 value -0.876832 suggestion {'alpha': 0.0001375347989177753, 'batch_size': 36, 'beta_1': 0.9783235318165553, 'beta_2': 0.999991461001032, 'epsilon': 2.8647627270591944e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.00022970950176557956, 'tol': 1.3792815886780375e-05, 'validation_fraction': 0.8300959148796717}
observation time 0.001428, current best -0.970766 at iter 12
suggestion time taken 0.001780 iter 13 next_points [{'alpha': 0.08729831018379013, 'batch_size': 111, 'beta_1': 0.985052183023016, 'beta_2': 0.9989725106962177, 'epsilon': 1.1409685698818894e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.001031943817019275, 'tol': 0.04082706367070208, 'validation_fraction': 0.3785539194954092}]
function_evaluation time 0.531137 value -0.910942 suggestion {'alpha': 0.08729831018379013, 'batch_size': 111, 'beta_1': 0.985052183023016, 'beta_2': 0.9989725106962177, 'epsilon': 1.1409685698818894e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.001031943817019275, 'tol': 0.04082706367070208, 'validation_fraction': 0.3785539194954092}
observation time 0.001428, current best -0.970766 at iter 13
suggestion time taken 0.001754 iter 14 next_points [{'alpha': 5.1477186496777353e-05, 'batch_size': 92, 'beta_1': 0.9670037156566657, 'beta_2': 0.9793150883005937, 'epsilon': 1.3114053600674284e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.003080164947286148, 'tol': 2.1442747973094488e-05, 'validation_fraction': 0.10219467385358894}]
function_evaluation time 0.934231 value -0.956867 suggestion {'alpha': 5.1477186496777353e-05, 'batch_size': 92, 'beta_1': 0.9670037156566657, 'beta_2': 0.9793150883005937, 'epsilon': 1.3114053600674284e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.003080164947286148, 'tol': 2.1442747973094488e-05, 'validation_fraction': 0.10219467385358894}
observation time 0.001439, current best -0.970766 at iter 14
saving meta data: {'args': {'--uuid': '59e32c65829a5be89a091f198148d10c', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

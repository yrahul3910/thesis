running: {'--uuid': 'f7be7b327ada53809b74986b33c67846', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u f7be7b327ada53809b74986b33c67846 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002389 iter 0 next_points [{'alpha': 0.033353104818983306, 'batch_size': 35, 'beta_1': 0.614582947940704, 'beta_2': 0.9071328783207743, 'epsilon': 6.520849874996403e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0008823839329589066, 'tol': 0.0002865297312686921, 'validation_fraction': 0.402839888025007}]
function_evaluation time 1.948430 value -0.970081 suggestion {'alpha': 0.033353104818983306, 'batch_size': 35, 'beta_1': 0.614582947940704, 'beta_2': 0.9071328783207743, 'epsilon': 6.520849874996403e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0008823839329589066, 'tol': 0.0002865297312686921, 'validation_fraction': 0.402839888025007}
observation time 0.000068, current best -0.970081 at iter 0
suggestion time taken 0.002610 iter 1 next_points [{'alpha': 0.0002453924930041626, 'batch_size': 151, 'beta_1': 0.5696005135914447, 'beta_2': 0.9834983376574034, 'epsilon': 8.509359098237972e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.0042500204067349315, 'tol': 0.00015319861614844458, 'validation_fraction': 0.12974693857059488}]
function_evaluation time 0.919481 value -0.965897 suggestion {'alpha': 0.0002453924930041626, 'batch_size': 151, 'beta_1': 0.5696005135914447, 'beta_2': 0.9834983376574034, 'epsilon': 8.509359098237972e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.0042500204067349315, 'tol': 0.00015319861614844458, 'validation_fraction': 0.12974693857059488}
observation time 0.000067, current best -0.970081 at iter 1
suggestion time taken 0.002297 iter 2 next_points [{'alpha': 0.0010093219679517393, 'batch_size': 197, 'beta_1': 0.9696546523679771, 'beta_2': 0.9533543111819169, 'epsilon': 1.4624145081758661e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0072264464927501324, 'tol': 0.08035305934935953, 'validation_fraction': 0.1085514636756031}]
function_evaluation time 0.485356 value -0.949197 suggestion {'alpha': 0.0010093219679517393, 'batch_size': 197, 'beta_1': 0.9696546523679771, 'beta_2': 0.9533543111819169, 'epsilon': 1.4624145081758661e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0072264464927501324, 'tol': 0.08035305934935953, 'validation_fraction': 0.1085514636756031}
observation time 0.000073, current best -0.970081 at iter 2
suggestion time taken 0.002178 iter 3 next_points [{'alpha': 0.00839726888338274, 'batch_size': 175, 'beta_1': 0.5840426656759369, 'beta_2': 0.9517023549013895, 'epsilon': 3.563467488612088e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.07848904099484195, 'tol': 1.6130573104448545e-05, 'validation_fraction': 0.17387205887463067}]
function_evaluation time 1.178554 value -0.844140 suggestion {'alpha': 0.00839726888338274, 'batch_size': 175, 'beta_1': 0.5840426656759369, 'beta_2': 0.9517023549013895, 'epsilon': 3.563467488612088e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.07848904099484195, 'tol': 1.6130573104448545e-05, 'validation_fraction': 0.17387205887463067}
observation time 0.000071, current best -0.970081 at iter 3
suggestion time taken 0.002130 iter 4 next_points [{'alpha': 0.00021554775897403164, 'batch_size': 85, 'beta_1': 0.6285559826802858, 'beta_2': 0.9165924010287394, 'epsilon': 8.677083047979016e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 1.032263554865231e-05, 'tol': 0.00014885054408342614, 'validation_fraction': 0.21271003039527966}]
function_evaluation time 2.476873 value -0.244503 suggestion {'alpha': 0.00021554775897403164, 'batch_size': 85, 'beta_1': 0.6285559826802858, 'beta_2': 0.9165924010287394, 'epsilon': 8.677083047979016e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 1.032263554865231e-05, 'tol': 0.00014885054408342614, 'validation_fraction': 0.21271003039527966}
observation time 0.000075, current best -0.970081 at iter 4
suggestion time taken 0.002148 iter 5 next_points [{'alpha': 0.041125252776154905, 'batch_size': 100, 'beta_1': 0.9845276099309878, 'beta_2': 0.9805222221760236, 'epsilon': 1.4082213220230642e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.019347666561005436, 'tol': 2.7447855982621145e-05, 'validation_fraction': 0.7688056218818157}]
function_evaluation time 0.860613 value -0.903242 suggestion {'alpha': 0.041125252776154905, 'batch_size': 100, 'beta_1': 0.9845276099309878, 'beta_2': 0.9805222221760236, 'epsilon': 1.4082213220230642e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.019347666561005436, 'tol': 2.7447855982621145e-05, 'validation_fraction': 0.7688056218818157}
observation time 0.000067, current best -0.970081 at iter 5
suggestion time taken 0.002128 iter 6 next_points [{'alpha': 0.0003438092427379191, 'batch_size': 138, 'beta_1': 0.9028295471485217, 'beta_2': 0.9214899253417186, 'epsilon': 3.1758771619596605e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0054103340803412945, 'tol': 0.01882345586469253, 'validation_fraction': 0.2410392147271943}]
function_evaluation time 0.417150 value -0.961723 suggestion {'alpha': 0.0003438092427379191, 'batch_size': 138, 'beta_1': 0.9028295471485217, 'beta_2': 0.9214899253417186, 'epsilon': 3.1758771619596605e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0054103340803412945, 'tol': 0.01882345586469253, 'validation_fraction': 0.2410392147271943}
observation time 0.000074, current best -0.970081 at iter 6
suggestion time taken 0.002221 iter 7 next_points [{'alpha': 0.0006447283660145482, 'batch_size': 55, 'beta_1': 0.8193238008775451, 'beta_2': 0.9108781887762957, 'epsilon': 7.532917508310375e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.017191892098829962, 'tol': 0.007116771664596587, 'validation_fraction': 0.4306712982647878}]
function_evaluation time 1.086746 value -0.954759 suggestion {'alpha': 0.0006447283660145482, 'batch_size': 55, 'beta_1': 0.8193238008775451, 'beta_2': 0.9108781887762957, 'epsilon': 7.532917508310375e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.017191892098829962, 'tol': 0.007116771664596587, 'validation_fraction': 0.4306712982647878}
observation time 0.000072, current best -0.970081 at iter 7
suggestion time taken 0.002158 iter 8 next_points [{'alpha': 3.626663857213165, 'batch_size': 36, 'beta_1': 0.6693400878566534, 'beta_2': 0.9326320012705824, 'epsilon': 1.1888578801480006e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.08936532919782313, 'tol': 0.00688166737013413, 'validation_fraction': 0.2612811010222246}]
function_evaluation time 0.985823 value -0.333360 suggestion {'alpha': 3.626663857213165, 'batch_size': 36, 'beta_1': 0.6693400878566534, 'beta_2': 0.9326320012705824, 'epsilon': 1.1888578801480006e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.08936532919782313, 'tol': 0.00688166737013413, 'validation_fraction': 0.2612811010222246}
observation time 0.000072, current best -0.970081 at iter 8
suggestion time taken 0.002115 iter 9 next_points [{'alpha': 0.1655491644128336, 'batch_size': 79, 'beta_1': 0.7589806890402263, 'beta_2': 0.9806068684127947, 'epsilon': 1.308532653719704e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.008498867752203538, 'tol': 0.00030251267802544927, 'validation_fraction': 0.15665554330385892}]
function_evaluation time 1.025983 value -0.968680 suggestion {'alpha': 0.1655491644128336, 'batch_size': 79, 'beta_1': 0.7589806890402263, 'beta_2': 0.9806068684127947, 'epsilon': 1.308532653719704e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.008498867752203538, 'tol': 0.00030251267802544927, 'validation_fraction': 0.15665554330385892}
observation time 0.000074, current best -0.970081 at iter 9
suggestion time taken 0.002360 iter 10 next_points [{'alpha': 6.520585843326761, 'batch_size': 219, 'beta_1': 0.6346659033159752, 'beta_2': 0.9262947980980344, 'epsilon': 5.597627277186591e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.06279034942486204, 'tol': 2.1595089124963536e-05, 'validation_fraction': 0.7844928025098442}]
function_evaluation time 0.335964 value -0.769023 suggestion {'alpha': 6.520585843326761, 'batch_size': 219, 'beta_1': 0.6346659033159752, 'beta_2': 0.9262947980980344, 'epsilon': 5.597627277186591e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.06279034942486204, 'tol': 2.1595089124963536e-05, 'validation_fraction': 0.7844928025098442}
observation time 0.000071, current best -0.970081 at iter 10
suggestion time taken 0.002115 iter 11 next_points [{'alpha': 7.028706030978997e-05, 'batch_size': 27, 'beta_1': 0.8147062601328924, 'beta_2': 0.9487602602011735, 'epsilon': 6.055933783211537e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.013265363866013357, 'tol': 0.00021918486568330695, 'validation_fraction': 0.4091952778828248}]
function_evaluation time 1.981491 value -0.945712 suggestion {'alpha': 7.028706030978997e-05, 'batch_size': 27, 'beta_1': 0.8147062601328924, 'beta_2': 0.9487602602011735, 'epsilon': 6.055933783211537e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.013265363866013357, 'tol': 0.00021918486568330695, 'validation_fraction': 0.4091952778828248}
observation time 0.000074, current best -0.970081 at iter 11
suggestion time taken 0.002142 iter 12 next_points [{'alpha': 7.2588642039945235, 'batch_size': 34, 'beta_1': 0.6808144440458583, 'beta_2': 0.9172862356977012, 'epsilon': 5.5053350073821796e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.053751235301140045, 'tol': 7.676445335499956e-05, 'validation_fraction': 0.31608276361412463}]
function_evaluation time 1.284621 value -0.764196 suggestion {'alpha': 7.2588642039945235, 'batch_size': 34, 'beta_1': 0.6808144440458583, 'beta_2': 0.9172862356977012, 'epsilon': 5.5053350073821796e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.053751235301140045, 'tol': 7.676445335499956e-05, 'validation_fraction': 0.31608276361412463}
observation time 0.000074, current best -0.970081 at iter 12
suggestion time taken 0.002178 iter 13 next_points [{'alpha': 0.0001314184375458125, 'batch_size': 21, 'beta_1': 0.8269368437220734, 'beta_2': 0.9541941851086518, 'epsilon': 1.1543929378425385e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.013956193508004883, 'tol': 1.899717087116722e-05, 'validation_fraction': 0.7934276671369337}]
function_evaluation time 0.881006 value -0.919309 suggestion {'alpha': 0.0001314184375458125, 'batch_size': 21, 'beta_1': 0.8269368437220734, 'beta_2': 0.9541941851086518, 'epsilon': 1.1543929378425385e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.013956193508004883, 'tol': 1.899717087116722e-05, 'validation_fraction': 0.7934276671369337}
observation time 0.000072, current best -0.970081 at iter 13
suggestion time taken 0.002112 iter 14 next_points [{'alpha': 0.833998776316156, 'batch_size': 144, 'beta_1': 0.9533894554328964, 'beta_2': 0.9611304030919626, 'epsilon': 1.1833506307685614e-09, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.001689147757964416, 'tol': 0.000858833696562912, 'validation_fraction': 0.12991055183446648}]
function_evaluation time 1.070677 value -0.965904 suggestion {'alpha': 0.833998776316156, 'batch_size': 144, 'beta_1': 0.9533894554328964, 'beta_2': 0.9611304030919626, 'epsilon': 1.1833506307685614e-09, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.001689147757964416, 'tol': 0.000858833696562912, 'validation_fraction': 0.12991055183446648}
observation time 0.000074, current best -0.970081 at iter 14
saving meta data: {'args': {'--uuid': 'f7be7b327ada53809b74986b33c67846', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

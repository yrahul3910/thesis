running: {'--uuid': '6e6d9b62ad9f507eb3ea5eed21e0d512', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 6e6d9b62ad9f507eb3ea5eed21e0d512 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002385 iter 0 next_points [{'alpha': 0.0016181083078939719, 'batch_size': 196, 'beta_1': 0.7076352342506146, 'beta_2': 0.9757789158419842, 'epsilon': 1.1212713599604395e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.00023778093318602378, 'tol': 0.004233290767499085, 'validation_fraction': 0.6076753776707527}]
function_evaluation time 1.731339 value -0.897026 suggestion {'alpha': 0.0016181083078939719, 'batch_size': 196, 'beta_1': 0.7076352342506146, 'beta_2': 0.9757789158419842, 'epsilon': 1.1212713599604395e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.00023778093318602378, 'tol': 0.004233290767499085, 'validation_fraction': 0.6076753776707527}
observation time 0.000068, current best -0.897026 at iter 0
suggestion time taken 0.002373 iter 1 next_points [{'alpha': 4.826864686646393, 'batch_size': 152, 'beta_1': 0.7666074588532624, 'beta_2': 0.9146303281068702, 'epsilon': 1.9950286403247123e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.00023504227212831327, 'tol': 0.02292450361558141, 'validation_fraction': 0.12822972199807348}]
function_evaluation time 1.014020 value -0.910920 suggestion {'alpha': 4.826864686646393, 'batch_size': 152, 'beta_1': 0.7666074588532624, 'beta_2': 0.9146303281068702, 'epsilon': 1.9950286403247123e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.00023504227212831327, 'tol': 0.02292450361558141, 'validation_fraction': 0.12822972199807348}
observation time 0.000069, current best -0.910920 at iter 1
suggestion time taken 0.002355 iter 2 next_points [{'alpha': 0.020414629906313264, 'batch_size': 150, 'beta_1': 0.6222589191848429, 'beta_2': 0.9891043912165316, 'epsilon': 2.679465039718905e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 3.287207486150893e-05, 'tol': 0.0014724540327677909, 'validation_fraction': 0.5276272853160835}]
function_evaluation time 2.040438 value -0.276650 suggestion {'alpha': 0.020414629906313264, 'batch_size': 150, 'beta_1': 0.6222589191848429, 'beta_2': 0.9891043912165316, 'epsilon': 2.679465039718905e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 3.287207486150893e-05, 'tol': 0.0014724540327677909, 'validation_fraction': 0.5276272853160835}
observation time 0.000070, current best -0.910920 at iter 2
suggestion time taken 0.002168 iter 3 next_points [{'alpha': 0.0004577782043318478, 'batch_size': 31, 'beta_1': 0.8008122193432722, 'beta_2': 0.9526487851975628, 'epsilon': 3.7307755989493235e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0005904401217127173, 'tol': 0.0006224741280264986, 'validation_fraction': 0.11235721825587146}]
function_evaluation time 1.979954 value -0.967988 suggestion {'alpha': 0.0004577782043318478, 'batch_size': 31, 'beta_1': 0.8008122193432722, 'beta_2': 0.9526487851975628, 'epsilon': 3.7307755989493235e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0005904401217127173, 'tol': 0.0006224741280264986, 'validation_fraction': 0.11235721825587146}
observation time 0.000070, current best -0.967988 at iter 3
suggestion time taken 0.002146 iter 4 next_points [{'alpha': 1.1568092003144371e-05, 'batch_size': 235, 'beta_1': 0.66889364516756, 'beta_2': 0.9557056303561893, 'epsilon': 5.753238922857833e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 5.9037216881581356e-05, 'tol': 0.0017217513702332276, 'validation_fraction': 0.5123239141601795}]
function_evaluation time 2.723793 value -0.733958 suggestion {'alpha': 1.1568092003144371e-05, 'batch_size': 235, 'beta_1': 0.66889364516756, 'beta_2': 0.9557056303561893, 'epsilon': 5.753238922857833e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 5.9037216881581356e-05, 'tol': 0.0017217513702332276, 'validation_fraction': 0.5123239141601795}
observation time 0.000070, current best -0.967988 at iter 4
suggestion time taken 0.002156 iter 5 next_points [{'alpha': 5.339136683802429e-05, 'batch_size': 204, 'beta_1': 0.6515494169423981, 'beta_2': 0.9933198750730292, 'epsilon': 5.305966880075964e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0014228888867483902, 'tol': 0.0027189143319421823, 'validation_fraction': 0.14822105856504628}]
function_evaluation time 1.004370 value -0.938071 suggestion {'alpha': 5.339136683802429e-05, 'batch_size': 204, 'beta_1': 0.6515494169423981, 'beta_2': 0.9933198750730292, 'epsilon': 5.305966880075964e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0014228888867483902, 'tol': 0.0027189143319421823, 'validation_fraction': 0.14822105856504628}
observation time 0.000072, current best -0.967988 at iter 5
suggestion time taken 0.002169 iter 6 next_points [{'alpha': 0.5817049823372871, 'batch_size': 142, 'beta_1': 0.9510574743801549, 'beta_2': 0.977955489814895, 'epsilon': 8.426470905528739e-07, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.0045566457133574415, 'tol': 1.2218833736815147e-05, 'validation_fraction': 0.21980151152053673}]
function_evaluation time 1.009821 value -0.962432 suggestion {'alpha': 0.5817049823372871, 'batch_size': 142, 'beta_1': 0.9510574743801549, 'beta_2': 0.977955489814895, 'epsilon': 8.426470905528739e-07, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.0045566457133574415, 'tol': 1.2218833736815147e-05, 'validation_fraction': 0.21980151152053673}
observation time 0.000075, current best -0.967988 at iter 6
suggestion time taken 0.002204 iter 7 next_points [{'alpha': 0.0005385282721740646, 'batch_size': 55, 'beta_1': 0.6376381102423078, 'beta_2': 0.989747375680143, 'epsilon': 3.991970772168004e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.042350540290164294, 'tol': 0.00013044854989539568, 'validation_fraction': 0.6470438946326534}]
function_evaluation time 0.826378 value -0.939465 suggestion {'alpha': 0.0005385282721740646, 'batch_size': 55, 'beta_1': 0.6376381102423078, 'beta_2': 0.989747375680143, 'epsilon': 3.991970772168004e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.042350540290164294, 'tol': 0.00013044854989539568, 'validation_fraction': 0.6470438946326534}
observation time 0.000075, current best -0.967988 at iter 7
suggestion time taken 0.002132 iter 8 next_points [{'alpha': 0.07148051650063567, 'batch_size': 210, 'beta_1': 0.9733605985649219, 'beta_2': 0.9616296631343265, 'epsilon': 4.803313129324701e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 6.173345378338863e-05, 'tol': 3.472713689103324e-05, 'validation_fraction': 0.11950092139391888}]
function_evaluation time 3.492953 value -0.735339 suggestion {'alpha': 0.07148051650063567, 'batch_size': 210, 'beta_1': 0.9733605985649219, 'beta_2': 0.9616296631343265, 'epsilon': 4.803313129324701e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 6.173345378338863e-05, 'tol': 3.472713689103324e-05, 'validation_fraction': 0.11950092139391888}
observation time 0.000074, current best -0.967988 at iter 8
suggestion time taken 0.002435 iter 9 next_points [{'alpha': 0.0008034610242786263, 'batch_size': 225, 'beta_1': 0.5448920530905643, 'beta_2': 0.911914151414402, 'epsilon': 1.1974337614875181e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.0033028442451905502, 'tol': 2.2987770289786033e-05, 'validation_fraction': 0.2676527098746943}]
function_evaluation time 1.058916 value -0.975639 suggestion {'alpha': 0.0008034610242786263, 'batch_size': 225, 'beta_1': 0.5448920530905643, 'beta_2': 0.911914151414402, 'epsilon': 1.1974337614875181e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.0033028442451905502, 'tol': 2.2987770289786033e-05, 'validation_fraction': 0.2676527098746943}
observation time 0.000074, current best -0.975639 at iter 9
suggestion time taken 0.002159 iter 10 next_points [{'alpha': 9.448934129178513, 'batch_size': 236, 'beta_1': 0.9356351103307453, 'beta_2': 0.9264617662859937, 'epsilon': 6.7717911662753326e-09, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.011662008869136839, 'tol': 0.0012268852173786143, 'validation_fraction': 0.20661851199426887}]
function_evaluation time 0.749395 value -0.966599 suggestion {'alpha': 9.448934129178513, 'batch_size': 236, 'beta_1': 0.9356351103307453, 'beta_2': 0.9264617662859937, 'epsilon': 6.7717911662753326e-09, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.011662008869136839, 'tol': 0.0012268852173786143, 'validation_fraction': 0.20661851199426887}
observation time 0.000077, current best -0.975639 at iter 10
suggestion time taken 0.002134 iter 11 next_points [{'alpha': 0.0009306731164681016, 'batch_size': 153, 'beta_1': 0.900742783143957, 'beta_2': 0.9670026266503939, 'epsilon': 2.6441858374809243e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 6.770642843587324e-05, 'tol': 0.0001688771439681834, 'validation_fraction': 0.322846025923786}]
function_evaluation time 4.418555 value -0.919261 suggestion {'alpha': 0.0009306731164681016, 'batch_size': 153, 'beta_1': 0.900742783143957, 'beta_2': 0.9670026266503939, 'epsilon': 2.6441858374809243e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 6.770642843587324e-05, 'tol': 0.0001688771439681834, 'validation_fraction': 0.322846025923786}
observation time 0.000072, current best -0.975639 at iter 11
suggestion time taken 0.002164 iter 12 next_points [{'alpha': 0.00014382562334549692, 'batch_size': 143, 'beta_1': 0.8904301987965703, 'beta_2': 0.9881973722770199, 'epsilon': 4.979657598598997e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.00018816901030072362, 'tol': 0.04868697094741174, 'validation_fraction': 0.7155100827146113}]
function_evaluation time 0.250514 value -0.265200 suggestion {'alpha': 0.00014382562334549692, 'batch_size': 143, 'beta_1': 0.8904301987965703, 'beta_2': 0.9881973722770199, 'epsilon': 4.979657598598997e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.00018816901030072362, 'tol': 0.04868697094741174, 'validation_fraction': 0.7155100827146113}
observation time 0.000073, current best -0.975639 at iter 12
suggestion time taken 0.002181 iter 13 next_points [{'alpha': 0.044119115131803666, 'batch_size': 71, 'beta_1': 0.5381994590502825, 'beta_2': 0.9581178418232341, 'epsilon': 4.81086578127688e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.024141989234340078, 'tol': 0.00602109989118028, 'validation_fraction': 0.43855431651969634}]
function_evaluation time 0.682488 value -0.954745 suggestion {'alpha': 0.044119115131803666, 'batch_size': 71, 'beta_1': 0.5381994590502825, 'beta_2': 0.9581178418232341, 'epsilon': 4.81086578127688e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.024141989234340078, 'tol': 0.00602109989118028, 'validation_fraction': 0.43855431651969634}
observation time 0.000076, current best -0.975639 at iter 13
suggestion time taken 0.002182 iter 14 next_points [{'alpha': 5.1361070370063114e-05, 'batch_size': 31, 'beta_1': 0.6752480923045829, 'beta_2': 0.9049283723315525, 'epsilon': 4.859470094168038e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 1.716789454674569e-05, 'tol': 0.00019470688856792643, 'validation_fraction': 0.1954070315134247}]
function_evaluation time 6.796859 value -0.751832 suggestion {'alpha': 5.1361070370063114e-05, 'batch_size': 31, 'beta_1': 0.6752480923045829, 'beta_2': 0.9049283723315525, 'epsilon': 4.859470094168038e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 1.716789454674569e-05, 'tol': 0.00019470688856792643, 'validation_fraction': 0.1954070315134247}
observation time 0.000076, current best -0.975639 at iter 14
saving meta data: {'args': {'--uuid': '6e6d9b62ad9f507eb3ea5eed21e0d512', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

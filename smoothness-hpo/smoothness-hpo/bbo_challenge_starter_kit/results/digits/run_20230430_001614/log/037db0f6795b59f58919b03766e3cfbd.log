running: {'--uuid': '037db0f6795b59f58919b03766e3cfbd', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d digits -o random-search -u 037db0f6795b59f58919b03766e3cfbd -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study random-search MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002585 iter 0 next_points [{'alpha': 5.2493264620941194e-05, 'batch_size': 199, 'beta_1': 0.9813683998005315, 'beta_2': 0.9785710853574244, 'epsilon': 6.140279129056577e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.022485257599711806, 'tol': 0.03807983121248257, 'validation_fraction': 0.12669936542293123}]
function_evaluation time 0.425874 value -0.903305 suggestion {'alpha': 5.2493264620941194e-05, 'batch_size': 199, 'beta_1': 0.9813683998005315, 'beta_2': 0.9785710853574244, 'epsilon': 6.140279129056577e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.022485257599711806, 'tol': 0.03807983121248257, 'validation_fraction': 0.12669936542293123}
observation time 0.000007, current best -0.903305 at iter 0
suggestion time taken 0.002572 iter 1 next_points [{'alpha': 6.98966167507982e-05, 'batch_size': 101, 'beta_1': 0.7870541014288139, 'beta_2': 0.9298779437511453, 'epsilon': 1.7766740213398264e-07, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.00012430215916825563, 'tol': 7.109258407246691e-05, 'validation_fraction': 0.2282588223694936}]
function_evaluation time 3.191573 value -0.936680 suggestion {'alpha': 6.98966167507982e-05, 'batch_size': 101, 'beta_1': 0.7870541014288139, 'beta_2': 0.9298779437511453, 'epsilon': 1.7766740213398264e-07, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.00012430215916825563, 'tol': 7.109258407246691e-05, 'validation_fraction': 0.2282588223694936}
observation time 0.000005, current best -0.936680 at iter 1
suggestion time taken 0.002494 iter 2 next_points [{'alpha': 0.00012197683775843778, 'batch_size': 245, 'beta_1': 0.6507292343837635, 'beta_2': 0.9990764052840133, 'epsilon': 5.287169572714316e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.0015098674186535958, 'tol': 2.862990750264e-05, 'validation_fraction': 0.6181488488882338}]
function_evaluation time 1.495065 value -0.925544 suggestion {'alpha': 0.00012197683775843778, 'batch_size': 245, 'beta_1': 0.6507292343837635, 'beta_2': 0.9990764052840133, 'epsilon': 5.287169572714316e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.0015098674186535958, 'tol': 2.862990750264e-05, 'validation_fraction': 0.6181488488882338}
observation time 0.000005, current best -0.936680 at iter 2
suggestion time taken 0.002534 iter 3 next_points [{'alpha': 0.002909664324470952, 'batch_size': 19, 'beta_1': 0.9811318516187537, 'beta_2': 0.9999638763186323, 'epsilon': 2.8866123369951213e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.028042340283258357, 'tol': 0.0031860823018667753, 'validation_fraction': 0.8540452961312077}]
function_evaluation time 0.902309 value -0.853813 suggestion {'alpha': 0.002909664324470952, 'batch_size': 19, 'beta_1': 0.9811318516187537, 'beta_2': 0.9999638763186323, 'epsilon': 2.8866123369951213e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.028042340283258357, 'tol': 0.0031860823018667753, 'validation_fraction': 0.8540452961312077}
observation time 0.000005, current best -0.936680 at iter 3
suggestion time taken 0.002515 iter 4 next_points [{'alpha': 0.0008007124107934072, 'batch_size': 237, 'beta_1': 0.605041240674687, 'beta_2': 0.9895866054909435, 'epsilon': 3.0455746100865197e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.020247983681637972, 'tol': 0.000432295044342473, 'validation_fraction': 0.5368381903819357}]
function_evaluation time 0.675771 value -0.947822 suggestion {'alpha': 0.0008007124107934072, 'batch_size': 237, 'beta_1': 0.605041240674687, 'beta_2': 0.9895866054909435, 'epsilon': 3.0455746100865197e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.020247983681637972, 'tol': 0.000432295044342473, 'validation_fraction': 0.5368381903819357}
observation time 0.000004, current best -0.947822 at iter 4
suggestion time taken 0.002532 iter 5 next_points [{'alpha': 0.002971199083039704, 'batch_size': 28, 'beta_1': 0.9804760679928712, 'beta_2': 0.9969503048902032, 'epsilon': 3.735906284270784e-08, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.00014507961122000768, 'tol': 1.04922935745571e-05, 'validation_fraction': 0.5245630577815369}]
function_evaluation time 4.485556 value -0.942939 suggestion {'alpha': 0.002971199083039704, 'batch_size': 28, 'beta_1': 0.9804760679928712, 'beta_2': 0.9969503048902032, 'epsilon': 3.735906284270784e-08, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.00014507961122000768, 'tol': 1.04922935745571e-05, 'validation_fraction': 0.5245630577815369}
observation time 0.000005, current best -0.947822 at iter 5
suggestion time taken 0.002578 iter 6 next_points [{'alpha': 0.03548642892867621, 'batch_size': 14, 'beta_1': 0.9613946416856508, 'beta_2': 0.9998487585374453, 'epsilon': 1.0808631986667961e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.0030604627219433045, 'tol': 0.015826346578612267, 'validation_fraction': 0.23703123180679905}]
function_evaluation time 1.408530 value -0.958943 suggestion {'alpha': 0.03548642892867621, 'batch_size': 14, 'beta_1': 0.9613946416856508, 'beta_2': 0.9998487585374453, 'epsilon': 1.0808631986667961e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.0030604627219433045, 'tol': 0.015826346578612267, 'validation_fraction': 0.23703123180679905}
observation time 0.000005, current best -0.958943 at iter 6
suggestion time taken 0.002443 iter 7 next_points [{'alpha': 5.8059053391178, 'batch_size': 57, 'beta_1': 0.9102793966175209, 'beta_2': 0.9424481769974852, 'epsilon': 3.303231904420161e-07, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.026845738355314282, 'tol': 0.000986255693363933, 'validation_fraction': 0.18827008447923735}]
function_evaluation time 1.195383 value -0.935980 suggestion {'alpha': 5.8059053391178, 'batch_size': 57, 'beta_1': 0.9102793966175209, 'beta_2': 0.9424481769974852, 'epsilon': 3.303231904420161e-07, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.026845738355314282, 'tol': 0.000986255693363933, 'validation_fraction': 0.18827008447923735}
observation time 0.000004, current best -0.958943 at iter 7
suggestion time taken 0.002534 iter 8 next_points [{'alpha': 0.06951238722715436, 'batch_size': 164, 'beta_1': 0.704923703234234, 'beta_2': 0.9894503276602903, 'epsilon': 1.9694006229806705e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.0009248781819127559, 'tol': 0.0002076613255365865, 'validation_fraction': 0.7943515384644351}]
function_evaluation time 1.560106 value -0.911629 suggestion {'alpha': 0.06951238722715436, 'batch_size': 164, 'beta_1': 0.704923703234234, 'beta_2': 0.9894503276602903, 'epsilon': 1.9694006229806705e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.0009248781819127559, 'tol': 0.0002076613255365865, 'validation_fraction': 0.7943515384644351}
observation time 0.000004, current best -0.958943 at iter 8
suggestion time taken 0.002520 iter 9 next_points [{'alpha': 2.527608933427093, 'batch_size': 145, 'beta_1': 0.8716095867206444, 'beta_2': 0.9996299435028846, 'epsilon': 1.5609467818875146e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.008129424103774052, 'tol': 5.9860077695985794e-05, 'validation_fraction': 0.1485575671390845}]
function_evaluation time 0.723780 value -0.964511 suggestion {'alpha': 2.527608933427093, 'batch_size': 145, 'beta_1': 0.8716095867206444, 'beta_2': 0.9996299435028846, 'epsilon': 1.5609467818875146e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.008129424103774052, 'tol': 5.9860077695985794e-05, 'validation_fraction': 0.1485575671390845}
observation time 0.000005, current best -0.964511 at iter 9
suggestion time taken 0.002511 iter 10 next_points [{'alpha': 5.9247225420886056e-05, 'batch_size': 29, 'beta_1': 0.9720210801792182, 'beta_2': 0.9998011911506052, 'epsilon': 1.9314994045974797e-08, 'hidden_layer_sizes': 78, 'learning_rate_init': 1.5740786635758216e-05, 'tol': 0.0013132640949386335, 'validation_fraction': 0.25189736791758854}]
function_evaluation time 11.742502 value -0.864975 suggestion {'alpha': 5.9247225420886056e-05, 'batch_size': 29, 'beta_1': 0.9720210801792182, 'beta_2': 0.9998011911506052, 'epsilon': 1.9314994045974797e-08, 'hidden_layer_sizes': 78, 'learning_rate_init': 1.5740786635758216e-05, 'tol': 0.0013132640949386335, 'validation_fraction': 0.25189736791758854}
observation time 0.000005, current best -0.964511 at iter 10
suggestion time taken 0.002511 iter 11 next_points [{'alpha': 0.9504575890657152, 'batch_size': 221, 'beta_1': 0.9371943597545449, 'beta_2': 0.9152936719196085, 'epsilon': 4.372211087371086e-08, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.0029121285029385453, 'tol': 8.993360733829494e-05, 'validation_fraction': 0.8698713285372016}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.658082 value -0.885165 suggestion {'alpha': 0.9504575890657152, 'batch_size': 221, 'beta_1': 0.9371943597545449, 'beta_2': 0.9152936719196085, 'epsilon': 4.372211087371086e-08, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.0029121285029385453, 'tol': 8.993360733829494e-05, 'validation_fraction': 0.8698713285372016}
observation time 0.000004, current best -0.964511 at iter 11
suggestion time taken 0.002518 iter 12 next_points [{'alpha': 0.001249171840244342, 'batch_size': 110, 'beta_1': 0.9883806734903678, 'beta_2': 0.9877852876972484, 'epsilon': 1.561301562096824e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.021951392265961135, 'tol': 0.009570565110020293, 'validation_fraction': 0.6954644902329781}]
function_evaluation time 0.651700 value -0.906748 suggestion {'alpha': 0.001249171840244342, 'batch_size': 110, 'beta_1': 0.9883806734903678, 'beta_2': 0.9877852876972484, 'epsilon': 1.561301562096824e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.021951392265961135, 'tol': 0.009570565110020293, 'validation_fraction': 0.6954644902329781}
observation time 0.000004, current best -0.964511 at iter 12
suggestion time taken 0.002782 iter 13 next_points [{'alpha': 0.00025904666961502193, 'batch_size': 112, 'beta_1': 0.5650286130517348, 'beta_2': 0.9987018220175337, 'epsilon': 6.797223224333335e-08, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.0028427969986065766, 'tol': 4.5184426097348235e-05, 'validation_fraction': 0.6095565970219393}]
function_evaluation time 1.126189 value -0.949891 suggestion {'alpha': 0.00025904666961502193, 'batch_size': 112, 'beta_1': 0.5650286130517348, 'beta_2': 0.9987018220175337, 'epsilon': 6.797223224333335e-08, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.0028427969986065766, 'tol': 4.5184426097348235e-05, 'validation_fraction': 0.6095565970219393}
observation time 0.000005, current best -0.964511 at iter 13
suggestion time taken 0.002574 iter 14 next_points [{'alpha': 3.323763588535189e-05, 'batch_size': 214, 'beta_1': 0.617107338674254, 'beta_2': 0.9999974847682137, 'epsilon': 1.1944327320843098e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0004765467723047816, 'tol': 0.06330743950621363, 'validation_fraction': 0.7342185479907989}]
function_evaluation time 0.211208 value -0.387669 suggestion {'alpha': 3.323763588535189e-05, 'batch_size': 214, 'beta_1': 0.617107338674254, 'beta_2': 0.9999974847682137, 'epsilon': 1.1944327320843098e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0004765467723047816, 'tol': 0.06330743950621363, 'validation_fraction': 0.7342185479907989}
observation time 0.000004, current best -0.964511 at iter 14
saving meta data: {'args': {'--uuid': '037db0f6795b59f58919b03766e3cfbd', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

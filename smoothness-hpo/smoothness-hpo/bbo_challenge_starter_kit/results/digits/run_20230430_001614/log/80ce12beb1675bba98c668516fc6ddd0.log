running: {'--uuid': '80ce12beb1675bba98c668516fc6ddd0', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d digits -o random-search -u 80ce12beb1675bba98c668516fc6ddd0 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study random-search MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002542 iter 0 next_points [{'alpha': 3.3134949869110936e-05, 'batch_size': 189, 'beta_1': 0.5078879332158398, 'beta_2': 0.9999982931123708, 'epsilon': 2.9950163853340037e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0003217759888539054, 'tol': 0.0016404392131312059, 'validation_fraction': 0.6987493711012129}]
function_evaluation time 2.027177 value -0.869839 suggestion {'alpha': 3.3134949869110936e-05, 'batch_size': 189, 'beta_1': 0.5078879332158398, 'beta_2': 0.9999982931123708, 'epsilon': 2.9950163853340037e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0003217759888539054, 'tol': 0.0016404392131312059, 'validation_fraction': 0.6987493711012129}
observation time 0.000006, current best -0.869839 at iter 0
suggestion time taken 0.002717 iter 1 next_points [{'alpha': 0.02828732379066466, 'batch_size': 227, 'beta_1': 0.9808450944464882, 'beta_2': 0.9996323619271256, 'epsilon': 3.086214875245087e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 2.3574689323838727e-05, 'tol': 0.0007614523679606786, 'validation_fraction': 0.5685375201743715}]
function_evaluation time 2.539874 value -0.419650 suggestion {'alpha': 0.02828732379066466, 'batch_size': 227, 'beta_1': 0.9808450944464882, 'beta_2': 0.9996323619271256, 'epsilon': 3.086214875245087e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 2.3574689323838727e-05, 'tol': 0.0007614523679606786, 'validation_fraction': 0.5685375201743715}
observation time 0.000004, current best -0.869839 at iter 1
suggestion time taken 0.002496 iter 2 next_points [{'alpha': 0.02148808437164655, 'batch_size': 70, 'beta_1': 0.8917858483024865, 'beta_2': 0.999230014499827, 'epsilon': 7.139858223353201e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0016121626669798167, 'tol': 0.002367216589800636, 'validation_fraction': 0.3077197448013185}]
function_evaluation time 1.284607 value -0.956867 suggestion {'alpha': 0.02148808437164655, 'batch_size': 70, 'beta_1': 0.8917858483024865, 'beta_2': 0.999230014499827, 'epsilon': 7.139858223353201e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0016121626669798167, 'tol': 0.002367216589800636, 'validation_fraction': 0.3077197448013185}
observation time 0.000004, current best -0.956867 at iter 2
suggestion time taken 0.002495 iter 3 next_points [{'alpha': 0.21894831552040395, 'batch_size': 42, 'beta_1': 0.950827033335225, 'beta_2': 0.9687928195188953, 'epsilon': 6.610667242515749e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 1.055309086436326e-05, 'tol': 0.055998786753001586, 'validation_fraction': 0.7815861801523515}]
function_evaluation time 0.229539 value -0.127996 suggestion {'alpha': 0.21894831552040395, 'batch_size': 42, 'beta_1': 0.950827033335225, 'beta_2': 0.9687928195188953, 'epsilon': 6.610667242515749e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 1.055309086436326e-05, 'tol': 0.055998786753001586, 'validation_fraction': 0.7815861801523515}
observation time 0.000005, current best -0.956867 at iter 3
suggestion time taken 0.002455 iter 4 next_points [{'alpha': 0.06878852336308344, 'batch_size': 194, 'beta_1': 0.7695819954413617, 'beta_2': 0.9756524561580103, 'epsilon': 1.3035860364827164e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.023872386398442524, 'tol': 0.017402087741238286, 'validation_fraction': 0.6052820607611599}]
function_evaluation time 0.413148 value -0.947111 suggestion {'alpha': 0.06878852336308344, 'batch_size': 194, 'beta_1': 0.7695819954413617, 'beta_2': 0.9756524561580103, 'epsilon': 1.3035860364827164e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.023872386398442524, 'tol': 0.017402087741238286, 'validation_fraction': 0.6052820607611599}
observation time 0.000004, current best -0.956867 at iter 4
suggestion time taken 0.002422 iter 5 next_points [{'alpha': 1.561582806067043, 'batch_size': 28, 'beta_1': 0.9691375978948619, 'beta_2': 0.9999823236868486, 'epsilon': 5.873001442021117e-08, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.0002877913189697746, 'tol': 0.006246348134360742, 'validation_fraction': 0.6178766227707168}]
function_evaluation time 1.254032 value -0.925547 suggestion {'alpha': 1.561582806067043, 'batch_size': 28, 'beta_1': 0.9691375978948619, 'beta_2': 0.9999823236868486, 'epsilon': 5.873001442021117e-08, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.0002877913189697746, 'tol': 0.006246348134360742, 'validation_fraction': 0.6178766227707168}
observation time 0.000005, current best -0.956867 at iter 5
suggestion time taken 0.002401 iter 6 next_points [{'alpha': 0.03520233366550598, 'batch_size': 240, 'beta_1': 0.7336301901711287, 'beta_2': 0.9043320149373679, 'epsilon': 3.9055392719237226e-07, 'hidden_layer_sizes': 171, 'learning_rate_init': 9.894304956762545e-05, 'tol': 4.5680894487566634e-05, 'validation_fraction': 0.17755250121760066}]
function_evaluation time 2.709909 value -0.940154 suggestion {'alpha': 0.03520233366550598, 'batch_size': 240, 'beta_1': 0.7336301901711287, 'beta_2': 0.9043320149373679, 'epsilon': 3.9055392719237226e-07, 'hidden_layer_sizes': 171, 'learning_rate_init': 9.894304956762545e-05, 'tol': 4.5680894487566634e-05, 'validation_fraction': 0.17755250121760066}
observation time 0.000004, current best -0.956867 at iter 6
suggestion time taken 0.002430 iter 7 next_points [{'alpha': 1.3082497396433062e-05, 'batch_size': 52, 'beta_1': 0.9879313654497317, 'beta_2': 0.9999884812161997, 'epsilon': 3.95093188944127e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.004136483793284414, 'tol': 0.010291911765428692, 'validation_fraction': 0.891259253223533}]
function_evaluation time 0.405484 value -0.851769 suggestion {'alpha': 1.3082497396433062e-05, 'batch_size': 52, 'beta_1': 0.9879313654497317, 'beta_2': 0.9999884812161997, 'epsilon': 3.95093188944127e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.004136483793284414, 'tol': 0.010291911765428692, 'validation_fraction': 0.891259253223533}
observation time 0.000005, current best -0.956867 at iter 7
suggestion time taken 0.002521 iter 8 next_points [{'alpha': 2.9920197109350826e-05, 'batch_size': 174, 'beta_1': 0.981994684133022, 'beta_2': 0.9999900776012001, 'epsilon': 1.5206608459591464e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.00035359420699954315, 'tol': 0.0007910256553901687, 'validation_fraction': 0.7105210661059301}]
function_evaluation time 1.884017 value -0.903988 suggestion {'alpha': 2.9920197109350826e-05, 'batch_size': 174, 'beta_1': 0.981994684133022, 'beta_2': 0.9999900776012001, 'epsilon': 1.5206608459591464e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.00035359420699954315, 'tol': 0.0007910256553901687, 'validation_fraction': 0.7105210661059301}
observation time 0.000005, current best -0.956867 at iter 8
suggestion time taken 0.002439 iter 9 next_points [{'alpha': 4.174038943749327, 'batch_size': 54, 'beta_1': 0.9805707977474656, 'beta_2': 0.9999981703551105, 'epsilon': 6.463673919748323e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0006303478541324665, 'tol': 0.011295351965909545, 'validation_fraction': 0.14465445368865726}]
function_evaluation time 1.259131 value -0.950607 suggestion {'alpha': 4.174038943749327, 'batch_size': 54, 'beta_1': 0.9805707977474656, 'beta_2': 0.9999981703551105, 'epsilon': 6.463673919748323e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0006303478541324665, 'tol': 0.011295351965909545, 'validation_fraction': 0.14465445368865726}
observation time 0.000005, current best -0.956867 at iter 9
suggestion time taken 0.002475 iter 10 next_points [{'alpha': 0.00033692721284607247, 'batch_size': 85, 'beta_1': 0.983854062349586, 'beta_2': 0.9959263905198973, 'epsilon': 5.000603257384095e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0007629030737838629, 'tol': 0.00013401944808666744, 'validation_fraction': 0.5023804338364671}]
function_evaluation time 1.666697 value -0.941543 suggestion {'alpha': 0.00033692721284607247, 'batch_size': 85, 'beta_1': 0.983854062349586, 'beta_2': 0.9959263905198973, 'epsilon': 5.000603257384095e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0007629030737838629, 'tol': 0.00013401944808666744, 'validation_fraction': 0.5023804338364671}
observation time 0.000004, current best -0.956867 at iter 10
suggestion time taken 0.002457 iter 11 next_points [{'alpha': 1.1479651626651807e-05, 'batch_size': 243, 'beta_1': 0.9871922104631748, 'beta_2': 0.999998928361737, 'epsilon': 1.1304299685022383e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.04677564999396191, 'tol': 0.0018603185437369235, 'validation_fraction': 0.15257493902090408}]
function_evaluation time 0.621974 value -0.455824 suggestion {'alpha': 1.1479651626651807e-05, 'batch_size': 243, 'beta_1': 0.9871922104631748, 'beta_2': 0.999998928361737, 'epsilon': 1.1304299685022383e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.04677564999396191, 'tol': 0.0018603185437369235, 'validation_fraction': 0.15257493902090408}
observation time 0.000005, current best -0.956867 at iter 11
suggestion time taken 0.002464 iter 12 next_points [{'alpha': 0.06365794301093747, 'batch_size': 171, 'beta_1': 0.9743790268399948, 'beta_2': 0.9955316489349247, 'epsilon': 5.4697867546596275e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0004924506737538669, 'tol': 0.0006364958616287129, 'validation_fraction': 0.45347091861695055}]
function_evaluation time 1.684513 value -0.946409 suggestion {'alpha': 0.06365794301093747, 'batch_size': 171, 'beta_1': 0.9743790268399948, 'beta_2': 0.9955316489349247, 'epsilon': 5.4697867546596275e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0004924506737538669, 'tol': 0.0006364958616287129, 'validation_fraction': 0.45347091861695055}
observation time 0.000005, current best -0.956867 at iter 12
suggestion time taken 0.002712 iter 13 next_points [{'alpha': 0.25487560984726576, 'batch_size': 74, 'beta_1': 0.5110714379892277, 'beta_2': 0.9995984713832485, 'epsilon': 9.304575687451085e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.05635517595345997, 'tol': 0.07746849804147361, 'validation_fraction': 0.22110320792421034}]
function_evaluation time 0.631294 value -0.842073 suggestion {'alpha': 0.25487560984726576, 'batch_size': 74, 'beta_1': 0.5110714379892277, 'beta_2': 0.9995984713832485, 'epsilon': 9.304575687451085e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.05635517595345997, 'tol': 0.07746849804147361, 'validation_fraction': 0.22110320792421034}
observation time 0.000005, current best -0.956867 at iter 13
suggestion time taken 0.002415 iter 14 next_points [{'alpha': 2.1874309946352805e-05, 'batch_size': 247, 'beta_1': 0.970694842156755, 'beta_2': 0.9999239885334573, 'epsilon': 4.832887116938202e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0044724068572537376, 'tol': 0.0022783179151397003, 'validation_fraction': 0.19478159584792337}]
function_evaluation time 0.747663 value -0.953366 suggestion {'alpha': 2.1874309946352805e-05, 'batch_size': 247, 'beta_1': 0.970694842156755, 'beta_2': 0.9999239885334573, 'epsilon': 4.832887116938202e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0044724068572537376, 'tol': 0.0022783179151397003, 'validation_fraction': 0.19478159584792337}
observation time 0.000005, current best -0.956867 at iter 14
saving meta data: {'args': {'--uuid': '80ce12beb1675bba98c668516fc6ddd0', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

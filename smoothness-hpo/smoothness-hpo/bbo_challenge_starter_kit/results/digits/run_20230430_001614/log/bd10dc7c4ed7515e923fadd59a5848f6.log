running: {'--uuid': 'bd10dc7c4ed7515e923fadd59a5848f6', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u bd10dc7c4ed7515e923fadd59a5848f6 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002132 iter 0 next_points [{'alpha': 0.14131693787603505, 'batch_size': 183, 'beta_1': 0.9873005423376334, 'beta_2': 0.9927521845231282, 'epsilon': 1.352683655662811e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 7.001310892865579e-05, 'tol': 0.08830989482605461, 'validation_fraction': 0.41870350684756424}]
function_evaluation time 0.346742 value -0.154455 suggestion {'alpha': 0.14131693787603505, 'batch_size': 183, 'beta_1': 0.9873005423376334, 'beta_2': 0.9927521845231282, 'epsilon': 1.352683655662811e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 7.001310892865579e-05, 'tol': 0.08830989482605461, 'validation_fraction': 0.41870350684756424}
observation time 0.001390, current best -0.154455 at iter 0
suggestion time taken 0.001745 iter 1 next_points [{'alpha': 0.003569515364891882, 'batch_size': 170, 'beta_1': 0.5519221131248861, 'beta_2': 0.9999930764080919, 'epsilon': 1.7690652052546267e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 1.1590600411026341e-05, 'tol': 0.05937425043965518, 'validation_fraction': 0.5637020400698716}]
function_evaluation time 0.224879 value -0.115532 suggestion {'alpha': 0.003569515364891882, 'batch_size': 170, 'beta_1': 0.5519221131248861, 'beta_2': 0.9999930764080919, 'epsilon': 1.7690652052546267e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 1.1590600411026341e-05, 'tol': 0.05937425043965518, 'validation_fraction': 0.5637020400698716}
observation time 0.001425, current best -0.154455 at iter 1
suggestion time taken 0.001757 iter 2 next_points [{'alpha': 0.0017010708322550087, 'batch_size': 62, 'beta_1': 0.9595217283746281, 'beta_2': 0.9999355227468567, 'epsilon': 5.388346561717638e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.01308190974970801, 'tol': 0.00012063186958636065, 'validation_fraction': 0.6680956585007831}]
function_evaluation time 0.857190 value -0.947815 suggestion {'alpha': 0.0017010708322550087, 'batch_size': 62, 'beta_1': 0.9595217283746281, 'beta_2': 0.9999355227468567, 'epsilon': 5.388346561717638e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.01308190974970801, 'tol': 0.00012063186958636065, 'validation_fraction': 0.6680956585007831}
observation time 0.001383, current best -0.947815 at iter 2
suggestion time taken 0.001739 iter 3 next_points [{'alpha': 0.010228771289594093, 'batch_size': 153, 'beta_1': 0.6708113477627968, 'beta_2': 0.9422948786833146, 'epsilon': 5.5241406938016955e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.0012715588041600275, 'tol': 1.0185281212308358e-05, 'validation_fraction': 0.8837605735479681}]
function_evaluation time 1.606403 value -0.901195 suggestion {'alpha': 0.010228771289594093, 'batch_size': 153, 'beta_1': 0.6708113477627968, 'beta_2': 0.9422948786833146, 'epsilon': 5.5241406938016955e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.0012715588041600275, 'tol': 1.0185281212308358e-05, 'validation_fraction': 0.8837605735479681}
observation time 0.001362, current best -0.947815 at iter 3
suggestion time taken 0.001776 iter 4 next_points [{'alpha': 3.8243194015770903, 'batch_size': 192, 'beta_1': 0.7810578622533824, 'beta_2': 0.9999666660835128, 'epsilon': 3.0774896855807536e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 2.534052020867286e-05, 'tol': 6.64569112062814e-05, 'validation_fraction': 0.1392610967419522}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.092567 value -0.112113 suggestion {'alpha': 3.8243194015770903, 'batch_size': 192, 'beta_1': 0.7810578622533824, 'beta_2': 0.9999666660835128, 'epsilon': 3.0774896855807536e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 2.534052020867286e-05, 'tol': 6.64569112062814e-05, 'validation_fraction': 0.1392610967419522}
observation time 0.001407, current best -0.947815 at iter 4
suggestion time taken 0.001714 iter 5 next_points [{'alpha': 0.051207680246020605, 'batch_size': 120, 'beta_1': 0.7626819190463783, 'beta_2': 0.9999988822474172, 'epsilon': 1.5020178439043063e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0003236943204758714, 'tol': 0.0004344003031395259, 'validation_fraction': 0.11909628253761782}]
function_evaluation time 2.055044 value -0.945724 suggestion {'alpha': 0.051207680246020605, 'batch_size': 120, 'beta_1': 0.7626819190463783, 'beta_2': 0.9999988822474172, 'epsilon': 1.5020178439043063e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0003236943204758714, 'tol': 0.0004344003031395259, 'validation_fraction': 0.11909628253761782}
observation time 0.001347, current best -0.947815 at iter 5
suggestion time taken 0.001758 iter 6 next_points [{'alpha': 0.11290390961874185, 'batch_size': 208, 'beta_1': 0.827577807379003, 'beta_2': 0.9882149188060891, 'epsilon': 1.2400561275146044e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.008045113556775672, 'tol': 0.00018636522845324666, 'validation_fraction': 0.22842612592092434}]
function_evaluation time 0.945726 value -0.965220 suggestion {'alpha': 0.11290390961874185, 'batch_size': 208, 'beta_1': 0.827577807379003, 'beta_2': 0.9882149188060891, 'epsilon': 1.2400561275146044e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.008045113556775672, 'tol': 0.00018636522845324666, 'validation_fraction': 0.22842612592092434}
observation time 0.001376, current best -0.965220 at iter 6
suggestion time taken 0.001767 iter 7 next_points [{'alpha': 0.00014012903713436322, 'batch_size': 49, 'beta_1': 0.9720993237827071, 'beta_2': 0.9999225900681497, 'epsilon': 8.952557976990089e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.06174404614653834, 'tol': 0.003924960088000929, 'validation_fraction': 0.5924087935894422}]
function_evaluation time 0.888759 value -0.450240 suggestion {'alpha': 0.00014012903713436322, 'batch_size': 49, 'beta_1': 0.9720993237827071, 'beta_2': 0.9999225900681497, 'epsilon': 8.952557976990089e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.06174404614653834, 'tol': 0.003924960088000929, 'validation_fraction': 0.5924087935894422}
observation time 0.001368, current best -0.965220 at iter 7
suggestion time taken 0.001761 iter 8 next_points [{'alpha': 0.00020166204484478554, 'batch_size': 106, 'beta_1': 0.7172801692667377, 'beta_2': 0.9995128471199184, 'epsilon': 4.2261734260803786e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.0015189594668224475, 'tol': 0.001589798002611567, 'validation_fraction': 0.16544450861874285}]
function_evaluation time 1.360375 value -0.965892 suggestion {'alpha': 0.00020166204484478554, 'batch_size': 106, 'beta_1': 0.7172801692667377, 'beta_2': 0.9995128471199184, 'epsilon': 4.2261734260803786e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.0015189594668224475, 'tol': 0.001589798002611567, 'validation_fraction': 0.16544450861874285}
observation time 0.001420, current best -0.965892 at iter 8
suggestion time taken 0.002029 iter 9 next_points [{'alpha': 3.7730529598799446e-05, 'batch_size': 19, 'beta_1': 0.8609782955311657, 'beta_2': 0.999984330617651, 'epsilon': 8.937196564915186e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.000688675972391484, 'tol': 0.0112229002460205, 'validation_fraction': 0.7583060499747122}]
function_evaluation time 0.935654 value -0.922767 suggestion {'alpha': 3.7730529598799446e-05, 'batch_size': 19, 'beta_1': 0.8609782955311657, 'beta_2': 0.999984330617651, 'epsilon': 8.937196564915186e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.000688675972391484, 'tol': 0.0112229002460205, 'validation_fraction': 0.7583060499747122}
observation time 0.001356, current best -0.965892 at iter 9
suggestion time taken 0.001738 iter 10 next_points [{'alpha': 0.01782489743188421, 'batch_size': 93, 'beta_1': 0.9540079100069198, 'beta_2': 0.999663493954939, 'epsilon': 4.24279532279148e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.0053192678025372475, 'tol': 3.3199590611315685e-05, 'validation_fraction': 0.2020129272623956}]
function_evaluation time 0.791338 value -0.957554 suggestion {'alpha': 0.01782489743188421, 'batch_size': 93, 'beta_1': 0.9540079100069198, 'beta_2': 0.999663493954939, 'epsilon': 4.24279532279148e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.0053192678025372475, 'tol': 3.3199590611315685e-05, 'validation_fraction': 0.2020129272623956}
observation time 0.001399, current best -0.965892 at iter 10
suggestion time taken 0.001732 iter 11 next_points [{'alpha': 1.181116524214208e-05, 'batch_size': 145, 'beta_1': 0.5897586634937431, 'beta_2': 0.9432001351663111, 'epsilon': 6.802131990180464e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 4.3551557958143227e-05, 'tol': 0.00010081826888117165, 'validation_fraction': 0.698085755562964}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.754530 value -0.545700 suggestion {'alpha': 1.181116524214208e-05, 'batch_size': 145, 'beta_1': 0.5897586634937431, 'beta_2': 0.9432001351663111, 'epsilon': 6.802131990180464e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 4.3551557958143227e-05, 'tol': 0.00010081826888117165, 'validation_fraction': 0.698085755562964}
observation time 0.001395, current best -0.965892 at iter 11
suggestion time taken 0.001727 iter 12 next_points [{'alpha': 8.319561987068144e-05, 'batch_size': 46, 'beta_1': 0.9760329697817659, 'beta_2': 0.997611050522812, 'epsilon': 2.1438388741338814e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.00024865080056948776, 'tol': 0.005879058230172963, 'validation_fraction': 0.40621435040655846}]
function_evaluation time 1.802469 value -0.925527 suggestion {'alpha': 8.319561987068144e-05, 'batch_size': 46, 'beta_1': 0.9760329697817659, 'beta_2': 0.997611050522812, 'epsilon': 2.1438388741338814e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.00024865080056948776, 'tol': 0.005879058230172963, 'validation_fraction': 0.40621435040655846}
observation time 0.001359, current best -0.965892 at iter 12
suggestion time taken 0.001939 iter 13 next_points [{'alpha': 8.066007499759097, 'batch_size': 76, 'beta_1': 0.873801691844919, 'beta_2': 0.999095134561436, 'epsilon': 3.0994066777625023e-07, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.04403654145490118, 'tol': 0.027534447614920986, 'validation_fraction': 0.3429890703351862}]
function_evaluation time 0.568623 value -0.945744 suggestion {'alpha': 8.066007499759097, 'batch_size': 76, 'beta_1': 0.873801691844919, 'beta_2': 0.999095134561436, 'epsilon': 3.0994066777625023e-07, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.04403654145490118, 'tol': 0.027534447614920986, 'validation_fraction': 0.3429890703351862}
observation time 0.001360, current best -0.965892 at iter 13
suggestion time taken 0.001692 iter 14 next_points [{'alpha': 2.0342499448781255, 'batch_size': 212, 'beta_1': 0.9253576265593695, 'beta_2': 0.9998553326639495, 'epsilon': 4.4328672120068165e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.014871455713413667, 'tol': 0.0029960729780976105, 'validation_fraction': 0.8125967979998959}]
function_evaluation time 0.680683 value -0.846954 suggestion {'alpha': 2.0342499448781255, 'batch_size': 212, 'beta_1': 0.9253576265593695, 'beta_2': 0.9998553326639495, 'epsilon': 4.4328672120068165e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.014871455713413667, 'tol': 0.0029960729780976105, 'validation_fraction': 0.8125967979998959}
observation time 0.001354, current best -0.965892 at iter 14
saving meta data: {'args': {'--uuid': 'bd10dc7c4ed7515e923fadd59a5848f6', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': 'bc3a7ca8d67b5f88b307de0a85009e6b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u bc3a7ca8d67b5f88b307de0a85009e6b -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002170 iter 0 next_points [{'alpha': 0.11131744313341653, 'batch_size': 68, 'beta_1': 0.8999774239083886, 'beta_2': 0.9870824713358036, 'epsilon': 8.615623437592441e-08, 'hidden_layer_sizes': 96, 'learning_rate_init': 2.5698626123511674e-05, 'tol': 0.0003081701765742008, 'validation_fraction': 0.13537900816499698}]
function_evaluation time 5.308269 value -0.886600 suggestion {'alpha': 0.11131744313341653, 'batch_size': 68, 'beta_1': 0.8999774239083886, 'beta_2': 0.9870824713358036, 'epsilon': 8.615623437592441e-08, 'hidden_layer_sizes': 96, 'learning_rate_init': 2.5698626123511674e-05, 'tol': 0.0003081701765742008, 'validation_fraction': 0.13537900816499698}
observation time 0.001387, current best -0.886600 at iter 0
suggestion time taken 0.001729 iter 1 next_points [{'alpha': 0.00017323445503360235, 'batch_size': 210, 'beta_1': 0.5678826703433167, 'beta_2': 0.9088603331076985, 'epsilon': 5.0458790903438964e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 3.367847808847973e-05, 'tol': 0.036542015639330676, 'validation_fraction': 0.5355385274323073}]
function_evaluation time 0.191714 value -0.100922 suggestion {'alpha': 0.00017323445503360235, 'batch_size': 210, 'beta_1': 0.5678826703433167, 'beta_2': 0.9088603331076985, 'epsilon': 5.0458790903438964e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 3.367847808847973e-05, 'tol': 0.036542015639330676, 'validation_fraction': 0.5355385274323073}
observation time 0.001467, current best -0.886600 at iter 1
suggestion time taken 0.001899 iter 2 next_points [{'alpha': 1.3053230375368938e-05, 'batch_size': 51, 'beta_1': 0.9477069499634507, 'beta_2': 0.9931479315580901, 'epsilon': 5.515744961424668e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 1.0194590770140589e-05, 'tol': 3.3174224974168246e-05, 'validation_fraction': 0.33243332627627664}]
function_evaluation time 0.571504 value -0.093249 suggestion {'alpha': 1.3053230375368938e-05, 'batch_size': 51, 'beta_1': 0.9477069499634507, 'beta_2': 0.9931479315580901, 'epsilon': 5.515744961424668e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 1.0194590770140589e-05, 'tol': 3.3174224974168246e-05, 'validation_fraction': 0.33243332627627664}
observation time 0.001423, current best -0.886600 at iter 2
suggestion time taken 0.001760 iter 3 next_points [{'alpha': 0.0010628738635838572, 'batch_size': 16, 'beta_1': 0.7734832077034784, 'beta_2': 0.9999959964385671, 'epsilon': 6.57762141497775e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0001036462468920973, 'tol': 0.005002498741885422, 'validation_fraction': 0.8398724095503726}]
function_evaluation time 2.353638 value -0.755091 suggestion {'alpha': 0.0010628738635838572, 'batch_size': 16, 'beta_1': 0.7734832077034784, 'beta_2': 0.9999959964385671, 'epsilon': 6.57762141497775e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0001036462468920973, 'tol': 0.005002498741885422, 'validation_fraction': 0.8398724095503726}
observation time 0.001602, current best -0.886600 at iter 3
suggestion time taken 0.001852 iter 4 next_points [{'alpha': 3.111142131999312, 'batch_size': 110, 'beta_1': 0.987619524975648, 'beta_2': 0.9999414493191525, 'epsilon': 1.3153345948237128e-07, 'hidden_layer_sizes': 127, 'learning_rate_init': 5.099671456080227e-05, 'tol': 0.00020112764780927614, 'validation_fraction': 0.3707514916162909}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 4.543244 value -0.748405 suggestion {'alpha': 3.111142131999312, 'batch_size': 110, 'beta_1': 0.987619524975648, 'beta_2': 0.9999414493191525, 'epsilon': 1.3153345948237128e-07, 'hidden_layer_sizes': 127, 'learning_rate_init': 5.099671456080227e-05, 'tol': 0.00020112764780927614, 'validation_fraction': 0.3707514916162909}
observation time 0.001385, current best -0.886600 at iter 4
suggestion time taken 0.001686 iter 5 next_points [{'alpha': 2.223676926075771, 'batch_size': 172, 'beta_1': 0.9522066318048003, 'beta_2': 0.9985569818041242, 'epsilon': 7.769010116436669e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0011547305341708721, 'tol': 0.011495348959515516, 'validation_fraction': 0.8941726882138553}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.518873 value -0.836474 suggestion {'alpha': 2.223676926075771, 'batch_size': 172, 'beta_1': 0.9522066318048003, 'beta_2': 0.9985569818041242, 'epsilon': 7.769010116436669e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0011547305341708721, 'tol': 0.011495348959515516, 'validation_fraction': 0.8941726882138553}
observation time 0.001384, current best -0.886600 at iter 5
suggestion time taken 0.001707 iter 6 next_points [{'alpha': 0.006462662944004416, 'batch_size': 31, 'beta_1': 0.677968470405176, 'beta_2': 0.9999834759989445, 'epsilon': 1.1760739080182881e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.006310087388481061, 'tol': 6.409511247811665e-05, 'validation_fraction': 0.6287452572882799}]
function_evaluation time 1.143110 value -0.940851 suggestion {'alpha': 0.006462662944004416, 'batch_size': 31, 'beta_1': 0.677968470405176, 'beta_2': 0.9999834759989445, 'epsilon': 1.1760739080182881e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.006310087388481061, 'tol': 6.409511247811665e-05, 'validation_fraction': 0.6287452572882799}
observation time 0.001406, current best -0.940851 at iter 6
suggestion time taken 0.001744 iter 7 next_points [{'alpha': 0.0006786326530574049, 'batch_size': 82, 'beta_1': 0.9775458466185573, 'beta_2': 0.996699428980045, 'epsilon': 3.5216067975742697e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.000249652602061467, 'tol': 0.021439007123900882, 'validation_fraction': 0.8526020795660341}]
function_evaluation time 0.402464 value -0.258295 suggestion {'alpha': 0.0006786326530574049, 'batch_size': 82, 'beta_1': 0.9775458466185573, 'beta_2': 0.996699428980045, 'epsilon': 3.5216067975742697e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.000249652602061467, 'tol': 0.021439007123900882, 'validation_fraction': 0.8526020795660341}
observation time 0.001349, current best -0.940851 at iter 7
suggestion time taken 0.001743 iter 8 next_points [{'alpha': 2.5682899638149454e-05, 'batch_size': 122, 'beta_1': 0.6395667393134761, 'beta_2': 0.9998508801485434, 'epsilon': 8.753089867107563e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.03750537596309593, 'tol': 0.05590949110678028, 'validation_fraction': 0.6634778363983489}]
function_evaluation time 0.359026 value -0.933890 suggestion {'alpha': 2.5682899638149454e-05, 'batch_size': 122, 'beta_1': 0.6395667393134761, 'beta_2': 0.9998508801485434, 'epsilon': 8.753089867107563e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.03750537596309593, 'tol': 0.05590949110678028, 'validation_fraction': 0.6634778363983489}
observation time 0.001441, current best -0.940851 at iter 8
suggestion time taken 0.001757 iter 9 next_points [{'alpha': 0.014670109627174329, 'batch_size': 143, 'beta_1': 0.9639072509784462, 'beta_2': 0.9808742595193168, 'epsilon': 7.272378642367445e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0917263210299478, 'tol': 0.0022004022448790825, 'validation_fraction': 0.2912010990024769}]
function_evaluation time 1.601655 value -0.917886 suggestion {'alpha': 0.014670109627174329, 'batch_size': 143, 'beta_1': 0.9639072509784462, 'beta_2': 0.9808742595193168, 'epsilon': 7.272378642367445e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0917263210299478, 'tol': 0.0022004022448790825, 'validation_fraction': 0.2912010990024769}
observation time 0.001433, current best -0.940851 at iter 9
suggestion time taken 0.001709 iter 10 next_points [{'alpha': 5.35275261528715e-05, 'batch_size': 183, 'beta_1': 0.8772108871415151, 'beta_2': 0.9999973295142189, 'epsilon': 2.143336815301411e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.0017317729421307687, 'tol': 0.0015161593999882686, 'validation_fraction': 0.7110687050881965}]
function_evaluation time 0.734238 value -0.933907 suggestion {'alpha': 5.35275261528715e-05, 'batch_size': 183, 'beta_1': 0.8772108871415151, 'beta_2': 0.9999973295142189, 'epsilon': 2.143336815301411e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.0017317729421307687, 'tol': 0.0015161593999882686, 'validation_fraction': 0.7110687050881965}
observation time 0.001360, current best -0.940851 at iter 10
suggestion time taken 0.001759 iter 11 next_points [{'alpha': 0.008287455730427636, 'batch_size': 232, 'beta_1': 0.8281309226973501, 'beta_2': 0.9999748141128412, 'epsilon': 9.922001977028776e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.0040935928196140295, 'tol': 0.0001195990102942199, 'validation_fraction': 0.23583433592053682}]
function_evaluation time 0.910157 value -0.962423 suggestion {'alpha': 0.008287455730427636, 'batch_size': 232, 'beta_1': 0.8281309226973501, 'beta_2': 0.9999748141128412, 'epsilon': 9.922001977028776e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.0040935928196140295, 'tol': 0.0001195990102942199, 'validation_fraction': 0.23583433592053682}
observation time 0.001364, current best -0.962423 at iter 11
suggestion time taken 0.001724 iter 12 next_points [{'alpha': 7.343728498793439, 'batch_size': 216, 'beta_1': 0.9838594090925712, 'beta_2': 0.9999911586954547, 'epsilon': 3.5608958982725e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.014343303793809846, 'tol': 8.787539566142114e-05, 'validation_fraction': 0.1772313586097885}]
function_evaluation time 1.243519 value -0.960334 suggestion {'alpha': 7.343728498793439, 'batch_size': 216, 'beta_1': 0.9838594090925712, 'beta_2': 0.9999911586954547, 'epsilon': 3.5608958982725e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.014343303793809846, 'tol': 8.787539566142114e-05, 'validation_fraction': 0.1772313586097885}
observation time 0.001391, current best -0.962423 at iter 12
suggestion time taken 0.001703 iter 13 next_points [{'alpha': 0.0003448581879989793, 'batch_size': 156, 'beta_1': 0.5237642341404876, 'beta_2': 0.9585891493851785, 'epsilon': 2.2331559002034104e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.015781394140138873, 'tol': 0.09931901493567412, 'validation_fraction': 0.7977094684868823}]
function_evaluation time 0.194529 value -0.892170 suggestion {'alpha': 0.0003448581879989793, 'batch_size': 156, 'beta_1': 0.5237642341404876, 'beta_2': 0.9585891493851785, 'epsilon': 2.2331559002034104e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.015781394140138873, 'tol': 0.09931901493567412, 'validation_fraction': 0.7977094684868823}
observation time 0.001337, current best -0.962423 at iter 13
suggestion time taken 0.001689 iter 14 next_points [{'alpha': 0.5525491052228652, 'batch_size': 192, 'beta_1': 0.9687406328657578, 'beta_2': 0.9999190385718216, 'epsilon': 3.0237023427528754e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.00012932263716201832, 'tol': 0.005535370973462646, 'validation_fraction': 0.5134895602102656}]
function_evaluation time 1.700843 value -0.851086 suggestion {'alpha': 0.5525491052228652, 'batch_size': 192, 'beta_1': 0.9687406328657578, 'beta_2': 0.9999190385718216, 'epsilon': 3.0237023427528754e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.00012932263716201832, 'tol': 0.005535370973462646, 'validation_fraction': 0.5134895602102656}
observation time 0.001381, current best -0.962423 at iter 14
saving meta data: {'args': {'--uuid': 'bc3a7ca8d67b5f88b307de0a85009e6b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

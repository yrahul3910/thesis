running: {'--uuid': '93b375bd24f354d19fe859128698f188', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d digits -o random-search -u 93b375bd24f354d19fe859128698f188 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study random-search MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002807 iter 0 next_points [{'alpha': 1.6791335539032584, 'batch_size': 165, 'beta_1': 0.712386448991185, 'beta_2': 0.9998992382333518, 'epsilon': 3.4764080332733916e-08, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.0074541425301595495, 'tol': 0.014522477159789106, 'validation_fraction': 0.24166717838965737}]
function_evaluation time 0.490467 value 0.110229 suggestion {'alpha': 1.6791335539032584, 'batch_size': 165, 'beta_1': 0.712386448991185, 'beta_2': 0.9998992382333518, 'epsilon': 3.4764080332733916e-08, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.0074541425301595495, 'tol': 0.014522477159789106, 'validation_fraction': 0.24166717838965737}
observation time 0.000006, current best 0.110229 at iter 0
suggestion time taken 0.002455 iter 1 next_points [{'alpha': 0.0001727407655930741, 'batch_size': 142, 'beta_1': 0.8456732895318594, 'beta_2': 0.9999925215407662, 'epsilon': 6.096627029644487e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0015318848547628313, 'tol': 2.510813246811524e-05, 'validation_fraction': 0.6997845912451134}]
function_evaluation time 1.146433 value 0.224071 suggestion {'alpha': 0.0001727407655930741, 'batch_size': 142, 'beta_1': 0.8456732895318594, 'beta_2': 0.9999925215407662, 'epsilon': 6.096627029644487e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0015318848547628313, 'tol': 2.510813246811524e-05, 'validation_fraction': 0.6997845912451134}
observation time 0.000006, current best 0.110229 at iter 1
suggestion time taken 0.002545 iter 2 next_points [{'alpha': 0.0057619658024565335, 'batch_size': 34, 'beta_1': 0.9829901211745986, 'beta_2': 0.9999969256687644, 'epsilon': 1.3567388017971287e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.05889403665322331, 'tol': 0.022919546760030638, 'validation_fraction': 0.8950703755978913}]
function_evaluation time 0.313765 value 3.633828 suggestion {'alpha': 0.0057619658024565335, 'batch_size': 34, 'beta_1': 0.9829901211745986, 'beta_2': 0.9999969256687644, 'epsilon': 1.3567388017971287e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.05889403665322331, 'tol': 0.022919546760030638, 'validation_fraction': 0.8950703755978913}
observation time 0.000005, current best 0.110229 at iter 2
suggestion time taken 0.002759 iter 3 next_points [{'alpha': 0.0003042427393470322, 'batch_size': 51, 'beta_1': 0.7801154047175507, 'beta_2': 0.9999035074999628, 'epsilon': 1.0592641415568357e-08, 'hidden_layer_sizes': 131, 'learning_rate_init': 2.8266582767410423e-05, 'tol': 0.035573052342532246, 'validation_fraction': 0.22956418916515897}]
function_evaluation time 0.677821 value 4.382746 suggestion {'alpha': 0.0003042427393470322, 'batch_size': 51, 'beta_1': 0.7801154047175507, 'beta_2': 0.9999035074999628, 'epsilon': 1.0592641415568357e-08, 'hidden_layer_sizes': 131, 'learning_rate_init': 2.8266582767410423e-05, 'tol': 0.035573052342532246, 'validation_fraction': 0.22956418916515897}
observation time 0.000005, current best 0.110229 at iter 3
suggestion time taken 0.002475 iter 4 next_points [{'alpha': 1.5482336463448772e-05, 'batch_size': 83, 'beta_1': 0.943410424173496, 'beta_2': 0.9954113323073134, 'epsilon': 9.58780215188024e-07, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0027898550239863255, 'tol': 0.03177110184931273, 'validation_fraction': 0.18758540166365303}]
function_evaluation time 0.612874 value 0.131694 suggestion {'alpha': 1.5482336463448772e-05, 'batch_size': 83, 'beta_1': 0.943410424173496, 'beta_2': 0.9954113323073134, 'epsilon': 9.58780215188024e-07, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0027898550239863255, 'tol': 0.03177110184931273, 'validation_fraction': 0.18758540166365303}
observation time 0.000005, current best 0.110229 at iter 4
suggestion time taken 0.002429 iter 5 next_points [{'alpha': 1.1131242695208046, 'batch_size': 118, 'beta_1': 0.9533190856802249, 'beta_2': 0.9999951542363951, 'epsilon': 1.1345816039827072e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.043392001417590954, 'tol': 0.049712653339478455, 'validation_fraction': 0.5157849848368483}]
function_evaluation time 0.506330 value 0.280689 suggestion {'alpha': 1.1131242695208046, 'batch_size': 118, 'beta_1': 0.9533190856802249, 'beta_2': 0.9999951542363951, 'epsilon': 1.1345816039827072e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.043392001417590954, 'tol': 0.049712653339478455, 'validation_fraction': 0.5157849848368483}
observation time 0.000005, current best 0.110229 at iter 5
suggestion time taken 0.002428 iter 6 next_points [{'alpha': 0.0014525674278108006, 'batch_size': 226, 'beta_1': 0.7690843455065564, 'beta_2': 0.9848027724191398, 'epsilon': 5.003996704445409e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.004302617919416147, 'tol': 0.00041203418612370557, 'validation_fraction': 0.7574130946362604}]
function_evaluation time 0.922262 value 0.235733 suggestion {'alpha': 0.0014525674278108006, 'batch_size': 226, 'beta_1': 0.7690843455065564, 'beta_2': 0.9848027724191398, 'epsilon': 5.003996704445409e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.004302617919416147, 'tol': 0.00041203418612370557, 'validation_fraction': 0.7574130946362604}
observation time 0.000005, current best 0.110229 at iter 6
suggestion time taken 0.002458 iter 7 next_points [{'alpha': 7.291326192341068e-05, 'batch_size': 55, 'beta_1': 0.8206081745846464, 'beta_2': 0.9789078054186258, 'epsilon': 6.8388507456421715e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.00026363758230703896, 'tol': 0.00012256904315436541, 'validation_fraction': 0.61564337582634}]
function_evaluation time 3.067361 value 0.194940 suggestion {'alpha': 7.291326192341068e-05, 'batch_size': 55, 'beta_1': 0.8206081745846464, 'beta_2': 0.9789078054186258, 'epsilon': 6.8388507456421715e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.00026363758230703896, 'tol': 0.00012256904315436541, 'validation_fraction': 0.61564337582634}
observation time 0.000006, current best 0.110229 at iter 7
suggestion time taken 0.002526 iter 8 next_points [{'alpha': 0.09553452178842166, 'batch_size': 118, 'beta_1': 0.9590780772650186, 'beta_2': 0.9999908801039292, 'epsilon': 3.082689877733943e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.030867291281320916, 'tol': 0.001985767825025117, 'validation_fraction': 0.8510994170372912}]
function_evaluation time 0.761188 value 0.637420 suggestion {'alpha': 0.09553452178842166, 'batch_size': 118, 'beta_1': 0.9590780772650186, 'beta_2': 0.9999908801039292, 'epsilon': 3.082689877733943e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.030867291281320916, 'tol': 0.001985767825025117, 'validation_fraction': 0.8510994170372912}
observation time 0.000005, current best 0.110229 at iter 8
suggestion time taken 0.002502 iter 9 next_points [{'alpha': 0.0033306734185528444, 'batch_size': 233, 'beta_1': 0.8154459663205935, 'beta_2': 0.9960192972581953, 'epsilon': 9.382285118852468e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0015487675957568429, 'tol': 0.0002385387838048139, 'validation_fraction': 0.7415585457797249}]
function_evaluation time 1.517110 value 0.246099 suggestion {'alpha': 0.0033306734185528444, 'batch_size': 233, 'beta_1': 0.8154459663205935, 'beta_2': 0.9960192972581953, 'epsilon': 9.382285118852468e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0015487675957568429, 'tol': 0.0002385387838048139, 'validation_fraction': 0.7415585457797249}
observation time 0.000006, current best 0.110229 at iter 9
suggestion time taken 0.002521 iter 10 next_points [{'alpha': 0.00021493551612315607, 'batch_size': 61, 'beta_1': 0.6016620032712716, 'beta_2': 0.9633514001975002, 'epsilon': 1.9592076969434732e-07, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0004399247112085404, 'tol': 0.057254174390198566, 'validation_fraction': 0.13396014376687262}]
function_evaluation time 0.796335 value 0.221206 suggestion {'alpha': 0.00021493551612315607, 'batch_size': 61, 'beta_1': 0.6016620032712716, 'beta_2': 0.9633514001975002, 'epsilon': 1.9592076969434732e-07, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0004399247112085404, 'tol': 0.057254174390198566, 'validation_fraction': 0.13396014376687262}
observation time 0.000006, current best 0.110229 at iter 10
suggestion time taken 0.002437 iter 11 next_points [{'alpha': 0.012842007879880669, 'batch_size': 110, 'beta_1': 0.5430520604878876, 'beta_2': 0.9984748528819969, 'epsilon': 3.888136878079182e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 1.8214692800720687e-05, 'tol': 0.017157574143734665, 'validation_fraction': 0.7318907750422653}]
function_evaluation time 0.191861 value 13.833838 suggestion {'alpha': 0.012842007879880669, 'batch_size': 110, 'beta_1': 0.5430520604878876, 'beta_2': 0.9984748528819969, 'epsilon': 3.888136878079182e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 1.8214692800720687e-05, 'tol': 0.017157574143734665, 'validation_fraction': 0.7318907750422653}
observation time 0.000005, current best 0.110229 at iter 11
suggestion time taken 0.002477 iter 12 next_points [{'alpha': 8.014451378299266e-05, 'batch_size': 179, 'beta_1': 0.5559764962847715, 'beta_2': 0.999581276036799, 'epsilon': 7.07591314356467e-08, 'hidden_layer_sizes': 191, 'learning_rate_init': 2.518042639079982e-05, 'tol': 1.1288580189744453e-05, 'validation_fraction': 0.5147890612305671}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.900226 value 3.410097 suggestion {'alpha': 8.014451378299266e-05, 'batch_size': 179, 'beta_1': 0.5559764962847715, 'beta_2': 0.999581276036799, 'epsilon': 7.07591314356467e-08, 'hidden_layer_sizes': 191, 'learning_rate_init': 2.518042639079982e-05, 'tol': 1.1288580189744453e-05, 'validation_fraction': 0.5147890612305671}
observation time 0.000005, current best 0.110229 at iter 12
suggestion time taken 0.002730 iter 13 next_points [{'alpha': 0.5649289183985605, 'batch_size': 210, 'beta_1': 0.9745636224432825, 'beta_2': 0.9999733879473518, 'epsilon': 2.8491039042103316e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 2.1201870093425053e-05, 'tol': 0.020455493240100982, 'validation_fraction': 0.8951345985403806}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.156575 value 8.129131 suggestion {'alpha': 0.5649289183985605, 'batch_size': 210, 'beta_1': 0.9745636224432825, 'beta_2': 0.9999733879473518, 'epsilon': 2.8491039042103316e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 2.1201870093425053e-05, 'tol': 0.020455493240100982, 'validation_fraction': 0.8951345985403806}
observation time 0.000005, current best 0.110229 at iter 13
suggestion time taken 0.002452 iter 14 next_points [{'alpha': 0.0004260696974644609, 'batch_size': 89, 'beta_1': 0.9794823715589331, 'beta_2': 0.9997377003738881, 'epsilon': 7.428687635830885e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 1.3697313196322448e-05, 'tol': 0.002697721082296296, 'validation_fraction': 0.39816901760614254}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.586577 value 7.340861 suggestion {'alpha': 0.0004260696974644609, 'batch_size': 89, 'beta_1': 0.9794823715589331, 'beta_2': 0.9997377003738881, 'epsilon': 7.428687635830885e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 1.3697313196322448e-05, 'tol': 0.002697721082296296, 'validation_fraction': 0.39816901760614254}
observation time 0.000005, current best 0.110229 at iter 14
saving meta data: {'args': {'--uuid': '93b375bd24f354d19fe859128698f188', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

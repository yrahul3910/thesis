running: {'--uuid': 'f965bcd6e8ac541fb24a69f8c74ca703', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u f965bcd6e8ac541fb24a69f8c74ca703 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study turbo MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002152 iter 0 next_points [{'alpha': 4.558737862219122e-05, 'batch_size': 174, 'beta_1': 0.6362019138423846, 'beta_2': 0.9999947281422938, 'epsilon': 1.3918320068760054e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.07385851881658552, 'tol': 8.315222982447524e-05, 'validation_fraction': 0.3815304710143699}]
function_evaluation time 0.659605 value 0.965868 suggestion {'alpha': 4.558737862219122e-05, 'batch_size': 174, 'beta_1': 0.6362019138423846, 'beta_2': 0.9999947281422938, 'epsilon': 1.3918320068760054e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.07385851881658552, 'tol': 8.315222982447524e-05, 'validation_fraction': 0.3815304710143699}
observation time 0.001421, current best 0.965868 at iter 0
suggestion time taken 0.001774 iter 1 next_points [{'alpha': 0.003639569856318074, 'batch_size': 88, 'beta_1': 0.9489563128228041, 'beta_2': 0.999563571979441, 'epsilon': 1.7347795133095824e-07, 'hidden_layer_sizes': 185, 'learning_rate_init': 7.996995068363763e-05, 'tol': 0.0004097532469664264, 'validation_fraction': 0.8606866228683372}]
function_evaluation time 3.278265 value 0.679866 suggestion {'alpha': 0.003639569856318074, 'batch_size': 88, 'beta_1': 0.9489563128228041, 'beta_2': 0.999563571979441, 'epsilon': 1.7347795133095824e-07, 'hidden_layer_sizes': 185, 'learning_rate_init': 7.996995068363763e-05, 'tol': 0.0004097532469664264, 'validation_fraction': 0.8606866228683372}
observation time 0.001377, current best 0.679866 at iter 1
suggestion time taken 0.002035 iter 2 next_points [{'alpha': 0.4631612552546008, 'batch_size': 45, 'beta_1': 0.9265743752737384, 'beta_2': 0.9993984083415826, 'epsilon': 2.529041335665139e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.00034177360413013965, 'tol': 0.0006073440744907306, 'validation_fraction': 0.7967277170076056}]
function_evaluation time 2.314022 value 0.359568 suggestion {'alpha': 0.4631612552546008, 'batch_size': 45, 'beta_1': 0.9265743752737384, 'beta_2': 0.9993984083415826, 'epsilon': 2.529041335665139e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.00034177360413013965, 'tol': 0.0006073440744907306, 'validation_fraction': 0.7967277170076056}
observation time 0.001401, current best 0.359568 at iter 2
suggestion time taken 0.001705 iter 3 next_points [{'alpha': 0.16850782972982883, 'batch_size': 203, 'beta_1': 0.8532489930643392, 'beta_2': 0.9979812323578047, 'epsilon': 3.991401209634932e-08, 'hidden_layer_sizes': 153, 'learning_rate_init': 2.2294821622890624e-05, 'tol': 2.164653706479082e-05, 'validation_fraction': 0.2734719118264329}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 5.122125 value 1.943462 suggestion {'alpha': 0.16850782972982883, 'batch_size': 203, 'beta_1': 0.8532489930643392, 'beta_2': 0.9979812323578047, 'epsilon': 3.991401209634932e-08, 'hidden_layer_sizes': 153, 'learning_rate_init': 2.2294821622890624e-05, 'tol': 2.164653706479082e-05, 'validation_fraction': 0.2734719118264329}
observation time 0.001385, current best 0.359568 at iter 3
suggestion time taken 0.001970 iter 4 next_points [{'alpha': 3.1010255332259956e-05, 'batch_size': 11, 'beta_1': 0.7259471266938122, 'beta_2': 0.9999971092329482, 'epsilon': 3.0556140265757662e-09, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.0009628149257074695, 'tol': 3.721167752278491e-05, 'validation_fraction': 0.5951149410828833}]
function_evaluation time 3.741657 value 0.219557 suggestion {'alpha': 3.1010255332259956e-05, 'batch_size': 11, 'beta_1': 0.7259471266938122, 'beta_2': 0.9999971092329482, 'epsilon': 3.0556140265757662e-09, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.0009628149257074695, 'tol': 3.721167752278491e-05, 'validation_fraction': 0.5951149410828833}
observation time 0.001406, current best 0.219557 at iter 4
suggestion time taken 0.001725 iter 5 next_points [{'alpha': 1.7551710251493096, 'batch_size': 111, 'beta_1': 0.8915541755353381, 'beta_2': 0.9901205827736775, 'epsilon': 5.63784121294276e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0001323157787010992, 'tol': 0.047215381686007876, 'validation_fraction': 0.21433536742433673}]
function_evaluation time 0.906651 value 0.724937 suggestion {'alpha': 1.7551710251493096, 'batch_size': 111, 'beta_1': 0.8915541755353381, 'beta_2': 0.9901205827736775, 'epsilon': 5.63784121294276e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0001323157787010992, 'tol': 0.047215381686007876, 'validation_fraction': 0.21433536742433673}
observation time 0.001394, current best 0.219557 at iter 5
suggestion time taken 0.001693 iter 6 next_points [{'alpha': 8.487491584220285, 'batch_size': 57, 'beta_1': 0.9798683760646371, 'beta_2': 0.9800229570291416, 'epsilon': 7.815594795296263e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.0022435539180143227, 'tol': 5.328952351157732e-05, 'validation_fraction': 0.30809178642376367}]
function_evaluation time 1.335670 value 0.213803 suggestion {'alpha': 8.487491584220285, 'batch_size': 57, 'beta_1': 0.9798683760646371, 'beta_2': 0.9800229570291416, 'epsilon': 7.815594795296263e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.0022435539180143227, 'tol': 5.328952351157732e-05, 'validation_fraction': 0.30809178642376367}
observation time 0.001567, current best 0.213803 at iter 6
suggestion time taken 0.001839 iter 7 next_points [{'alpha': 1.9714576673309712e-05, 'batch_size': 154, 'beta_1': 0.9424439858640952, 'beta_2': 0.9999989024095864, 'epsilon': 1.521568464720717e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.015988998623213596, 'tol': 0.0008255733664234875, 'validation_fraction': 0.7099354592112745}]
function_evaluation time 0.830258 value 0.302082 suggestion {'alpha': 1.9714576673309712e-05, 'batch_size': 154, 'beta_1': 0.9424439858640952, 'beta_2': 0.9999989024095864, 'epsilon': 1.521568464720717e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.015988998623213596, 'tol': 0.0008255733664234875, 'validation_fraction': 0.7099354592112745}
observation time 0.001401, current best 0.213803 at iter 7
suggestion time taken 0.001710 iter 8 next_points [{'alpha': 0.0009277854147487825, 'batch_size': 33, 'beta_1': 0.9607041329108846, 'beta_2': 0.9986794650797799, 'epsilon': 2.376429328395707e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 1.1276652225440758e-05, 'tol': 0.03428409534282148, 'validation_fraction': 0.8376769033087881}]
function_evaluation time 0.330559 value 8.639713 suggestion {'alpha': 0.0009277854147487825, 'batch_size': 33, 'beta_1': 0.9607041329108846, 'beta_2': 0.9986794650797799, 'epsilon': 2.376429328395707e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 1.1276652225440758e-05, 'tol': 0.03428409534282148, 'validation_fraction': 0.8376769033087881}
observation time 0.001432, current best 0.213803 at iter 8
suggestion time taken 0.001701 iter 9 next_points [{'alpha': 0.008865525993780448, 'batch_size': 218, 'beta_1': 0.7894816030221518, 'beta_2': 0.9999930989472393, 'epsilon': 1.577412421039082e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 3.662884404837395e-05, 'tol': 0.0021940974041881082, 'validation_fraction': 0.5076492132176226}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.569068 value 9.131007 suggestion {'alpha': 0.008865525993780448, 'batch_size': 218, 'beta_1': 0.7894816030221518, 'beta_2': 0.9999930989472393, 'epsilon': 1.577412421039082e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 3.662884404837395e-05, 'tol': 0.0021940974041881082, 'validation_fraction': 0.5076492132176226}
observation time 0.001416, current best 0.213803 at iter 9
suggestion time taken 0.001749 iter 10 next_points [{'alpha': 0.05424394652130875, 'batch_size': 176, 'beta_1': 0.9765628487877204, 'beta_2': 0.9999535130758346, 'epsilon': 3.7775781661384253e-07, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.00892082787958108, 'tol': 1.2470264211195619e-05, 'validation_fraction': 0.2374472170491429}]
function_evaluation time 0.904880 value 0.164931 suggestion {'alpha': 0.05424394652130875, 'batch_size': 176, 'beta_1': 0.9765628487877204, 'beta_2': 0.9999535130758346, 'epsilon': 3.7775781661384253e-07, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.00892082787958108, 'tol': 1.2470264211195619e-05, 'validation_fraction': 0.2374472170491429}
observation time 0.001420, current best 0.164931 at iter 10
suggestion time taken 0.001987 iter 11 next_points [{'alpha': 4.357894375970319, 'batch_size': 101, 'beta_1': 0.6103851693430241, 'beta_2': 0.9953830615557495, 'epsilon': 6.917920742330463e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 4.425120306214359e-05, 'tol': 0.010886850073704468, 'validation_fraction': 0.459086332852322}]
function_evaluation time 0.290334 value 11.015858 suggestion {'alpha': 4.357894375970319, 'batch_size': 101, 'beta_1': 0.6103851693430241, 'beta_2': 0.9953830615557495, 'epsilon': 6.917920742330463e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 4.425120306214359e-05, 'tol': 0.010886850073704468, 'validation_fraction': 0.459086332852322}
observation time 0.001386, current best 0.164931 at iter 11
suggestion time taken 0.002001 iter 12 next_points [{'alpha': 0.00028321010980953695, 'batch_size': 72, 'beta_1': 0.9017139456013977, 'beta_2': 0.9360331390765134, 'epsilon': 1.0601549150491915e-07, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.00019014627847162624, 'tol': 0.08721824871527334, 'validation_fraction': 0.13681858968520832}]
function_evaluation time 0.781041 value 0.373732 suggestion {'alpha': 0.00028321010980953695, 'batch_size': 72, 'beta_1': 0.9017139456013977, 'beta_2': 0.9360331390765134, 'epsilon': 1.0601549150491915e-07, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.00019014627847162624, 'tol': 0.08721824871527334, 'validation_fraction': 0.13681858968520832}
observation time 0.001372, current best 0.164931 at iter 12
suggestion time taken 0.001674 iter 13 next_points [{'alpha': 0.002794704186968833, 'batch_size': 130, 'beta_1': 0.7041981191929071, 'beta_2': 0.9999107533417696, 'epsilon': 2.6711703637542822e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0017194094551584236, 'tol': 0.00029058352101972283, 'validation_fraction': 0.16935600061102637}]
function_evaluation time 1.295232 value 0.135397 suggestion {'alpha': 0.002794704186968833, 'batch_size': 130, 'beta_1': 0.7041981191929071, 'beta_2': 0.9999107533417696, 'epsilon': 2.6711703637542822e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0017194094551584236, 'tol': 0.00029058352101972283, 'validation_fraction': 0.16935600061102637}
observation time 0.001627, current best 0.135397 at iter 13
suggestion time taken 0.001795 iter 14 next_points [{'alpha': 0.00014992455025596805, 'batch_size': 229, 'beta_1': 0.9735272578371631, 'beta_2': 0.9999823186291117, 'epsilon': 7.444683910545628e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.05969391479442739, 'tol': 0.0015264244625783352, 'validation_fraction': 0.8962564478503192}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.277407 value 5.628444 suggestion {'alpha': 0.00014992455025596805, 'batch_size': 229, 'beta_1': 0.9735272578371631, 'beta_2': 0.9999823186291117, 'epsilon': 7.444683910545628e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.05969391479442739, 'tol': 0.0015264244625783352, 'validation_fraction': 0.8962564478503192}
observation time 0.001344, current best 0.135397 at iter 14
saving meta data: {'args': {'--uuid': 'f965bcd6e8ac541fb24a69f8c74ca703', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

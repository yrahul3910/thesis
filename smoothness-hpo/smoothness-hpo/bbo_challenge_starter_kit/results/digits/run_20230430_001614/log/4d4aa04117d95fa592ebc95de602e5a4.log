running: {'--uuid': '4d4aa04117d95fa592ebc95de602e5a4', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d digits -o random-search -u 4d4aa04117d95fa592ebc95de602e5a4 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study random-search MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002527 iter 0 next_points [{'alpha': 1.0229038196654093e-05, 'batch_size': 201, 'beta_1': 0.8291972455077994, 'beta_2': 0.9999526141822622, 'epsilon': 1.234764408244286e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 5.5917774897536566e-05, 'tol': 1.9499725489469926e-05, 'validation_fraction': 0.3441882616706663}]
function_evaluation time 5.279752 value -0.885881 suggestion {'alpha': 1.0229038196654093e-05, 'batch_size': 201, 'beta_1': 0.8291972455077994, 'beta_2': 0.9999526141822622, 'epsilon': 1.234764408244286e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 5.5917774897536566e-05, 'tol': 1.9499725489469926e-05, 'validation_fraction': 0.3441882616706663}
observation time 0.000006, current best -0.885881 at iter 0
suggestion time taken 0.002476 iter 1 next_points [{'alpha': 0.09710646076962638, 'batch_size': 249, 'beta_1': 0.9871058678101466, 'beta_2': 0.9999962203029009, 'epsilon': 8.338507453329543e-07, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.025118862107173068, 'tol': 0.012125191760777263, 'validation_fraction': 0.4473632013520393}]
function_evaluation time 0.674567 value -0.921375 suggestion {'alpha': 0.09710646076962638, 'batch_size': 249, 'beta_1': 0.9871058678101466, 'beta_2': 0.9999962203029009, 'epsilon': 8.338507453329543e-07, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.025118862107173068, 'tol': 0.012125191760777263, 'validation_fraction': 0.4473632013520393}
observation time 0.000005, current best -0.921375 at iter 1
suggestion time taken 0.002764 iter 2 next_points [{'alpha': 0.003595589404349609, 'batch_size': 26, 'beta_1': 0.9842721543448467, 'beta_2': 0.9998753848476739, 'epsilon': 7.016653792420536e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.3068722684967588e-05, 'tol': 0.023069429398318173, 'validation_fraction': 0.36650117588431697}]
function_evaluation time 0.661703 value -0.112679 suggestion {'alpha': 0.003595589404349609, 'batch_size': 26, 'beta_1': 0.9842721543448467, 'beta_2': 0.9998753848476739, 'epsilon': 7.016653792420536e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.3068722684967588e-05, 'tol': 0.023069429398318173, 'validation_fraction': 0.36650117588431697}
observation time 0.000006, current best -0.921375 at iter 2
suggestion time taken 0.002416 iter 3 next_points [{'alpha': 0.01393674773820329, 'batch_size': 93, 'beta_1': 0.7228931437396527, 'beta_2': 0.999987648653048, 'epsilon': 1.366853014783265e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 7.925646896825876e-05, 'tol': 5.127442528851678e-05, 'validation_fraction': 0.3069656521806155}]
function_evaluation time 4.369459 value -0.892867 suggestion {'alpha': 0.01393674773820329, 'batch_size': 93, 'beta_1': 0.7228931437396527, 'beta_2': 0.999987648653048, 'epsilon': 1.366853014783265e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 7.925646896825876e-05, 'tol': 5.127442528851678e-05, 'validation_fraction': 0.3069656521806155}
observation time 0.000005, current best -0.921375 at iter 3
suggestion time taken 0.002459 iter 4 next_points [{'alpha': 0.5784356475741362, 'batch_size': 39, 'beta_1': 0.6447789236687214, 'beta_2': 0.9806545016510775, 'epsilon': 5.6603522651020816e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0011264805772618408, 'tol': 0.025114679300098242, 'validation_fraction': 0.7928111547074912}]
function_evaluation time 0.518563 value -0.909521 suggestion {'alpha': 0.5784356475741362, 'batch_size': 39, 'beta_1': 0.6447789236687214, 'beta_2': 0.9806545016510775, 'epsilon': 5.6603522651020816e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0011264805772618408, 'tol': 0.025114679300098242, 'validation_fraction': 0.7928111547074912}
observation time 0.000005, current best -0.921375 at iter 4
suggestion time taken 0.002664 iter 5 next_points [{'alpha': 2.746418573962701, 'batch_size': 179, 'beta_1': 0.9523081330610285, 'beta_2': 0.9999759892030936, 'epsilon': 3.618646263130217e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.000874255640368771, 'tol': 0.05517349803804892, 'validation_fraction': 0.10475280519924307}]
function_evaluation time 0.627361 value -0.933210 suggestion {'alpha': 2.746418573962701, 'batch_size': 179, 'beta_1': 0.9523081330610285, 'beta_2': 0.9999759892030936, 'epsilon': 3.618646263130217e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.000874255640368771, 'tol': 0.05517349803804892, 'validation_fraction': 0.10475280519924307}
observation time 0.000005, current best -0.933210 at iter 5
suggestion time taken 0.002406 iter 6 next_points [{'alpha': 1.5449659462903523e-05, 'batch_size': 210, 'beta_1': 0.9851206397104727, 'beta_2': 0.9999986567006883, 'epsilon': 1.4531566452977453e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.03469914011924693, 'tol': 0.0002675659452723882, 'validation_fraction': 0.8819175969382358}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.534176 value -0.677098 suggestion {'alpha': 1.5449659462903523e-05, 'batch_size': 210, 'beta_1': 0.9851206397104727, 'beta_2': 0.9999986567006883, 'epsilon': 1.4531566452977453e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.03469914011924693, 'tol': 0.0002675659452723882, 'validation_fraction': 0.8819175969382358}
observation time 0.000005, current best -0.933210 at iter 6
suggestion time taken 0.002444 iter 7 next_points [{'alpha': 0.029280100571845425, 'batch_size': 35, 'beta_1': 0.9701793298450182, 'beta_2': 0.9994300280654033, 'epsilon': 3.374362456961511e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0014418443332151413, 'tol': 1.1616408659710298e-05, 'validation_fraction': 0.8243015530963367}]
function_evaluation time 0.999005 value -0.924136 suggestion {'alpha': 0.029280100571845425, 'batch_size': 35, 'beta_1': 0.9701793298450182, 'beta_2': 0.9994300280654033, 'epsilon': 3.374362456961511e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0014418443332151413, 'tol': 1.1616408659710298e-05, 'validation_fraction': 0.8243015530963367}
observation time 0.000005, current best -0.933210 at iter 7
suggestion time taken 0.002422 iter 8 next_points [{'alpha': 9.456441874999657, 'batch_size': 103, 'beta_1': 0.8802556566066897, 'beta_2': 0.999998282000513, 'epsilon': 1.9643092510045752e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.0015729320142319207, 'tol': 1.0866664080507179e-05, 'validation_fraction': 0.6505874129599736}]
function_evaluation time 1.238012 value -0.955468 suggestion {'alpha': 9.456441874999657, 'batch_size': 103, 'beta_1': 0.8802556566066897, 'beta_2': 0.999998282000513, 'epsilon': 1.9643092510045752e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.0015729320142319207, 'tol': 1.0866664080507179e-05, 'validation_fraction': 0.6505874129599736}
observation time 0.000006, current best -0.955468 at iter 8
suggestion time taken 0.002432 iter 9 next_points [{'alpha': 0.021887454093443715, 'batch_size': 137, 'beta_1': 0.9831104470931888, 'beta_2': 0.9665884021199488, 'epsilon': 7.226197960206524e-08, 'hidden_layer_sizes': 72, 'learning_rate_init': 7.878171055538598e-05, 'tol': 2.549071402010798e-05, 'validation_fraction': 0.13175587882226572}]
function_evaluation time 2.376446 value -0.746477 suggestion {'alpha': 0.021887454093443715, 'batch_size': 137, 'beta_1': 0.9831104470931888, 'beta_2': 0.9665884021199488, 'epsilon': 7.226197960206524e-08, 'hidden_layer_sizes': 72, 'learning_rate_init': 7.878171055538598e-05, 'tol': 2.549071402010798e-05, 'validation_fraction': 0.13175587882226572}
observation time 0.000005, current best -0.955468 at iter 9
suggestion time taken 0.002441 iter 10 next_points [{'alpha': 2.2324800168809564, 'batch_size': 199, 'beta_1': 0.7650807315445182, 'beta_2': 0.9999906696008208, 'epsilon': 6.521707115284302e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.0002154578358949066, 'tol': 7.193590976728407e-05, 'validation_fraction': 0.8739510744223816}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 1.864922 value -0.655321 suggestion {'alpha': 2.2324800168809564, 'batch_size': 199, 'beta_1': 0.7650807315445182, 'beta_2': 0.9999906696008208, 'epsilon': 6.521707115284302e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.0002154578358949066, 'tol': 7.193590976728407e-05, 'validation_fraction': 0.8739510744223816}
observation time 0.000006, current best -0.955468 at iter 10
suggestion time taken 0.002424 iter 11 next_points [{'alpha': 9.63758178007009, 'batch_size': 119, 'beta_1': 0.9456699495108146, 'beta_2': 0.9999888264464318, 'epsilon': 6.296888268188715e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 9.910221292357625e-05, 'tol': 0.004370256545270709, 'validation_fraction': 0.3352056976987232}]
function_evaluation time 2.843944 value -0.891432 suggestion {'alpha': 9.63758178007009, 'batch_size': 119, 'beta_1': 0.9456699495108146, 'beta_2': 0.9999888264464318, 'epsilon': 6.296888268188715e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 9.910221292357625e-05, 'tol': 0.004370256545270709, 'validation_fraction': 0.3352056976987232}
observation time 0.000005, current best -0.955468 at iter 11
suggestion time taken 0.002425 iter 12 next_points [{'alpha': 0.06000955650513467, 'batch_size': 143, 'beta_1': 0.6445213267223012, 'beta_2': 0.9996043645820754, 'epsilon': 3.211198226415004e-09, 'hidden_layer_sizes': 137, 'learning_rate_init': 2.5026299290193673e-05, 'tol': 0.0004116113531700209, 'validation_fraction': 0.19377050830654485}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 5.516667 value -0.687413 suggestion {'alpha': 0.06000955650513467, 'batch_size': 143, 'beta_1': 0.6445213267223012, 'beta_2': 0.9996043645820754, 'epsilon': 3.211198226415004e-09, 'hidden_layer_sizes': 137, 'learning_rate_init': 2.5026299290193673e-05, 'tol': 0.0004116113531700209, 'validation_fraction': 0.19377050830654485}
observation time 0.000005, current best -0.955468 at iter 12
suggestion time taken 0.002398 iter 13 next_points [{'alpha': 0.028657000654333537, 'batch_size': 193, 'beta_1': 0.987492542800503, 'beta_2': 0.9843232177118717, 'epsilon': 1.4806655595599042e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.001618050995341202, 'tol': 0.03719019759264034, 'validation_fraction': 0.20909442892595895}]
function_evaluation time 0.566603 value -0.933892 suggestion {'alpha': 0.028657000654333537, 'batch_size': 193, 'beta_1': 0.987492542800503, 'beta_2': 0.9843232177118717, 'epsilon': 1.4806655595599042e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.001618050995341202, 'tol': 0.03719019759264034, 'validation_fraction': 0.20909442892595895}
observation time 0.000005, current best -0.955468 at iter 13
suggestion time taken 0.002464 iter 14 next_points [{'alpha': 0.04041891776668327, 'batch_size': 47, 'beta_1': 0.9858102336562414, 'beta_2': 0.9869824349348217, 'epsilon': 6.41696905615408e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.004302216421771973, 'tol': 0.04372687642947644, 'validation_fraction': 0.6909229255271139}]
function_evaluation time 0.418349 value -0.934587 suggestion {'alpha': 0.04041891776668327, 'batch_size': 47, 'beta_1': 0.9858102336562414, 'beta_2': 0.9869824349348217, 'epsilon': 6.41696905615408e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.004302216421771973, 'tol': 0.04372687642947644, 'validation_fraction': 0.6909229255271139}
observation time 0.000005, current best -0.955468 at iter 14
saving meta data: {'args': {'--uuid': '4d4aa04117d95fa592ebc95de602e5a4', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

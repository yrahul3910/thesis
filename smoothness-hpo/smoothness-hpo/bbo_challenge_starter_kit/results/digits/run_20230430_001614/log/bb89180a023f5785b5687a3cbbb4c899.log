running: {'--uuid': 'bb89180a023f5785b5687a3cbbb4c899', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u bb89180a023f5785b5687a3cbbb4c899 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study smoothness MLP-adam digits acc 15 1
with data root: None
suggestion time taken 9.455852 iter 0 next_points [{'alpha': 7.04098033396125, 'batch_size': 21, 'beta_1': 0.9858005071371269, 'beta_2': 0.9561659851388825, 'epsilon': 1.726934884645421e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 1.972812562300252e-05, 'tol': 0.006704565180128642, 'validation_fraction': 0.35808009746594627}]
function_evaluation time 5.794379 value -0.869202 suggestion {'alpha': 7.04098033396125, 'batch_size': 21, 'beta_1': 0.9858005071371269, 'beta_2': 0.9561659851388825, 'epsilon': 1.726934884645421e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 1.972812562300252e-05, 'tol': 0.006704565180128642, 'validation_fraction': 0.35808009746594627}
observation time 0.000007, current best -0.869202 at iter 0
suggestion time taken 9.253718 iter 1 next_points [{'alpha': 0.06323184252960164, 'batch_size': 11, 'beta_1': 0.9853727422642443, 'beta_2': 0.9813512267818095, 'epsilon': 2.4781705459398813e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0014519043596065526, 'tol': 1.5735211724657145e-05, 'validation_fraction': 0.4009161481662487}]
function_evaluation time 3.174164 value -0.968699 suggestion {'alpha': 0.06323184252960164, 'batch_size': 11, 'beta_1': 0.9853727422642443, 'beta_2': 0.9813512267818095, 'epsilon': 2.4781705459398813e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0014519043596065526, 'tol': 1.5735211724657145e-05, 'validation_fraction': 0.4009161481662487}
observation time 0.000005, current best -0.968699 at iter 1
suggestion time taken 9.309564 iter 2 next_points [{'alpha': 2.013617693656756, 'batch_size': 19, 'beta_1': 0.970267124390285, 'beta_2': 0.9974935153766844, 'epsilon': 4.33579474183213e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0032450537331863817, 'tol': 1.88443714029479e-05, 'validation_fraction': 0.2302802269931724}]
function_evaluation time 1.844579 value -0.960332 suggestion {'alpha': 2.013617693656756, 'batch_size': 19, 'beta_1': 0.970267124390285, 'beta_2': 0.9974935153766844, 'epsilon': 4.33579474183213e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0032450537331863817, 'tol': 1.88443714029479e-05, 'validation_fraction': 0.2302802269931724}
observation time 0.000005, current best -0.968699 at iter 2
suggestion time taken 9.494066 iter 3 next_points [{'alpha': 0.1667499249301836, 'batch_size': 23, 'beta_1': 0.8654537739491163, 'beta_2': 0.999911693958945, 'epsilon': 2.4642854651743378e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0979633756961871, 'tol': 0.0008444083860978701, 'validation_fraction': 0.6606584304034816}]
function_evaluation time 0.577859 value -0.251677 suggestion {'alpha': 0.1667499249301836, 'batch_size': 23, 'beta_1': 0.8654537739491163, 'beta_2': 0.999911693958945, 'epsilon': 2.4642854651743378e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0979633756961871, 'tol': 0.0008444083860978701, 'validation_fraction': 0.6606584304034816}
observation time 0.000006, current best -0.968699 at iter 3
suggestion time taken 9.273393 iter 4 next_points [{'alpha': 0.0009529940355837556, 'batch_size': 35, 'beta_1': 0.7264871041743112, 'beta_2': 0.999216825098208, 'epsilon': 1.5140016441833674e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.004055181205049671, 'tol': 0.001118101235741212, 'validation_fraction': 0.7562260788795213}]
function_evaluation time 1.416389 value -0.931826 suggestion {'alpha': 0.0009529940355837556, 'batch_size': 35, 'beta_1': 0.7264871041743112, 'beta_2': 0.999216825098208, 'epsilon': 1.5140016441833674e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.004055181205049671, 'tol': 0.001118101235741212, 'validation_fraction': 0.7562260788795213}
observation time 0.000006, current best -0.968699 at iter 4
suggestion time taken 9.272229 iter 5 next_points [{'alpha': 0.043044392821189804, 'batch_size': 18, 'beta_1': 0.8309764877288537, 'beta_2': 0.999846038669765, 'epsilon': 4.3635083106585195e-07, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.025537961509910993, 'tol': 0.017678804499815633, 'validation_fraction': 0.6139339207789508}]
function_evaluation time 0.740710 value -0.932518 suggestion {'alpha': 0.043044392821189804, 'batch_size': 18, 'beta_1': 0.8309764877288537, 'beta_2': 0.999846038669765, 'epsilon': 4.3635083106585195e-07, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.025537961509910993, 'tol': 0.017678804499815633, 'validation_fraction': 0.6139339207789508}
observation time 0.000006, current best -0.968699 at iter 5
suggestion time taken 9.241633 iter 6 next_points [{'alpha': 0.13902214361086032, 'batch_size': 39, 'beta_1': 0.9732561964211733, 'beta_2': 0.9999821155021005, 'epsilon': 2.6299227076705576e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 2.2128053973977447e-05, 'tol': 0.00017807879461161023, 'validation_fraction': 0.24487703663031093}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 7.348015 value -0.701082 suggestion {'alpha': 0.13902214361086032, 'batch_size': 39, 'beta_1': 0.9732561964211733, 'beta_2': 0.9999821155021005, 'epsilon': 2.6299227076705576e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 2.2128053973977447e-05, 'tol': 0.00017807879461161023, 'validation_fraction': 0.24487703663031093}
observation time 0.000006, current best -0.968699 at iter 6
suggestion time taken 9.295068 iter 7 next_points [{'alpha': 3.568212137672398e-05, 'batch_size': 27, 'beta_1': 0.9166511082260159, 'beta_2': 0.9999133024619696, 'epsilon': 1.4093288293068913e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.00030518070514152086, 'tol': 0.010237700796880368, 'validation_fraction': 0.5056063016505598}]
function_evaluation time 1.446014 value -0.890053 suggestion {'alpha': 3.568212137672398e-05, 'batch_size': 27, 'beta_1': 0.9166511082260159, 'beta_2': 0.9999133024619696, 'epsilon': 1.4093288293068913e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.00030518070514152086, 'tol': 0.010237700796880368, 'validation_fraction': 0.5056063016505598}
observation time 0.000005, current best -0.968699 at iter 7
suggestion time taken 9.194698 iter 8 next_points [{'alpha': 0.0004986683051153416, 'batch_size': 33, 'beta_1': 0.8891578522084888, 'beta_2': 0.9999984556186533, 'epsilon': 6.3088246578111e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.021732208480200122, 'tol': 0.054229113961514065, 'validation_fraction': 0.7984299368847788}]
function_evaluation time 0.421313 value -0.924146 suggestion {'alpha': 0.0004986683051153416, 'batch_size': 33, 'beta_1': 0.8891578522084888, 'beta_2': 0.9999984556186533, 'epsilon': 6.3088246578111e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.021732208480200122, 'tol': 0.054229113961514065, 'validation_fraction': 0.7984299368847788}
observation time 0.000006, current best -0.968699 at iter 8
suggestion time taken 9.325561 iter 9 next_points [{'alpha': 0.008314760370416955, 'batch_size': 17, 'beta_1': 0.9136937003076324, 'beta_2': 0.9902758118853123, 'epsilon': 3.0045303928568143e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.00022046193188341665, 'tol': 0.0004476739985091144, 'validation_fraction': 0.6957607265159188}]
function_evaluation time 4.666837 value -0.937364 suggestion {'alpha': 0.008314760370416955, 'batch_size': 17, 'beta_1': 0.9136937003076324, 'beta_2': 0.9902758118853123, 'epsilon': 3.0045303928568143e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.00022046193188341665, 'tol': 0.0004476739985091144, 'validation_fraction': 0.6957607265159188}
observation time 0.000006, current best -0.968699 at iter 9
suggestion time taken 9.292826 iter 10 next_points [{'alpha': 0.002640477546623543, 'batch_size': 38, 'beta_1': 0.8246321141578922, 'beta_2': 0.999987411271493, 'epsilon': 7.898069446613457e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0008673578951121778, 'tol': 0.013273260647699943, 'validation_fraction': 0.4755294746144273}]
function_evaluation time 0.799846 value -0.928339 suggestion {'alpha': 0.002640477546623543, 'batch_size': 38, 'beta_1': 0.8246321141578922, 'beta_2': 0.999987411271493, 'epsilon': 7.898069446613457e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0008673578951121778, 'tol': 0.013273260647699943, 'validation_fraction': 0.4755294746144273}
observation time 0.000006, current best -0.968699 at iter 10
suggestion time taken 9.332890 iter 11 next_points [{'alpha': 0.002131097842124103, 'batch_size': 36, 'beta_1': 0.862208056677007, 'beta_2': 0.9999551741331103, 'epsilon': 3.8206295748632365e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.0002341263332652078, 'tol': 0.0007403146846931682, 'validation_fraction': 0.24610462610480496}]
function_evaluation time 3.895465 value -0.940861 suggestion {'alpha': 0.002131097842124103, 'batch_size': 36, 'beta_1': 0.862208056677007, 'beta_2': 0.9999551741331103, 'epsilon': 3.8206295748632365e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.0002341263332652078, 'tol': 0.0007403146846931682, 'validation_fraction': 0.24610462610480496}
observation time 0.000005, current best -0.968699 at iter 11
suggestion time taken 9.238157 iter 12 next_points [{'alpha': 0.13672657813132608, 'batch_size': 21, 'beta_1': 0.6193818124783648, 'beta_2': 0.9995354086987203, 'epsilon': 1.2649030400480922e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 1.522922341359487e-05, 'tol': 0.00027227196514020146, 'validation_fraction': 0.31644190084126905}]
function_evaluation time 12.106440 value -0.707518 suggestion {'alpha': 0.13672657813132608, 'batch_size': 21, 'beta_1': 0.6193818124783648, 'beta_2': 0.9995354086987203, 'epsilon': 1.2649030400480922e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 1.522922341359487e-05, 'tol': 0.00027227196514020146, 'validation_fraction': 0.31644190084126905}
observation time 0.000005, current best -0.968699 at iter 12
suggestion time taken 9.273047 iter 13 next_points [{'alpha': 0.013100531234700546, 'batch_size': 23, 'beta_1': 0.9899922598082599, 'beta_2': 0.9999679539710408, 'epsilon': 4.4295973671406655e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.04199669535611136, 'tol': 2.4169903782527755e-05, 'validation_fraction': 0.29249997930317584}]
function_evaluation time 2.405773 value -0.900501 suggestion {'alpha': 0.013100531234700546, 'batch_size': 23, 'beta_1': 0.9899922598082599, 'beta_2': 0.9999679539710408, 'epsilon': 4.4295973671406655e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.04199669535611136, 'tol': 2.4169903782527755e-05, 'validation_fraction': 0.29249997930317584}
observation time 0.000006, current best -0.968699 at iter 13
suggestion time taken 9.306635 iter 14 next_points [{'alpha': 0.00026172966644673725, 'batch_size': 25, 'beta_1': 0.8013129164342262, 'beta_2': 0.9997301165368412, 'epsilon': 1.195361410305239e-09, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.00010074498922266413, 'tol': 0.016164077663942955, 'validation_fraction': 0.1404335089317977}]
function_evaluation time 1.876774 value -0.870589 suggestion {'alpha': 0.00026172966644673725, 'batch_size': 25, 'beta_1': 0.8013129164342262, 'beta_2': 0.9997301165368412, 'epsilon': 1.195361410305239e-09, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.00010074498922266413, 'tol': 0.016164077663942955, 'validation_fraction': 0.1404335089317977}
observation time 0.000004, current best -0.968699 at iter 14
saving meta data: {'args': {'--uuid': 'bb89180a023f5785b5687a3cbbb4c899', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

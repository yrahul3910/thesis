running: {'--uuid': '8479a29b47fa5b739abcbea04a08a4af', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u 8479a29b47fa5b739abcbea04a08a4af -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study smoothness MLP-adam digits nll 15 1
with data root: None
suggestion time taken 9.419137 iter 0 next_points [{'alpha': 2.2793136541456564e-05, 'batch_size': 34, 'beta_1': 0.8803794690463356, 'beta_2': 0.9993357270653715, 'epsilon': 1.8838956670557677e-09, 'hidden_layer_sizes': 185, 'learning_rate_init': 8.693853001445542e-05, 'tol': 0.04661957997127857, 'validation_fraction': 0.4607787439134781}]
function_evaluation time 1.384655 value 0.568856 suggestion {'alpha': 2.2793136541456564e-05, 'batch_size': 34, 'beta_1': 0.8803794690463356, 'beta_2': 0.9993357270653715, 'epsilon': 1.8838956670557677e-09, 'hidden_layer_sizes': 185, 'learning_rate_init': 8.693853001445542e-05, 'tol': 0.04661957997127857, 'validation_fraction': 0.4607787439134781}
observation time 0.000006, current best 0.568856 at iter 0
suggestion time taken 9.297210 iter 1 next_points [{'alpha': 0.42582194994258404, 'batch_size': 29, 'beta_1': 0.979429835281228, 'beta_2': 0.9999873077183492, 'epsilon': 8.273269205224465e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.00234405451015147, 'tol': 0.0914901839532476, 'validation_fraction': 0.10546504122144575}]
function_evaluation time 0.755039 value 0.139615 suggestion {'alpha': 0.42582194994258404, 'batch_size': 29, 'beta_1': 0.979429835281228, 'beta_2': 0.9999873077183492, 'epsilon': 8.273269205224465e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.00234405451015147, 'tol': 0.0914901839532476, 'validation_fraction': 0.10546504122144575}
observation time 0.000006, current best 0.139615 at iter 1
suggestion time taken 9.251801 iter 2 next_points [{'alpha': 2.5118879689450552e-05, 'batch_size': 19, 'beta_1': 0.7922099422145639, 'beta_2': 0.9999939140553346, 'epsilon': 3.626962475148835e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 1.7183177769330355e-05, 'tol': 1.9895424891230576e-05, 'validation_fraction': 0.5901238741250311}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 10.220809 value 0.582352 suggestion {'alpha': 2.5118879689450552e-05, 'batch_size': 19, 'beta_1': 0.7922099422145639, 'beta_2': 0.9999939140553346, 'epsilon': 3.626962475148835e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 1.7183177769330355e-05, 'tol': 1.9895424891230576e-05, 'validation_fraction': 0.5901238741250311}
observation time 0.000006, current best 0.139615 at iter 2
suggestion time taken 9.579140 iter 3 next_points [{'alpha': 0.00045415936874440707, 'batch_size': 13, 'beta_1': 0.7020735150596084, 'beta_2': 0.9893914196531582, 'epsilon': 8.837643265520092e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.0008503450421584704, 'tol': 1.828344032903116e-05, 'validation_fraction': 0.4930073166922231}]
function_evaluation time 4.279826 value 0.172554 suggestion {'alpha': 0.00045415936874440707, 'batch_size': 13, 'beta_1': 0.7020735150596084, 'beta_2': 0.9893914196531582, 'epsilon': 8.837643265520092e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.0008503450421584704, 'tol': 1.828344032903116e-05, 'validation_fraction': 0.4930073166922231}
observation time 0.000005, current best 0.139615 at iter 3
suggestion time taken 9.230246 iter 4 next_points [{'alpha': 0.36635934439007506, 'batch_size': 24, 'beta_1': 0.6701829505559183, 'beta_2': 0.9999974830869888, 'epsilon': 8.292859207034138e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.00014191362927770082, 'tol': 0.005063288801539193, 'validation_fraction': 0.16317697787022403}]
function_evaluation time 4.492909 value 0.178879 suggestion {'alpha': 0.36635934439007506, 'batch_size': 24, 'beta_1': 0.6701829505559183, 'beta_2': 0.9999974830869888, 'epsilon': 8.292859207034138e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.00014191362927770082, 'tol': 0.005063288801539193, 'validation_fraction': 0.16317697787022403}
observation time 0.000005, current best 0.139615 at iter 4
suggestion time taken 9.241304 iter 5 next_points [{'alpha': 0.9963454260614372, 'batch_size': 12, 'beta_1': 0.9842642223278935, 'beta_2': 0.9996190787571103, 'epsilon': 1.2204399108904865e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.021855475848767632, 'tol': 0.0005914708689885461, 'validation_fraction': 0.7144384539779508}]
function_evaluation time 1.636043 value 0.218526 suggestion {'alpha': 0.9963454260614372, 'batch_size': 12, 'beta_1': 0.9842642223278935, 'beta_2': 0.9996190787571103, 'epsilon': 1.2204399108904865e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.021855475848767632, 'tol': 0.0005914708689885461, 'validation_fraction': 0.7144384539779508}
observation time 0.000006, current best 0.139615 at iter 5
suggestion time taken 9.193658 iter 6 next_points [{'alpha': 2.0909741806079825e-05, 'batch_size': 79, 'beta_1': 0.5942960937332211, 'beta_2': 0.9999973784258799, 'epsilon': 1.5649524946418561e-09, 'hidden_layer_sizes': 50, 'learning_rate_init': 6.710028650905158e-05, 'tol': 0.00017504712710301635, 'validation_fraction': 0.5962586597385343}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.105530 value 7.592253 suggestion {'alpha': 2.0909741806079825e-05, 'batch_size': 79, 'beta_1': 0.5942960937332211, 'beta_2': 0.9999973784258799, 'epsilon': 1.5649524946418561e-09, 'hidden_layer_sizes': 50, 'learning_rate_init': 6.710028650905158e-05, 'tol': 0.00017504712710301635, 'validation_fraction': 0.5962586597385343}
observation time 0.000006, current best 0.139615 at iter 6
suggestion time taken 9.230103 iter 7 next_points [{'alpha': 2.833103757496038, 'batch_size': 38, 'beta_1': 0.9880240293356163, 'beta_2': 0.9893471604046535, 'epsilon': 7.524993536450706e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.00010888425574728462, 'tol': 0.0008654121789823757, 'validation_fraction': 0.7495879958482489}]
function_evaluation time 4.982687 value 0.248652 suggestion {'alpha': 2.833103757496038, 'batch_size': 38, 'beta_1': 0.9880240293356163, 'beta_2': 0.9893471604046535, 'epsilon': 7.524993536450706e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.00010888425574728462, 'tol': 0.0008654121789823757, 'validation_fraction': 0.7495879958482489}
observation time 0.000005, current best 0.139615 at iter 7
suggestion time taken 9.258664 iter 8 next_points [{'alpha': 1.3169824181865846, 'batch_size': 11, 'beta_1': 0.5315592980667124, 'beta_2': 0.9999304537891852, 'epsilon': 4.9236191646268265e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 1.3014120660125281e-05, 'tol': 5.903643455382983e-05, 'validation_fraction': 0.7695742220287631}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 7.877722 value 3.366856 suggestion {'alpha': 1.3169824181865846, 'batch_size': 11, 'beta_1': 0.5315592980667124, 'beta_2': 0.9999304537891852, 'epsilon': 4.9236191646268265e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 1.3014120660125281e-05, 'tol': 5.903643455382983e-05, 'validation_fraction': 0.7695742220287631}
observation time 0.000006, current best 0.139615 at iter 8
suggestion time taken 9.263207 iter 9 next_points [{'alpha': 0.06557270417337262, 'batch_size': 54, 'beta_1': 0.812401078243198, 'beta_2': 0.9999858175884083, 'epsilon': 1.4297402783729597e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0017354666705917063, 'tol': 0.004223520695625446, 'validation_fraction': 0.4841176395107006}]
function_evaluation time 0.903071 value 0.165141 suggestion {'alpha': 0.06557270417337262, 'batch_size': 54, 'beta_1': 0.812401078243198, 'beta_2': 0.9999858175884083, 'epsilon': 1.4297402783729597e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0017354666705917063, 'tol': 0.004223520695625446, 'validation_fraction': 0.4841176395107006}
observation time 0.000005, current best 0.139615 at iter 9
suggestion time taken 9.187876 iter 10 next_points [{'alpha': 1.1849799122781797, 'batch_size': 28, 'beta_1': 0.8515862196827673, 'beta_2': 0.9999496192342531, 'epsilon': 7.11679044873532e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.007263971132108135, 'tol': 0.0023181285441571356, 'validation_fraction': 0.76799344660482}]
function_evaluation time 0.926769 value 0.201331 suggestion {'alpha': 1.1849799122781797, 'batch_size': 28, 'beta_1': 0.8515862196827673, 'beta_2': 0.9999496192342531, 'epsilon': 7.11679044873532e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.007263971132108135, 'tol': 0.0023181285441571356, 'validation_fraction': 0.76799344660482}
observation time 0.000005, current best 0.139615 at iter 10
suggestion time taken 9.286952 iter 11 next_points [{'alpha': 9.368390841537447, 'batch_size': 22, 'beta_1': 0.9887789332154149, 'beta_2': 0.9999825696673544, 'epsilon': 1.229436654142099e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 3.414731057054024e-05, 'tol': 0.0004592604257703901, 'validation_fraction': 0.4250936535971794}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 7.334029 value 4.689220 suggestion {'alpha': 9.368390841537447, 'batch_size': 22, 'beta_1': 0.9887789332154149, 'beta_2': 0.9999825696673544, 'epsilon': 1.229436654142099e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 3.414731057054024e-05, 'tol': 0.0004592604257703901, 'validation_fraction': 0.4250936535971794}
observation time 0.000005, current best 0.139615 at iter 11
suggestion time taken 9.245451 iter 12 next_points [{'alpha': 0.011239440452629139, 'batch_size': 13, 'beta_1': 0.9424627386181413, 'beta_2': 0.9999689216867422, 'epsilon': 5.207033321384561e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.06365202583550138, 'tol': 1.4583360185813171e-05, 'validation_fraction': 0.7114159309709622}]
function_evaluation time 0.803277 value 1.461818 suggestion {'alpha': 0.011239440452629139, 'batch_size': 13, 'beta_1': 0.9424627386181413, 'beta_2': 0.9999689216867422, 'epsilon': 5.207033321384561e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.06365202583550138, 'tol': 1.4583360185813171e-05, 'validation_fraction': 0.7114159309709622}
observation time 0.000005, current best 0.139615 at iter 12
suggestion time taken 9.260113 iter 13 next_points [{'alpha': 0.00012981307021811702, 'batch_size': 22, 'beta_1': 0.8262284845883016, 'beta_2': 0.9997698631941294, 'epsilon': 2.42132415266217e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.00014478648919547443, 'tol': 1.9778354345842205e-05, 'validation_fraction': 0.48400212873102955}]
function_evaluation time 5.916625 value 0.270180 suggestion {'alpha': 0.00012981307021811702, 'batch_size': 22, 'beta_1': 0.8262284845883016, 'beta_2': 0.9997698631941294, 'epsilon': 2.42132415266217e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.00014478648919547443, 'tol': 1.9778354345842205e-05, 'validation_fraction': 0.48400212873102955}
observation time 0.000005, current best 0.139615 at iter 13
suggestion time taken 9.211160 iter 14 next_points [{'alpha': 0.20474150253107276, 'batch_size': 14, 'beta_1': 0.8282316403130168, 'beta_2': 0.9999984531050999, 'epsilon': 8.41699184197767e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 3.083823769626956e-05, 'tol': 0.08337384958189867, 'validation_fraction': 0.7618995936923132}]
function_evaluation time 0.479347 value 6.376201 suggestion {'alpha': 0.20474150253107276, 'batch_size': 14, 'beta_1': 0.8282316403130168, 'beta_2': 0.9999984531050999, 'epsilon': 8.41699184197767e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 3.083823769626956e-05, 'tol': 0.08337384958189867, 'validation_fraction': 0.7618995936923132}
observation time 0.000006, current best 0.139615 at iter 14
saving meta data: {'args': {'--uuid': '8479a29b47fa5b739abcbea04a08a4af', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

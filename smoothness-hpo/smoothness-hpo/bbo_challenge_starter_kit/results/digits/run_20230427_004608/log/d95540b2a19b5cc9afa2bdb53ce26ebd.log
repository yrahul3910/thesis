running: {'--uuid': 'd95540b2a19b5cc9afa2bdb53ce26ebd', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d diabetes -o opentuner -u d95540b2a19b5cc9afa2bdb53ce26ebd -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230427_004608
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study opentuner MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.031612 iter 0 next_points [{'hidden_layer_sizes': 99, 'alpha': 1.9119814631232335, 'batch_size': 217, 'learning_rate_init': 0.058967445235883424, 'tol': 0.057149572065389335, 'validation_fraction': 0.2292686293177294, 'beta_1': 0.6453063045548819, 'beta_2': 0.943122705359186, 'epsilon': 4.350872148400621e-07}]
function_evaluation time 0.151408 value 54.570741 suggestion {'hidden_layer_sizes': 99, 'alpha': 1.9119814631232335, 'batch_size': 217, 'learning_rate_init': 0.058967445235883424, 'tol': 0.057149572065389335, 'validation_fraction': 0.2292686293177294, 'beta_1': 0.6453063045548819, 'beta_2': 0.943122705359186, 'epsilon': 4.350872148400621e-07}
observation time 0.004251, current best 54.570741 at iter 0
suggestion time taken 0.007819 iter 1 next_points [{'hidden_layer_sizes': 99, 'alpha': 1.3138105314608488, 'batch_size': 217, 'learning_rate_init': 0.058967445235883424, 'tol': 0.056996468251554404, 'validation_fraction': 0.2292686293177294, 'beta_1': 0.6453063045548819, 'beta_2': 0.943122705359186, 'epsilon': 4.350872148400621e-07}]
function_evaluation time 0.159840 value 54.856966 suggestion {'hidden_layer_sizes': 99, 'alpha': 1.3138105314608488, 'batch_size': 217, 'learning_rate_init': 0.058967445235883424, 'tol': 0.056996468251554404, 'validation_fraction': 0.2292686293177294, 'beta_1': 0.6453063045548819, 'beta_2': 0.943122705359186, 'epsilon': 4.350872148400621e-07}
observation time 0.001870, current best 54.570741 at iter 1
suggestion time taken 0.007103 iter 2 next_points [{'hidden_layer_sizes': 99, 'alpha': 6.062188836814975, 'batch_size': 217, 'learning_rate_init': 0.0385489470482056, 'tol': 0.057149572065389335, 'validation_fraction': 0.6041300362238382, 'beta_1': 0.6453063045548819, 'beta_2': 0.943122705359186, 'epsilon': 4.350872148400621e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.181994 value 52.033236 suggestion {'hidden_layer_sizes': 99, 'alpha': 6.062188836814975, 'batch_size': 217, 'learning_rate_init': 0.0385489470482056, 'tol': 0.057149572065389335, 'validation_fraction': 0.6041300362238382, 'beta_1': 0.6453063045548819, 'beta_2': 0.943122705359186, 'epsilon': 4.350872148400621e-07}
observation time 0.001874, current best 52.033236 at iter 2
suggestion time taken 0.046334 iter 3 next_points [{'validation_fraction': 0.28491274488446755, 'beta_2': 0.949978962693292, 'batch_size': 207, 'tol': 0.0976834625192106, 'epsilon': 2.719260267241831e-07, 'alpha': 3.446720692607643, 'hidden_layer_sizes': 141, 'beta_1': 0.5113209862709318, 'learning_rate_init': 0.05843050372002783}]
function_evaluation time 0.151494 value 49.924822 suggestion {'validation_fraction': 0.28491274488446755, 'beta_2': 0.949978962693292, 'batch_size': 207, 'tol': 0.0976834625192106, 'epsilon': 2.719260267241831e-07, 'alpha': 3.446720692607643, 'hidden_layer_sizes': 141, 'beta_1': 0.5113209862709318, 'learning_rate_init': 0.05843050372002783}
observation time 0.001852, current best 49.924822 at iter 3
suggestion time taken 0.006848 iter 4 next_points [{'validation_fraction': 0.28491274488446755, 'beta_2': 0.9038872773256861, 'batch_size': 207, 'tol': 0.0976834625192106, 'epsilon': 2.719260267241831e-07, 'alpha': 3.446720692607643, 'hidden_layer_sizes': 141, 'beta_1': 0.5113209862709318, 'learning_rate_init': 0.05843050372002783}]
function_evaluation time 0.158023 value 50.325839 suggestion {'validation_fraction': 0.28491274488446755, 'beta_2': 0.9038872773256861, 'batch_size': 207, 'tol': 0.0976834625192106, 'epsilon': 2.719260267241831e-07, 'alpha': 3.446720692607643, 'hidden_layer_sizes': 141, 'beta_1': 0.5113209862709318, 'learning_rate_init': 0.05843050372002783}
observation time 0.001859, current best 49.924822 at iter 4
suggestion time taken 0.006450 iter 5 next_points [{'hidden_layer_sizes': 71, 'alpha': 0.15584663224128364, 'batch_size': 92, 'learning_rate_init': 0.059797094322336646, 'tol': 0.01406125186191114, 'validation_fraction': 0.5202061735621407, 'beta_1': 0.7059454912465633, 'beta_2': 0.9194348899371775, 'epsilon': 1.1342265229860493e-07}]
function_evaluation time 0.142596 value 49.164228 suggestion {'hidden_layer_sizes': 71, 'alpha': 0.15584663224128364, 'batch_size': 92, 'learning_rate_init': 0.059797094322336646, 'tol': 0.01406125186191114, 'validation_fraction': 0.5202061735621407, 'beta_1': 0.7059454912465633, 'beta_2': 0.9194348899371775, 'epsilon': 1.1342265229860493e-07}
observation time 0.001957, current best 49.164228 at iter 5
suggestion time taken 0.005193 iter 6 next_points [{'validation_fraction': 0.2608791669823492, 'beta_2': 0.9740269052207332, 'batch_size': 46, 'tol': 0.06420532533816951, 'epsilon': 4.762251865358659e-07, 'alpha': 2.564704489844732, 'hidden_layer_sizes': 170, 'beta_1': 0.573550313035162, 'learning_rate_init': 0.011918440855445512}]
function_evaluation time 0.293910 value 51.067909 suggestion {'validation_fraction': 0.2608791669823492, 'beta_2': 0.9740269052207332, 'batch_size': 46, 'tol': 0.06420532533816951, 'epsilon': 4.762251865358659e-07, 'alpha': 2.564704489844732, 'hidden_layer_sizes': 170, 'beta_1': 0.573550313035162, 'learning_rate_init': 0.011918440855445512}
observation time 0.001905, current best 49.164228 at iter 6
suggestion time taken 0.006049 iter 7 next_points [{'hidden_layer_sizes': 184, 'alpha': 2.2168072567913635, 'batch_size': 20, 'learning_rate_init': 0.07021322314545968, 'tol': 0.044343114569819146, 'validation_fraction': 0.25118763561578894, 'beta_1': 0.9173798631282506, 'beta_2': 0.9148049180446371, 'epsilon': 2.1648705309015758e-07}]
function_evaluation time 0.277535 value 44.662704 suggestion {'hidden_layer_sizes': 184, 'alpha': 2.2168072567913635, 'batch_size': 20, 'learning_rate_init': 0.07021322314545968, 'tol': 0.044343114569819146, 'validation_fraction': 0.25118763561578894, 'beta_1': 0.9173798631282506, 'beta_2': 0.9148049180446371, 'epsilon': 2.1648705309015758e-07}
observation time 0.001837, current best 44.662704 at iter 7
suggestion time taken 0.006110 iter 8 next_points [{'hidden_layer_sizes': 196, 'alpha': 8.282186591119043, 'batch_size': 76, 'learning_rate_init': 0.03442580266434286, 'tol': 0.03277342933673915, 'validation_fraction': 0.6605605398680809, 'beta_1': 0.9403712896983842, 'beta_2': 0.9725201047314067, 'epsilon': 6.922956826976568e-07}]
function_evaluation time 0.219165 value 52.952230 suggestion {'hidden_layer_sizes': 196, 'alpha': 8.282186591119043, 'batch_size': 76, 'learning_rate_init': 0.03442580266434286, 'tol': 0.03277342933673915, 'validation_fraction': 0.6605605398680809, 'beta_1': 0.9403712896983842, 'beta_2': 0.9725201047314067, 'epsilon': 6.922956826976568e-07}
observation time 0.002090, current best 44.662704 at iter 8
suggestion time taken 0.006177 iter 9 next_points [{'hidden_layer_sizes': 119, 'alpha': 1.9461729355193396, 'batch_size': 189, 'learning_rate_init': 0.07353137111789125, 'tol': 0.005287849653682942, 'validation_fraction': 0.5508492176224269, 'beta_1': 0.6821154059478725, 'beta_2': 0.9680380305249219, 'epsilon': 8.872317464574508e-09}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.175206 value 46.501648 suggestion {'hidden_layer_sizes': 119, 'alpha': 1.9461729355193396, 'batch_size': 189, 'learning_rate_init': 0.07353137111789125, 'tol': 0.005287849653682942, 'validation_fraction': 0.5508492176224269, 'beta_1': 0.6821154059478725, 'beta_2': 0.9680380305249219, 'epsilon': 8.872317464574508e-09}
observation time 0.002047, current best 44.662704 at iter 9
suggestion time taken 0.006192 iter 10 next_points [{'hidden_layer_sizes': 92, 'alpha': 9.682797378815742, 'batch_size': 164, 'learning_rate_init': 0.08742220157245366, 'tol': 0.007455806936127841, 'validation_fraction': 0.16804254449762218, 'beta_1': 0.7712213993868045, 'beta_2': 0.9035373952232378, 'epsilon': 3.6277587370289646e-07}]
function_evaluation time 0.195853 value 44.467648 suggestion {'hidden_layer_sizes': 92, 'alpha': 9.682797378815742, 'batch_size': 164, 'learning_rate_init': 0.08742220157245366, 'tol': 0.007455806936127841, 'validation_fraction': 0.16804254449762218, 'beta_1': 0.7712213993868045, 'beta_2': 0.9035373952232378, 'epsilon': 3.6277587370289646e-07}
observation time 0.002748, current best 44.467648 at iter 10
suggestion time taken 0.005929 iter 11 next_points [{'hidden_layer_sizes': 152, 'alpha': 1.3229888113135995, 'batch_size': 184, 'learning_rate_init': 0.046116937069944956, 'tol': 0.08483002272855604, 'validation_fraction': 0.5628680334110648, 'beta_1': 0.7723469010243602, 'beta_2': 0.9097410236390502, 'epsilon': 6.825181263775116e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.175613 value 52.492669 suggestion {'hidden_layer_sizes': 152, 'alpha': 1.3229888113135995, 'batch_size': 184, 'learning_rate_init': 0.046116937069944956, 'tol': 0.08483002272855604, 'validation_fraction': 0.5628680334110648, 'beta_1': 0.7723469010243602, 'beta_2': 0.9097410236390502, 'epsilon': 6.825181263775116e-07}
observation time 0.001883, current best 44.467648 at iter 11
suggestion time taken 0.006032 iter 12 next_points [{'hidden_layer_sizes': 135, 'alpha': 2.655018222796576, 'batch_size': 32, 'learning_rate_init': 0.02074069254225457, 'tol': 0.05816864780133118, 'validation_fraction': 0.4185570345326133, 'beta_1': 0.7367890605640779, 'beta_2': 0.9814345249565418, 'epsilon': 6.088913530327412e-07}]
function_evaluation time 0.230586 value 51.121362 suggestion {'hidden_layer_sizes': 135, 'alpha': 2.655018222796576, 'batch_size': 32, 'learning_rate_init': 0.02074069254225457, 'tol': 0.05816864780133118, 'validation_fraction': 0.4185570345326133, 'beta_1': 0.7367890605640779, 'beta_2': 0.9814345249565418, 'epsilon': 6.088913530327412e-07}
observation time 0.001839, current best 44.467648 at iter 12
suggestion time taken 0.006998 iter 13 next_points [{'hidden_layer_sizes': 92, 'alpha': 9.682797378815742, 'batch_size': 164, 'learning_rate_init': 0.08742220157245366, 'tol': 0.007455806936127841, 'validation_fraction': 0.29296860831121263, 'beta_1': 0.7712213993868045, 'beta_2': 0.9019996797534, 'epsilon': 3.6277587370289646e-07}]
function_evaluation time 0.194952 value 45.292225 suggestion {'hidden_layer_sizes': 92, 'alpha': 9.682797378815742, 'batch_size': 164, 'learning_rate_init': 0.08742220157245366, 'tol': 0.007455806936127841, 'validation_fraction': 0.29296860831121263, 'beta_1': 0.7712213993868045, 'beta_2': 0.9019996797534, 'epsilon': 3.6277587370289646e-07}
observation time 0.001858, current best 44.467648 at iter 13
suggestion time taken 0.005248 iter 14 next_points [{'validation_fraction': 0.789573477584901, 'beta_2': 0.9015497558589216, 'batch_size': 192, 'tol': 0.06290594174683799, 'epsilon': 7.675149375224445e-07, 'alpha': 5.242089179274136, 'hidden_layer_sizes': 54, 'beta_1': 0.5912667255111458, 'learning_rate_init': 0.05504056887179492}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.136687 value 53.660405 suggestion {'validation_fraction': 0.789573477584901, 'beta_2': 0.9015497558589216, 'batch_size': 192, 'tol': 0.06290594174683799, 'epsilon': 7.675149375224445e-07, 'alpha': 5.242089179274136, 'hidden_layer_sizes': 54, 'beta_1': 0.5912667255111458, 'learning_rate_init': 0.05504056887179492}
observation time 0.001854, current best 44.467648 at iter 14
saving meta data: {'args': {'--uuid': 'd95540b2a19b5cc9afa2bdb53ce26ebd', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

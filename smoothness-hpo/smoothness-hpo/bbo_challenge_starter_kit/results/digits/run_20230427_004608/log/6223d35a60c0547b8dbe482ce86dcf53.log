running: {'--uuid': '6223d35a60c0547b8dbe482ce86dcf53', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d diabetes -o opentuner -u 6223d35a60c0547b8dbe482ce86dcf53 -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230427_004608
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study opentuner MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.031918 iter 0 next_points [{'hidden_layer_sizes': 61, 'alpha': 0.3518915006382583, 'batch_size': 73, 'learning_rate_init': 0.04359524765859473, 'tol': 0.06310301462564187, 'validation_fraction': 0.8540551470176703, 'beta_1': 0.8055102384900042, 'beta_2': 0.9359736545021626, 'epsilon': 9.790578739451893e-08}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.140579 value 4166.729551 suggestion {'hidden_layer_sizes': 61, 'alpha': 0.3518915006382583, 'batch_size': 73, 'learning_rate_init': 0.04359524765859473, 'tol': 0.06310301462564187, 'validation_fraction': 0.8540551470176703, 'beta_1': 0.8055102384900042, 'beta_2': 0.9359736545021626, 'epsilon': 9.790578739451893e-08}
observation time 0.004455, current best 4166.729551 at iter 0
suggestion time taken 0.007922 iter 1 next_points [{'hidden_layer_sizes': 61, 'alpha': 1.4716490526071757, 'batch_size': 218, 'learning_rate_init': 0.04359524765859473, 'tol': 0.06310301462564187, 'validation_fraction': 0.8540551470176703, 'beta_1': 0.8055102384900042, 'beta_2': 0.9359736545021626, 'epsilon': 9.790578739451893e-08}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.102091 value 12711.840790 suggestion {'hidden_layer_sizes': 61, 'alpha': 1.4716490526071757, 'batch_size': 218, 'learning_rate_init': 0.04359524765859473, 'tol': 0.06310301462564187, 'validation_fraction': 0.8540551470176703, 'beta_1': 0.8055102384900042, 'beta_2': 0.9359736545021626, 'epsilon': 9.790578739451893e-08}
observation time 0.001880, current best 4166.729551 at iter 1
suggestion time taken 0.007097 iter 2 next_points [{'hidden_layer_sizes': 61, 'alpha': 0.3518915006382583, 'batch_size': 73, 'learning_rate_init': 0.0448100641239652, 'tol': 0.06310301462564187, 'validation_fraction': 0.7887768904581959, 'beta_1': 0.8281241482486144, 'beta_2': 0.9359736545021626, 'epsilon': 9.790578739451893e-08}]
function_evaluation time 0.148360 value 8906.938464 suggestion {'hidden_layer_sizes': 61, 'alpha': 0.3518915006382583, 'batch_size': 73, 'learning_rate_init': 0.0448100641239652, 'tol': 0.06310301462564187, 'validation_fraction': 0.7887768904581959, 'beta_1': 0.8281241482486144, 'beta_2': 0.9359736545021626, 'epsilon': 9.790578739451893e-08}
observation time 0.001801, current best 4166.729551 at iter 2
suggestion time taken 0.045810 iter 3 next_points [{'validation_fraction': 0.8451527042493797, 'tol': 0.05074614727868359, 'hidden_layer_sizes': 110, 'batch_size': 161, 'epsilon': 1.6380749637331837e-07, 'beta_1': 0.6485267751113204, 'beta_2': 0.9906350449520709, 'learning_rate_init': 0.09839522616068101, 'alpha': 3.413275208462545}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.098380 value 3777.403947 suggestion {'validation_fraction': 0.8451527042493797, 'tol': 0.05074614727868359, 'hidden_layer_sizes': 110, 'batch_size': 161, 'epsilon': 1.6380749637331837e-07, 'beta_1': 0.6485267751113204, 'beta_2': 0.9906350449520709, 'learning_rate_init': 0.09839522616068101, 'alpha': 3.413275208462545}
observation time 0.001850, current best 3777.403947 at iter 3
suggestion time taken 0.005902 iter 4 next_points [{'hidden_layer_sizes': 156, 'alpha': 0.20497488144895465, 'batch_size': 60, 'learning_rate_init': 0.05199686841653366, 'tol': 0.09542818459038653, 'validation_fraction': 0.24855253175373404, 'beta_1': 0.7779237117219431, 'beta_2': 0.9772806705796048, 'epsilon': 6.430389464523168e-07}]
function_evaluation time 0.153987 value 3114.100112 suggestion {'hidden_layer_sizes': 156, 'alpha': 0.20497488144895465, 'batch_size': 60, 'learning_rate_init': 0.05199686841653366, 'tol': 0.09542818459038653, 'validation_fraction': 0.24855253175373404, 'beta_1': 0.7779237117219431, 'beta_2': 0.9772806705796048, 'epsilon': 6.430389464523168e-07}
observation time 0.001842, current best 3114.100112 at iter 4
suggestion time taken 0.005077 iter 5 next_points [{'validation_fraction': 0.18405166033763526, 'tol': 0.07894904324634482, 'hidden_layer_sizes': 172, 'batch_size': 152, 'epsilon': 7.80375125548043e-07, 'beta_1': 0.9515760698719316, 'beta_2': 0.9528697462428319, 'learning_rate_init': 0.013903374970563199, 'alpha': 0.05612316856150506}]
function_evaluation time 0.090253 value 26211.637624 suggestion {'validation_fraction': 0.18405166033763526, 'tol': 0.07894904324634482, 'hidden_layer_sizes': 172, 'batch_size': 152, 'epsilon': 7.80375125548043e-07, 'beta_1': 0.9515760698719316, 'beta_2': 0.9528697462428319, 'learning_rate_init': 0.013903374970563199, 'alpha': 0.05612316856150506}
observation time 0.001958, current best 3114.100112 at iter 5
suggestion time taken 0.005807 iter 6 next_points [{'hidden_layer_sizes': 180, 'alpha': 3.235221672590543, 'batch_size': 70, 'learning_rate_init': 0.016653558324841656, 'tol': 0.07525762124026929, 'validation_fraction': 0.40463790764255325, 'beta_1': 0.6770247789220882, 'beta_2': 0.9020139253078101, 'epsilon': 6.011600731941892e-07}]
function_evaluation time 0.252875 value 3717.079958 suggestion {'hidden_layer_sizes': 180, 'alpha': 3.235221672590543, 'batch_size': 70, 'learning_rate_init': 0.016653558324841656, 'tol': 0.07525762124026929, 'validation_fraction': 0.40463790764255325, 'beta_1': 0.6770247789220882, 'beta_2': 0.9020139253078101, 'epsilon': 6.011600731941892e-07}
observation time 0.001865, current best 3114.100112 at iter 6
suggestion time taken 0.005846 iter 7 next_points [{'hidden_layer_sizes': 199, 'alpha': 1.033725900299721, 'batch_size': 56, 'learning_rate_init': 0.08855040408023733, 'tol': 0.02365190878916106, 'validation_fraction': 0.8033615732570452, 'beta_1': 0.8117331254244203, 'beta_2': 0.9657154482776421, 'epsilon': 4.915270971633513e-07}]
function_evaluation time 0.146138 value 3609.883526 suggestion {'hidden_layer_sizes': 199, 'alpha': 1.033725900299721, 'batch_size': 56, 'learning_rate_init': 0.08855040408023733, 'tol': 0.02365190878916106, 'validation_fraction': 0.8033615732570452, 'beta_1': 0.8117331254244203, 'beta_2': 0.9657154482776421, 'epsilon': 4.915270971633513e-07}
observation time 0.001790, current best 3114.100112 at iter 7
suggestion time taken 0.005193 iter 8 next_points [{'validation_fraction': 0.14736701188937645, 'tol': 0.04146112160673681, 'hidden_layer_sizes': 94, 'batch_size': 176, 'epsilon': 4.5431205100751506e-07, 'beta_1': 0.5640377615978731, 'beta_2': 0.9180584596030861, 'learning_rate_init': 0.08753473933114202, 'alpha': 1.75879040428293}]
function_evaluation time 0.120148 value 3205.207804 suggestion {'validation_fraction': 0.14736701188937645, 'tol': 0.04146112160673681, 'hidden_layer_sizes': 94, 'batch_size': 176, 'epsilon': 4.5431205100751506e-07, 'beta_1': 0.5640377615978731, 'beta_2': 0.9180584596030861, 'learning_rate_init': 0.08753473933114202, 'alpha': 1.75879040428293}
observation time 0.001818, current best 3114.100112 at iter 8
suggestion time taken 0.005848 iter 9 next_points [{'hidden_layer_sizes': 85, 'alpha': 6.243344652594086, 'batch_size': 180, 'learning_rate_init': 0.02828745389439462, 'tol': 0.0014904910054120324, 'validation_fraction': 0.26409933918613104, 'beta_1': 0.6721570513302276, 'beta_2': 0.9482412705849924, 'epsilon': 1.1883621559543145e-08}]
function_evaluation time 0.442097 value 3025.977578 suggestion {'hidden_layer_sizes': 85, 'alpha': 6.243344652594086, 'batch_size': 180, 'learning_rate_init': 0.02828745389439462, 'tol': 0.0014904910054120324, 'validation_fraction': 0.26409933918613104, 'beta_1': 0.6721570513302276, 'beta_2': 0.9482412705849924, 'epsilon': 1.1883621559543145e-08}
observation time 0.001777, current best 3025.977578 at iter 9
suggestion time taken 0.006227 iter 10 next_points [{'hidden_layer_sizes': 159, 'alpha': 1.409163387014312, 'batch_size': 109, 'learning_rate_init': 0.04568641014171331, 'tol': 0.0775243033414749, 'validation_fraction': 0.3640843615495609, 'beta_1': 0.9637371198648128, 'beta_2': 0.9756258920554887, 'epsilon': 4.682983580089607e-07}]
function_evaluation time 0.183475 value 4269.648007 suggestion {'hidden_layer_sizes': 159, 'alpha': 1.409163387014312, 'batch_size': 109, 'learning_rate_init': 0.04568641014171331, 'tol': 0.0775243033414749, 'validation_fraction': 0.3640843615495609, 'beta_1': 0.9637371198648128, 'beta_2': 0.9756258920554887, 'epsilon': 4.682983580089607e-07}
observation time 0.002651, current best 3025.977578 at iter 10
suggestion time taken 0.005795 iter 11 next_points [{'hidden_layer_sizes': 123, 'alpha': 3.6927726713262863, 'batch_size': 73, 'learning_rate_init': 0.02848712200259922, 'tol': 0.049010730769439785, 'validation_fraction': 0.7909832414056782, 'beta_1': 0.8824103036296507, 'beta_2': 0.966177489095091, 'epsilon': 7.730019303825154e-07}]
function_evaluation time 0.134362 value 17042.676245 suggestion {'hidden_layer_sizes': 123, 'alpha': 3.6927726713262863, 'batch_size': 73, 'learning_rate_init': 0.02848712200259922, 'tol': 0.049010730769439785, 'validation_fraction': 0.7909832414056782, 'beta_1': 0.8824103036296507, 'beta_2': 0.966177489095091, 'epsilon': 7.730019303825154e-07}
observation time 0.001759, current best 3025.977578 at iter 11
suggestion time taken 0.006029 iter 12 next_points [{'hidden_layer_sizes': 94, 'alpha': 2.819459593098945, 'batch_size': 39, 'learning_rate_init': 0.06713360757234892, 'tol': 0.08718856299806392, 'validation_fraction': 0.25009244543591513, 'beta_1': 0.5900932549220894, 'beta_2': 0.9380168831500562, 'epsilon': 2.5766627401221833e-07}]
function_evaluation time 0.098320 value 2973.155731 suggestion {'hidden_layer_sizes': 94, 'alpha': 2.819459593098945, 'batch_size': 39, 'learning_rate_init': 0.06713360757234892, 'tol': 0.08718856299806392, 'validation_fraction': 0.25009244543591513, 'beta_1': 0.5900932549220894, 'beta_2': 0.9380168831500562, 'epsilon': 2.5766627401221833e-07}
observation time 0.001792, current best 2973.155731 at iter 12
suggestion time taken 0.005927 iter 13 next_points [{'hidden_layer_sizes': 69, 'alpha': 8.225217495396295, 'batch_size': 149, 'learning_rate_init': 0.016431202182404615, 'tol': 0.08451439120715502, 'validation_fraction': 0.7493981812582851, 'beta_1': 0.6576677252267261, 'beta_2': 0.975314466620667, 'epsilon': 1.9330014114413052e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.046220 value 28112.920764 suggestion {'hidden_layer_sizes': 69, 'alpha': 8.225217495396295, 'batch_size': 149, 'learning_rate_init': 0.016431202182404615, 'tol': 0.08451439120715502, 'validation_fraction': 0.7493981812582851, 'beta_1': 0.6576677252267261, 'beta_2': 0.975314466620667, 'epsilon': 1.9330014114413052e-07}
observation time 0.001730, current best 2973.155731 at iter 13
suggestion time taken 0.005775 iter 14 next_points [{'hidden_layer_sizes': 69, 'alpha': 0.44759261941105305, 'batch_size': 36, 'learning_rate_init': 0.08074518058649464, 'tol': 0.01811729234720365, 'validation_fraction': 0.39809290880778514, 'beta_1': 0.7075017478525134, 'beta_2': 0.9883623496027633, 'epsilon': 6.373992217650604e-07}]
function_evaluation time 0.115838 value 2886.619155 suggestion {'hidden_layer_sizes': 69, 'alpha': 0.44759261941105305, 'batch_size': 36, 'learning_rate_init': 0.08074518058649464, 'tol': 0.01811729234720365, 'validation_fraction': 0.39809290880778514, 'beta_1': 0.7075017478525134, 'beta_2': 0.9883623496027633, 'epsilon': 6.373992217650604e-07}
observation time 0.002034, current best 2886.619155 at iter 14
saving meta data: {'args': {'--uuid': '6223d35a60c0547b8dbe482ce86dcf53', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

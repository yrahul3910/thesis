running: {'--uuid': '8889ddb434185e2a8aede658de41b1f6', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d diabetes -o hyperopt -u 8889ddb434185e2a8aede658de41b1f6 -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230427_004608
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study hyperopt MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002581 iter 0 next_points [{'alpha': 0.0002673369383743823, 'batch_size': 235, 'beta_1': 0.5436775941580417, 'beta_2': 0.9023757235594103, 'epsilon': 4.0498933726052495e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.002604283527148204, 'tol': 0.008242097804445599, 'validation_fraction': 0.19685076943254837}]
function_evaluation time 0.061773 value 151.391715 suggestion {'alpha': 0.0002673369383743823, 'batch_size': 235, 'beta_1': 0.5436775941580417, 'beta_2': 0.9023757235594103, 'epsilon': 4.0498933726052495e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.002604283527148204, 'tol': 0.008242097804445599, 'validation_fraction': 0.19685076943254837}
observation time 0.000062, current best 151.391715 at iter 0
suggestion time taken 0.002392 iter 1 next_points [{'alpha': 0.000784491136601414, 'batch_size': 157, 'beta_1': 0.5668413773889374, 'beta_2': 0.9425801491979708, 'epsilon': 4.0908295038770574e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 3.248115638268126e-05, 'tol': 7.199358515883037e-05, 'validation_fraction': 0.7348489192554762}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.050186 value 151.620048 suggestion {'alpha': 0.000784491136601414, 'batch_size': 157, 'beta_1': 0.5668413773889374, 'beta_2': 0.9425801491979708, 'epsilon': 4.0908295038770574e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 3.248115638268126e-05, 'tol': 7.199358515883037e-05, 'validation_fraction': 0.7348489192554762}
observation time 0.000070, current best 151.391715 at iter 1
suggestion time taken 0.002153 iter 2 next_points [{'alpha': 0.004587605645070442, 'batch_size': 56, 'beta_1': 0.6456128063913725, 'beta_2': 0.945150595777849, 'epsilon': 1.7894272711539264e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.00027011026282415063, 'tol': 3.0435441169389024e-05, 'validation_fraction': 0.12576103928444687}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.435674 value 144.055190 suggestion {'alpha': 0.004587605645070442, 'batch_size': 56, 'beta_1': 0.6456128063913725, 'beta_2': 0.945150595777849, 'epsilon': 1.7894272711539264e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.00027011026282415063, 'tol': 3.0435441169389024e-05, 'validation_fraction': 0.12576103928444687}
observation time 0.000063, current best 144.055190 at iter 2
suggestion time taken 0.002309 iter 3 next_points [{'alpha': 1.9266026333553719, 'batch_size': 215, 'beta_1': 0.6225198177696704, 'beta_2': 0.9444380942839968, 'epsilon': 2.802634013611387e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.00023636993010983597, 'tol': 0.020330131750946705, 'validation_fraction': 0.21058263983834777}]
function_evaluation time 0.088345 value 151.481664 suggestion {'alpha': 1.9266026333553719, 'batch_size': 215, 'beta_1': 0.6225198177696704, 'beta_2': 0.9444380942839968, 'epsilon': 2.802634013611387e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.00023636993010983597, 'tol': 0.020330131750946705, 'validation_fraction': 0.21058263983834777}
observation time 0.000076, current best 144.055190 at iter 3
suggestion time taken 0.002188 iter 4 next_points [{'alpha': 0.00024156260770276923, 'batch_size': 113, 'beta_1': 0.8762967200253222, 'beta_2': 0.9917505351333331, 'epsilon': 1.3774722141963172e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 1.599017372573472e-05, 'tol': 0.0006445922632594624, 'validation_fraction': 0.37952387211431543}]
function_evaluation time 0.045906 value 151.775380 suggestion {'alpha': 0.00024156260770276923, 'batch_size': 113, 'beta_1': 0.8762967200253222, 'beta_2': 0.9917505351333331, 'epsilon': 1.3774722141963172e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 1.599017372573472e-05, 'tol': 0.0006445922632594624, 'validation_fraction': 0.37952387211431543}
observation time 0.000074, current best 144.055190 at iter 4
suggestion time taken 0.002176 iter 5 next_points [{'alpha': 0.006320038129544609, 'batch_size': 80, 'beta_1': 0.8246387297865828, 'beta_2': 0.9251615480215664, 'epsilon': 1.1110093933901631e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.00024406645049272703, 'tol': 0.006735294327082126, 'validation_fraction': 0.11408182537224694}]
function_evaluation time 0.061161 value 151.342684 suggestion {'alpha': 0.006320038129544609, 'batch_size': 80, 'beta_1': 0.8246387297865828, 'beta_2': 0.9251615480215664, 'epsilon': 1.1110093933901631e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.00024406645049272703, 'tol': 0.006735294327082126, 'validation_fraction': 0.11408182537224694}
observation time 0.000071, current best 144.055190 at iter 5
suggestion time taken 0.002116 iter 6 next_points [{'alpha': 1.6030291097706095, 'batch_size': 167, 'beta_1': 0.9429567129955142, 'beta_2': 0.9202029154611662, 'epsilon': 9.517612548094e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0031823451809140733, 'tol': 0.0005103416603151695, 'validation_fraction': 0.7918921381733408}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.742391 value 122.806588 suggestion {'alpha': 1.6030291097706095, 'batch_size': 167, 'beta_1': 0.9429567129955142, 'beta_2': 0.9202029154611662, 'epsilon': 9.517612548094e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0031823451809140733, 'tol': 0.0005103416603151695, 'validation_fraction': 0.7918921381733408}
observation time 0.000071, current best 122.806588 at iter 6
suggestion time taken 0.002168 iter 7 next_points [{'alpha': 0.8267551728161908, 'batch_size': 67, 'beta_1': 0.6088439115803232, 'beta_2': 0.987699337273911, 'epsilon': 6.47283654293673e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.026046575664443287, 'tol': 0.00025394607673922653, 'validation_fraction': 0.4548277087192813}]
function_evaluation time 0.547779 value 45.295861 suggestion {'alpha': 0.8267551728161908, 'batch_size': 67, 'beta_1': 0.6088439115803232, 'beta_2': 0.987699337273911, 'epsilon': 6.47283654293673e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.026046575664443287, 'tol': 0.00025394607673922653, 'validation_fraction': 0.4548277087192813}
observation time 0.000070, current best 45.295861 at iter 7
suggestion time taken 0.002365 iter 8 next_points [{'alpha': 1.8268858299109e-05, 'batch_size': 227, 'beta_1': 0.5543824207572929, 'beta_2': 0.939905950099391, 'epsilon': 3.946592348091942e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.0013882012395265136, 'tol': 0.0017366146992483418, 'validation_fraction': 0.39523782099078963}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.071086 value 151.379581 suggestion {'alpha': 1.8268858299109e-05, 'batch_size': 227, 'beta_1': 0.5543824207572929, 'beta_2': 0.939905950099391, 'epsilon': 3.946592348091942e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.0013882012395265136, 'tol': 0.0017366146992483418, 'validation_fraction': 0.39523782099078963}
observation time 0.000071, current best 45.295861 at iter 8
suggestion time taken 0.002124 iter 9 next_points [{'alpha': 0.029801450117429924, 'batch_size': 229, 'beta_1': 0.9784578476675194, 'beta_2': 0.9480614973961027, 'epsilon': 6.262660352493024e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0004936450574438306, 'tol': 0.0018104066690901729, 'validation_fraction': 0.36869399844680817}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.063755 value 151.481627 suggestion {'alpha': 0.029801450117429924, 'batch_size': 229, 'beta_1': 0.9784578476675194, 'beta_2': 0.9480614973961027, 'epsilon': 6.262660352493024e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0004936450574438306, 'tol': 0.0018104066690901729, 'validation_fraction': 0.36869399844680817}
observation time 0.000068, current best 45.295861 at iter 9
suggestion time taken 0.002107 iter 10 next_points [{'alpha': 0.012744238535204101, 'batch_size': 106, 'beta_1': 0.6382394921611265, 'beta_2': 0.9824234153625989, 'epsilon': 6.080075300097702e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.0011728771463278068, 'tol': 0.00022445517101170884, 'validation_fraction': 0.19352543727099378}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.407397 value 107.006498 suggestion {'alpha': 0.012744238535204101, 'batch_size': 106, 'beta_1': 0.6382394921611265, 'beta_2': 0.9824234153625989, 'epsilon': 6.080075300097702e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.0011728771463278068, 'tol': 0.00022445517101170884, 'validation_fraction': 0.19352543727099378}
observation time 0.000070, current best 45.295861 at iter 10
suggestion time taken 0.002366 iter 11 next_points [{'alpha': 0.23728136165262806, 'batch_size': 164, 'beta_1': 0.7311888322593955, 'beta_2': 0.9028736016300394, 'epsilon': 5.144242419195461e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.03372469682628749, 'tol': 2.8046527254147927e-05, 'validation_fraction': 0.8813531850689281}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.373800 value 49.555391 suggestion {'alpha': 0.23728136165262806, 'batch_size': 164, 'beta_1': 0.7311888322593955, 'beta_2': 0.9028736016300394, 'epsilon': 5.144242419195461e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.03372469682628749, 'tol': 2.8046527254147927e-05, 'validation_fraction': 0.8813531850689281}
observation time 0.000072, current best 45.295861 at iter 11
suggestion time taken 0.002116 iter 12 next_points [{'alpha': 1.9691893723313985, 'batch_size': 244, 'beta_1': 0.8535972262035036, 'beta_2': 0.9980633174646225, 'epsilon': 1.4758134639930885e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.0004305597034991163, 'tol': 0.0028281761785439547, 'validation_fraction': 0.6936783912381171}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.044180 value 151.749066 suggestion {'alpha': 1.9691893723313985, 'batch_size': 244, 'beta_1': 0.8535972262035036, 'beta_2': 0.9980633174646225, 'epsilon': 1.4758134639930885e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.0004305597034991163, 'tol': 0.0028281761785439547, 'validation_fraction': 0.6936783912381171}
observation time 0.000077, current best 45.295861 at iter 12
suggestion time taken 0.002208 iter 13 next_points [{'alpha': 1.1619917723195506e-05, 'batch_size': 176, 'beta_1': 0.578757136775802, 'beta_2': 0.9297926507962971, 'epsilon': 1.1304186729443372e-09, 'hidden_layer_sizes': 185, 'learning_rate_init': 8.77585986998354e-05, 'tol': 1.2406168867469612e-05, 'validation_fraction': 0.1882178869076727}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.373832 value 150.912395 suggestion {'alpha': 1.1619917723195506e-05, 'batch_size': 176, 'beta_1': 0.578757136775802, 'beta_2': 0.9297926507962971, 'epsilon': 1.1304186729443372e-09, 'hidden_layer_sizes': 185, 'learning_rate_init': 8.77585986998354e-05, 'tol': 1.2406168867469612e-05, 'validation_fraction': 0.1882178869076727}
observation time 0.000072, current best 45.295861 at iter 13
suggestion time taken 0.002127 iter 14 next_points [{'alpha': 0.00411924867595117, 'batch_size': 219, 'beta_1': 0.5370062000821997, 'beta_2': 0.9710225351767049, 'epsilon': 1.3707568638595178e-07, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0001698168816565045, 'tol': 0.04685205163401841, 'validation_fraction': 0.21747091506142943}]
function_evaluation time 0.075443 value 151.577364 suggestion {'alpha': 0.00411924867595117, 'batch_size': 219, 'beta_1': 0.5370062000821997, 'beta_2': 0.9710225351767049, 'epsilon': 1.3707568638595178e-07, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0001698168816565045, 'tol': 0.04685205163401841, 'validation_fraction': 0.21747091506142943}
observation time 0.000072, current best 45.295861 at iter 14
saving meta data: {'args': {'--uuid': '8889ddb434185e2a8aede658de41b1f6', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

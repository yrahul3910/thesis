running: {'--uuid': 'd818e7af17eb5ba08548c43dd97553f9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d diabetes -o turbo -u d818e7af17eb5ba08548c43dd97553f9 -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230427_004608
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study turbo MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002439 iter 0 next_points [{'alpha': 1.8089547228297016, 'batch_size': 80, 'beta_1': 0.5449248780099575, 'beta_2': 0.9999965944892505, 'epsilon': 5.762692719684826e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.012141095655305512, 'tol': 0.0064255783228345685, 'validation_fraction': 0.19244560893604773}]
function_evaluation time 0.213080 value 3813.056442 suggestion {'alpha': 1.8089547228297016, 'batch_size': 80, 'beta_1': 0.5449248780099575, 'beta_2': 0.9999965944892505, 'epsilon': 5.762692719684826e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.012141095655305512, 'tol': 0.0064255783228345685, 'validation_fraction': 0.19244560893604773}
observation time 0.001430, current best 3813.056442 at iter 0
suggestion time taken 0.001776 iter 1 next_points [{'alpha': 0.004427310068248681, 'batch_size': 233, 'beta_1': 0.738699122678561, 'beta_2': 0.9999428426574988, 'epsilon': 1.1695300572352284e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0006873132903407993, 'tol': 5.2956487937946665e-05, 'validation_fraction': 0.6717050006126396}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.633524 value 28496.122687 suggestion {'alpha': 0.004427310068248681, 'batch_size': 233, 'beta_1': 0.738699122678561, 'beta_2': 0.9999428426574988, 'epsilon': 1.1695300572352284e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0006873132903407993, 'tol': 5.2956487937946665e-05, 'validation_fraction': 0.6717050006126396}
observation time 0.001403, current best 3813.056442 at iter 1
suggestion time taken 0.001732 iter 2 next_points [{'alpha': 6.599725876364156e-05, 'batch_size': 21, 'beta_1': 0.8006614494889963, 'beta_2': 0.9999099998587999, 'epsilon': 7.162524957316213e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.00026229442288506534, 'tol': 0.016845222260811633, 'validation_fraction': 0.4876382286504612}]
function_evaluation time 0.147078 value 28992.428884 suggestion {'alpha': 6.599725876364156e-05, 'batch_size': 21, 'beta_1': 0.8006614494889963, 'beta_2': 0.9999099998587999, 'epsilon': 7.162524957316213e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.00026229442288506534, 'tol': 0.016845222260811633, 'validation_fraction': 0.4876382286504612}
observation time 0.001383, current best 3813.056442 at iter 2
suggestion time taken 0.002044 iter 3 next_points [{'alpha': 0.015493851422685166, 'batch_size': 67, 'beta_1': 0.9537250983384954, 'beta_2': 0.9472553419704266, 'epsilon': 6.278905110325903e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 7.601599907110685e-05, 'tol': 0.009991435743503837, 'validation_fraction': 0.12479026672229385}]
function_evaluation time 0.109372 value 29068.390417 suggestion {'alpha': 0.015493851422685166, 'batch_size': 67, 'beta_1': 0.9537250983384954, 'beta_2': 0.9472553419704266, 'epsilon': 6.278905110325903e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 7.601599907110685e-05, 'tol': 0.009991435743503837, 'validation_fraction': 0.12479026672229385}
observation time 0.001433, current best 3813.056442 at iter 3
suggestion time taken 0.001717 iter 4 next_points [{'alpha': 0.3269733879491836, 'batch_size': 102, 'beta_1': 0.8574161524279751, 'beta_2': 0.9831901205245749, 'epsilon': 1.9319677450694576e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 2.763107156804105e-05, 'tol': 0.00020169718101872586, 'validation_fraction': 0.23730803328121003}]
function_evaluation time 0.103748 value 29143.720732 suggestion {'alpha': 0.3269733879491836, 'batch_size': 102, 'beta_1': 0.8574161524279751, 'beta_2': 0.9831901205245749, 'epsilon': 1.9319677450694576e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 2.763107156804105e-05, 'tol': 0.00020169718101872586, 'validation_fraction': 0.23730803328121003}
observation time 0.001446, current best 3813.056442 at iter 4
suggestion time taken 0.001726 iter 5 next_points [{'alpha': 1.6974534624983438e-05, 'batch_size': 123, 'beta_1': 0.9818900286688556, 'beta_2': 0.9240501825444684, 'epsilon': 2.784282330328606e-07, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.007381482853601058, 'tol': 0.00012616355116468105, 'validation_fraction': 0.6374230009824587}]
function_evaluation time 0.791471 value 8025.044165 suggestion {'alpha': 1.6974534624983438e-05, 'batch_size': 123, 'beta_1': 0.9818900286688556, 'beta_2': 0.9240501825444684, 'epsilon': 2.784282330328606e-07, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.007381482853601058, 'tol': 0.00012616355116468105, 'validation_fraction': 0.6374230009824587}
observation time 0.001423, current best 3813.056442 at iter 5
suggestion time taken 0.001784 iter 6 next_points [{'alpha': 6.018819954169028, 'batch_size': 200, 'beta_1': 0.8745459251693172, 'beta_2': 0.9995673129551537, 'epsilon': 5.7722000469525846e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 2.0426147799377128e-05, 'tol': 0.0041794021578385465, 'validation_fraction': 0.8951064244734929}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.052554 value 29142.569971 suggestion {'alpha': 6.018819954169028, 'batch_size': 200, 'beta_1': 0.8745459251693172, 'beta_2': 0.9995673129551537, 'epsilon': 5.7722000469525846e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 2.0426147799377128e-05, 'tol': 0.0041794021578385465, 'validation_fraction': 0.8951064244734929}
observation time 0.001415, current best 3813.056442 at iter 6
suggestion time taken 0.001743 iter 7 next_points [{'alpha': 0.0004669147239901211, 'batch_size': 242, 'beta_1': 0.7139154731375039, 'beta_2': 0.9912644283646135, 'epsilon': 1.1327607463151365e-08, 'hidden_layer_sizes': 83, 'learning_rate_init': 6.136362535559375e-05, 'tol': 1.3085620800626392e-05, 'validation_fraction': 0.8681597899160876}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.614707 value 29120.651730 suggestion {'alpha': 0.0004669147239901211, 'batch_size': 242, 'beta_1': 0.7139154731375039, 'beta_2': 0.9912644283646135, 'epsilon': 1.1327607463151365e-08, 'hidden_layer_sizes': 83, 'learning_rate_init': 6.136362535559375e-05, 'tol': 1.3085620800626392e-05, 'validation_fraction': 0.8681597899160876}
observation time 0.001402, current best 3813.056442 at iter 7
suggestion time taken 0.001703 iter 8 next_points [{'alpha': 0.0002506144528468873, 'batch_size': 25, 'beta_1': 0.9846445978935167, 'beta_2': 0.9999927009112995, 'epsilon': 4.810186553965338e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.0008788067185087816, 'tol': 0.00034609689636991867, 'validation_fraction': 0.16565538304711525}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.257753 value 3800.568332 suggestion {'alpha': 0.0002506144528468873, 'batch_size': 25, 'beta_1': 0.9846445978935167, 'beta_2': 0.9999927009112995, 'epsilon': 4.810186553965338e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.0008788067185087816, 'tol': 0.00034609689636991867, 'validation_fraction': 0.16565538304711525}
observation time 0.001391, current best 3800.568332 at iter 8
suggestion time taken 0.001677 iter 9 next_points [{'alpha': 0.010916041199955344, 'batch_size': 42, 'beta_1': 0.5912556669685798, 'beta_2': 0.9999778226989579, 'epsilon': 1.0979603938097155e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.06928353230870497, 'tol': 0.0006450850694345643, 'validation_fraction': 0.11290505794938031}]
function_evaluation time 0.346717 value 2930.113778 suggestion {'alpha': 0.010916041199955344, 'batch_size': 42, 'beta_1': 0.5912556669685798, 'beta_2': 0.9999778226989579, 'epsilon': 1.0979603938097155e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.06928353230870497, 'tol': 0.0006450850694345643, 'validation_fraction': 0.11290505794938031}
observation time 0.001337, current best 2930.113778 at iter 9
suggestion time taken 0.001740 iter 10 next_points [{'alpha': 0.00010314729508542014, 'batch_size': 155, 'beta_1': 0.9204077143107744, 'beta_2': 0.9999987494042656, 'epsilon': 1.6139920425695306e-08, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.0004758606561241004, 'tol': 0.0009330864746904291, 'validation_fraction': 0.5629169869473598}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.061506 value 29094.693190 suggestion {'alpha': 0.00010314729508542014, 'batch_size': 155, 'beta_1': 0.9204077143107744, 'beta_2': 0.9999987494042656, 'epsilon': 1.6139920425695306e-08, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.0004758606561241004, 'tol': 0.0009330864746904291, 'validation_fraction': 0.5629169869473598}
observation time 0.001364, current best 2930.113778 at iter 10
suggestion time taken 0.001727 iter 11 next_points [{'alpha': 0.17015777135753626, 'batch_size': 94, 'beta_1': 0.8191300433438465, 'beta_2': 0.9999834694811902, 'epsilon': 1.4802420388320847e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 1.5415328044106626e-05, 'tol': 0.0030354010347725014, 'validation_fraction': 0.7819595226967655}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.047719 value 29164.048277 suggestion {'alpha': 0.17015777135753626, 'batch_size': 94, 'beta_1': 0.8191300433438465, 'beta_2': 0.9999834694811902, 'epsilon': 1.4802420388320847e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 1.5415328044106626e-05, 'tol': 0.0030354010347725014, 'validation_fraction': 0.7819595226967655}
observation time 0.001371, current best 2930.113778 at iter 11
suggestion time taken 0.001681 iter 12 next_points [{'alpha': 0.0358753596142011, 'batch_size': 174, 'beta_1': 0.6688321242407587, 'beta_2': 0.9990299066094379, 'epsilon': 5.731257377345e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.00012313614666116288, 'tol': 0.0015790295292516154, 'validation_fraction': 0.2989948856189722}]
function_evaluation time 0.062397 value 29110.992596 suggestion {'alpha': 0.0358753596142011, 'batch_size': 174, 'beta_1': 0.6688321242407587, 'beta_2': 0.9990299066094379, 'epsilon': 5.731257377345e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.00012313614666116288, 'tol': 0.0015790295292516154, 'validation_fraction': 0.2989948856189722}
observation time 0.001362, current best 2930.113778 at iter 12
suggestion time taken 0.001696 iter 13 next_points [{'alpha': 0.0010005968974376178, 'batch_size': 130, 'beta_1': 0.961685995700164, 'beta_2': 0.999996940572463, 'epsilon': 1.1950737418575643e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.053405216316615794, 'tol': 0.02758381179101748, 'validation_fraction': 0.3683126603594663}]
function_evaluation time 0.163926 value 4036.946246 suggestion {'alpha': 0.0010005968974376178, 'batch_size': 130, 'beta_1': 0.961685995700164, 'beta_2': 0.999996940572463, 'epsilon': 1.1950737418575643e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.053405216316615794, 'tol': 0.02758381179101748, 'validation_fraction': 0.3683126603594663}
observation time 0.001363, current best 2930.113778 at iter 13
suggestion time taken 0.001990 iter 14 next_points [{'alpha': 0.0741651694268097, 'batch_size': 169, 'beta_1': 0.9360975568231411, 'beta_2': 0.9767701019742953, 'epsilon': 3.0508989460419192e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.015152438566399236, 'tol': 0.05160795545687678, 'validation_fraction': 0.7465416598124078}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.051302 value 28189.471854 suggestion {'alpha': 0.0741651694268097, 'batch_size': 169, 'beta_1': 0.9360975568231411, 'beta_2': 0.9767701019742953, 'epsilon': 3.0508989460419192e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.015152438566399236, 'tol': 0.05160795545687678, 'validation_fraction': 0.7465416598124078}
observation time 0.001351, current best 2930.113778 at iter 14
saving meta data: {'args': {'--uuid': 'd818e7af17eb5ba08548c43dd97553f9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

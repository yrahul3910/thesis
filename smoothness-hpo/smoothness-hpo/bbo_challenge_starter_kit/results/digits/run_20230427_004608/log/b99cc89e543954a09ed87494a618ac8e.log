running: {'--uuid': 'b99cc89e543954a09ed87494a618ac8e', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d diabetes -o turbo -u b99cc89e543954a09ed87494a618ac8e -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230427_004608
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study turbo MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002095 iter 0 next_points [{'alpha': 0.4617646293221441, 'batch_size': 162, 'beta_1': 0.8776069257538307, 'beta_2': 0.9855341826042932, 'epsilon': 3.3876489435704687e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0002303272826502008, 'tol': 0.00035980484125105447, 'validation_fraction': 0.8488107886565562}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.051951 value 151.678825 suggestion {'alpha': 0.4617646293221441, 'batch_size': 162, 'beta_1': 0.8776069257538307, 'beta_2': 0.9855341826042932, 'epsilon': 3.3876489435704687e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0002303272826502008, 'tol': 0.00035980484125105447, 'validation_fraction': 0.8488107886565562}
observation time 0.001389, current best 151.678825 at iter 0
suggestion time taken 0.001783 iter 1 next_points [{'alpha': 5.078359068941832, 'batch_size': 183, 'beta_1': 0.8232008992402328, 'beta_2': 0.9931815180480221, 'epsilon': 1.1301822142063078e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.00015062480243163196, 'tol': 5.133899927201117e-05, 'validation_fraction': 0.4592524801131712}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.861881 value 151.121908 suggestion {'alpha': 5.078359068941832, 'batch_size': 183, 'beta_1': 0.8232008992402328, 'beta_2': 0.9931815180480221, 'epsilon': 1.1301822142063078e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.00015062480243163196, 'tol': 5.133899927201117e-05, 'validation_fraction': 0.4592524801131712}
observation time 0.001399, current best 151.121908 at iter 1
suggestion time taken 0.001809 iter 2 next_points [{'alpha': 0.011518311558487225, 'batch_size': 89, 'beta_1': 0.9701499525391917, 'beta_2': 0.9999428734776434, 'epsilon': 5.951737368814604e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.03901997533666549, 'tol': 0.00019076114565586883, 'validation_fraction': 0.7981201008794317}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.206885 value 56.324914 suggestion {'alpha': 0.011518311558487225, 'batch_size': 89, 'beta_1': 0.9701499525391917, 'beta_2': 0.9999428734776434, 'epsilon': 5.951737368814604e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.03901997533666549, 'tol': 0.00019076114565586883, 'validation_fraction': 0.7981201008794317}
observation time 0.001427, current best 56.324914 at iter 2
suggestion time taken 0.001738 iter 3 next_points [{'alpha': 0.1895359670101988, 'batch_size': 212, 'beta_1': 0.6506162515449019, 'beta_2': 0.995153327769575, 'epsilon': 4.435053750300761e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.007896075462696581, 'tol': 0.0026020624794093716, 'validation_fraction': 0.862256699393614}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.649432 value 53.402602 suggestion {'alpha': 0.1895359670101988, 'batch_size': 212, 'beta_1': 0.6506162515449019, 'beta_2': 0.995153327769575, 'epsilon': 4.435053750300761e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.007896075462696581, 'tol': 0.0026020624794093716, 'validation_fraction': 0.862256699393614}
observation time 0.001411, current best 53.402602 at iter 3
suggestion time taken 0.001726 iter 4 next_points [{'alpha': 1.2564903244798313, 'batch_size': 78, 'beta_1': 0.8485420767532136, 'beta_2': 0.9991851157718155, 'epsilon': 2.5048570006510964e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.003265976830863195, 'tol': 0.0035644926234913595, 'validation_fraction': 0.3940221420785036}]
function_evaluation time 0.971709 value 53.402830 suggestion {'alpha': 1.2564903244798313, 'batch_size': 78, 'beta_1': 0.8485420767532136, 'beta_2': 0.9991851157718155, 'epsilon': 2.5048570006510964e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.003265976830863195, 'tol': 0.0035644926234913595, 'validation_fraction': 0.3940221420785036}
observation time 0.001372, current best 53.402602 at iter 4
suggestion time taken 0.001735 iter 5 next_points [{'alpha': 0.00018203059426258946, 'batch_size': 47, 'beta_1': 0.9887929852892786, 'beta_2': 0.9999907553402203, 'epsilon': 8.680136677739136e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 4.345003227887079e-05, 'tol': 8.476360495158323e-05, 'validation_fraction': 0.5748726078437824}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.360972 value 151.177046 suggestion {'alpha': 0.00018203059426258946, 'batch_size': 47, 'beta_1': 0.9887929852892786, 'beta_2': 0.9999907553402203, 'epsilon': 8.680136677739136e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 4.345003227887079e-05, 'tol': 8.476360495158323e-05, 'validation_fraction': 0.5748726078437824}
observation time 0.001400, current best 53.402602 at iter 5
suggestion time taken 0.001751 iter 6 next_points [{'alpha': 3.0294971773289244e-05, 'batch_size': 202, 'beta_1': 0.9595513934146375, 'beta_2': 0.9972315540319953, 'epsilon': 8.588072254553996e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.028266894247244496, 'tol': 0.00013760483278208843, 'validation_fraction': 0.15124414306871717}]
function_evaluation time 0.269741 value 55.662962 suggestion {'alpha': 3.0294971773289244e-05, 'batch_size': 202, 'beta_1': 0.9595513934146375, 'beta_2': 0.9972315540319953, 'epsilon': 8.588072254553996e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.028266894247244496, 'tol': 0.00013760483278208843, 'validation_fraction': 0.15124414306871717}
observation time 0.001415, current best 53.402602 at iter 6
suggestion time taken 0.002053 iter 7 next_points [{'alpha': 0.0026215166007644113, 'batch_size': 199, 'beta_1': 0.7991681657920355, 'beta_2': 0.9999821481612204, 'epsilon': 2.356186179493327e-08, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.0007191913167566326, 'tol': 0.0005405822919858723, 'validation_fraction': 0.10272334126185328}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.297450 value 135.314231 suggestion {'alpha': 0.0026215166007644113, 'batch_size': 199, 'beta_1': 0.7991681657920355, 'beta_2': 0.9999821481612204, 'epsilon': 2.356186179493327e-08, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.0007191913167566326, 'tol': 0.0005405822919858723, 'validation_fraction': 0.10272334126185328}
observation time 0.001383, current best 53.402602 at iter 7
suggestion time taken 0.001740 iter 8 next_points [{'alpha': 0.0002219170096502472, 'batch_size': 106, 'beta_1': 0.749209248467348, 'beta_2': 0.999561966001365, 'epsilon': 3.357882175208124e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 4.118905694658538e-05, 'tol': 0.05113941555911161, 'validation_fraction': 0.7291537895167033}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.058030 value 151.564967 suggestion {'alpha': 0.0002219170096502472, 'batch_size': 106, 'beta_1': 0.749209248467348, 'beta_2': 0.999561966001365, 'epsilon': 3.357882175208124e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 4.118905694658538e-05, 'tol': 0.05113941555911161, 'validation_fraction': 0.7291537895167033}
observation time 0.001400, current best 53.402602 at iter 8
suggestion time taken 0.001740 iter 9 next_points [{'alpha': 0.0856736551601742, 'batch_size': 114, 'beta_1': 0.9816061492530342, 'beta_2': 0.9647528828911701, 'epsilon': 3.553587434656917e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.0942359165117408, 'tol': 0.0008697144743253409, 'validation_fraction': 0.19719467815815722}]
function_evaluation time 0.184104 value 49.024233 suggestion {'alpha': 0.0856736551601742, 'batch_size': 114, 'beta_1': 0.9816061492530342, 'beta_2': 0.9647528828911701, 'epsilon': 3.553587434656917e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.0942359165117408, 'tol': 0.0008697144743253409, 'validation_fraction': 0.19719467815815722}
observation time 0.001370, current best 49.024233 at iter 9
suggestion time taken 0.001742 iter 10 next_points [{'alpha': 4.46601809809401, 'batch_size': 225, 'beta_1': 0.9857505996808867, 'beta_2': 0.9990949362580366, 'epsilon': 2.9435369022956e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 9.588731504604863e-05, 'tol': 0.0191277621598965, 'validation_fraction': 0.22436100632997152}]
function_evaluation time 0.079313 value 151.518908 suggestion {'alpha': 4.46601809809401, 'batch_size': 225, 'beta_1': 0.9857505996808867, 'beta_2': 0.9990949362580366, 'epsilon': 2.9435369022956e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 9.588731504604863e-05, 'tol': 0.0191277621598965, 'validation_fraction': 0.22436100632997152}
observation time 0.001362, current best 49.024233 at iter 10
suggestion time taken 0.001961 iter 11 next_points [{'alpha': 0.00040693100283869464, 'batch_size': 242, 'beta_1': 0.9556911374322957, 'beta_2': 0.999786176619301, 'epsilon': 1.516298478099788e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 2.361058663791595e-05, 'tol': 0.028702539704128435, 'validation_fraction': 0.14723477030621937}]
function_evaluation time 0.073065 value 151.554841 suggestion {'alpha': 0.00040693100283869464, 'batch_size': 242, 'beta_1': 0.9556911374322957, 'beta_2': 0.999786176619301, 'epsilon': 1.516298478099788e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 2.361058663791595e-05, 'tol': 0.028702539704128435, 'validation_fraction': 0.14723477030621937}
observation time 0.001421, current best 49.024233 at iter 11
suggestion time taken 0.001725 iter 12 next_points [{'alpha': 0.00128748411006074, 'batch_size': 17, 'beta_1': 0.9763299679115871, 'beta_2': 0.999997704431583, 'epsilon': 7.723479563244886e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.004875584271876339, 'tol': 0.011165306478510597, 'validation_fraction': 0.2821171070234695}]
function_evaluation time 0.479266 value 51.921491 suggestion {'alpha': 0.00128748411006074, 'batch_size': 17, 'beta_1': 0.9763299679115871, 'beta_2': 0.999997704431583, 'epsilon': 7.723479563244886e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.004875584271876339, 'tol': 0.011165306478510597, 'validation_fraction': 0.2821171070234695}
observation time 0.001420, current best 49.024233 at iter 12
suggestion time taken 0.002111 iter 13 next_points [{'alpha': 0.6085097841107734, 'batch_size': 56, 'beta_1': 0.582405361568496, 'beta_2': 0.9999945355988171, 'epsilon': 1.3362091188393695e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0004184247374296032, 'tol': 2.0718814247665106e-05, 'validation_fraction': 0.887249841417265}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.542207 value 150.575391 suggestion {'alpha': 0.6085097841107734, 'batch_size': 56, 'beta_1': 0.582405361568496, 'beta_2': 0.9999945355988171, 'epsilon': 1.3362091188393695e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0004184247374296032, 'tol': 2.0718814247665106e-05, 'validation_fraction': 0.887249841417265}
observation time 0.001405, current best 49.024233 at iter 13
suggestion time taken 0.001745 iter 14 next_points [{'alpha': 0.04882070791387423, 'batch_size': 26, 'beta_1': 0.9471179831339566, 'beta_2': 0.999969442145469, 'epsilon': 1.297786418674639e-07, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.023063674071501533, 'tol': 3.0534850852922606e-05, 'validation_fraction': 0.5957441440020892}]
function_evaluation time 0.605277 value 45.576844 suggestion {'alpha': 0.04882070791387423, 'batch_size': 26, 'beta_1': 0.9471179831339566, 'beta_2': 0.999969442145469, 'epsilon': 1.297786418674639e-07, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.023063674071501533, 'tol': 3.0534850852922606e-05, 'validation_fraction': 0.5957441440020892}
observation time 0.001410, current best 45.576844 at iter 14
saving meta data: {'args': {'--uuid': 'b99cc89e543954a09ed87494a618ac8e', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

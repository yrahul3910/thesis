running: {'--uuid': 'dc0e2e7b18ff562994565d36cb0da1c6', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d diabetes -o turbo -u dc0e2e7b18ff562994565d36cb0da1c6 -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230427_004608
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study turbo MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002131 iter 0 next_points [{'alpha': 1.6088139708207578, 'batch_size': 11, 'beta_1': 0.5865289601801884, 'beta_2': 0.9998553431131603, 'epsilon': 7.76336433493383e-07, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.0009134558834835968, 'tol': 0.003252933871592765, 'validation_fraction': 0.27421736394289514}]
function_evaluation time 2.232027 value 53.761347 suggestion {'alpha': 1.6088139708207578, 'batch_size': 11, 'beta_1': 0.5865289601801884, 'beta_2': 0.9998553431131603, 'epsilon': 7.76336433493383e-07, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.0009134558834835968, 'tol': 0.003252933871592765, 'validation_fraction': 0.27421736394289514}
observation time 0.001357, current best 53.761347 at iter 0
suggestion time taken 0.001763 iter 1 next_points [{'alpha': 0.0004548519683015229, 'batch_size': 108, 'beta_1': 0.9749839745199231, 'beta_2': 0.9975526122498017, 'epsilon': 7.209620800911593e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.027046734566745344, 'tol': 4.654473743394382e-05, 'validation_fraction': 0.7412172435992825}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.301914 value 55.490705 suggestion {'alpha': 0.0004548519683015229, 'batch_size': 108, 'beta_1': 0.9749839745199231, 'beta_2': 0.9975526122498017, 'epsilon': 7.209620800911593e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.027046734566745344, 'tol': 4.654473743394382e-05, 'validation_fraction': 0.7412172435992825}
observation time 0.001398, current best 53.761347 at iter 1
suggestion time taken 0.001769 iter 2 next_points [{'alpha': 4.062010883216142e-05, 'batch_size': 163, 'beta_1': 0.8330968199496611, 'beta_2': 0.9949162122778398, 'epsilon': 1.0038580043884506e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.05129188515995868, 'tol': 0.01335936736527329, 'validation_fraction': 0.521145215047968}]
function_evaluation time 0.196819 value 49.838103 suggestion {'alpha': 4.062010883216142e-05, 'batch_size': 163, 'beta_1': 0.8330968199496611, 'beta_2': 0.9949162122778398, 'epsilon': 1.0038580043884506e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.05129188515995868, 'tol': 0.01335936736527329, 'validation_fraction': 0.521145215047968}
observation time 0.001701, current best 49.838103 at iter 2
suggestion time taken 0.001749 iter 3 next_points [{'alpha': 0.0002297482432304287, 'batch_size': 113, 'beta_1': 0.9715607416672148, 'beta_2': 0.9999953232980752, 'epsilon': 1.194535683729134e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.00028598327429100366, 'tol': 1.1788459800236713e-05, 'validation_fraction': 0.24111329012434993}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.279320 value 149.119554 suggestion {'alpha': 0.0002297482432304287, 'batch_size': 113, 'beta_1': 0.9715607416672148, 'beta_2': 0.9999953232980752, 'epsilon': 1.194535683729134e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.00028598327429100366, 'tol': 1.1788459800236713e-05, 'validation_fraction': 0.24111329012434993}
observation time 0.001381, current best 49.838103 at iter 3
suggestion time taken 0.001768 iter 4 next_points [{'alpha': 5.975745155435042, 'batch_size': 85, 'beta_1': 0.7900902786521977, 'beta_2': 0.999936526111764, 'epsilon': 2.7671020359777042e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.009844654207494143, 'tol': 0.07730225181368398, 'validation_fraction': 0.3158076200385847}]
function_evaluation time 0.106018 value 108.948583 suggestion {'alpha': 5.975745155435042, 'batch_size': 85, 'beta_1': 0.7900902786521977, 'beta_2': 0.999936526111764, 'epsilon': 2.7671020359777042e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.009844654207494143, 'tol': 0.07730225181368398, 'validation_fraction': 0.3158076200385847}
observation time 0.001360, current best 49.838103 at iter 4
suggestion time taken 0.001811 iter 5 next_points [{'alpha': 0.8699336962260256, 'batch_size': 242, 'beta_1': 0.9578190110435015, 'beta_2': 0.9995873868995845, 'epsilon': 2.2419505098613656e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0020320555778682472, 'tol': 0.004249866565502901, 'validation_fraction': 0.8021156025329659}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.055975 value 151.202177 suggestion {'alpha': 0.8699336962260256, 'batch_size': 242, 'beta_1': 0.9578190110435015, 'beta_2': 0.9995873868995845, 'epsilon': 2.2419505098613656e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0020320555778682472, 'tol': 0.004249866565502901, 'validation_fraction': 0.8021156025329659}
observation time 0.001386, current best 49.838103 at iter 5
suggestion time taken 0.001724 iter 6 next_points [{'alpha': 0.006643381926535526, 'batch_size': 229, 'beta_1': 0.6833157770521038, 'beta_2': 0.9999749305201224, 'epsilon': 1.1537372063681382e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.00012034677171810824, 'tol': 0.0004059405533777553, 'validation_fraction': 0.15803740167139757}]
function_evaluation time 0.083896 value 151.558879 suggestion {'alpha': 0.006643381926535526, 'batch_size': 229, 'beta_1': 0.6833157770521038, 'beta_2': 0.9999749305201224, 'epsilon': 1.1537372063681382e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.00012034677171810824, 'tol': 0.0004059405533777553, 'validation_fraction': 0.15803740167139757}
observation time 0.001389, current best 49.838103 at iter 6
suggestion time taken 0.001767 iter 7 next_points [{'alpha': 0.28650466641207406, 'batch_size': 23, 'beta_1': 0.5191487973411538, 'beta_2': 0.9999986361469344, 'epsilon': 5.656888070975675e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 1.6866290822236902e-05, 'tol': 3.010108664415949e-05, 'validation_fraction': 0.40478909667420965}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.310445 value 151.091283 suggestion {'alpha': 0.28650466641207406, 'batch_size': 23, 'beta_1': 0.5191487973411538, 'beta_2': 0.9999986361469344, 'epsilon': 5.656888070975675e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 1.6866290822236902e-05, 'tol': 3.010108664415949e-05, 'validation_fraction': 0.40478909667420965}
observation time 0.001455, current best 49.838103 at iter 7
suggestion time taken 0.001773 iter 8 next_points [{'alpha': 0.001957884056343073, 'batch_size': 147, 'beta_1': 0.7297511536198713, 'beta_2': 0.9998863006222745, 'epsilon': 3.0596812109352863e-07, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0005119490170229404, 'tol': 0.0001766730395910705, 'validation_fraction': 0.8865699810313352}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.779067 value 148.820011 suggestion {'alpha': 0.001957884056343073, 'batch_size': 147, 'beta_1': 0.7297511536198713, 'beta_2': 0.9998863006222745, 'epsilon': 3.0596812109352863e-07, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0005119490170229404, 'tol': 0.0001766730395910705, 'validation_fraction': 0.8865699810313352}
observation time 0.001413, current best 49.838103 at iter 8
suggestion time taken 0.001771 iter 9 next_points [{'alpha': 0.0001500949109189739, 'batch_size': 42, 'beta_1': 0.6463253791113425, 'beta_2': 0.984088252089282, 'epsilon': 2.0610933236805843e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.005128766435267777, 'tol': 0.025836186760364376, 'validation_fraction': 0.18392688077863503}]
function_evaluation time 0.402994 value 54.587228 suggestion {'alpha': 0.0001500949109189739, 'batch_size': 42, 'beta_1': 0.6463253791113425, 'beta_2': 0.984088252089282, 'epsilon': 2.0610933236805843e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.005128766435267777, 'tol': 0.025836186760364376, 'validation_fraction': 0.18392688077863503}
observation time 0.001626, current best 49.838103 at iter 9
suggestion time taken 0.001796 iter 10 next_points [{'alpha': 4.660339000024563e-05, 'batch_size': 135, 'beta_1': 0.9440574275382633, 'beta_2': 0.9999872532180079, 'epsilon': 4.1203081513517636e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.021096958450422726, 'tol': 0.03839411834567993, 'validation_fraction': 0.43739649926834384}]
function_evaluation time 0.243393 value 54.979833 suggestion {'alpha': 4.660339000024563e-05, 'batch_size': 135, 'beta_1': 0.9440574275382633, 'beta_2': 0.9999872532180079, 'epsilon': 4.1203081513517636e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.021096958450422726, 'tol': 0.03839411834567993, 'validation_fraction': 0.43739649926834384}
observation time 0.001381, current best 49.838103 at iter 10
suggestion time taken 0.001722 iter 11 next_points [{'alpha': 1.682500542581173e-05, 'batch_size': 221, 'beta_1': 0.9878456842677407, 'beta_2': 0.9999974846510621, 'epsilon': 1.2706345701399863e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.00218896883004574, 'tol': 0.014686950372861616, 'validation_fraction': 0.7191334247035404}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.053941 value 151.129772 suggestion {'alpha': 1.682500542581173e-05, 'batch_size': 221, 'beta_1': 0.9878456842677407, 'beta_2': 0.9999974846510621, 'epsilon': 1.2706345701399863e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.00218896883004574, 'tol': 0.014686950372861616, 'validation_fraction': 0.7191334247035404}
observation time 0.001344, current best 49.838103 at iter 11
suggestion time taken 0.001718 iter 12 next_points [{'alpha': 0.009165004532707506, 'batch_size': 97, 'beta_1': 0.9118373747166382, 'beta_2': 0.9344267508358544, 'epsilon': 1.6722666860230167e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.09208509526395292, 'tol': 0.000596349498339172, 'validation_fraction': 0.10932139378006066}]
function_evaluation time 0.339473 value 45.728114 suggestion {'alpha': 0.009165004532707506, 'batch_size': 97, 'beta_1': 0.9118373747166382, 'beta_2': 0.9344267508358544, 'epsilon': 1.6722666860230167e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.09208509526395292, 'tol': 0.000596349498339172, 'validation_fraction': 0.10932139378006066}
observation time 0.001608, current best 45.728114 at iter 12
suggestion time taken 0.001762 iter 13 next_points [{'alpha': 0.16060416512508713, 'batch_size': 155, 'beta_1': 0.8771368172633084, 'beta_2': 0.9775162076376974, 'epsilon': 2.546985926498832e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 3.2496452306798097e-05, 'tol': 0.001799572465698471, 'validation_fraction': 0.13156217988618912}]
function_evaluation time 0.042952 value 151.513286 suggestion {'alpha': 0.16060416512508713, 'batch_size': 155, 'beta_1': 0.8771368172633084, 'beta_2': 0.9775162076376974, 'epsilon': 2.546985926498832e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 3.2496452306798097e-05, 'tol': 0.001799572465698471, 'validation_fraction': 0.13156217988618912}
observation time 0.001415, current best 45.728114 at iter 13
suggestion time taken 0.001739 iter 14 next_points [{'alpha': 0.016018592780061618, 'batch_size': 191, 'beta_1': 0.8682444241172547, 'beta_2': 0.9987953344208288, 'epsilon': 3.899524903424524e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.00010379828186576337, 'tol': 0.0002611999243996564, 'validation_fraction': 0.6795248137441667}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.052746 value 151.529574 suggestion {'alpha': 0.016018592780061618, 'batch_size': 191, 'beta_1': 0.8682444241172547, 'beta_2': 0.9987953344208288, 'epsilon': 3.899524903424524e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.00010379828186576337, 'tol': 0.0002611999243996564, 'validation_fraction': 0.6795248137441667}
observation time 0.001355, current best 45.728114 at iter 14
saving meta data: {'args': {'--uuid': 'dc0e2e7b18ff562994565d36cb0da1c6', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

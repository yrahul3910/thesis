running: {'--uuid': '9e6d2d5881bc54d6bf3692e320320df2', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_194925', '--opt': 'smoothness', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d wine -o smoothness -u 9e6d2d5881bc54d6bf3692e320320df2 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_194925
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])
Signature errors:
                     0    1    2    3    4  max
MLP-adam_wine_acc  0.0  0.0  0.0  0.0  0.0  0.0
max                0.0  0.0  0.0  0.0  0.0  0.0
starting sklearn study smoothness MLP-adam wine acc 15 1
with data root: None
suggestion time taken 9.387851 iter 0 next_points [{'alpha': 2.920353261339674, 'batch_size': 73, 'beta_1': 0.5032423398148936, 'beta_2': 0.9999381676780095, 'epsilon': 8.917939193284248e-09, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.0008044024416122818, 'tol': 0.0002575191445322181, 'validation_fraction': 0.7055993903228772}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.051497 value -0.427833 suggestion {'alpha': 2.920353261339674, 'batch_size': 73, 'beta_1': 0.5032423398148936, 'beta_2': 0.9999381676780095, 'epsilon': 8.917939193284248e-09, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.0008044024416122818, 'tol': 0.0002575191445322181, 'validation_fraction': 0.7055993903228772}
observation time 0.000006, current best -0.427833 at iter 0
suggestion time taken 9.372630 iter 1 next_points [{'alpha': 1.7549647695036796, 'batch_size': 21, 'beta_1': 0.8374162642285768, 'beta_2': 0.9999921955421592, 'epsilon': 1.1483939029340756e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 1.3724893354978968e-05, 'tol': 0.07338831350336338, 'validation_fraction': 0.22489950180374615}]
function_evaluation time 0.084610 value -0.344828 suggestion {'alpha': 1.7549647695036796, 'batch_size': 21, 'beta_1': 0.8374162642285768, 'beta_2': 0.9999921955421592, 'epsilon': 1.1483939029340756e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 1.3724893354978968e-05, 'tol': 0.07338831350336338, 'validation_fraction': 0.22489950180374615}
observation time 0.000007, current best -0.427833 at iter 1
suggestion time taken 9.312814 iter 2 next_points [{'alpha': 0.0001043514106127321, 'batch_size': 27, 'beta_1': 0.5657169558832101, 'beta_2': 0.9999373740679973, 'epsilon': 1.1209497886139772e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0009164700972424608, 'tol': 0.06630463676376158, 'validation_fraction': 0.2858807458154035}]
function_evaluation time 0.126669 value -0.711576 suggestion {'alpha': 0.0001043514106127321, 'batch_size': 27, 'beta_1': 0.5657169558832101, 'beta_2': 0.9999373740679973, 'epsilon': 1.1209497886139772e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0009164700972424608, 'tol': 0.06630463676376158, 'validation_fraction': 0.2858807458154035}
observation time 0.000006, current best -0.711576 at iter 2
suggestion time taken 9.669250 iter 3 next_points [{'alpha': 0.0013853137329014546, 'batch_size': 27, 'beta_1': 0.8599779536786506, 'beta_2': 0.9999751866223412, 'epsilon': 8.405074533337352e-08, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.0011031726254891938, 'tol': 0.00013235407930843593, 'validation_fraction': 0.24205504917397566}]
function_evaluation time 0.169945 value -0.725123 suggestion {'alpha': 0.0013853137329014546, 'batch_size': 27, 'beta_1': 0.8599779536786506, 'beta_2': 0.9999751866223412, 'epsilon': 8.405074533337352e-08, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.0011031726254891938, 'tol': 0.00013235407930843593, 'validation_fraction': 0.24205504917397566}
observation time 0.000005, current best -0.725123 at iter 3
suggestion time taken 9.515436 iter 4 next_points [{'alpha': 0.0019653011223257186, 'batch_size': 31, 'beta_1': 0.675824638016644, 'beta_2': 0.9439233678715021, 'epsilon': 1.5704116387394733e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.01926570711382587, 'tol': 0.0004422836867718635, 'validation_fraction': 0.3144647325218508}]
function_evaluation time 0.170936 value -0.830296 suggestion {'alpha': 0.0019653011223257186, 'batch_size': 31, 'beta_1': 0.675824638016644, 'beta_2': 0.9439233678715021, 'epsilon': 1.5704116387394733e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.01926570711382587, 'tol': 0.0004422836867718635, 'validation_fraction': 0.3144647325218508}
observation time 0.000005, current best -0.830296 at iter 4
suggestion time taken 9.520787 iter 5 next_points [{'alpha': 0.34856262453315046, 'batch_size': 15, 'beta_1': 0.9888345319983625, 'beta_2': 0.9999306455937819, 'epsilon': 4.636459786708902e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.026079682021413014, 'tol': 0.0008158846999967188, 'validation_fraction': 0.1112760055468281}]
function_evaluation time 0.189685 value -0.810591 suggestion {'alpha': 0.34856262453315046, 'batch_size': 15, 'beta_1': 0.9888345319983625, 'beta_2': 0.9999306455937819, 'epsilon': 4.636459786708902e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.026079682021413014, 'tol': 0.0008158846999967188, 'validation_fraction': 0.1112760055468281}
observation time 0.000006, current best -0.830296 at iter 5
suggestion time taken 9.567814 iter 6 next_points [{'alpha': 4.29186290591502e-05, 'batch_size': 18, 'beta_1': 0.9320081388743586, 'beta_2': 0.9999624648654379, 'epsilon': 2.179056193373517e-09, 'hidden_layer_sizes': 103, 'learning_rate_init': 3.418086465480349e-05, 'tol': 1.9005304431962412e-05, 'validation_fraction': 0.19113293553608815}]
function_evaluation time 0.106587 value -0.371921 suggestion {'alpha': 4.29186290591502e-05, 'batch_size': 18, 'beta_1': 0.9320081388743586, 'beta_2': 0.9999624648654379, 'epsilon': 2.179056193373517e-09, 'hidden_layer_sizes': 103, 'learning_rate_init': 3.418086465480349e-05, 'tol': 1.9005304431962412e-05, 'validation_fraction': 0.19113293553608815}
observation time 0.000006, current best -0.830296 at iter 6
suggestion time taken 9.555609 iter 7 next_points [{'alpha': 0.0010877598508688881, 'batch_size': 24, 'beta_1': 0.6799056515780711, 'beta_2': 0.9998761070003672, 'epsilon': 7.563467664591003e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0008086728376354795, 'tol': 0.09207933064473653, 'validation_fraction': 0.25512001650570854}]
function_evaluation time 0.145331 value -0.768227 suggestion {'alpha': 0.0010877598508688881, 'batch_size': 24, 'beta_1': 0.6799056515780711, 'beta_2': 0.9998761070003672, 'epsilon': 7.563467664591003e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0008086728376354795, 'tol': 0.09207933064473653, 'validation_fraction': 0.25512001650570854}
observation time 0.000006, current best -0.830296 at iter 7
suggestion time taken 9.547968 iter 8 next_points [{'alpha': 2.7583439377423393, 'batch_size': 27, 'beta_1': 0.916351665954572, 'beta_2': 0.9980746070006611, 'epsilon': 1.1537396042918045e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 1.2440291200278122e-05, 'tol': 0.004606837247750915, 'validation_fraction': 0.19863691262350808}]
function_evaluation time 0.106885 value -0.449754 suggestion {'alpha': 2.7583439377423393, 'batch_size': 27, 'beta_1': 0.916351665954572, 'beta_2': 0.9980746070006611, 'epsilon': 1.1537396042918045e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 1.2440291200278122e-05, 'tol': 0.004606837247750915, 'validation_fraction': 0.19863691262350808}
observation time 0.000006, current best -0.830296 at iter 8
suggestion time taken 9.617974 iter 9 next_points [{'alpha': 0.1124664048294729, 'batch_size': 32, 'beta_1': 0.989923145987236, 'beta_2': 0.9997759099405292, 'epsilon': 5.341958072671527e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.030965927504235914, 'tol': 0.00018067674831923476, 'validation_fraction': 0.48069351310474495}]
function_evaluation time 0.126989 value -0.655419 suggestion {'alpha': 0.1124664048294729, 'batch_size': 32, 'beta_1': 0.989923145987236, 'beta_2': 0.9997759099405292, 'epsilon': 5.341958072671527e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.030965927504235914, 'tol': 0.00018067674831923476, 'validation_fraction': 0.48069351310474495}
observation time 0.000006, current best -0.830296 at iter 9
suggestion time taken 9.570458 iter 10 next_points [{'alpha': 9.974979087430386, 'batch_size': 23, 'beta_1': 0.9015136947842053, 'beta_2': 0.996246953677022, 'epsilon': 8.678402676618158e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0008177297604847925, 'tol': 0.009841750085255521, 'validation_fraction': 0.7071073683348226}]
function_evaluation time 0.109542 value -0.479557 suggestion {'alpha': 9.974979087430386, 'batch_size': 23, 'beta_1': 0.9015136947842053, 'beta_2': 0.996246953677022, 'epsilon': 8.678402676618158e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0008177297604847925, 'tol': 0.009841750085255521, 'validation_fraction': 0.7071073683348226}
observation time 0.000006, current best -0.830296 at iter 10
suggestion time taken 9.637737 iter 11 next_points [{'alpha': 0.00012705299209515817, 'batch_size': 20, 'beta_1': 0.9141815615221983, 'beta_2': 0.996837026903698, 'epsilon': 2.6952914289287176e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.0002937457153444213, 'tol': 0.001303176599755802, 'validation_fraction': 0.7218683331496416}]
function_evaluation time 0.074898 value -0.336207 suggestion {'alpha': 0.00012705299209515817, 'batch_size': 20, 'beta_1': 0.9141815615221983, 'beta_2': 0.996837026903698, 'epsilon': 2.6952914289287176e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.0002937457153444213, 'tol': 0.001303176599755802, 'validation_fraction': 0.7218683331496416}
observation time 0.000006, current best -0.830296 at iter 11
suggestion time taken 9.629223 iter 12 next_points [{'alpha': 0.00038676341749097515, 'batch_size': 24, 'beta_1': 0.6469047462695893, 'beta_2': 0.9999333006695178, 'epsilon': 7.914044834896925e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.005612323318350264, 'tol': 0.02542729033324554, 'validation_fraction': 0.10761893657242003}]
function_evaluation time 0.162937 value -0.726601 suggestion {'alpha': 0.00038676341749097515, 'batch_size': 24, 'beta_1': 0.6469047462695893, 'beta_2': 0.9999333006695178, 'epsilon': 7.914044834896925e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.005612323318350264, 'tol': 0.02542729033324554, 'validation_fraction': 0.10761893657242003}
observation time 0.000006, current best -0.830296 at iter 12
suggestion time taken 9.675238 iter 13 next_points [{'alpha': 0.7189655714478361, 'batch_size': 29, 'beta_1': 0.6919382170856155, 'beta_2': 0.9936307478735719, 'epsilon': 6.10538760766469e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.00013273404351824364, 'tol': 5.423278557709874e-05, 'validation_fraction': 0.5510724778894259}]
function_evaluation time 0.063381 value -0.380788 suggestion {'alpha': 0.7189655714478361, 'batch_size': 29, 'beta_1': 0.6919382170856155, 'beta_2': 0.9936307478735719, 'epsilon': 6.10538760766469e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.00013273404351824364, 'tol': 5.423278557709874e-05, 'validation_fraction': 0.5510724778894259}
observation time 0.000006, current best -0.830296 at iter 13
suggestion time taken 9.699728 iter 14 next_points [{'alpha': 0.00012811281644918815, 'batch_size': 19, 'beta_1': 0.9826939261978593, 'beta_2': 0.9264771748007115, 'epsilon': 4.482869140995579e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.00016462793093535003, 'tol': 1.0100034379930626e-05, 'validation_fraction': 0.8826381416625192}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.044175 value -0.359360 suggestion {'alpha': 0.00012811281644918815, 'batch_size': 19, 'beta_1': 0.9826939261978593, 'beta_2': 0.9264771748007115, 'epsilon': 4.482869140995579e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.00016462793093535003, 'tol': 1.0100034379930626e-05, 'validation_fraction': 0.8826381416625192}
observation time 0.000006, current best -0.830296 at iter 14
saving meta data: {'args': {'--uuid': '9e6d2d5881bc54d6bf3692e320320df2', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_194925', '--opt': 'smoothness', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])}
saving results
saving timing
saving suggest log
done

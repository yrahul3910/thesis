running: {'--uuid': '5ee103d4e77d5e4087a7e5021a33d684', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d diabetes -o opentuner -u 5ee103d4e77d5e4087a7e5021a33d684 -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_055340
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study opentuner MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.017865 iter 0 next_points [{'hidden_layer_sizes': 177, 'alpha': 8.709739851270626, 'batch_size': 93, 'learning_rate_init': 0.04979802416766515, 'tol': 0.012380617009435314, 'validation_fraction': 0.16447927728163025, 'beta_1': 0.7680640461278623, 'beta_2': 0.9878209333083555, 'epsilon': 9.686062744379266e-07}]
function_evaluation time 0.228063 value 46.134154 suggestion {'hidden_layer_sizes': 177, 'alpha': 8.709739851270626, 'batch_size': 93, 'learning_rate_init': 0.04979802416766515, 'tol': 0.012380617009435314, 'validation_fraction': 0.16447927728163025, 'beta_1': 0.7680640461278623, 'beta_2': 0.9878209333083555, 'epsilon': 9.686062744379266e-07}
observation time 0.004368, current best 46.134154 at iter 0
suggestion time taken 0.046583 iter 1 next_points [{'batch_size': 163, 'epsilon': 6.022964062218628e-07, 'beta_2': 0.9789130658663872, 'validation_fraction': 0.40246708915578566, 'alpha': 9.007851633359088, 'learning_rate_init': 0.019392101296459453, 'tol': 0.09990309799448853, 'beta_1': 0.507281075694995, 'hidden_layer_sizes': 77}]
function_evaluation time 0.180563 value 59.991140 suggestion {'batch_size': 163, 'epsilon': 6.022964062218628e-07, 'beta_2': 0.9789130658663872, 'validation_fraction': 0.40246708915578566, 'alpha': 9.007851633359088, 'learning_rate_init': 0.019392101296459453, 'tol': 0.09990309799448853, 'beta_1': 0.507281075694995, 'hidden_layer_sizes': 77}
observation time 0.001846, current best 46.134154 at iter 1
suggestion time taken 0.007298 iter 2 next_points [{'hidden_layer_sizes': 177, 'alpha': 8.5631372501247, 'batch_size': 93, 'learning_rate_init': 0.04979802416766515, 'tol': 0.02394350905398517, 'validation_fraction': 0.10246884788341992, 'beta_1': 0.7680640461278623, 'beta_2': 0.9878209333083555, 'epsilon': 9.686062744379266e-07}]
function_evaluation time 0.187248 value 48.179272 suggestion {'hidden_layer_sizes': 177, 'alpha': 8.5631372501247, 'batch_size': 93, 'learning_rate_init': 0.04979802416766515, 'tol': 0.02394350905398517, 'validation_fraction': 0.10246884788341992, 'beta_1': 0.7680640461278623, 'beta_2': 0.9878209333083555, 'epsilon': 9.686062744379266e-07}
observation time 0.001845, current best 46.134154 at iter 2
suggestion time taken 0.021181 iter 3 next_points [{'alpha': 4.432493547948482, 'tol': 0.014778491562846541, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.09180587822765422, 'beta_2': 0.9013070314372804, 'validation_fraction': 0.6319819493263631, 'beta_1': 0.5594455690398329, 'batch_size': 52, 'epsilon': 1.4876486056966575e-07}]
function_evaluation time 0.136756 value 46.117043 suggestion {'alpha': 4.432493547948482, 'tol': 0.014778491562846541, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.09180587822765422, 'beta_2': 0.9013070314372804, 'validation_fraction': 0.6319819493263631, 'beta_1': 0.5594455690398329, 'batch_size': 52, 'epsilon': 1.4876486056966575e-07}
observation time 0.002032, current best 46.117043 at iter 3
suggestion time taken 0.005860 iter 4 next_points [{'alpha': 0.6398713297878419, 'tol': 0.07982759473020933, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.04508628459965618, 'beta_2': 0.9173402719358683, 'validation_fraction': 0.16036241459062606, 'beta_1': 0.8514304165038709, 'batch_size': 231, 'epsilon': 1.714668477486848e-07}]
function_evaluation time 0.172919 value 53.959189 suggestion {'alpha': 0.6398713297878419, 'tol': 0.07982759473020933, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.04508628459965618, 'beta_2': 0.9173402719358683, 'validation_fraction': 0.16036241459062606, 'beta_1': 0.8514304165038709, 'batch_size': 231, 'epsilon': 1.714668477486848e-07}
observation time 0.001843, current best 46.117043 at iter 4
suggestion time taken 0.006905 iter 5 next_points [{'alpha': 4.432493547948482, 'tol': 0.0024219480526703097, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.09180587822765422, 'beta_2': 0.9013070314372804, 'validation_fraction': 0.6319819493263631, 'beta_1': 0.5594455690398329, 'batch_size': 217, 'epsilon': 1.4876486056966575e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.187459 value 44.630611 suggestion {'alpha': 4.432493547948482, 'tol': 0.0024219480526703097, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.09180587822765422, 'beta_2': 0.9013070314372804, 'validation_fraction': 0.6319819493263631, 'beta_1': 0.5594455690398329, 'batch_size': 217, 'epsilon': 1.4876486056966575e-07}
observation time 0.002027, current best 44.630611 at iter 5
suggestion time taken 0.006685 iter 6 next_points [{'alpha': 4.432493547948482, 'tol': 0.0024219480526703097, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.09180587822765422, 'beta_2': 0.9013070314372804, 'validation_fraction': 0.6319819493263631, 'beta_1': 0.5594455690398329, 'batch_size': 217, 'epsilon': 1.4876486056966575e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.199641 value 45.316759 suggestion {'alpha': 4.432493547948482, 'tol': 0.0024219480526703097, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.09180587822765422, 'beta_2': 0.9013070314372804, 'validation_fraction': 0.6319819493263631, 'beta_1': 0.5594455690398329, 'batch_size': 217, 'epsilon': 1.4876486056966575e-07}
observation time 0.001894, current best 44.630611 at iter 6
suggestion time taken 0.006906 iter 7 next_points [{'alpha': 4.432493547948482, 'tol': 0.04095999885866413, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.09180587822765422, 'beta_2': 0.9013070314372804, 'validation_fraction': 0.6319819493263631, 'beta_1': 0.5594455690398329, 'batch_size': 217, 'epsilon': 1.4876486056966575e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.112853 value 50.873241 suggestion {'alpha': 4.432493547948482, 'tol': 0.04095999885866413, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.09180587822765422, 'beta_2': 0.9013070314372804, 'validation_fraction': 0.6319819493263631, 'beta_1': 0.5594455690398329, 'batch_size': 217, 'epsilon': 1.4876486056966575e-07}
observation time 0.001830, current best 44.630611 at iter 7
suggestion time taken 0.006559 iter 8 next_points [{'alpha': 1.4501055474980689, 'tol': 0.0019972503532496477, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.00508318771007692, 'beta_2': 0.9719628254473045, 'validation_fraction': 0.47094120742717605, 'beta_1': 0.7826667744230604, 'batch_size': 196, 'epsilon': 9.301316891424372e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.808812 value 75.071220 suggestion {'alpha': 1.4501055474980689, 'tol': 0.0019972503532496477, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.00508318771007692, 'beta_2': 0.9719628254473045, 'validation_fraction': 0.47094120742717605, 'beta_1': 0.7826667744230604, 'batch_size': 196, 'epsilon': 9.301316891424372e-07}
observation time 0.001821, current best 44.630611 at iter 8
suggestion time taken 0.006870 iter 9 next_points [{'alpha': 4.432493547948482, 'tol': 0.0024219480526703097, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.07093422446413482, 'beta_2': 0.9013070314372804, 'validation_fraction': 0.6319819493263631, 'beta_1': 0.5594455690398329, 'batch_size': 217, 'epsilon': 1.4876486056966575e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.234285 value 45.579313 suggestion {'alpha': 4.432493547948482, 'tol': 0.0024219480526703097, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.07093422446413482, 'beta_2': 0.9013070314372804, 'validation_fraction': 0.6319819493263631, 'beta_1': 0.5594455690398329, 'batch_size': 217, 'epsilon': 1.4876486056966575e-07}
observation time 0.001878, current best 44.630611 at iter 9
suggestion time taken 0.007000 iter 10 next_points [{'alpha': 4.432493547948482, 'tol': 0.034698007615805375, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.09180587822765422, 'beta_2': 0.9013070314372804, 'validation_fraction': 0.6319819493263631, 'beta_1': 0.5594455690398329, 'batch_size': 217, 'epsilon': 2.9941987125855953e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.120808 value 47.430894 suggestion {'alpha': 4.432493547948482, 'tol': 0.034698007615805375, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.09180587822765422, 'beta_2': 0.9013070314372804, 'validation_fraction': 0.6319819493263631, 'beta_1': 0.5594455690398329, 'batch_size': 217, 'epsilon': 2.9941987125855953e-07}
observation time 0.002693, current best 44.630611 at iter 10
suggestion time taken 0.005969 iter 11 next_points [{'alpha': 2.0152001207682875, 'tol': 0.07256814076980815, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.07580912147737233, 'beta_2': 0.9109634106381554, 'validation_fraction': 0.3236490079579526, 'beta_1': 0.9615777657682638, 'batch_size': 69, 'epsilon': 8.033785607047529e-07}]
function_evaluation time 0.191139 value 44.986784 suggestion {'alpha': 2.0152001207682875, 'tol': 0.07256814076980815, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.07580912147737233, 'beta_2': 0.9109634106381554, 'validation_fraction': 0.3236490079579526, 'beta_1': 0.9615777657682638, 'batch_size': 69, 'epsilon': 8.033785607047529e-07}
observation time 0.001835, current best 44.630611 at iter 11
suggestion time taken 0.006907 iter 12 next_points [{'alpha': 4.432493547948482, 'tol': 0.08729872793413122, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.09180587822765422, 'beta_2': 0.9013070314372804, 'validation_fraction': 0.6319819493263631, 'beta_1': 0.5594455690398329, 'batch_size': 241, 'epsilon': 1.4876486056966575e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.108016 value 50.812543 suggestion {'alpha': 4.432493547948482, 'tol': 0.08729872793413122, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.09180587822765422, 'beta_2': 0.9013070314372804, 'validation_fraction': 0.6319819493263631, 'beta_1': 0.5594455690398329, 'batch_size': 241, 'epsilon': 1.4876486056966575e-07}
observation time 0.002312, current best 44.630611 at iter 12
suggestion time taken 0.006192 iter 13 next_points [{'alpha': 0.7702490953755393, 'tol': 0.07807290664060111, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.015883189316849112, 'beta_2': 0.9843633718634422, 'validation_fraction': 0.47620442348550396, 'beta_1': 0.9258078693680531, 'batch_size': 234, 'epsilon': 9.24779470474173e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.054107 value 148.820116 suggestion {'alpha': 0.7702490953755393, 'tol': 0.07807290664060111, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.015883189316849112, 'beta_2': 0.9843633718634422, 'validation_fraction': 0.47620442348550396, 'beta_1': 0.9258078693680531, 'batch_size': 234, 'epsilon': 9.24779470474173e-07}
observation time 0.002087, current best 44.630611 at iter 13
suggestion time taken 0.007148 iter 14 next_points [{'alpha': 4.432493547948482, 'tol': 0.0024219480526703097, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.09180587822765422, 'beta_2': 0.9013070314372804, 'validation_fraction': 0.6319819493263631, 'beta_1': 0.5594455690398329, 'batch_size': 217, 'epsilon': 9.633395551550119e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.211697 value 45.672592 suggestion {'alpha': 4.432493547948482, 'tol': 0.0024219480526703097, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.09180587822765422, 'beta_2': 0.9013070314372804, 'validation_fraction': 0.6319819493263631, 'beta_1': 0.5594455690398329, 'batch_size': 217, 'epsilon': 9.633395551550119e-07}
observation time 0.001830, current best 44.630611 at iter 14
saving meta data: {'args': {'--uuid': '5ee103d4e77d5e4087a7e5021a33d684', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

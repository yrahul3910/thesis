running: {'--uuid': '582827d85b705f4a803bd036363e70a7', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d diabetes -o random-search -u 582827d85b705f4a803bd036363e70a7 -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_055340
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study random-search MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002532 iter 0 next_points [{'alpha': 0.02785308572895254, 'batch_size': 223, 'beta_1': 0.940791559490493, 'beta_2': 0.9997178533293795, 'epsilon': 8.687155884098427e-07, 'hidden_layer_sizes': 158, 'learning_rate_init': 6.573715363297033e-05, 'tol': 8.38311968833352e-05, 'validation_fraction': 0.8744669878484448}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.053658 value 151.617534 suggestion {'alpha': 0.02785308572895254, 'batch_size': 223, 'beta_1': 0.940791559490493, 'beta_2': 0.9997178533293795, 'epsilon': 8.687155884098427e-07, 'hidden_layer_sizes': 158, 'learning_rate_init': 6.573715363297033e-05, 'tol': 8.38311968833352e-05, 'validation_fraction': 0.8744669878484448}
observation time 0.000007, current best 151.617534 at iter 0
suggestion time taken 0.002500 iter 1 next_points [{'alpha': 0.033315021504897735, 'batch_size': 172, 'beta_1': 0.9543292598686417, 'beta_2': 0.9999546271743418, 'epsilon': 4.5878249118214514e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.00028230559429145866, 'tol': 0.028914062582519186, 'validation_fraction': 0.7553432155042604}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.048142 value 151.689354 suggestion {'alpha': 0.033315021504897735, 'batch_size': 172, 'beta_1': 0.9543292598686417, 'beta_2': 0.9999546271743418, 'epsilon': 4.5878249118214514e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.00028230559429145866, 'tol': 0.028914062582519186, 'validation_fraction': 0.7553432155042604}
observation time 0.000005, current best 151.617534 at iter 1
suggestion time taken 0.002523 iter 2 next_points [{'alpha': 0.353923682422809, 'batch_size': 34, 'beta_1': 0.8725485103914936, 'beta_2': 0.9917150084669797, 'epsilon': 3.322758809990005e-07, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.07387458050730905, 'tol': 0.051815260402306156, 'validation_fraction': 0.10834747042075274}]
function_evaluation time 0.136445 value 44.888280 suggestion {'alpha': 0.353923682422809, 'batch_size': 34, 'beta_1': 0.8725485103914936, 'beta_2': 0.9917150084669797, 'epsilon': 3.322758809990005e-07, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.07387458050730905, 'tol': 0.051815260402306156, 'validation_fraction': 0.10834747042075274}
observation time 0.000005, current best 44.888280 at iter 2
suggestion time taken 0.002463 iter 3 next_points [{'alpha': 0.3894218262235366, 'batch_size': 99, 'beta_1': 0.8287489418210322, 'beta_2': 0.9999957853875282, 'epsilon': 2.3545574189925136e-07, 'hidden_layer_sizes': 145, 'learning_rate_init': 8.680545262785701e-05, 'tol': 0.00017937994512983425, 'validation_fraction': 0.8887916334010015}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.051613 value 151.466903 suggestion {'alpha': 0.3894218262235366, 'batch_size': 99, 'beta_1': 0.8287489418210322, 'beta_2': 0.9999957853875282, 'epsilon': 2.3545574189925136e-07, 'hidden_layer_sizes': 145, 'learning_rate_init': 8.680545262785701e-05, 'tol': 0.00017937994512983425, 'validation_fraction': 0.8887916334010015}
observation time 0.000005, current best 44.888280 at iter 3
suggestion time taken 0.002514 iter 4 next_points [{'alpha': 0.8534843900844398, 'batch_size': 244, 'beta_1': 0.9815064582122732, 'beta_2': 0.9774835179268372, 'epsilon': 1.9450072464467225e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.02097273777939667, 'tol': 0.000808394852116762, 'validation_fraction': 0.40482591470506685}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.415444 value 54.564759 suggestion {'alpha': 0.8534843900844398, 'batch_size': 244, 'beta_1': 0.9815064582122732, 'beta_2': 0.9774835179268372, 'epsilon': 1.9450072464467225e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.02097273777939667, 'tol': 0.000808394852116762, 'validation_fraction': 0.40482591470506685}
observation time 0.000004, current best 44.888280 at iter 4
suggestion time taken 0.002461 iter 5 next_points [{'alpha': 0.000839199944592339, 'batch_size': 171, 'beta_1': 0.6932927710806861, 'beta_2': 0.9998615131391211, 'epsilon': 9.093864225617953e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 3.786080932691661e-05, 'tol': 0.0004264020353067543, 'validation_fraction': 0.7130158908702205}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.047886 value 151.626419 suggestion {'alpha': 0.000839199944592339, 'batch_size': 171, 'beta_1': 0.6932927710806861, 'beta_2': 0.9998615131391211, 'epsilon': 9.093864225617953e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 3.786080932691661e-05, 'tol': 0.0004264020353067543, 'validation_fraction': 0.7130158908702205}
observation time 0.000005, current best 44.888280 at iter 5
suggestion time taken 0.002513 iter 6 next_points [{'alpha': 1.141051016152672, 'batch_size': 29, 'beta_1': 0.8835336299865604, 'beta_2': 0.9999987749622613, 'epsilon': 2.298744860759784e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.00016968920581888707, 'tol': 3.5413482226753884e-05, 'validation_fraction': 0.8613392145688005}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.799095 value 150.724154 suggestion {'alpha': 1.141051016152672, 'batch_size': 29, 'beta_1': 0.8835336299865604, 'beta_2': 0.9999987749622613, 'epsilon': 2.298744860759784e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.00016968920581888707, 'tol': 3.5413482226753884e-05, 'validation_fraction': 0.8613392145688005}
observation time 0.000004, current best 44.888280 at iter 6
suggestion time taken 0.002477 iter 7 next_points [{'alpha': 0.00013458239106853832, 'batch_size': 44, 'beta_1': 0.6256541745811343, 'beta_2': 0.9999877661516762, 'epsilon': 2.39324607002727e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0013948392156625967, 'tol': 0.001422734957293862, 'validation_fraction': 0.7774256066767283}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.901092 value 112.493800 suggestion {'alpha': 0.00013458239106853832, 'batch_size': 44, 'beta_1': 0.6256541745811343, 'beta_2': 0.9999877661516762, 'epsilon': 2.39324607002727e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0013948392156625967, 'tol': 0.001422734957293862, 'validation_fraction': 0.7774256066767283}
observation time 0.000004, current best 44.888280 at iter 7
suggestion time taken 0.002484 iter 8 next_points [{'alpha': 0.00902443074952876, 'batch_size': 116, 'beta_1': 0.9870200067828624, 'beta_2': 0.9999543240837976, 'epsilon': 1.5322902836814635e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 1.659972359499161e-05, 'tol': 0.007583401661386207, 'validation_fraction': 0.6910145610479025}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.060075 value 151.543627 suggestion {'alpha': 0.00902443074952876, 'batch_size': 116, 'beta_1': 0.9870200067828624, 'beta_2': 0.9999543240837976, 'epsilon': 1.5322902836814635e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 1.659972359499161e-05, 'tol': 0.007583401661386207, 'validation_fraction': 0.6910145610479025}
observation time 0.000004, current best 44.888280 at iter 8
suggestion time taken 0.002483 iter 9 next_points [{'alpha': 0.01639870507049735, 'batch_size': 242, 'beta_1': 0.8611841857765503, 'beta_2': 0.999946358334624, 'epsilon': 3.3444613075474278e-09, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.00017966016946816647, 'tol': 0.0009290051896952229, 'validation_fraction': 0.23937781457640955}]
function_evaluation time 0.074727 value 151.479397 suggestion {'alpha': 0.01639870507049735, 'batch_size': 242, 'beta_1': 0.8611841857765503, 'beta_2': 0.999946358334624, 'epsilon': 3.3444613075474278e-09, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.00017966016946816647, 'tol': 0.0009290051896952229, 'validation_fraction': 0.23937781457640955}
observation time 0.000004, current best 44.888280 at iter 9
suggestion time taken 0.002444 iter 10 next_points [{'alpha': 0.025695967811706397, 'batch_size': 216, 'beta_1': 0.8756825359914906, 'beta_2': 0.9999872822037525, 'epsilon': 1.24945973321137e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0001540862072919132, 'tol': 0.06379302385137615, 'validation_fraction': 0.11481548564122668}]
function_evaluation time 0.070428 value 151.433960 suggestion {'alpha': 0.025695967811706397, 'batch_size': 216, 'beta_1': 0.8756825359914906, 'beta_2': 0.9999872822037525, 'epsilon': 1.24945973321137e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0001540862072919132, 'tol': 0.06379302385137615, 'validation_fraction': 0.11481548564122668}
observation time 0.000004, current best 44.888280 at iter 10
suggestion time taken 0.002449 iter 11 next_points [{'alpha': 0.14290381790791043, 'batch_size': 208, 'beta_1': 0.9890086188259501, 'beta_2': 0.9999935084263062, 'epsilon': 6.710357817677781e-07, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.01615401727550581, 'tol': 0.0041206727288325236, 'validation_fraction': 0.4035701736898879}]
function_evaluation time 0.476676 value 54.935503 suggestion {'alpha': 0.14290381790791043, 'batch_size': 208, 'beta_1': 0.9890086188259501, 'beta_2': 0.9999935084263062, 'epsilon': 6.710357817677781e-07, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.01615401727550581, 'tol': 0.0041206727288325236, 'validation_fraction': 0.4035701736898879}
observation time 0.000004, current best 44.888280 at iter 11
suggestion time taken 0.002504 iter 12 next_points [{'alpha': 0.5282555698542345, 'batch_size': 151, 'beta_1': 0.9625455060533057, 'beta_2': 0.9999879901054662, 'epsilon': 3.471034452188134e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 2.6109467937333054e-05, 'tol': 0.02071056370702127, 'validation_fraction': 0.17121214367070528}]
function_evaluation time 0.068497 value 151.805209 suggestion {'alpha': 0.5282555698542345, 'batch_size': 151, 'beta_1': 0.9625455060533057, 'beta_2': 0.9999879901054662, 'epsilon': 3.471034452188134e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 2.6109467937333054e-05, 'tol': 0.02071056370702127, 'validation_fraction': 0.17121214367070528}
observation time 0.000004, current best 44.888280 at iter 12
suggestion time taken 0.002435 iter 13 next_points [{'alpha': 0.05917006244150442, 'batch_size': 13, 'beta_1': 0.9174671044384645, 'beta_2': 0.9070058176727123, 'epsilon': 3.586784144034013e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0014683624288218374, 'tol': 0.0002615205713116549, 'validation_fraction': 0.864389771073902}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.099507 value 115.778462 suggestion {'alpha': 0.05917006244150442, 'batch_size': 13, 'beta_1': 0.9174671044384645, 'beta_2': 0.9070058176727123, 'epsilon': 3.586784144034013e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0014683624288218374, 'tol': 0.0002615205713116549, 'validation_fraction': 0.864389771073902}
observation time 0.000004, current best 44.888280 at iter 13
suggestion time taken 0.002473 iter 14 next_points [{'alpha': 4.684168353876843, 'batch_size': 213, 'beta_1': 0.858716668931487, 'beta_2': 0.9994772450847116, 'epsilon': 1.2781565696797168e-09, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.003901464439233447, 'tol': 5.997264709567788e-05, 'validation_fraction': 0.7895274871247625}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.788945 value 66.253743 suggestion {'alpha': 4.684168353876843, 'batch_size': 213, 'beta_1': 0.858716668931487, 'beta_2': 0.9994772450847116, 'epsilon': 1.2781565696797168e-09, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.003901464439233447, 'tol': 5.997264709567788e-05, 'validation_fraction': 0.7895274871247625}
observation time 0.000005, current best 44.888280 at iter 14
saving meta data: {'args': {'--uuid': '582827d85b705f4a803bd036363e70a7', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

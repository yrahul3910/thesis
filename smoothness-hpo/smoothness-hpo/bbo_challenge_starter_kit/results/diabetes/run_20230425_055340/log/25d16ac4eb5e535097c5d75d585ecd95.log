running: {'--uuid': '25d16ac4eb5e535097c5d75d585ecd95', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d diabetes -o hyperopt -u 25d16ac4eb5e535097c5d75d585ecd95 -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_055340
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study hyperopt MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002358 iter 0 next_points [{'alpha': 1.5934877645969324e-05, 'batch_size': 128, 'beta_1': 0.9210607748265777, 'beta_2': 0.9760849869943735, 'epsilon': 2.934204020993706e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 1.9438100289352234e-05, 'tol': 7.162928458903913e-05, 'validation_fraction': 0.2238944715678226}]
function_evaluation time 0.093840 value 151.533269 suggestion {'alpha': 1.5934877645969324e-05, 'batch_size': 128, 'beta_1': 0.9210607748265777, 'beta_2': 0.9760849869943735, 'epsilon': 2.934204020993706e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 1.9438100289352234e-05, 'tol': 7.162928458903913e-05, 'validation_fraction': 0.2238944715678226}
observation time 0.000070, current best 151.533269 at iter 0
suggestion time taken 0.002426 iter 1 next_points [{'alpha': 0.0008151465804128152, 'batch_size': 121, 'beta_1': 0.5369046582516503, 'beta_2': 0.9007346852796774, 'epsilon': 8.327527662755962e-08, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.03173878010851561, 'tol': 0.005603750273005812, 'validation_fraction': 0.24526008816435227}]
function_evaluation time 0.416474 value 45.448920 suggestion {'alpha': 0.0008151465804128152, 'batch_size': 121, 'beta_1': 0.5369046582516503, 'beta_2': 0.9007346852796774, 'epsilon': 8.327527662755962e-08, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.03173878010851561, 'tol': 0.005603750273005812, 'validation_fraction': 0.24526008816435227}
observation time 0.000072, current best 45.448920 at iter 1
suggestion time taken 0.002364 iter 2 next_points [{'alpha': 0.2759451690905207, 'batch_size': 170, 'beta_1': 0.603675171732628, 'beta_2': 0.9726836144055935, 'epsilon': 1.903023037992673e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.00019858319265409085, 'tol': 0.00013569406069651404, 'validation_fraction': 0.19422615941369886}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.230275 value 150.209920 suggestion {'alpha': 0.2759451690905207, 'batch_size': 170, 'beta_1': 0.603675171732628, 'beta_2': 0.9726836144055935, 'epsilon': 1.903023037992673e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.00019858319265409085, 'tol': 0.00013569406069651404, 'validation_fraction': 0.19422615941369886}
observation time 0.000071, current best 45.448920 at iter 2
suggestion time taken 0.002118 iter 3 next_points [{'alpha': 4.991380813759233e-05, 'batch_size': 33, 'beta_1': 0.9290861915645638, 'beta_2': 0.9720947972834374, 'epsilon': 9.041511795911624e-07, 'hidden_layer_sizes': 174, 'learning_rate_init': 6.476707566759275e-05, 'tol': 0.0001412115305327769, 'validation_fraction': 0.38845590254214063}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.126137 value 150.084687 suggestion {'alpha': 4.991380813759233e-05, 'batch_size': 33, 'beta_1': 0.9290861915645638, 'beta_2': 0.9720947972834374, 'epsilon': 9.041511795911624e-07, 'hidden_layer_sizes': 174, 'learning_rate_init': 6.476707566759275e-05, 'tol': 0.0001412115305327769, 'validation_fraction': 0.38845590254214063}
observation time 0.000072, current best 45.448920 at iter 3
suggestion time taken 0.002114 iter 4 next_points [{'alpha': 0.00010689633707064118, 'batch_size': 112, 'beta_1': 0.7307183505678696, 'beta_2': 0.9612039573267394, 'epsilon': 1.877774615122937e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.04340055757805987, 'tol': 0.022186724783733847, 'validation_fraction': 0.859454467073221}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.158712 value 52.033312 suggestion {'alpha': 0.00010689633707064118, 'batch_size': 112, 'beta_1': 0.7307183505678696, 'beta_2': 0.9612039573267394, 'epsilon': 1.877774615122937e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.04340055757805987, 'tol': 0.022186724783733847, 'validation_fraction': 0.859454467073221}
observation time 0.000076, current best 45.448920 at iter 4
suggestion time taken 0.002104 iter 5 next_points [{'alpha': 0.3145153943371781, 'batch_size': 52, 'beta_1': 0.5846774640247547, 'beta_2': 0.9625026746982996, 'epsilon': 3.5907490208686327e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 9.282697698765321e-05, 'tol': 0.010187414568887594, 'validation_fraction': 0.8745352480622737}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.046633 value 151.518940 suggestion {'alpha': 0.3145153943371781, 'batch_size': 52, 'beta_1': 0.5846774640247547, 'beta_2': 0.9625026746982996, 'epsilon': 3.5907490208686327e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 9.282697698765321e-05, 'tol': 0.010187414568887594, 'validation_fraction': 0.8745352480622737}
observation time 0.000069, current best 45.448920 at iter 5
suggestion time taken 0.002118 iter 6 next_points [{'alpha': 0.5573466444657125, 'batch_size': 116, 'beta_1': 0.7307066701684671, 'beta_2': 0.9421544318842827, 'epsilon': 1.0751025141833118e-09, 'hidden_layer_sizes': 124, 'learning_rate_init': 3.2831135345586834e-05, 'tol': 3.825520943891567e-05, 'validation_fraction': 0.5575603866018085}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.998064 value 151.338273 suggestion {'alpha': 0.5573466444657125, 'batch_size': 116, 'beta_1': 0.7307066701684671, 'beta_2': 0.9421544318842827, 'epsilon': 1.0751025141833118e-09, 'hidden_layer_sizes': 124, 'learning_rate_init': 3.2831135345586834e-05, 'tol': 3.825520943891567e-05, 'validation_fraction': 0.5575603866018085}
observation time 0.000072, current best 45.448920 at iter 6
suggestion time taken 0.002176 iter 7 next_points [{'alpha': 0.013565488582356544, 'batch_size': 136, 'beta_1': 0.7087359971341841, 'beta_2': 0.9051705846938176, 'epsilon': 4.9912187934837316e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.000954574745187842, 'tol': 2.203752313989808e-05, 'validation_fraction': 0.7056639632215387}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.571098 value 149.865018 suggestion {'alpha': 0.013565488582356544, 'batch_size': 136, 'beta_1': 0.7087359971341841, 'beta_2': 0.9051705846938176, 'epsilon': 4.9912187934837316e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.000954574745187842, 'tol': 2.203752313989808e-05, 'validation_fraction': 0.7056639632215387}
observation time 0.000074, current best 45.448920 at iter 7
suggestion time taken 0.002114 iter 8 next_points [{'alpha': 0.007139691305550547, 'batch_size': 201, 'beta_1': 0.6717482396747346, 'beta_2': 0.9983184495283329, 'epsilon': 3.651646120956581e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.00015419740249860876, 'tol': 0.00013275824094403598, 'validation_fraction': 0.13667473615661427}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.023788 value 150.652778 suggestion {'alpha': 0.007139691305550547, 'batch_size': 201, 'beta_1': 0.6717482396747346, 'beta_2': 0.9983184495283329, 'epsilon': 3.651646120956581e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.00015419740249860876, 'tol': 0.00013275824094403598, 'validation_fraction': 0.13667473615661427}
observation time 0.000070, current best 45.448920 at iter 8
suggestion time taken 0.002112 iter 9 next_points [{'alpha': 0.02794499324703001, 'batch_size': 54, 'beta_1': 0.9136115739496085, 'beta_2': 0.9169340339528916, 'epsilon': 2.6750895057391643e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.08938753902536424, 'tol': 0.00338837781766789, 'validation_fraction': 0.3507308118774254}]
function_evaluation time 0.235444 value 43.722165 suggestion {'alpha': 0.02794499324703001, 'batch_size': 54, 'beta_1': 0.9136115739496085, 'beta_2': 0.9169340339528916, 'epsilon': 2.6750895057391643e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.08938753902536424, 'tol': 0.00338837781766789, 'validation_fraction': 0.3507308118774254}
observation time 0.000075, current best 43.722165 at iter 9
suggestion time taken 0.002147 iter 10 next_points [{'alpha': 3.1355792412993893, 'batch_size': 98, 'beta_1': 0.6515529579347218, 'beta_2': 0.9372232792330347, 'epsilon': 1.005977787575052e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.025024165848996457, 'tol': 2.3303145577116338e-05, 'validation_fraction': 0.45542493420223906}]
function_evaluation time 0.579072 value 44.270116 suggestion {'alpha': 3.1355792412993893, 'batch_size': 98, 'beta_1': 0.6515529579347218, 'beta_2': 0.9372232792330347, 'epsilon': 1.005977787575052e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.025024165848996457, 'tol': 2.3303145577116338e-05, 'validation_fraction': 0.45542493420223906}
observation time 0.000073, current best 43.722165 at iter 10
suggestion time taken 0.002120 iter 11 next_points [{'alpha': 0.0002501668871678762, 'batch_size': 145, 'beta_1': 0.8448322519748941, 'beta_2': 0.977263641506536, 'epsilon': 6.276360929851519e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0005133711876070062, 'tol': 4.3052100958074874e-05, 'validation_fraction': 0.12782772414874438}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.168290 value 147.054896 suggestion {'alpha': 0.0002501668871678762, 'batch_size': 145, 'beta_1': 0.8448322519748941, 'beta_2': 0.977263641506536, 'epsilon': 6.276360929851519e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0005133711876070062, 'tol': 4.3052100958074874e-05, 'validation_fraction': 0.12782772414874438}
observation time 0.000072, current best 43.722165 at iter 11
suggestion time taken 0.002133 iter 12 next_points [{'alpha': 8.119747014944759e-05, 'batch_size': 43, 'beta_1': 0.7605049755207308, 'beta_2': 0.9552066833395519, 'epsilon': 1.2375723216873485e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.000549452493889594, 'tol': 0.06287625329267532, 'validation_fraction': 0.20470478955619592}]
function_evaluation time 0.085282 value 150.882312 suggestion {'alpha': 8.119747014944759e-05, 'batch_size': 43, 'beta_1': 0.7605049755207308, 'beta_2': 0.9552066833395519, 'epsilon': 1.2375723216873485e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.000549452493889594, 'tol': 0.06287625329267532, 'validation_fraction': 0.20470478955619592}
observation time 0.000077, current best 43.722165 at iter 12
suggestion time taken 0.002183 iter 13 next_points [{'alpha': 5.258235760234386, 'batch_size': 153, 'beta_1': 0.916698151041716, 'beta_2': 0.970236554117249, 'epsilon': 3.231778173421012e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.007691349099231943, 'tol': 0.0007791075660871468, 'validation_fraction': 0.13683227733305525}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.013205 value 48.479083 suggestion {'alpha': 5.258235760234386, 'batch_size': 153, 'beta_1': 0.916698151041716, 'beta_2': 0.970236554117249, 'epsilon': 3.231778173421012e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.007691349099231943, 'tol': 0.0007791075660871468, 'validation_fraction': 0.13683227733305525}
observation time 0.000076, current best 43.722165 at iter 13
suggestion time taken 0.002148 iter 14 next_points [{'alpha': 0.9112047601787122, 'batch_size': 129, 'beta_1': 0.5184182880241575, 'beta_2': 0.9683262783465809, 'epsilon': 4.481113710276801e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 3.1781583850476733e-05, 'tol': 0.0001595201692344108, 'validation_fraction': 0.2104362232268591}]
function_evaluation time 0.044831 value 151.633314 suggestion {'alpha': 0.9112047601787122, 'batch_size': 129, 'beta_1': 0.5184182880241575, 'beta_2': 0.9683262783465809, 'epsilon': 4.481113710276801e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 3.1781583850476733e-05, 'tol': 0.0001595201692344108, 'validation_fraction': 0.2104362232268591}
observation time 0.000074, current best 43.722165 at iter 14
saving meta data: {'args': {'--uuid': '25d16ac4eb5e535097c5d75d585ecd95', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

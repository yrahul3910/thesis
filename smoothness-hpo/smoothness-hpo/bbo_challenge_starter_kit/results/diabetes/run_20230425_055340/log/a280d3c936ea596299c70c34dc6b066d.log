running: {'--uuid': 'a280d3c936ea596299c70c34dc6b066d', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d diabetes -o hyperopt -u a280d3c936ea596299c70c34dc6b066d -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_055340
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study hyperopt MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002344 iter 0 next_points [{'alpha': 0.23862250119651426, 'batch_size': 175, 'beta_1': 0.9499268391655684, 'beta_2': 0.9278331873048903, 'epsilon': 3.743782404048852e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.06497614564072561, 'tol': 0.0007765951038430373, 'validation_fraction': 0.2654436779129957}]
function_evaluation time 0.266527 value 48.429649 suggestion {'alpha': 0.23862250119651426, 'batch_size': 175, 'beta_1': 0.9499268391655684, 'beta_2': 0.9278331873048903, 'epsilon': 3.743782404048852e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.06497614564072561, 'tol': 0.0007765951038430373, 'validation_fraction': 0.2654436779129957}
observation time 0.000064, current best 48.429649 at iter 0
suggestion time taken 0.002342 iter 1 next_points [{'alpha': 0.8798634607308321, 'batch_size': 104, 'beta_1': 0.527011778465501, 'beta_2': 0.9043046142448601, 'epsilon': 2.5698582784509263e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 4.360574132661966e-05, 'tol': 0.00013856820840011392, 'validation_fraction': 0.6171934679727721}]
function_evaluation time 0.077348 value 151.695194 suggestion {'alpha': 0.8798634607308321, 'batch_size': 104, 'beta_1': 0.527011778465501, 'beta_2': 0.9043046142448601, 'epsilon': 2.5698582784509263e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 4.360574132661966e-05, 'tol': 0.00013856820840011392, 'validation_fraction': 0.6171934679727721}
observation time 0.000072, current best 48.429649 at iter 1
suggestion time taken 0.002374 iter 2 next_points [{'alpha': 0.002803584949693244, 'batch_size': 164, 'beta_1': 0.8453771010049271, 'beta_2': 0.9742584278341024, 'epsilon': 4.607614723249266e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.005379060977582194, 'tol': 1.2179559506480138e-05, 'validation_fraction': 0.35078487519472007}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.113659 value 51.273276 suggestion {'alpha': 0.002803584949693244, 'batch_size': 164, 'beta_1': 0.8453771010049271, 'beta_2': 0.9742584278341024, 'epsilon': 4.607614723249266e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.005379060977582194, 'tol': 1.2179559506480138e-05, 'validation_fraction': 0.35078487519472007}
observation time 0.000083, current best 48.429649 at iter 2
suggestion time taken 0.002131 iter 3 next_points [{'alpha': 0.16561921748429856, 'batch_size': 101, 'beta_1': 0.5277633726844434, 'beta_2': 0.9712483068176501, 'epsilon': 1.9219538845911193e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 7.038184573018145e-05, 'tol': 0.008048932387168469, 'validation_fraction': 0.34386817979433154}]
function_evaluation time 0.075848 value 151.603195 suggestion {'alpha': 0.16561921748429856, 'batch_size': 101, 'beta_1': 0.5277633726844434, 'beta_2': 0.9712483068176501, 'epsilon': 1.9219538845911193e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 7.038184573018145e-05, 'tol': 0.008048932387168469, 'validation_fraction': 0.34386817979433154}
observation time 0.000071, current best 48.429649 at iter 3
suggestion time taken 0.002124 iter 4 next_points [{'alpha': 0.0008102639248592925, 'batch_size': 51, 'beta_1': 0.7346943870675329, 'beta_2': 0.953823195651457, 'epsilon': 8.621515213995132e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 4.5872990764221963e-05, 'tol': 0.0002860911054159662, 'validation_fraction': 0.43805219358581265}]
function_evaluation time 0.114294 value 151.532080 suggestion {'alpha': 0.0008102639248592925, 'batch_size': 51, 'beta_1': 0.7346943870675329, 'beta_2': 0.953823195651457, 'epsilon': 8.621515213995132e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 4.5872990764221963e-05, 'tol': 0.0002860911054159662, 'validation_fraction': 0.43805219358581265}
observation time 0.000061, current best 48.429649 at iter 4
suggestion time taken 0.002108 iter 5 next_points [{'alpha': 0.0728130659551462, 'batch_size': 247, 'beta_1': 0.7199513702017546, 'beta_2': 0.913521378524383, 'epsilon': 1.6019200983258052e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.0058778995364717895, 'tol': 0.006064171126039447, 'validation_fraction': 0.23148913556600753}]
function_evaluation time 0.341408 value 132.168439 suggestion {'alpha': 0.0728130659551462, 'batch_size': 247, 'beta_1': 0.7199513702017546, 'beta_2': 0.913521378524383, 'epsilon': 1.6019200983258052e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.0058778995364717895, 'tol': 0.006064171126039447, 'validation_fraction': 0.23148913556600753}
observation time 0.000077, current best 48.429649 at iter 5
suggestion time taken 0.002145 iter 6 next_points [{'alpha': 0.038774581189900556, 'batch_size': 12, 'beta_1': 0.7272210381819891, 'beta_2': 0.9521435035834553, 'epsilon': 2.6411410554354383e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.00019266835252285241, 'tol': 0.0006127982949249238, 'validation_fraction': 0.5981285736107648}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.407893 value 145.675403 suggestion {'alpha': 0.038774581189900556, 'batch_size': 12, 'beta_1': 0.7272210381819891, 'beta_2': 0.9521435035834553, 'epsilon': 2.6411410554354383e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.00019266835252285241, 'tol': 0.0006127982949249238, 'validation_fraction': 0.5981285736107648}
observation time 0.000070, current best 48.429649 at iter 6
suggestion time taken 0.002188 iter 7 next_points [{'alpha': 3.3898246419558595, 'batch_size': 41, 'beta_1': 0.848696595036169, 'beta_2': 0.9923948988358433, 'epsilon': 2.53306228390801e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.00024294086526886866, 'tol': 3.0053938253787277e-05, 'validation_fraction': 0.38177709544739663}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.150455 value 147.091876 suggestion {'alpha': 3.3898246419558595, 'batch_size': 41, 'beta_1': 0.848696595036169, 'beta_2': 0.9923948988358433, 'epsilon': 2.53306228390801e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.00024294086526886866, 'tol': 3.0053938253787277e-05, 'validation_fraction': 0.38177709544739663}
observation time 0.000079, current best 48.429649 at iter 7
suggestion time taken 0.002168 iter 8 next_points [{'alpha': 0.002349896732231693, 'batch_size': 203, 'beta_1': 0.9883693285553222, 'beta_2': 0.9965480466167699, 'epsilon': 3.068815678941898e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.013069389879849213, 'tol': 0.06703632043033826, 'validation_fraction': 0.13682905897486067}]
function_evaluation time 0.090518 value 143.592553 suggestion {'alpha': 0.002349896732231693, 'batch_size': 203, 'beta_1': 0.9883693285553222, 'beta_2': 0.9965480466167699, 'epsilon': 3.068815678941898e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.013069389879849213, 'tol': 0.06703632043033826, 'validation_fraction': 0.13682905897486067}
observation time 0.000075, current best 48.429649 at iter 8
suggestion time taken 0.002144 iter 9 next_points [{'alpha': 0.005328506347261726, 'batch_size': 247, 'beta_1': 0.5756967162294084, 'beta_2': 0.9806642620582902, 'epsilon': 1.2068052915429142e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.05728538163528177, 'tol': 4.05537024895906e-05, 'validation_fraction': 0.15325983956379138}]
function_evaluation time 0.375612 value 45.404798 suggestion {'alpha': 0.005328506347261726, 'batch_size': 247, 'beta_1': 0.5756967162294084, 'beta_2': 0.9806642620582902, 'epsilon': 1.2068052915429142e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.05728538163528177, 'tol': 4.05537024895906e-05, 'validation_fraction': 0.15325983956379138}
observation time 0.000075, current best 45.404798 at iter 9
suggestion time taken 0.002144 iter 10 next_points [{'alpha': 0.1363315403123427, 'batch_size': 65, 'beta_1': 0.5872229356373595, 'beta_2': 0.9480155614534305, 'epsilon': 1.6064282402553265e-09, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0004654419543099994, 'tol': 0.0016587557468646188, 'validation_fraction': 0.6777444405961233}]
function_evaluation time 0.077124 value 151.413070 suggestion {'alpha': 0.1363315403123427, 'batch_size': 65, 'beta_1': 0.5872229356373595, 'beta_2': 0.9480155614534305, 'epsilon': 1.6064282402553265e-09, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0004654419543099994, 'tol': 0.0016587557468646188, 'validation_fraction': 0.6777444405961233}
observation time 0.000079, current best 45.404798 at iter 10
suggestion time taken 0.002218 iter 11 next_points [{'alpha': 0.0004766043111318127, 'batch_size': 230, 'beta_1': 0.541428518806119, 'beta_2': 0.9971420353913177, 'epsilon': 5.101472979727641e-07, 'hidden_layer_sizes': 145, 'learning_rate_init': 1.889472502233066e-05, 'tol': 0.0011891283087787216, 'validation_fraction': 0.5511479306283364}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.060856 value 151.604457 suggestion {'alpha': 0.0004766043111318127, 'batch_size': 230, 'beta_1': 0.541428518806119, 'beta_2': 0.9971420353913177, 'epsilon': 5.101472979727641e-07, 'hidden_layer_sizes': 145, 'learning_rate_init': 1.889472502233066e-05, 'tol': 0.0011891283087787216, 'validation_fraction': 0.5511479306283364}
observation time 0.000074, current best 45.404798 at iter 11
suggestion time taken 0.002190 iter 12 next_points [{'alpha': 0.0017698957246315731, 'batch_size': 87, 'beta_1': 0.7046233640727466, 'beta_2': 0.9327755239475802, 'epsilon': 1.3528736111824286e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 4.635092249490637e-05, 'tol': 0.09566408475215996, 'validation_fraction': 0.21793100668830928}]
function_evaluation time 0.105246 value 151.579935 suggestion {'alpha': 0.0017698957246315731, 'batch_size': 87, 'beta_1': 0.7046233640727466, 'beta_2': 0.9327755239475802, 'epsilon': 1.3528736111824286e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 4.635092249490637e-05, 'tol': 0.09566408475215996, 'validation_fraction': 0.21793100668830928}
observation time 0.000080, current best 45.404798 at iter 12
suggestion time taken 0.002175 iter 13 next_points [{'alpha': 0.001071086389923024, 'batch_size': 151, 'beta_1': 0.7738081683734053, 'beta_2': 0.9271187699894532, 'epsilon': 6.341323965999604e-07, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.05497679940362247, 'tol': 0.0005048581815256543, 'validation_fraction': 0.6897337824354686}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.359546 value 46.271819 suggestion {'alpha': 0.001071086389923024, 'batch_size': 151, 'beta_1': 0.7738081683734053, 'beta_2': 0.9271187699894532, 'epsilon': 6.341323965999604e-07, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.05497679940362247, 'tol': 0.0005048581815256543, 'validation_fraction': 0.6897337824354686}
observation time 0.000075, current best 45.404798 at iter 13
suggestion time taken 0.002121 iter 14 next_points [{'alpha': 2.6488846570902655e-05, 'batch_size': 85, 'beta_1': 0.6640061809456275, 'beta_2': 0.9581836907606828, 'epsilon': 2.5395500836871524e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 7.514680189323511e-05, 'tol': 0.00010415089147031027, 'validation_fraction': 0.2192118432053565}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.582944 value 150.785718 suggestion {'alpha': 2.6488846570902655e-05, 'batch_size': 85, 'beta_1': 0.6640061809456275, 'beta_2': 0.9581836907606828, 'epsilon': 2.5395500836871524e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 7.514680189323511e-05, 'tol': 0.00010415089147031027, 'validation_fraction': 0.2192118432053565}
observation time 0.000077, current best 45.404798 at iter 14
saving meta data: {'args': {'--uuid': 'a280d3c936ea596299c70c34dc6b066d', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

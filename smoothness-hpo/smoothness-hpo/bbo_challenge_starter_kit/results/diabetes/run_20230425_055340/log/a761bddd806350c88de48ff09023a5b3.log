running: {'--uuid': 'a761bddd806350c88de48ff09023a5b3', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d diabetes -o random-search -u a761bddd806350c88de48ff09023a5b3 -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_055340
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study random-search MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002478 iter 0 next_points [{'alpha': 5.281895356423274, 'batch_size': 187, 'beta_1': 0.9748518041811287, 'beta_2': 0.999998741748314, 'epsilon': 1.897157713054429e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.00037715387454141446, 'tol': 1.0521433809415702e-05, 'validation_fraction': 0.8211484319017789}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.805075 value 28642.275449 suggestion {'alpha': 5.281895356423274, 'batch_size': 187, 'beta_1': 0.9748518041811287, 'beta_2': 0.999998741748314, 'epsilon': 1.897157713054429e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.00037715387454141446, 'tol': 1.0521433809415702e-05, 'validation_fraction': 0.8211484319017789}
observation time 0.000005, current best 28642.275449 at iter 0
suggestion time taken 0.002519 iter 1 next_points [{'alpha': 0.001510928132871682, 'batch_size': 209, 'beta_1': 0.9763445153352378, 'beta_2': 0.9992303793688609, 'epsilon': 2.701397892387734e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 1.2413544212926901e-05, 'tol': 0.001814047010857075, 'validation_fraction': 0.88739435632772}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.054094 value 29131.855396 suggestion {'alpha': 0.001510928132871682, 'batch_size': 209, 'beta_1': 0.9763445153352378, 'beta_2': 0.9992303793688609, 'epsilon': 2.701397892387734e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 1.2413544212926901e-05, 'tol': 0.001814047010857075, 'validation_fraction': 0.88739435632772}
observation time 0.000004, current best 28642.275449 at iter 1
suggestion time taken 0.002493 iter 2 next_points [{'alpha': 0.00828859954933354, 'batch_size': 25, 'beta_1': 0.5002487426926421, 'beta_2': 0.9867199585817971, 'epsilon': 1.5146723272805612e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 2.202584654504655e-05, 'tol': 0.0013106032584241126, 'validation_fraction': 0.30162609906532406}]
function_evaluation time 0.168618 value 29089.261580 suggestion {'alpha': 0.00828859954933354, 'batch_size': 25, 'beta_1': 0.5002487426926421, 'beta_2': 0.9867199585817971, 'epsilon': 1.5146723272805612e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 2.202584654504655e-05, 'tol': 0.0013106032584241126, 'validation_fraction': 0.30162609906532406}
observation time 0.000004, current best 28642.275449 at iter 2
suggestion time taken 0.002532 iter 3 next_points [{'alpha': 0.0024691773314558002, 'batch_size': 201, 'beta_1': 0.9716907600925869, 'beta_2': 0.9999672884708084, 'epsilon': 2.808218336098236e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.026525781552800564, 'tol': 0.0008445861346112364, 'validation_fraction': 0.808795658528072}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.268409 value 4231.301390 suggestion {'alpha': 0.0024691773314558002, 'batch_size': 201, 'beta_1': 0.9716907600925869, 'beta_2': 0.9999672884708084, 'epsilon': 2.808218336098236e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.026525781552800564, 'tol': 0.0008445861346112364, 'validation_fraction': 0.808795658528072}
observation time 0.000004, current best 4231.301390 at iter 3
suggestion time taken 0.002442 iter 4 next_points [{'alpha': 0.0017324394915009984, 'batch_size': 80, 'beta_1': 0.8831343454736059, 'beta_2': 0.9999987965122532, 'epsilon': 1.3044171186748573e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 1.7670298786771256e-05, 'tol': 0.003504908782489484, 'validation_fraction': 0.6386967061851941}]
function_evaluation time 0.059206 value 29039.376410 suggestion {'alpha': 0.0017324394915009984, 'batch_size': 80, 'beta_1': 0.8831343454736059, 'beta_2': 0.9999987965122532, 'epsilon': 1.3044171186748573e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 1.7670298786771256e-05, 'tol': 0.003504908782489484, 'validation_fraction': 0.6386967061851941}
observation time 0.000005, current best 4231.301390 at iter 4
suggestion time taken 0.002678 iter 5 next_points [{'alpha': 0.5092623953931447, 'batch_size': 188, 'beta_1': 0.811832475984345, 'beta_2': 0.9999908210385988, 'epsilon': 3.4698094038455923e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0001861396543988628, 'tol': 6.467204087645734e-05, 'validation_fraction': 0.2034666200112787}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.087271 value 28700.875930 suggestion {'alpha': 0.5092623953931447, 'batch_size': 188, 'beta_1': 0.811832475984345, 'beta_2': 0.9999908210385988, 'epsilon': 3.4698094038455923e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0001861396543988628, 'tol': 6.467204087645734e-05, 'validation_fraction': 0.2034666200112787}
observation time 0.000005, current best 4231.301390 at iter 5
suggestion time taken 0.002502 iter 6 next_points [{'alpha': 0.11725481877271748, 'batch_size': 160, 'beta_1': 0.9635366238471095, 'beta_2': 0.9999979396874105, 'epsilon': 6.2190694506051644e-09, 'hidden_layer_sizes': 183, 'learning_rate_init': 2.144370734374403e-05, 'tol': 0.008890028143275226, 'validation_fraction': 0.11509778144473767}]
function_evaluation time 0.094532 value 29165.888617 suggestion {'alpha': 0.11725481877271748, 'batch_size': 160, 'beta_1': 0.9635366238471095, 'beta_2': 0.9999979396874105, 'epsilon': 6.2190694506051644e-09, 'hidden_layer_sizes': 183, 'learning_rate_init': 2.144370734374403e-05, 'tol': 0.008890028143275226, 'validation_fraction': 0.11509778144473767}
observation time 0.000005, current best 4231.301390 at iter 6
suggestion time taken 0.002512 iter 7 next_points [{'alpha': 2.2823498102499267, 'batch_size': 234, 'beta_1': 0.9770247754854549, 'beta_2': 0.9810245531825115, 'epsilon': 3.2954938595533245e-09, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.00042019842700164443, 'tol': 0.010726855358433441, 'validation_fraction': 0.6600616648399164}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.060538 value 29060.993272 suggestion {'alpha': 2.2823498102499267, 'batch_size': 234, 'beta_1': 0.9770247754854549, 'beta_2': 0.9810245531825115, 'epsilon': 3.2954938595533245e-09, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.00042019842700164443, 'tol': 0.010726855358433441, 'validation_fraction': 0.6600616648399164}
observation time 0.000003, current best 4231.301390 at iter 7
suggestion time taken 0.002472 iter 8 next_points [{'alpha': 5.872707024172142e-05, 'batch_size': 137, 'beta_1': 0.9766671715439267, 'beta_2': 0.9999941463796129, 'epsilon': 6.293983377020802e-09, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.07879119736499306, 'tol': 0.03166343140079241, 'validation_fraction': 0.8242599144443521}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.126113 value 4417.401702 suggestion {'alpha': 5.872707024172142e-05, 'batch_size': 137, 'beta_1': 0.9766671715439267, 'beta_2': 0.9999941463796129, 'epsilon': 6.293983377020802e-09, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.07879119736499306, 'tol': 0.03166343140079241, 'validation_fraction': 0.8242599144443521}
observation time 0.000005, current best 4231.301390 at iter 8
suggestion time taken 0.002385 iter 9 next_points [{'alpha': 0.2315715134458197, 'batch_size': 40, 'beta_1': 0.9587914815646579, 'beta_2': 0.9992063881793927, 'epsilon': 1.203508017775544e-08, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0007900664769876405, 'tol': 0.06073348220215947, 'validation_fraction': 0.4289761187329493}]
function_evaluation time 0.119940 value 28838.316570 suggestion {'alpha': 0.2315715134458197, 'batch_size': 40, 'beta_1': 0.9587914815646579, 'beta_2': 0.9992063881793927, 'epsilon': 1.203508017775544e-08, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0007900664769876405, 'tol': 0.06073348220215947, 'validation_fraction': 0.4289761187329493}
observation time 0.000005, current best 4231.301390 at iter 9
suggestion time taken 0.002520 iter 10 next_points [{'alpha': 0.02554007152167849, 'batch_size': 235, 'beta_1': 0.7736563553130609, 'beta_2': 0.9999966478462914, 'epsilon': 3.49532259979562e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 2.6443062249296356e-05, 'tol': 0.00034087266505263594, 'validation_fraction': 0.15571164235862986}]
function_evaluation time 0.090451 value 29112.211612 suggestion {'alpha': 0.02554007152167849, 'batch_size': 235, 'beta_1': 0.7736563553130609, 'beta_2': 0.9999966478462914, 'epsilon': 3.49532259979562e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 2.6443062249296356e-05, 'tol': 0.00034087266505263594, 'validation_fraction': 0.15571164235862986}
observation time 0.000004, current best 4231.301390 at iter 10
suggestion time taken 0.002465 iter 11 next_points [{'alpha': 0.17106798305248097, 'batch_size': 206, 'beta_1': 0.6413475057793374, 'beta_2': 0.9864627471321117, 'epsilon': 1.0519819584040124e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.0009490951056216229, 'tol': 0.05475079005651845, 'validation_fraction': 0.2608309014852951}]
function_evaluation time 0.059638 value 29026.389112 suggestion {'alpha': 0.17106798305248097, 'batch_size': 206, 'beta_1': 0.6413475057793374, 'beta_2': 0.9864627471321117, 'epsilon': 1.0519819584040124e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.0009490951056216229, 'tol': 0.05475079005651845, 'validation_fraction': 0.2608309014852951}
observation time 0.000004, current best 4231.301390 at iter 11
suggestion time taken 0.002468 iter 12 next_points [{'alpha': 3.7420389409445544e-05, 'batch_size': 240, 'beta_1': 0.9802691807943729, 'beta_2': 0.998285949795257, 'epsilon': 1.9477746745302983e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0017735496817428114, 'tol': 4.4585894437012425e-05, 'validation_fraction': 0.40419552011938986}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.784914 value 26100.766550 suggestion {'alpha': 3.7420389409445544e-05, 'batch_size': 240, 'beta_1': 0.9802691807943729, 'beta_2': 0.998285949795257, 'epsilon': 1.9477746745302983e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0017735496817428114, 'tol': 4.4585894437012425e-05, 'validation_fraction': 0.40419552011938986}
observation time 0.000004, current best 4231.301390 at iter 12
suggestion time taken 0.002529 iter 13 next_points [{'alpha': 1.6399090872208437, 'batch_size': 88, 'beta_1': 0.6755823582196694, 'beta_2': 0.9988950306717371, 'epsilon': 3.0813540120654115e-09, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0003605685567032051, 'tol': 0.06445316066182834, 'validation_fraction': 0.6290826071424362}]
function_evaluation time 0.075678 value 29092.988763 suggestion {'alpha': 1.6399090872208437, 'batch_size': 88, 'beta_1': 0.6755823582196694, 'beta_2': 0.9988950306717371, 'epsilon': 3.0813540120654115e-09, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0003605685567032051, 'tol': 0.06445316066182834, 'validation_fraction': 0.6290826071424362}
observation time 0.000004, current best 4231.301390 at iter 13
suggestion time taken 0.002473 iter 14 next_points [{'alpha': 0.0002602065541684868, 'batch_size': 51, 'beta_1': 0.8743595571891065, 'beta_2': 0.9960266845391278, 'epsilon': 1.1475592195364217e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.0009477646715487567, 'tol': 1.9462324959399156e-05, 'validation_fraction': 0.8968301411381169}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.587291 value 28207.174146 suggestion {'alpha': 0.0002602065541684868, 'batch_size': 51, 'beta_1': 0.8743595571891065, 'beta_2': 0.9960266845391278, 'epsilon': 1.1475592195364217e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.0009477646715487567, 'tol': 1.9462324959399156e-05, 'validation_fraction': 0.8968301411381169}
observation time 0.000004, current best 4231.301390 at iter 14
saving meta data: {'args': {'--uuid': 'a761bddd806350c88de48ff09023a5b3', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

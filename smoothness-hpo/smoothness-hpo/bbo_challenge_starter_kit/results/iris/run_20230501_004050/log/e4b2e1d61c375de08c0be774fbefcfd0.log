running: {'--uuid': 'e4b2e1d61c375de08c0be774fbefcfd0', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230501_004050', '--opt': 'smoothness', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d iris -o smoothness -u e4b2e1d61c375de08c0be774fbefcfd0 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230501_004050
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [1.3105719841770722, 1.7760947732249062, 1.4322107566090756, 0.9097804858215804, 0.5745987066718419])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_iris_nll betwen [1.31057198 1.56976556 1.25224472 0.90978049 0.39813052] and [1.32439241 1.77609477 1.43221076 0.9966468  0.57459871]
  warnings.warn(

Signature errors:
                         0         1         2         3         4       max
MLP-adam_iris_nll  0.01382  0.206329  0.179966  0.086866  0.176468  0.206329
max                0.01382  0.206329  0.179966  0.086866  0.176468  0.206329
starting sklearn study smoothness MLP-adam iris nll 15 1
with data root: None
suggestion time taken 9.411217 iter 0 next_points [{'alpha': 3.5987798880308577, 'batch_size': 17, 'beta_1': 0.9735643000646217, 'beta_2': 0.997912689608625, 'epsilon': 1.0744911269360682e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 1.8433301392325896e-05, 'tol': 0.00210636270315804, 'validation_fraction': 0.7961383169143871}]
function_evaluation time 0.054644 value 1.477351 suggestion {'alpha': 3.5987798880308577, 'batch_size': 17, 'beta_1': 0.9735643000646217, 'beta_2': 0.997912689608625, 'epsilon': 1.0744911269360682e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 1.8433301392325896e-05, 'tol': 0.00210636270315804, 'validation_fraction': 0.7961383169143871}
observation time 0.000007, current best 1.477351 at iter 0
suggestion time taken 9.243774 iter 1 next_points [{'alpha': 7.4104984801009115, 'batch_size': 51, 'beta_1': 0.966631486071528, 'beta_2': 0.9955946138537096, 'epsilon': 1.2483207847098629e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.00015010920174473897, 'tol': 0.09663435999147227, 'validation_fraction': 0.7180505786495553}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.043508 value 1.354459 suggestion {'alpha': 7.4104984801009115, 'batch_size': 51, 'beta_1': 0.966631486071528, 'beta_2': 0.9955946138537096, 'epsilon': 1.2483207847098629e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.00015010920174473897, 'tol': 0.09663435999147227, 'validation_fraction': 0.7180505786495553}
observation time 0.000008, current best 1.354459 at iter 1
suggestion time taken 9.325602 iter 2 next_points [{'alpha': 6.620530301770103e-05, 'batch_size': 27, 'beta_1': 0.5697548677744763, 'beta_2': 0.9840490910270873, 'epsilon': 1.5213047129928966e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.90718248329251e-05, 'tol': 2.691557624807808e-05, 'validation_fraction': 0.8207383266543746}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.042906 value 1.676706 suggestion {'alpha': 6.620530301770103e-05, 'batch_size': 27, 'beta_1': 0.5697548677744763, 'beta_2': 0.9840490910270873, 'epsilon': 1.5213047129928966e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.90718248329251e-05, 'tol': 2.691557624807808e-05, 'validation_fraction': 0.8207383266543746}
observation time 0.000007, current best 1.354459 at iter 2
suggestion time taken 9.581615 iter 3 next_points [{'alpha': 0.0009714296719486138, 'batch_size': 46, 'beta_1': 0.9553768768714027, 'beta_2': 0.9766634816286973, 'epsilon': 7.1236335582011984e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0002907641531468305, 'tol': 0.04119873723908889, 'validation_fraction': 0.8616376636515821}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.046680 value 1.320115 suggestion {'alpha': 0.0009714296719486138, 'batch_size': 46, 'beta_1': 0.9553768768714027, 'beta_2': 0.9766634816286973, 'epsilon': 7.1236335582011984e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0002907641531468305, 'tol': 0.04119873723908889, 'validation_fraction': 0.8616376636515821}
observation time 0.000006, current best 1.320115 at iter 3
suggestion time taken 9.500392 iter 4 next_points [{'alpha': 0.03074814003513623, 'batch_size': 23, 'beta_1': 0.8362543174050291, 'beta_2': 0.9965158779985355, 'epsilon': 1.7214031123385697e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.0009149686378434277, 'tol': 0.049971454494973686, 'validation_fraction': 0.5355760009127875}]
function_evaluation time 0.065622 value 1.299512 suggestion {'alpha': 0.03074814003513623, 'batch_size': 23, 'beta_1': 0.8362543174050291, 'beta_2': 0.9965158779985355, 'epsilon': 1.7214031123385697e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.0009149686378434277, 'tol': 0.049971454494973686, 'validation_fraction': 0.5355760009127875}
observation time 0.000006, current best 1.299512 at iter 4
suggestion time taken 9.492990 iter 5 next_points [{'alpha': 0.1501886570952479, 'batch_size': 21, 'beta_1': 0.9755223872778557, 'beta_2': 0.9999633321341704, 'epsilon': 1.5100824600180552e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.004748821939946285, 'tol': 0.0011550930186191948, 'validation_fraction': 0.34453042135202705}]
function_evaluation time 0.113772 value 0.491372 suggestion {'alpha': 0.1501886570952479, 'batch_size': 21, 'beta_1': 0.9755223872778557, 'beta_2': 0.9999633321341704, 'epsilon': 1.5100824600180552e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.004748821939946285, 'tol': 0.0011550930186191948, 'validation_fraction': 0.34453042135202705}
observation time 0.000006, current best 0.491372 at iter 5
suggestion time taken 9.500323 iter 6 next_points [{'alpha': 0.000860086382017618, 'batch_size': 39, 'beta_1': 0.9892694232180561, 'beta_2': 0.9888528878359588, 'epsilon': 3.9553823462054386e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.0005660772342877388, 'tol': 0.0005265014022379237, 'validation_fraction': 0.432788671138277}]
function_evaluation time 0.075459 value 1.281917 suggestion {'alpha': 0.000860086382017618, 'batch_size': 39, 'beta_1': 0.9892694232180561, 'beta_2': 0.9888528878359588, 'epsilon': 3.9553823462054386e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.0005660772342877388, 'tol': 0.0005265014022379237, 'validation_fraction': 0.432788671138277}
observation time 0.000005, current best 0.491372 at iter 6
suggestion time taken 9.483541 iter 7 next_points [{'alpha': 0.035561338315073444, 'batch_size': 45, 'beta_1': 0.972082038711244, 'beta_2': 0.9990088102540964, 'epsilon': 2.3361465879389206e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0014614295540159338, 'tol': 4.0299398511443776e-05, 'validation_fraction': 0.5613513377942534}]
function_evaluation time 0.059417 value 1.159968 suggestion {'alpha': 0.035561338315073444, 'batch_size': 45, 'beta_1': 0.972082038711244, 'beta_2': 0.9990088102540964, 'epsilon': 2.3361465879389206e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0014614295540159338, 'tol': 4.0299398511443776e-05, 'validation_fraction': 0.5613513377942534}
observation time 0.000005, current best 0.491372 at iter 7
suggestion time taken 9.525182 iter 8 next_points [{'alpha': 0.017035385224368833, 'batch_size': 17, 'beta_1': 0.7245620005708883, 'beta_2': 0.9999988490812951, 'epsilon': 1.1812364436754993e-08, 'hidden_layer_sizes': 191, 'learning_rate_init': 2.7583766646951143e-05, 'tol': 0.0004027228175275938, 'validation_fraction': 0.821627785453509}]
function_evaluation time 0.049625 value 1.201220 suggestion {'alpha': 0.017035385224368833, 'batch_size': 17, 'beta_1': 0.7245620005708883, 'beta_2': 0.9999988490812951, 'epsilon': 1.1812364436754993e-08, 'hidden_layer_sizes': 191, 'learning_rate_init': 2.7583766646951143e-05, 'tol': 0.0004027228175275938, 'validation_fraction': 0.821627785453509}
observation time 0.000006, current best 0.491372 at iter 8
suggestion time taken 9.534761 iter 9 next_points [{'alpha': 0.0004521480484966912, 'batch_size': 29, 'beta_1': 0.563034232846885, 'beta_2': 0.9999601025119669, 'epsilon': 1.6905592809265305e-08, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.008446540753392682, 'tol': 0.00021185874726016286, 'validation_fraction': 0.8209056110494529}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.092829 value 0.431150 suggestion {'alpha': 0.0004521480484966912, 'batch_size': 29, 'beta_1': 0.563034232846885, 'beta_2': 0.9999601025119669, 'epsilon': 1.6905592809265305e-08, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.008446540753392682, 'tol': 0.00021185874726016286, 'validation_fraction': 0.8209056110494529}
observation time 0.000006, current best 0.431150 at iter 9
suggestion time taken 9.607296 iter 10 next_points [{'alpha': 4.325710502647192, 'batch_size': 27, 'beta_1': 0.97641919737209, 'beta_2': 0.9999895521724032, 'epsilon': 1.992259762301769e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.023175095188470007, 'tol': 0.0004721524619033303, 'validation_fraction': 0.2800411690705317}]
function_evaluation time 0.096106 value 0.492748 suggestion {'alpha': 4.325710502647192, 'batch_size': 27, 'beta_1': 0.97641919737209, 'beta_2': 0.9999895521724032, 'epsilon': 1.992259762301769e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.023175095188470007, 'tol': 0.0004721524619033303, 'validation_fraction': 0.2800411690705317}
observation time 0.000006, current best 0.431150 at iter 10
suggestion time taken 9.538403 iter 11 next_points [{'alpha': 0.002407331141981528, 'batch_size': 15, 'beta_1': 0.9628638361758348, 'beta_2': 0.9943373366915284, 'epsilon': 1.62923171353524e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.011758407645762714, 'tol': 1.4131346333473199e-05, 'validation_fraction': 0.8788688046541034}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.078147 value 0.863243 suggestion {'alpha': 0.002407331141981528, 'batch_size': 15, 'beta_1': 0.9628638361758348, 'beta_2': 0.9943373366915284, 'epsilon': 1.62923171353524e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.011758407645762714, 'tol': 1.4131346333473199e-05, 'validation_fraction': 0.8788688046541034}
observation time 0.000006, current best 0.431150 at iter 11
suggestion time taken 9.580544 iter 12 next_points [{'alpha': 0.001010866379880339, 'batch_size': 21, 'beta_1': 0.98899259448459, 'beta_2': 0.9999936014017783, 'epsilon': 1.4534633946910807e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 1.315232600175576e-05, 'tol': 0.000720379035615759, 'validation_fraction': 0.7991232836873315}]
function_evaluation time 0.043486 value 1.478023 suggestion {'alpha': 0.001010866379880339, 'batch_size': 21, 'beta_1': 0.98899259448459, 'beta_2': 0.9999936014017783, 'epsilon': 1.4534633946910807e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 1.315232600175576e-05, 'tol': 0.000720379035615759, 'validation_fraction': 0.7991232836873315}
observation time 0.000006, current best 0.431150 at iter 12
suggestion time taken 9.568579 iter 13 next_points [{'alpha': 0.0007196883918837093, 'batch_size': 24, 'beta_1': 0.7609865655945725, 'beta_2': 0.9812116099413455, 'epsilon': 1.280890112405345e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.002276013605128616, 'tol': 0.004828150435900204, 'validation_fraction': 0.8328240225688067}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.063660 value 1.021802 suggestion {'alpha': 0.0007196883918837093, 'batch_size': 24, 'beta_1': 0.7609865655945725, 'beta_2': 0.9812116099413455, 'epsilon': 1.280890112405345e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.002276013605128616, 'tol': 0.004828150435900204, 'validation_fraction': 0.8328240225688067}
observation time 0.000006, current best 0.431150 at iter 13
suggestion time taken 9.706120 iter 14 next_points [{'alpha': 0.11829844449994222, 'batch_size': 24, 'beta_1': 0.8624040015973052, 'beta_2': 0.9996758900368223, 'epsilon': 1.4279748004013917e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.02770508726012305, 'tol': 0.009750381217838873, 'validation_fraction': 0.5436641975671527}]
function_evaluation time 0.094574 value 0.292652 suggestion {'alpha': 0.11829844449994222, 'batch_size': 24, 'beta_1': 0.8624040015973052, 'beta_2': 0.9996758900368223, 'epsilon': 1.4279748004013917e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.02770508726012305, 'tol': 0.009750381217838873, 'validation_fraction': 0.5436641975671527}
observation time 0.000006, current best 0.292652 at iter 14
saving meta data: {'args': {'--uuid': 'e4b2e1d61c375de08c0be774fbefcfd0', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230501_004050', '--opt': 'smoothness', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [1.3105719841770722, 1.7760947732249062, 1.4322107566090756, 0.9097804858215804, 0.5745987066718419])}
saving results
saving timing
saving suggest log
done

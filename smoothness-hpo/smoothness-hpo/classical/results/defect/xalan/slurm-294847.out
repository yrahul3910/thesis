2023-03-25 22:49:24.143005: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
2023-03-25 22:49:30.247775: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-25 22:49:30.333349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-03-25 22:49:31.053847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.65GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2023-03-25 22:49:31.053918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 22:49:31.213642: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 22:49:31.213729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-25 22:49:31.280337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-25 22:49:31.318056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-25 22:49:31.466370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-03-25 22:49:31.523332: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-25 22:49:31.546036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-25 22:49:31.559534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-03-25 22:49:31.560082: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-25 22:49:31.562161: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-25 22:49:31.562538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.65GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2023-03-25 22:49:31.562559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 22:49:31.562572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 22:49:31.562583: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-25 22:49:31.562594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-25 22:49:31.562604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-25 22:49:31.562615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-03-25 22:49:31.562625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-25 22:49:31.562635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-25 22:49:31.562943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-03-25 22:49:31.577671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 22:49:34.534816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-03-25 22:49:34.535166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2023-03-25 22:49:34.535184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2023-03-25 22:49:34.550126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7281 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:41:00.0, compute capability: 7.5)
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
2023-03-25 22:49:35.074886: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-03-25 22:49:35.114399: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2994420000 Hz
Epoch 1/500
2023-03-25 22:49:35.691109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 22:49:38.309183: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
 1/23 [>.............................] - ETA: 1:13 - loss: 0.102022/23 [===========================>..] - ETA: 0s - loss: 0.1072  23/23 [==============================] - 3s 2ms/step - loss: 0.1071
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.101923/23 [==============================] - 0s 2ms/step - loss: 0.0965
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.088723/23 [==============================] - 0s 2ms/step - loss: 0.0846
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.073623/23 [==============================] - 0s 2ms/step - loss: 0.0741
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.070023/23 [==============================] - 0s 2ms/step - loss: 0.0689
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.067623/23 [==============================] - 0s 2ms/step - loss: 0.0657
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.062723/23 [==============================] - 0s 2ms/step - loss: 0.0603
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.056423/23 [==============================] - 0s 2ms/step - loss: 0.0566
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.054923/23 [==============================] - 0s 2ms/step - loss: 0.0538
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.051023/23 [==============================] - 0s 2ms/step - loss: 0.0502
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046323/23 [==============================] - 0s 2ms/step - loss: 0.0406
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.037123/23 [==============================] - 0s 2ms/step - loss: 0.0360
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031623/23 [==============================] - 0s 2ms/step - loss: 0.0342
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034323/23 [==============================] - 0s 2ms/step - loss: 0.0336
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033123/23 [==============================] - 0s 2ms/step - loss: 0.0328
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031623/23 [==============================] - 0s 2ms/step - loss: 0.0315
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.035323/23 [==============================] - 0s 2ms/step - loss: 0.0320
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031123/23 [==============================] - 0s 2ms/step - loss: 0.0310
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025223/23 [==============================] - 0s 2ms/step - loss: 0.0301
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030623/23 [==============================] - 0s 2ms/step - loss: 0.0307
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031023/23 [==============================] - 0s 2ms/step - loss: 0.0309
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029123/23 [==============================] - 0s 2ms/step - loss: 0.0305
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031423/23 [==============================] - 0s 2ms/step - loss: 0.0301
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030323/23 [==============================] - 0s 2ms/step - loss: 0.0299
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031223/23 [==============================] - 0s 2ms/step - loss: 0.0304
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.028323/23 [==============================] - 0s 2ms/step - loss: 0.0299
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030623/23 [==============================] - 0s 2ms/step - loss: 0.0298
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027623/23 [==============================] - 0s 2ms/step - loss: 0.0292
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025223/23 [==============================] - 0s 2ms/step - loss: 0.0291
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030923/23 [==============================] - 0s 2ms/step - loss: 0.0298
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029723/23 [==============================] - 0s 2ms/step - loss: 0.0287
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030623/23 [==============================] - 0s 2ms/step - loss: 0.0294
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030223/23 [==============================] - 0s 2ms/step - loss: 0.0291
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027823/23 [==============================] - 0s 2ms/step - loss: 0.0281
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029823/23 [==============================] - 0s 2ms/step - loss: 0.0282
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026123/23 [==============================] - 0s 2ms/step - loss: 0.0279
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027023/23 [==============================] - 0s 2ms/step - loss: 0.0282
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.028423/23 [==============================] - 0s 2ms/step - loss: 0.0282
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031523/23 [==============================] - 0s 2ms/step - loss: 0.0281
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027923/23 [==============================] - 0s 2ms/step - loss: 0.0279
Epoch 41/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026323/23 [==============================] - 0s 2ms/step - loss: 0.0274
Epoch 42/500
 1/23 [>.............................] - ETA: 0s - loss: 0.028423/23 [==============================] - 0s 2ms/step - loss: 0.0274
Epoch 43/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027123/23 [==============================] - 0s 2ms/step - loss: 0.0273
Epoch 44/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030823/23 [==============================] - 0s 2ms/step - loss: 0.0277
Epoch 45/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027423/23 [==============================] - 0s 2ms/step - loss: 0.0274
Epoch 46/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025823/23 [==============================] - 0s 2ms/step - loss: 0.0275
Epoch 47/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025923/23 [==============================] - 0s 2ms/step - loss: 0.0268
Epoch 48/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025123/23 [==============================] - 0s 2ms/step - loss: 0.0271
Epoch 49/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025023/23 [==============================] - 0s 2ms/step - loss: 0.0269
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 6s - loss: 0.052823/23 [==============================] - 0s 2ms/step - loss: 0.0519
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.048223/23 [==============================] - 0s 2ms/step - loss: 0.0465
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040523/23 [==============================] - 0s 2ms/step - loss: 0.0376
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029523/23 [==============================] - 0s 2ms/step - loss: 0.0261
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016823/23 [==============================] - 0s 2ms/step - loss: 0.0151
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.011323/23 [==============================] - 0s 2ms/step - loss: 0.0103
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009423/23 [==============================] - 0s 2ms/step - loss: 0.0094
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009123/23 [==============================] - 0s 2ms/step - loss: 0.0091
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009823/23 [==============================] - 0s 2ms/step - loss: 0.0091
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009823/23 [==============================] - 0s 2ms/step - loss: 0.0084
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009023/23 [==============================] - 0s 2ms/step - loss: 0.0078
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006723/23 [==============================] - 0s 2ms/step - loss: 0.0073
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006523/23 [==============================] - 0s 2ms/step - loss: 0.0072
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.008723/23 [==============================] - 0s 2ms/step - loss: 0.0074
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.005123/23 [==============================] - 0s 2ms/step - loss: 0.0069
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.008623/23 [==============================] - 0s 2ms/step - loss: 0.0073
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006423/23 [==============================] - 0s 2ms/step - loss: 0.0070
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006723/23 [==============================] - 0s 2ms/step - loss: 0.0070
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006423/23 [==============================] - 0s 2ms/step - loss: 0.0071
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006223/23 [==============================] - 0s 2ms/step - loss: 0.0069
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007423/23 [==============================] - 0s 2ms/step - loss: 0.0071
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 5s - loss: 0.106723/23 [==============================] - 0s 2ms/step - loss: 0.1014
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.088423/23 [==============================] - 0s 2ms/step - loss: 0.0875
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.079123/23 [==============================] - 0s 2ms/step - loss: 0.0780
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.071523/23 [==============================] - 0s 2ms/step - loss: 0.0730
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.069923/23 [==============================] - 0s 2ms/step - loss: 0.0673
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.068323/23 [==============================] - 0s 2ms/step - loss: 0.0594
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.057923/23 [==============================] - 0s 2ms/step - loss: 0.0544
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.054923/23 [==============================] - 0s 2ms/step - loss: 0.0530
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.048523/23 [==============================] - 0s 2ms/step - loss: 0.0506
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.050223/23 [==============================] - 0s 2ms/step - loss: 0.0492
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.048623/23 [==============================] - 0s 2ms/step - loss: 0.0494
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045723/23 [==============================] - 0s 2ms/step - loss: 0.0468
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.050423/23 [==============================] - 0s 2ms/step - loss: 0.0464
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046023/23 [==============================] - 0s 2ms/step - loss: 0.0450
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.043323/23 [==============================] - 0s 2ms/step - loss: 0.0434
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041823/23 [==============================] - 0s 2ms/step - loss: 0.0428
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041623/23 [==============================] - 0s 2ms/step - loss: 0.0420
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039423/23 [==============================] - 0s 2ms/step - loss: 0.0405
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040323/23 [==============================] - 0s 2ms/step - loss: 0.0398
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036723/23 [==============================] - 0s 2ms/step - loss: 0.0370
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033923/23 [==============================] - 0s 2ms/step - loss: 0.0365
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.035723/23 [==============================] - 0s 2ms/step - loss: 0.0355
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033223/23 [==============================] - 0s 2ms/step - loss: 0.0346
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029923/23 [==============================] - 0s 2ms/step - loss: 0.0337
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034623/23 [==============================] - 0s 2ms/step - loss: 0.0329
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034623/23 [==============================] - 0s 2ms/step - loss: 0.0334
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036223/23 [==============================] - 0s 2ms/step - loss: 0.0336
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.035123/23 [==============================] - 0s 2ms/step - loss: 0.0331
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033523/23 [==============================] - 0s 2ms/step - loss: 0.0322
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.032723/23 [==============================] - 0s 2ms/step - loss: 0.0319
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027823/23 [==============================] - 0s 2ms/step - loss: 0.0317
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030223/23 [==============================] - 0s 2ms/step - loss: 0.0314
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.032923/23 [==============================] - 0s 2ms/step - loss: 0.0314
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031923/23 [==============================] - 0s 2ms/step - loss: 0.0307
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030723/23 [==============================] - 0s 2ms/step - loss: 0.0309
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031523/23 [==============================] - 0s 2ms/step - loss: 0.0308
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029623/23 [==============================] - 0s 2ms/step - loss: 0.0308
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.028423/23 [==============================] - 0s 2ms/step - loss: 0.0297
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029923/23 [==============================] - 0s 2ms/step - loss: 0.0300
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031423/23 [==============================] - 0s 2ms/step - loss: 0.0305
Epoch 41/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025523/23 [==============================] - 0s 2ms/step - loss: 0.0292
Epoch 42/500
 1/23 [>.............................] - ETA: 0s - loss: 0.028923/23 [==============================] - 0s 2ms/step - loss: 0.0290
Epoch 43/500
 1/23 [>.............................] - ETA: 0s - loss: 0.028623/23 [==============================] - 0s 2ms/step - loss: 0.0281
Epoch 44/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026123/23 [==============================] - 0s 2ms/step - loss: 0.0272
Epoch 45/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027623/23 [==============================] - 0s 2ms/step - loss: 0.0278
Epoch 46/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025823/23 [==============================] - 0s 2ms/step - loss: 0.0273
Epoch 47/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029223/23 [==============================] - 0s 2ms/step - loss: 0.0272
Epoch 48/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024323/23 [==============================] - 0s 2ms/step - loss: 0.0267
Epoch 49/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027223/23 [==============================] - 0s 2ms/step - loss: 0.0271
Epoch 50/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029123/23 [==============================] - 0s 2ms/step - loss: 0.0267
Epoch 51/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024123/23 [==============================] - 0s 2ms/step - loss: 0.0269
Epoch 52/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027623/23 [==============================] - 0s 2ms/step - loss: 0.0265
Epoch 53/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025523/23 [==============================] - 0s 2ms/step - loss: 0.0265
Epoch 54/500
 1/23 [>.............................] - ETA: 0s - loss: 0.028723/23 [==============================] - 0s 2ms/step - loss: 0.0264
Epoch 55/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027223/23 [==============================] - 0s 2ms/step - loss: 0.0261
Epoch 56/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024923/23 [==============================] - 0s 2ms/step - loss: 0.0264
Epoch 57/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024123/23 [==============================] - 0s 2ms/step - loss: 0.0261
Epoch 58/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027823/23 [==============================] - 0s 2ms/step - loss: 0.0265
Epoch 59/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024723/23 [==============================] - 0s 2ms/step - loss: 0.0258
Epoch 60/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027623/23 [==============================] - 0s 2ms/step - loss: 0.0264
Epoch 61/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025823/23 [==============================] - 0s 2ms/step - loss: 0.0259
Epoch 62/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026923/23 [==============================] - 0s 2ms/step - loss: 0.0259
Epoch 63/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027823/23 [==============================] - 0s 2ms/step - loss: 0.0262
Epoch 64/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025923/23 [==============================] - 0s 2ms/step - loss: 0.0261
Epoch 65/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024723/23 [==============================] - 0s 2ms/step - loss: 0.0258
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running wfo
[get_model] Finished running wfo
Beta: -216908919.9155547  | Score: 0.0
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 5s - loss: 0.107123/23 [==============================] - 0s 2ms/step - loss: 0.1034
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.095423/23 [==============================] - 0s 2ms/step - loss: 0.0871
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.079323/23 [==============================] - 0s 2ms/step - loss: 0.0748
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.075423/23 [==============================] - 0s 2ms/step - loss: 0.0676
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.068423/23 [==============================] - 0s 2ms/step - loss: 0.0646
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.059523/23 [==============================] - 0s 2ms/step - loss: 0.0610
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.059823/23 [==============================] - 0s 2ms/step - loss: 0.0613
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.067323/23 [==============================] - 0s 2ms/step - loss: 0.0619
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.060323/23 [==============================] - 0s 2ms/step - loss: 0.0605
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.057023/23 [==============================] - 0s 2ms/step - loss: 0.0605
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.057723/23 [==============================] - 0s 2ms/step - loss: 0.0603
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.056723/23 [==============================] - 0s 2ms/step - loss: 0.0600
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.056923/23 [==============================] - 0s 2ms/step - loss: 0.0596
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.059323/23 [==============================] - 0s 2ms/step - loss: 0.0597
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.059323/23 [==============================] - 0s 2ms/step - loss: 0.0592
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.057123/23 [==============================] - 0s 2ms/step - loss: 0.0594
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.061023/23 [==============================] - 0s 2ms/step - loss: 0.0589
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.058723/23 [==============================] - 0s 2ms/step - loss: 0.0579
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.061323/23 [==============================] - 0s 2ms/step - loss: 0.0575
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.053523/23 [==============================] - 0s 2ms/step - loss: 0.0554
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.059423/23 [==============================] - 0s 2ms/step - loss: 0.0545
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045723/23 [==============================] - 0s 2ms/step - loss: 0.0520
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045823/23 [==============================] - 0s 2ms/step - loss: 0.0510
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.055123/23 [==============================] - 0s 2ms/step - loss: 0.0511
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.049923/23 [==============================] - 0s 2ms/step - loss: 0.0493
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046223/23 [==============================] - 0s 2ms/step - loss: 0.0462
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045923/23 [==============================] - 0s 2ms/step - loss: 0.0462
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.049823/23 [==============================] - 0s 2ms/step - loss: 0.0454
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046623/23 [==============================] - 0s 2ms/step - loss: 0.0441
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.047623/23 [==============================] - 0s 2ms/step - loss: 0.0436
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044123/23 [==============================] - 0s 2ms/step - loss: 0.0424
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039223/23 [==============================] - 0s 2ms/step - loss: 0.0410
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040023/23 [==============================] - 0s 2ms/step - loss: 0.0400
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038823/23 [==============================] - 0s 2ms/step - loss: 0.0392
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033323/23 [==============================] - 0s 2ms/step - loss: 0.0383
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036223/23 [==============================] - 0s 2ms/step - loss: 0.0380
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038123/23 [==============================] - 0s 2ms/step - loss: 0.0382
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036523/23 [==============================] - 0s 2ms/step - loss: 0.0372
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036023/23 [==============================] - 0s 2ms/step - loss: 0.0342
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029723/23 [==============================] - 0s 2ms/step - loss: 0.0260
Epoch 41/500
 1/23 [>.............................] - ETA: 0s - loss: 0.023123/23 [==============================] - 0s 2ms/step - loss: 0.0218
Epoch 42/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018623/23 [==============================] - 0s 2ms/step - loss: 0.0193
Epoch 43/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019423/23 [==============================] - 0s 2ms/step - loss: 0.0179
Epoch 44/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017223/23 [==============================] - 0s 2ms/step - loss: 0.0171
Epoch 45/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015123/23 [==============================] - 0s 2ms/step - loss: 0.0167
Epoch 46/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015223/23 [==============================] - 0s 2ms/step - loss: 0.0161
Epoch 47/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015423/23 [==============================] - 0s 2ms/step - loss: 0.0160
Epoch 48/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014423/23 [==============================] - 0s 2ms/step - loss: 0.0156
Epoch 49/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014323/23 [==============================] - 0s 2ms/step - loss: 0.0152
Epoch 50/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014223/23 [==============================] - 0s 2ms/step - loss: 0.0150
Epoch 51/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018023/23 [==============================] - 0s 2ms/step - loss: 0.0155
Epoch 52/500
 1/23 [>.............................] - ETA: 0s - loss: 0.012723/23 [==============================] - 0s 2ms/step - loss: 0.0147
Epoch 53/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017123/23 [==============================] - 0s 2ms/step - loss: 0.0154
Epoch 54/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015723/23 [==============================] - 0s 2ms/step - loss: 0.0144
Epoch 55/500
 1/23 [>.............................] - ETA: 0s - loss: 0.013523/23 [==============================] - 0s 2ms/step - loss: 0.0145
Epoch 56/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014523/23 [==============================] - 0s 2ms/step - loss: 0.0146
Epoch 57/500
 1/23 [>.............................] - ETA: 0s - loss: 0.013923/23 [==============================] - 0s 2ms/step - loss: 0.0145
Epoch 58/500
 1/23 [>.............................] - ETA: 0s - loss: 0.013623/23 [==============================] - 0s 2ms/step - loss: 0.0143
Epoch 59/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015123/23 [==============================] - 0s 2ms/step - loss: 0.0146
Epoch 60/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014223/23 [==============================] - 0s 2ms/step - loss: 0.0141
Epoch 61/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014123/23 [==============================] - 0s 2ms/step - loss: 0.0140
Epoch 62/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015123/23 [==============================] - 0s 2ms/step - loss: 0.0138
Epoch 63/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014623/23 [==============================] - 0s 2ms/step - loss: 0.0141
Epoch 64/500
 1/23 [>.............................] - ETA: 0s - loss: 0.013423/23 [==============================] - 0s 2ms/step - loss: 0.0137
Epoch 65/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015723/23 [==============================] - 0s 2ms/step - loss: 0.0136
Epoch 66/500
 1/23 [>.............................] - ETA: 0s - loss: 0.013623/23 [==============================] - 0s 2ms/step - loss: 0.0134
Epoch 67/500
 1/23 [>.............................] - ETA: 0s - loss: 0.013923/23 [==============================] - 0s 2ms/step - loss: 0.0137
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
Beta: -68165631094.22639  | Score: 0.0
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_9 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 5s - loss: 0.096923/23 [==============================] - ETA: 0s - loss: 0.091723/23 [==============================] - 0s 2ms/step - loss: 0.0916
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.081523/23 [==============================] - 0s 2ms/step - loss: 0.0791
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.067423/23 [==============================] - 0s 2ms/step - loss: 0.0710
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.070323/23 [==============================] - 0s 2ms/step - loss: 0.0663
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.067323/23 [==============================] - 0s 2ms/step - loss: 0.0640
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.067423/23 [==============================] - 0s 2ms/step - loss: 0.0625
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.064523/23 [==============================] - 0s 2ms/step - loss: 0.0610
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.056723/23 [==============================] - 0s 2ms/step - loss: 0.0585
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.054123/23 [==============================] - 0s 2ms/step - loss: 0.0553
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.055023/23 [==============================] - 0s 2ms/step - loss: 0.0538
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.057223/23 [==============================] - 0s 2ms/step - loss: 0.0511
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.050723/23 [==============================] - 0s 2ms/step - loss: 0.0493
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.048823/23 [==============================] - 0s 2ms/step - loss: 0.0482
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.048423/23 [==============================] - 0s 2ms/step - loss: 0.0485
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044823/23 [==============================] - 0s 2ms/step - loss: 0.0457
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.043523/23 [==============================] - 0s 2ms/step - loss: 0.0458
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044823/23 [==============================] - 0s 2ms/step - loss: 0.0467
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045823/23 [==============================] - 0s 2ms/step - loss: 0.0456
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041023/23 [==============================] - 0s 2ms/step - loss: 0.0448
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.048223/23 [==============================] - 0s 2ms/step - loss: 0.0454
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.043323/23 [==============================] - 0s 2ms/step - loss: 0.0438
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.051923/23 [==============================] - 0s 2ms/step - loss: 0.0448
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.042223/23 [==============================] - 0s 2ms/step - loss: 0.0429
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.043923/23 [==============================] - 0s 2ms/step - loss: 0.0432
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041123/23 [==============================] - 0s 2ms/step - loss: 0.0434
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.047623/23 [==============================] - 0s 2ms/step - loss: 0.0447
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044823/23 [==============================] - 0s 2ms/step - loss: 0.0439
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.042423/23 [==============================] - 0s 2ms/step - loss: 0.0435
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041323/23 [==============================] - 0s 2ms/step - loss: 0.0422
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.042123/23 [==============================] - 0s 2ms/step - loss: 0.0427
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040023/23 [==============================] - 0s 2ms/step - loss: 0.0425
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.042423/23 [==============================] - 0s 2ms/step - loss: 0.0430
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041323/23 [==============================] - 0s 2ms/step - loss: 0.0419
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045723/23 [==============================] - 0s 2ms/step - loss: 0.0431
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040423/23 [==============================] - 0s 2ms/step - loss: 0.0424
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038923/23 [==============================] - 0s 2ms/step - loss: 0.0423
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036623/23 [==============================] - 0s 2ms/step - loss: 0.0413
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.037223/23 [==============================] - 0s 2ms/step - loss: 0.0413
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.043323/23 [==============================] - 0s 2ms/step - loss: 0.0424
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045223/23 [==============================] - 0s 2ms/step - loss: 0.0416
Epoch 41/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039723/23 [==============================] - 0s 2ms/step - loss: 0.0427
Epoch 42/500
 1/23 [>.............................] - ETA: 0s - loss: 0.043923/23 [==============================] - 0s 2ms/step - loss: 0.0426
Epoch 43/500
 1/23 [>.............................] - ETA: 0s - loss: 0.042123/23 [==============================] - 0s 2ms/step - loss: 0.0420
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
Beta: -286235350478.3867  | Score: 0.46216216216216216
[get_model] Running wfo
[get_model] Finished running wfo
Beta: -1116458623844.7373  | Score: 0.0
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_11 (InputLayer)        [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 6s - loss: 0.052723/23 [==============================] - 0s 2ms/step - loss: 0.0495
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040423/23 [==============================] - 0s 2ms/step - loss: 0.0366
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027923/23 [==============================] - 0s 2ms/step - loss: 0.0248
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016323/23 [==============================] - 0s 2ms/step - loss: 0.0147
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.008923/23 [==============================] - 0s 2ms/step - loss: 0.0086
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006223/23 [==============================] - 0s 2ms/step - loss: 0.0066
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006023/23 [==============================] - 0s 2ms/step - loss: 0.0054
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003523/23 [==============================] - 0s 2ms/step - loss: 0.0042
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004023/23 [==============================] - 0s 2ms/step - loss: 0.0034
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003123/23 [==============================] - 0s 2ms/step - loss: 0.0035
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003723/23 [==============================] - 0s 2ms/step - loss: 0.0032
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003123/23 [==============================] - 0s 2ms/step - loss: 0.0031
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003023/23 [==============================] - 0s 2ms/step - loss: 0.0030
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002923/23 [==============================] - 0s 2ms/step - loss: 0.0030
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002223/23 [==============================] - 0s 2ms/step - loss: 0.0028
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002723/23 [==============================] - 0s 2ms/step - loss: 0.0028
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003023/23 [==============================] - 0s 2ms/step - loss: 0.0028
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002823/23 [==============================] - 0s 2ms/step - loss: 0.0027
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002823/23 [==============================] - 0s 2ms/step - loss: 0.0027
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
Beta: -2845314816498.7114  | Score: 0.3572679509632224
Accuracy: 0.46216216216216216
Time: 24.680519342422485

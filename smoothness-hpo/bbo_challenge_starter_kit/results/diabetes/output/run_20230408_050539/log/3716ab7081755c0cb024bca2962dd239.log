running: {'--uuid': '3716ab7081755c0cb024bca2962dd239', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_050539', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d diabetes -o turbo -u 3716ab7081755c0cb024bca2962dd239 -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230408_050539
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study turbo MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002071 iter 0 next_points [{'alpha': 0.00510231449616851, 'batch_size': 81, 'beta_1': 0.856257407868201, 'beta_2': 0.9897516117306646, 'epsilon': 1.4372885819230418e-07, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.039282766413945985, 'tol': 0.07372633264197517, 'validation_fraction': 0.8993827765330463}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.064899 value 22365.149763 suggestion {'alpha': 0.00510231449616851, 'batch_size': 81, 'beta_1': 0.856257407868201, 'beta_2': 0.9897516117306646, 'epsilon': 1.4372885819230418e-07, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.039282766413945985, 'tol': 0.07372633264197517, 'validation_fraction': 0.8993827765330463}
observation time 0.001343, current best 22365.149763 at iter 0
suggestion time taken 0.001747 iter 1 next_points [{'alpha': 5.282929584446326, 'batch_size': 207, 'beta_1': 0.7301685008841542, 'beta_2': 0.9999671252666097, 'epsilon': 5.986461607772407e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.0002265372249047479, 'tol': 0.040725837216428674, 'validation_fraction': 0.19183537384901986}]
function_evaluation time 0.104249 value 29081.170725 suggestion {'alpha': 5.282929584446326, 'batch_size': 207, 'beta_1': 0.7301685008841542, 'beta_2': 0.9999671252666097, 'epsilon': 5.986461607772407e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.0002265372249047479, 'tol': 0.040725837216428674, 'validation_fraction': 0.19183537384901986}
observation time 0.001362, current best 22365.149763 at iter 1
suggestion time taken 0.002029 iter 2 next_points [{'alpha': 7.213472777207843e-05, 'batch_size': 153, 'beta_1': 0.6225237497024585, 'beta_2': 0.9998787539076779, 'epsilon': 9.405598528992403e-08, 'hidden_layer_sizes': 119, 'learning_rate_init': 4.4159113157401725e-05, 'tol': 0.001963899664598332, 'validation_fraction': 0.1462762237314924}]
function_evaluation time 0.078951 value 29102.447887 suggestion {'alpha': 7.213472777207843e-05, 'batch_size': 153, 'beta_1': 0.6225237497024585, 'beta_2': 0.9998787539076779, 'epsilon': 9.405598528992403e-08, 'hidden_layer_sizes': 119, 'learning_rate_init': 4.4159113157401725e-05, 'tol': 0.001963899664598332, 'validation_fraction': 0.1462762237314924}
observation time 0.001377, current best 22365.149763 at iter 2
suggestion time taken 0.002104 iter 3 next_points [{'alpha': 0.0006173618435379414, 'batch_size': 237, 'beta_1': 0.97420182899703, 'beta_2': 0.9934591997395583, 'epsilon': 1.914445929887719e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.007338925802558675, 'tol': 0.007996454465096257, 'validation_fraction': 0.8575753303766465}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.055497 value 28649.988074 suggestion {'alpha': 0.0006173618435379414, 'batch_size': 237, 'beta_1': 0.97420182899703, 'beta_2': 0.9934591997395583, 'epsilon': 1.914445929887719e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.007338925802558675, 'tol': 0.007996454465096257, 'validation_fraction': 0.8575753303766465}
observation time 0.001381, current best 22365.149763 at iter 3
suggestion time taken 0.002036 iter 4 next_points [{'alpha': 0.2518389725646707, 'batch_size': 172, 'beta_1': 0.9592821110714, 'beta_2': 0.9999940608340677, 'epsilon': 1.9855940326175407e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.00013803142273736052, 'tol': 0.00010181594636794024, 'validation_fraction': 0.4058309565622053}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.354615 value 29100.776343 suggestion {'alpha': 0.2518389725646707, 'batch_size': 172, 'beta_1': 0.9592821110714, 'beta_2': 0.9999940608340677, 'epsilon': 1.9855940326175407e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.00013803142273736052, 'tol': 0.00010181594636794024, 'validation_fraction': 0.4058309565622053}
observation time 0.001360, current best 22365.149763 at iter 4
suggestion time taken 0.001785 iter 5 next_points [{'alpha': 1.6036263442882301, 'batch_size': 95, 'beta_1': 0.6870075932535442, 'beta_2': 0.9154229798151384, 'epsilon': 3.899586084090564e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0004286333903456828, 'tol': 5.6034121236360556e-05, 'validation_fraction': 0.8341725885713748}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.789218 value 28562.401571 suggestion {'alpha': 1.6036263442882301, 'batch_size': 95, 'beta_1': 0.6870075932535442, 'beta_2': 0.9154229798151384, 'epsilon': 3.899586084090564e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0004286333903456828, 'tol': 5.6034121236360556e-05, 'validation_fraction': 0.8341725885713748}
observation time 0.001400, current best 22365.149763 at iter 5
suggestion time taken 0.001698 iter 6 next_points [{'alpha': 0.0019516583628163488, 'batch_size': 16, 'beta_1': 0.9520257488481754, 'beta_2': 0.9999989379843305, 'epsilon': 4.15295944966549e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.000991301611903851, 'tol': 1.5374317072653173e-05, 'validation_fraction': 0.7267503447746406}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.424080 value 16885.989050 suggestion {'alpha': 0.0019516583628163488, 'batch_size': 16, 'beta_1': 0.9520257488481754, 'beta_2': 0.9999989379843305, 'epsilon': 4.15295944966549e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.000991301611903851, 'tol': 1.5374317072653173e-05, 'validation_fraction': 0.7267503447746406}
observation time 0.001385, current best 16885.989050 at iter 6
suggestion time taken 0.001799 iter 7 next_points [{'alpha': 0.32329734059242393, 'batch_size': 127, 'beta_1': 0.9837683819261116, 'beta_2': 0.9999979901783549, 'epsilon': 1.1333800653963176e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 1.0712464191268867e-05, 'tol': 0.0002494324570502337, 'validation_fraction': 0.1718208429057466}]
function_evaluation time 0.082289 value 29115.496264 suggestion {'alpha': 0.32329734059242393, 'batch_size': 127, 'beta_1': 0.9837683819261116, 'beta_2': 0.9999979901783549, 'epsilon': 1.1333800653963176e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 1.0712464191268867e-05, 'tol': 0.0002494324570502337, 'validation_fraction': 0.1718208429057466}
observation time 0.001434, current best 16885.989050 at iter 7
suggestion time taken 0.001712 iter 8 next_points [{'alpha': 0.06884980210122019, 'batch_size': 181, 'beta_1': 0.9694812761443803, 'beta_2': 0.9998417799374624, 'epsilon': 1.3388339313036348e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0788392690604586, 'tol': 0.0006019946690529872, 'validation_fraction': 0.3101987510638261}]
function_evaluation time 0.210837 value 3544.112813 suggestion {'alpha': 0.06884980210122019, 'batch_size': 181, 'beta_1': 0.9694812761443803, 'beta_2': 0.9998417799374624, 'epsilon': 1.3388339313036348e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0788392690604586, 'tol': 0.0006019946690529872, 'validation_fraction': 0.3101987510638261}
observation time 0.001358, current best 3544.112813 at iter 8
suggestion time taken 0.001720 iter 9 next_points [{'alpha': 0.0012220935146684431, 'batch_size': 63, 'beta_1': 0.6077140563866815, 'beta_2': 0.9995065637072221, 'epsilon': 3.1377885153901964e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.0251768646644078, 'tol': 0.029855642658014037, 'validation_fraction': 0.5308351517943654}]
function_evaluation time 0.208800 value 3735.956371 suggestion {'alpha': 0.0012220935146684431, 'batch_size': 63, 'beta_1': 0.6077140563866815, 'beta_2': 0.9995065637072221, 'epsilon': 3.1377885153901964e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.0251768646644078, 'tol': 0.029855642658014037, 'validation_fraction': 0.5308351517943654}
observation time 0.001587, current best 3544.112813 at iter 9
suggestion time taken 0.001746 iter 10 next_points [{'alpha': 3.6404383787350355e-05, 'batch_size': 102, 'beta_1': 0.810265738277051, 'beta_2': 0.997623683444262, 'epsilon': 2.428361667963112e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.01525781324054427, 'tol': 3.06359812348962e-05, 'validation_fraction': 0.814647132627054}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.716893 value 3347.138838 suggestion {'alpha': 3.6404383787350355e-05, 'batch_size': 102, 'beta_1': 0.810265738277051, 'beta_2': 0.997623683444262, 'epsilon': 2.428361667963112e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.01525781324054427, 'tol': 3.06359812348962e-05, 'validation_fraction': 0.814647132627054}
observation time 0.001405, current best 3347.138838 at iter 10
suggestion time taken 0.001734 iter 11 next_points [{'alpha': 0.8068368335396109, 'batch_size': 137, 'beta_1': 0.8944382889938867, 'beta_2': 0.9999860446111937, 'epsilon': 4.472507636732111e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.012730005598210536, 'tol': 0.005033835607877683, 'validation_fraction': 0.25471079632227783}]
function_evaluation time 0.287311 value 3734.786315 suggestion {'alpha': 0.8068368335396109, 'batch_size': 137, 'beta_1': 0.8944382889938867, 'beta_2': 0.9999860446111937, 'epsilon': 4.472507636732111e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.012730005598210536, 'tol': 0.005033835607877683, 'validation_fraction': 0.25471079632227783}
observation time 0.001366, current best 3347.138838 at iter 11
suggestion time taken 0.001713 iter 12 next_points [{'alpha': 0.055835637032269646, 'batch_size': 240, 'beta_1': 0.782604120250045, 'beta_2': 0.956537505617916, 'epsilon': 3.993005656068863e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0021257466236909786, 'tol': 0.0009681316830933897, 'validation_fraction': 0.7555052415057009}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.684180 value 25286.323607 suggestion {'alpha': 0.055835637032269646, 'batch_size': 240, 'beta_1': 0.782604120250045, 'beta_2': 0.956537505617916, 'epsilon': 3.993005656068863e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0021257466236909786, 'tol': 0.0009681316830933897, 'validation_fraction': 0.7555052415057009}
observation time 0.001353, current best 3347.138838 at iter 12
suggestion time taken 0.001801 iter 13 next_points [{'alpha': 1.2353886820509661e-05, 'batch_size': 124, 'beta_1': 0.5050835432773776, 'beta_2': 0.9986004970341344, 'epsilon': 6.937061918095742e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.00472317933770283, 'tol': 0.0003451440445524801, 'validation_fraction': 0.11861817343430338}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.165834 value 3809.716627 suggestion {'alpha': 1.2353886820509661e-05, 'batch_size': 124, 'beta_1': 0.5050835432773776, 'beta_2': 0.9986004970341344, 'epsilon': 6.937061918095742e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.00472317933770283, 'tol': 0.0003451440445524801, 'validation_fraction': 0.11861817343430338}
observation time 0.001430, current best 3347.138838 at iter 13
suggestion time taken 0.001741 iter 14 next_points [{'alpha': 0.00010814539392259233, 'batch_size': 60, 'beta_1': 0.9078812957688152, 'beta_2': 0.9999935426276196, 'epsilon': 8.950086256593034e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.0013601958264700112, 'tol': 0.010357282672585262, 'validation_fraction': 0.606767934285382}]
function_evaluation time 0.079290 value 28946.378437 suggestion {'alpha': 0.00010814539392259233, 'batch_size': 60, 'beta_1': 0.9078812957688152, 'beta_2': 0.9999935426276196, 'epsilon': 8.950086256593034e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.0013601958264700112, 'tol': 0.010357282672585262, 'validation_fraction': 0.606767934285382}
observation time 0.001446, current best 3347.138838 at iter 14
saving meta data: {'args': {'--uuid': '3716ab7081755c0cb024bca2962dd239', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_050539', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

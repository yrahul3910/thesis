running: {'--uuid': '18d4fdda19175ee0bdb61ec780b073f8', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_050539', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d diabetes -o hyperopt -u 18d4fdda19175ee0bdb61ec780b073f8 -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230408_050539
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study hyperopt MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002299 iter 0 next_points [{'alpha': 0.7578832111675778, 'batch_size': 211, 'beta_1': 0.7051762841319906, 'beta_2': 0.9910984481989938, 'epsilon': 1.604965581045579e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.00017973776021483224, 'tol': 0.019002739973133908, 'validation_fraction': 0.13046604890889552}]
function_evaluation time 0.091390 value 151.528862 suggestion {'alpha': 0.7578832111675778, 'batch_size': 211, 'beta_1': 0.7051762841319906, 'beta_2': 0.9910984481989938, 'epsilon': 1.604965581045579e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.00017973776021483224, 'tol': 0.019002739973133908, 'validation_fraction': 0.13046604890889552}
observation time 0.000057, current best 151.528862 at iter 0
suggestion time taken 0.002086 iter 1 next_points [{'alpha': 0.0008131091945762616, 'batch_size': 227, 'beta_1': 0.7341286839361704, 'beta_2': 0.9331177370523255, 'epsilon': 1.538594646783863e-07, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.0005382154211269345, 'tol': 0.0013705624362185637, 'validation_fraction': 0.23399893529523938}]
function_evaluation time 0.079336 value 151.569127 suggestion {'alpha': 0.0008131091945762616, 'batch_size': 227, 'beta_1': 0.7341286839361704, 'beta_2': 0.9331177370523255, 'epsilon': 1.538594646783863e-07, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.0005382154211269345, 'tol': 0.0013705624362185637, 'validation_fraction': 0.23399893529523938}
observation time 0.000059, current best 151.528862 at iter 1
suggestion time taken 0.002129 iter 2 next_points [{'alpha': 1.0952561199107928e-05, 'batch_size': 55, 'beta_1': 0.8785814740731235, 'beta_2': 0.9001754227293954, 'epsilon': 6.386915618324544e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 7.813761529780239e-05, 'tol': 0.00045127736718983175, 'validation_fraction': 0.19211984797433032}]
function_evaluation time 0.065969 value 151.614211 suggestion {'alpha': 1.0952561199107928e-05, 'batch_size': 55, 'beta_1': 0.8785814740731235, 'beta_2': 0.9001754227293954, 'epsilon': 6.386915618324544e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 7.813761529780239e-05, 'tol': 0.00045127736718983175, 'validation_fraction': 0.19211984797433032}
observation time 0.000067, current best 151.528862 at iter 2
suggestion time taken 0.002359 iter 3 next_points [{'alpha': 0.5882924660467662, 'batch_size': 125, 'beta_1': 0.5373185494882822, 'beta_2': 0.9703659572785863, 'epsilon': 5.402126225510033e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.010046316012821696, 'tol': 0.03438297577953109, 'validation_fraction': 0.11883610647233339}]
function_evaluation time 0.426214 value 53.129766 suggestion {'alpha': 0.5882924660467662, 'batch_size': 125, 'beta_1': 0.5373185494882822, 'beta_2': 0.9703659572785863, 'epsilon': 5.402126225510033e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.010046316012821696, 'tol': 0.03438297577953109, 'validation_fraction': 0.11883610647233339}
observation time 0.000059, current best 53.129766 at iter 3
suggestion time taken 0.002054 iter 4 next_points [{'alpha': 0.0003888200057438243, 'batch_size': 131, 'beta_1': 0.6964613124817974, 'beta_2': 0.9503825658735706, 'epsilon': 5.303576692483838e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.004683873298145718, 'tol': 0.002393561841832477, 'validation_fraction': 0.13538800258064132}]
function_evaluation time 0.990520 value 55.687498 suggestion {'alpha': 0.0003888200057438243, 'batch_size': 131, 'beta_1': 0.6964613124817974, 'beta_2': 0.9503825658735706, 'epsilon': 5.303576692483838e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.004683873298145718, 'tol': 0.002393561841832477, 'validation_fraction': 0.13538800258064132}
observation time 0.000067, current best 53.129766 at iter 4
suggestion time taken 0.002172 iter 5 next_points [{'alpha': 0.00020795359947134188, 'batch_size': 225, 'beta_1': 0.7956583779921953, 'beta_2': 0.9924671692123221, 'epsilon': 6.996864309942857e-07, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.000976701517457599, 'tol': 3.0417000753196432e-05, 'validation_fraction': 0.44162561213456725}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.999594 value 143.998515 suggestion {'alpha': 0.00020795359947134188, 'batch_size': 225, 'beta_1': 0.7956583779921953, 'beta_2': 0.9924671692123221, 'epsilon': 6.996864309942857e-07, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.000976701517457599, 'tol': 3.0417000753196432e-05, 'validation_fraction': 0.44162561213456725}
observation time 0.000075, current best 53.129766 at iter 5
suggestion time taken 0.002163 iter 6 next_points [{'alpha': 3.400572153242485e-05, 'batch_size': 240, 'beta_1': 0.5976933712345883, 'beta_2': 0.9840321590516431, 'epsilon': 5.784364396012681e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.00028496203879445125, 'tol': 0.0005481296168388905, 'validation_fraction': 0.5340762814660079}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.035388 value 151.584916 suggestion {'alpha': 3.400572153242485e-05, 'batch_size': 240, 'beta_1': 0.5976933712345883, 'beta_2': 0.9840321590516431, 'epsilon': 5.784364396012681e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.00028496203879445125, 'tol': 0.0005481296168388905, 'validation_fraction': 0.5340762814660079}
observation time 0.000069, current best 53.129766 at iter 6
suggestion time taken 0.002326 iter 7 next_points [{'alpha': 0.14014955330865567, 'batch_size': 44, 'beta_1': 0.796019659350263, 'beta_2': 0.938299255119241, 'epsilon': 2.2376284802823362e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.06376468905478352, 'tol': 0.00685734591031565, 'validation_fraction': 0.1915603271607995}]
function_evaluation time 0.218606 value 43.535524 suggestion {'alpha': 0.14014955330865567, 'batch_size': 44, 'beta_1': 0.796019659350263, 'beta_2': 0.938299255119241, 'epsilon': 2.2376284802823362e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.06376468905478352, 'tol': 0.00685734591031565, 'validation_fraction': 0.1915603271607995}
observation time 0.000096, current best 43.535524 at iter 7
suggestion time taken 0.002131 iter 8 next_points [{'alpha': 0.013737815182614896, 'batch_size': 36, 'beta_1': 0.7575980026504604, 'beta_2': 0.9135891922515108, 'epsilon': 6.229766912058345e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0025950771379795075, 'tol': 0.008295624682798883, 'validation_fraction': 0.28233425122001954}]
function_evaluation time 1.056665 value 54.146500 suggestion {'alpha': 0.013737815182614896, 'batch_size': 36, 'beta_1': 0.7575980026504604, 'beta_2': 0.9135891922515108, 'epsilon': 6.229766912058345e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0025950771379795075, 'tol': 0.008295624682798883, 'validation_fraction': 0.28233425122001954}
observation time 0.000071, current best 43.535524 at iter 8
suggestion time taken 0.002123 iter 9 next_points [{'alpha': 2.524049833501695, 'batch_size': 219, 'beta_1': 0.9529029214680556, 'beta_2': 0.9524393955157269, 'epsilon': 2.8400207905484702e-08, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.00979893767807993, 'tol': 0.004625411233197401, 'validation_fraction': 0.26253706880253275}]
function_evaluation time 0.822076 value 54.621932 suggestion {'alpha': 2.524049833501695, 'batch_size': 219, 'beta_1': 0.9529029214680556, 'beta_2': 0.9524393955157269, 'epsilon': 2.8400207905484702e-08, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.00979893767807993, 'tol': 0.004625411233197401, 'validation_fraction': 0.26253706880253275}
observation time 0.000077, current best 43.535524 at iter 9
suggestion time taken 0.002155 iter 10 next_points [{'alpha': 5.788005228541825e-05, 'batch_size': 225, 'beta_1': 0.6478391579282633, 'beta_2': 0.9615577154890217, 'epsilon': 7.2511025309322506e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.0032185917414896885, 'tol': 0.00012180041583125953, 'validation_fraction': 0.17435139577298803}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.113753 value 62.767807 suggestion {'alpha': 5.788005228541825e-05, 'batch_size': 225, 'beta_1': 0.6478391579282633, 'beta_2': 0.9615577154890217, 'epsilon': 7.2511025309322506e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.0032185917414896885, 'tol': 0.00012180041583125953, 'validation_fraction': 0.17435139577298803}
observation time 0.000073, current best 43.535524 at iter 10
suggestion time taken 0.002116 iter 11 next_points [{'alpha': 0.19163023396333656, 'batch_size': 62, 'beta_1': 0.631217590296842, 'beta_2': 0.9546296272999604, 'epsilon': 2.387676615795129e-09, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.0009169900336922145, 'tol': 2.1346241404616236e-05, 'validation_fraction': 0.8049660893505624}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.862881 value 146.029789 suggestion {'alpha': 0.19163023396333656, 'batch_size': 62, 'beta_1': 0.631217590296842, 'beta_2': 0.9546296272999604, 'epsilon': 2.387676615795129e-09, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.0009169900336922145, 'tol': 2.1346241404616236e-05, 'validation_fraction': 0.8049660893505624}
observation time 0.000079, current best 43.535524 at iter 11
suggestion time taken 0.002158 iter 12 next_points [{'alpha': 0.14333580226611026, 'batch_size': 57, 'beta_1': 0.7643219929929973, 'beta_2': 0.9927509216220819, 'epsilon': 1.3692451185626496e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.02242545291468122, 'tol': 0.0014274377319664169, 'validation_fraction': 0.13667711101998958}]
function_evaluation time 0.387591 value 45.202814 suggestion {'alpha': 0.14333580226611026, 'batch_size': 57, 'beta_1': 0.7643219929929973, 'beta_2': 0.9927509216220819, 'epsilon': 1.3692451185626496e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.02242545291468122, 'tol': 0.0014274377319664169, 'validation_fraction': 0.13667711101998958}
observation time 0.000057, current best 43.535524 at iter 12
suggestion time taken 0.002124 iter 13 next_points [{'alpha': 0.07330027661217947, 'batch_size': 178, 'beta_1': 0.8641876461654961, 'beta_2': 0.9813222105699559, 'epsilon': 1.1754622958864825e-08, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0024182750546900495, 'tol': 0.00040765314910173726, 'validation_fraction': 0.5442940004361455}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.815013 value 127.266341 suggestion {'alpha': 0.07330027661217947, 'batch_size': 178, 'beta_1': 0.8641876461654961, 'beta_2': 0.9813222105699559, 'epsilon': 1.1754622958864825e-08, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0024182750546900495, 'tol': 0.00040765314910173726, 'validation_fraction': 0.5442940004361455}
observation time 0.000063, current best 43.535524 at iter 13
suggestion time taken 0.002295 iter 14 next_points [{'alpha': 0.05091378258508373, 'batch_size': 27, 'beta_1': 0.5996932768112779, 'beta_2': 0.9658153364575932, 'epsilon': 2.9387430717623848e-09, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.011043514738226104, 'tol': 6.805038665641929e-05, 'validation_fraction': 0.3579333818047432}]
function_evaluation time 1.107423 value 44.571077 suggestion {'alpha': 0.05091378258508373, 'batch_size': 27, 'beta_1': 0.5996932768112779, 'beta_2': 0.9658153364575932, 'epsilon': 2.9387430717623848e-09, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.011043514738226104, 'tol': 6.805038665641929e-05, 'validation_fraction': 0.3579333818047432}
observation time 0.000064, current best 43.535524 at iter 14
saving meta data: {'args': {'--uuid': '18d4fdda19175ee0bdb61ec780b073f8', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_050539', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '92da4b9a6f6d548d8975b4d5fd3a7917', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_050539', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d diabetes -o turbo -u 92da4b9a6f6d548d8975b4d5fd3a7917 -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230408_050539
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study turbo MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002263 iter 0 next_points [{'alpha': 0.02225345576996036, 'batch_size': 11, 'beta_1': 0.9151425887499266, 'beta_2': 0.9727034142578077, 'epsilon': 6.803068717158891e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0015111320468855973, 'tol': 0.003547701920434944, 'validation_fraction': 0.7643248574531152}]
function_evaluation time 1.674097 value 5203.518915 suggestion {'alpha': 0.02225345576996036, 'batch_size': 11, 'beta_1': 0.9151425887499266, 'beta_2': 0.9727034142578077, 'epsilon': 6.803068717158891e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0015111320468855973, 'tol': 0.003547701920434944, 'validation_fraction': 0.7643248574531152}
observation time 0.001489, current best 5203.518915 at iter 0
suggestion time taken 0.001795 iter 1 next_points [{'alpha': 0.0019952532281225593, 'batch_size': 86, 'beta_1': 0.7476778040733697, 'beta_2': 0.946378544357707, 'epsilon': 1.1347844935068825e-08, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.07649886201706181, 'tol': 1.520346752630163e-05, 'validation_fraction': 0.816650386561914}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.237612 value 3317.210407 suggestion {'alpha': 0.0019952532281225593, 'batch_size': 86, 'beta_1': 0.7476778040733697, 'beta_2': 0.946378544357707, 'epsilon': 1.1347844935068825e-08, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.07649886201706181, 'tol': 1.520346752630163e-05, 'validation_fraction': 0.816650386561914}
observation time 0.001339, current best 3317.210407 at iter 1
suggestion time taken 0.001737 iter 2 next_points [{'alpha': 6.729845709171746, 'batch_size': 79, 'beta_1': 0.8941642104412802, 'beta_2': 0.9991675488055636, 'epsilon': 4.673693602465683e-09, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.00020943067017650647, 'tol': 0.00102820429872437, 'validation_fraction': 0.6680303557400098}]
function_evaluation time 0.078174 value 29097.211788 suggestion {'alpha': 6.729845709171746, 'batch_size': 79, 'beta_1': 0.8941642104412802, 'beta_2': 0.9991675488055636, 'epsilon': 4.673693602465683e-09, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.00020943067017650647, 'tol': 0.00102820429872437, 'validation_fraction': 0.6680303557400098}
observation time 0.001330, current best 3317.210407 at iter 2
suggestion time taken 0.001751 iter 3 next_points [{'alpha': 1.6675665129855668, 'batch_size': 41, 'beta_1': 0.6665596240528168, 'beta_2': 0.9999946220931045, 'epsilon': 2.438228889157256e-07, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.0005144624261566239, 'tol': 2.1206392844951102e-05, 'validation_fraction': 0.3512277308131801}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.898260 value 15923.305726 suggestion {'alpha': 1.6675665129855668, 'batch_size': 41, 'beta_1': 0.6665596240528168, 'beta_2': 0.9999946220931045, 'epsilon': 2.438228889157256e-07, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.0005144624261566239, 'tol': 2.1206392844951102e-05, 'validation_fraction': 0.3512277308131801}
observation time 0.001350, current best 3317.210407 at iter 3
suggestion time taken 0.001774 iter 4 next_points [{'alpha': 5.98504672084721e-05, 'batch_size': 224, 'beta_1': 0.8593492319385208, 'beta_2': 0.9906525066816508, 'epsilon': 1.677767850245184e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.004386962115354541, 'tol': 0.00026331427966169734, 'validation_fraction': 0.7367869475545422}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.621473 value 17351.298423 suggestion {'alpha': 5.98504672084721e-05, 'batch_size': 224, 'beta_1': 0.8593492319385208, 'beta_2': 0.9906525066816508, 'epsilon': 1.677767850245184e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.004386962115354541, 'tol': 0.00026331427966169734, 'validation_fraction': 0.7367869475545422}
observation time 0.001342, current best 3317.210407 at iter 4
suggestion time taken 0.001746 iter 5 next_points [{'alpha': 0.00044844938710343054, 'batch_size': 198, 'beta_1': 0.9471949908683677, 'beta_2': 0.9999692597375931, 'epsilon': 5.6932017354848166e-08, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.001165774411456637, 'tol': 3.236956788003929e-05, 'validation_fraction': 0.4647747783944395}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.995211 value 25975.133262 suggestion {'alpha': 0.00044844938710343054, 'batch_size': 198, 'beta_1': 0.9471949908683677, 'beta_2': 0.9999692597375931, 'epsilon': 5.6932017354848166e-08, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.001165774411456637, 'tol': 3.236956788003929e-05, 'validation_fraction': 0.4647747783944395}
observation time 0.001332, current best 3317.210407 at iter 5
suggestion time taken 0.001793 iter 6 next_points [{'alpha': 3.15317591422163, 'batch_size': 140, 'beta_1': 0.9635530853007395, 'beta_2': 0.9999073828575992, 'epsilon': 5.2413506261797406e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.0031855726434345264, 'tol': 0.0387474683303159, 'validation_fraction': 0.1308556277519681}]
function_evaluation time 0.091253 value 28710.433738 suggestion {'alpha': 3.15317591422163, 'batch_size': 140, 'beta_1': 0.9635530853007395, 'beta_2': 0.9999073828575992, 'epsilon': 5.2413506261797406e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.0031855726434345264, 'tol': 0.0387474683303159, 'validation_fraction': 0.1308556277519681}
observation time 0.001403, current best 3317.210407 at iter 6
suggestion time taken 0.001924 iter 7 next_points [{'alpha': 0.8579907215911894, 'batch_size': 49, 'beta_1': 0.718339590391775, 'beta_2': 0.9998322739479464, 'epsilon': 2.290407090955639e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0001002580303381846, 'tol': 0.07892022109526783, 'validation_fraction': 0.3727889328269388}]
function_evaluation time 0.066822 value 29044.115372 suggestion {'alpha': 0.8579907215911894, 'batch_size': 49, 'beta_1': 0.718339590391775, 'beta_2': 0.9998322739479464, 'epsilon': 2.290407090955639e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0001002580303381846, 'tol': 0.07892022109526783, 'validation_fraction': 0.3727889328269388}
observation time 0.001326, current best 3317.210407 at iter 7
suggestion time taken 0.001738 iter 8 next_points [{'alpha': 0.0003722125722685489, 'batch_size': 168, 'beta_1': 0.9517451519199979, 'beta_2': 0.9999893280907195, 'epsilon': 1.0620065149275053e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.021735216899360553, 'tol': 0.00010585973354813848, 'validation_fraction': 0.16724358329300398}]
function_evaluation time 0.331902 value 3986.962318 suggestion {'alpha': 0.0003722125722685489, 'batch_size': 168, 'beta_1': 0.9517451519199979, 'beta_2': 0.9999893280907195, 'epsilon': 1.0620065149275053e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.021735216899360553, 'tol': 0.00010585973354813848, 'validation_fraction': 0.16724358329300398}
observation time 0.001371, current best 3317.210407 at iter 8
suggestion time taken 0.001722 iter 9 next_points [{'alpha': 0.03840593618825437, 'batch_size': 178, 'beta_1': 0.9889794698125857, 'beta_2': 0.9999972290040874, 'epsilon': 1.544024265401073e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.0003536240523801731, 'tol': 0.021672830521829965, 'validation_fraction': 0.8364974360641615}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.043382 value 29081.193245 suggestion {'alpha': 0.03840593618825437, 'batch_size': 178, 'beta_1': 0.9889794698125857, 'beta_2': 0.9999972290040874, 'epsilon': 1.544024265401073e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.0003536240523801731, 'tol': 0.021672830521829965, 'validation_fraction': 0.8364974360641615}
observation time 0.001306, current best 3317.210407 at iter 9
suggestion time taken 0.001727 iter 10 next_points [{'alpha': 0.005409675390386074, 'batch_size': 151, 'beta_1': 0.9298817216878525, 'beta_2': 0.9964519985609211, 'epsilon': 1.384273541332807e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 1.0733613124753688e-05, 'tol': 0.00011835760478010176, 'validation_fraction': 0.2980130718664778}]
function_evaluation time 0.069174 value 29112.740634 suggestion {'alpha': 0.005409675390386074, 'batch_size': 151, 'beta_1': 0.9298817216878525, 'beta_2': 0.9964519985609211, 'epsilon': 1.384273541332807e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 1.0733613124753688e-05, 'tol': 0.00011835760478010176, 'validation_fraction': 0.2980130718664778}
observation time 0.001402, current best 3317.210407 at iter 10
suggestion time taken 0.001828 iter 11 next_points [{'alpha': 0.0012724181944447634, 'batch_size': 31, 'beta_1': 0.5448523201303063, 'beta_2': 0.9982187070668952, 'epsilon': 7.344437492652383e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.00015648986481674477, 'tol': 0.007946473531375089, 'validation_fraction': 0.23837107249951903}]
function_evaluation time 0.156578 value 29056.106166 suggestion {'alpha': 0.0012724181944447634, 'batch_size': 31, 'beta_1': 0.5448523201303063, 'beta_2': 0.9982187070668952, 'epsilon': 7.344437492652383e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.00015648986481674477, 'tol': 0.007946473531375089, 'validation_fraction': 0.23837107249951903}
observation time 0.001327, current best 3317.210407 at iter 11
suggestion time taken 0.001774 iter 12 next_points [{'alpha': 2.4556792191953658e-05, 'batch_size': 67, 'beta_1': 0.5784386239006846, 'beta_2': 0.9997480746139306, 'epsilon': 4.5373277918136187e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 5.598679088548982e-05, 'tol': 0.001714370031669505, 'validation_fraction': 0.19840996323763885}]
function_evaluation time 0.065835 value 29064.670816 suggestion {'alpha': 2.4556792191953658e-05, 'batch_size': 67, 'beta_1': 0.5784386239006846, 'beta_2': 0.9997480746139306, 'epsilon': 4.5373277918136187e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 5.598679088548982e-05, 'tol': 0.001714370031669505, 'validation_fraction': 0.19840996323763885}
observation time 0.001337, current best 3317.210407 at iter 12
suggestion time taken 0.002042 iter 13 next_points [{'alpha': 0.30065060653837156, 'batch_size': 112, 'beta_1': 0.9841868728987718, 'beta_2': 0.9999851811580932, 'epsilon': 2.2632181171551934e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.013181861552347665, 'tol': 0.030247541258721148, 'validation_fraction': 0.5701595309600915}]
function_evaluation time 0.374735 value 4479.751655 suggestion {'alpha': 0.30065060653837156, 'batch_size': 112, 'beta_1': 0.9841868728987718, 'beta_2': 0.9999851811580932, 'epsilon': 2.2632181171551934e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.013181861552347665, 'tol': 0.030247541258721148, 'validation_fraction': 0.5701595309600915}
observation time 0.001324, current best 3317.210407 at iter 13
suggestion time taken 0.001898 iter 14 next_points [{'alpha': 9.89942228166326e-05, 'batch_size': 245, 'beta_1': 0.974805206320252, 'beta_2': 0.9896336924757829, 'epsilon': 1.783084639828524e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.033935430456515606, 'tol': 0.010860377905033329, 'validation_fraction': 0.5076158547574232}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.286561 value 4217.722253 suggestion {'alpha': 9.89942228166326e-05, 'batch_size': 245, 'beta_1': 0.974805206320252, 'beta_2': 0.9896336924757829, 'epsilon': 1.783084639828524e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.033935430456515606, 'tol': 0.010860377905033329, 'validation_fraction': 0.5076158547574232}
observation time 0.001317, current best 3317.210407 at iter 14
saving meta data: {'args': {'--uuid': '92da4b9a6f6d548d8975b4d5fd3a7917', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_050539', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

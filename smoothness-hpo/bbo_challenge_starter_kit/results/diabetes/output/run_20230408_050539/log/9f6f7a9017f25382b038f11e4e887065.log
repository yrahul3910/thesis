running: {'--uuid': '9f6f7a9017f25382b038f11e4e887065', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_050539', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d diabetes -o random-search -u 9f6f7a9017f25382b038f11e4e887065 -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230408_050539
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study random-search MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002480 iter 0 next_points [{'alpha': 1.2363687032675298e-05, 'batch_size': 170, 'beta_1': 0.8515734872376188, 'beta_2': 0.9996082445055624, 'epsilon': 2.5683616251491015e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0020495135609838633, 'tol': 0.022364580798650547, 'validation_fraction': 0.15017154508693437}]
function_evaluation time 0.093225 value 150.779472 suggestion {'alpha': 1.2363687032675298e-05, 'batch_size': 170, 'beta_1': 0.8515734872376188, 'beta_2': 0.9996082445055624, 'epsilon': 2.5683616251491015e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0020495135609838633, 'tol': 0.022364580798650547, 'validation_fraction': 0.15017154508693437}
observation time 0.000004, current best 150.779472 at iter 0
suggestion time taken 0.002452 iter 1 next_points [{'alpha': 3.167022854856426e-05, 'batch_size': 139, 'beta_1': 0.5137492002729903, 'beta_2': 0.9996457751831894, 'epsilon': 4.237666712274807e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.022259834046801152, 'tol': 0.0009406315673731466, 'validation_fraction': 0.5994641780999764}]
function_evaluation time 0.566193 value 47.134703 suggestion {'alpha': 3.167022854856426e-05, 'batch_size': 139, 'beta_1': 0.5137492002729903, 'beta_2': 0.9996457751831894, 'epsilon': 4.237666712274807e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.022259834046801152, 'tol': 0.0009406315673731466, 'validation_fraction': 0.5994641780999764}
observation time 0.000004, current best 47.134703 at iter 1
suggestion time taken 0.002497 iter 2 next_points [{'alpha': 0.6387381710551063, 'batch_size': 173, 'beta_1': 0.9893663830882792, 'beta_2': 0.999997884907461, 'epsilon': 4.5310064810423e-08, 'hidden_layer_sizes': 131, 'learning_rate_init': 5.097597668672625e-05, 'tol': 0.005930555184088531, 'validation_fraction': 0.49653112655509835}]
function_evaluation time 0.062083 value 151.531371 suggestion {'alpha': 0.6387381710551063, 'batch_size': 173, 'beta_1': 0.9893663830882792, 'beta_2': 0.999997884907461, 'epsilon': 4.5310064810423e-08, 'hidden_layer_sizes': 131, 'learning_rate_init': 5.097597668672625e-05, 'tol': 0.005930555184088531, 'validation_fraction': 0.49653112655509835}
observation time 0.000004, current best 47.134703 at iter 2
suggestion time taken 0.002465 iter 3 next_points [{'alpha': 1.560378005424376e-05, 'batch_size': 73, 'beta_1': 0.5750770385476879, 'beta_2': 0.9836674723392712, 'epsilon': 6.245997180314446e-09, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.013975241394374782, 'tol': 0.00471992678127982, 'validation_fraction': 0.6447985726051577}]
function_evaluation time 0.338242 value 52.272985 suggestion {'alpha': 1.560378005424376e-05, 'batch_size': 73, 'beta_1': 0.5750770385476879, 'beta_2': 0.9836674723392712, 'epsilon': 6.245997180314446e-09, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.013975241394374782, 'tol': 0.00471992678127982, 'validation_fraction': 0.6447985726051577}
observation time 0.000003, current best 47.134703 at iter 3
suggestion time taken 0.002512 iter 4 next_points [{'alpha': 9.213904626889587, 'batch_size': 83, 'beta_1': 0.9302699072624927, 'beta_2': 0.9999323038087975, 'epsilon': 1.3897729725124925e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 9.637286135113776e-05, 'tol': 0.0002115096290931378, 'validation_fraction': 0.3388306919359377}]
function_evaluation time 0.166802 value 151.385418 suggestion {'alpha': 9.213904626889587, 'batch_size': 83, 'beta_1': 0.9302699072624927, 'beta_2': 0.9999323038087975, 'epsilon': 1.3897729725124925e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 9.637286135113776e-05, 'tol': 0.0002115096290931378, 'validation_fraction': 0.3388306919359377}
observation time 0.000005, current best 47.134703 at iter 4
suggestion time taken 0.002484 iter 5 next_points [{'alpha': 0.016076379950751195, 'batch_size': 11, 'beta_1': 0.6246647662810607, 'beta_2': 0.999649122419701, 'epsilon': 1.2690489790200405e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.04310910243887923, 'tol': 0.0007914621489000079, 'validation_fraction': 0.8381377483152064}]
function_evaluation time 0.405381 value 45.540604 suggestion {'alpha': 0.016076379950751195, 'batch_size': 11, 'beta_1': 0.6246647662810607, 'beta_2': 0.999649122419701, 'epsilon': 1.2690489790200405e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.04310910243887923, 'tol': 0.0007914621489000079, 'validation_fraction': 0.8381377483152064}
observation time 0.000003, current best 45.540604 at iter 5
suggestion time taken 0.002459 iter 6 next_points [{'alpha': 8.351297440404883, 'batch_size': 121, 'beta_1': 0.9207208730970221, 'beta_2': 0.9999984153434109, 'epsilon': 4.115626281883994e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.007772976577546891, 'tol': 0.0005182885087618821, 'validation_fraction': 0.5392597332575847}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.647920 value 53.280314 suggestion {'alpha': 8.351297440404883, 'batch_size': 121, 'beta_1': 0.9207208730970221, 'beta_2': 0.9999984153434109, 'epsilon': 4.115626281883994e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.007772976577546891, 'tol': 0.0005182885087618821, 'validation_fraction': 0.5392597332575847}
observation time 0.000004, current best 45.540604 at iter 6
suggestion time taken 0.002737 iter 7 next_points [{'alpha': 2.4395024606515873e-05, 'batch_size': 189, 'beta_1': 0.9502230997027343, 'beta_2': 0.9999974710153416, 'epsilon': 5.484671922845096e-08, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.003803156243993385, 'tol': 2.8252048305759403e-05, 'validation_fraction': 0.8824698016320064}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.763930 value 77.088182 suggestion {'alpha': 2.4395024606515873e-05, 'batch_size': 189, 'beta_1': 0.9502230997027343, 'beta_2': 0.9999974710153416, 'epsilon': 5.484671922845096e-08, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.003803156243993385, 'tol': 2.8252048305759403e-05, 'validation_fraction': 0.8824698016320064}
observation time 0.000004, current best 45.540604 at iter 7
suggestion time taken 0.002490 iter 8 next_points [{'alpha': 3.8774894646564833, 'batch_size': 101, 'beta_1': 0.985131302776917, 'beta_2': 0.999663764679342, 'epsilon': 6.484695691054692e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.0002760421039290453, 'tol': 0.00019605104671150834, 'validation_fraction': 0.6852967641211538}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.441739 value 151.357732 suggestion {'alpha': 3.8774894646564833, 'batch_size': 101, 'beta_1': 0.985131302776917, 'beta_2': 0.999663764679342, 'epsilon': 6.484695691054692e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.0002760421039290453, 'tol': 0.00019605104671150834, 'validation_fraction': 0.6852967641211538}
observation time 0.000004, current best 45.540604 at iter 8
suggestion time taken 0.002486 iter 9 next_points [{'alpha': 2.007696491299197, 'batch_size': 93, 'beta_1': 0.9156025580889368, 'beta_2': 0.9830444648212382, 'epsilon': 1.239645802563998e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.0004975710928440251, 'tol': 0.0309589668118712, 'validation_fraction': 0.6061329356242348}]
function_evaluation time 0.063135 value 151.440236 suggestion {'alpha': 2.007696491299197, 'batch_size': 93, 'beta_1': 0.9156025580889368, 'beta_2': 0.9830444648212382, 'epsilon': 1.239645802563998e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.0004975710928440251, 'tol': 0.0309589668118712, 'validation_fraction': 0.6061329356242348}
observation time 0.000004, current best 45.540604 at iter 9
suggestion time taken 0.002545 iter 10 next_points [{'alpha': 0.014822328162119938, 'batch_size': 177, 'beta_1': 0.9871719023380022, 'beta_2': 0.9999410096526608, 'epsilon': 1.540314644604569e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.0045228561765075495, 'tol': 0.0003285145980316603, 'validation_fraction': 0.7113302267695399}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.625520 value 123.423029 suggestion {'alpha': 0.014822328162119938, 'batch_size': 177, 'beta_1': 0.9871719023380022, 'beta_2': 0.9999410096526608, 'epsilon': 1.540314644604569e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.0045228561765075495, 'tol': 0.0003285145980316603, 'validation_fraction': 0.7113302267695399}
observation time 0.000004, current best 45.540604 at iter 10
suggestion time taken 0.002525 iter 11 next_points [{'alpha': 0.18207335107367184, 'batch_size': 196, 'beta_1': 0.9457046531460778, 'beta_2': 0.9994547540649098, 'epsilon': 1.9219340895131263e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.001665356662362469, 'tol': 0.001625345683705824, 'validation_fraction': 0.8938279487909123}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.050194 value 151.282530 suggestion {'alpha': 0.18207335107367184, 'batch_size': 196, 'beta_1': 0.9457046531460778, 'beta_2': 0.9994547540649098, 'epsilon': 1.9219340895131263e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.001665356662362469, 'tol': 0.001625345683705824, 'validation_fraction': 0.8938279487909123}
observation time 0.000004, current best 45.540604 at iter 11
suggestion time taken 0.002472 iter 12 next_points [{'alpha': 4.312613224161151e-05, 'batch_size': 86, 'beta_1': 0.9820949243437788, 'beta_2': 0.9999911776919882, 'epsilon': 4.126470493146032e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 3.57698759033257e-05, 'tol': 0.00011106791633348039, 'validation_fraction': 0.8007952076780651}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.053692 value 151.528673 suggestion {'alpha': 4.312613224161151e-05, 'batch_size': 86, 'beta_1': 0.9820949243437788, 'beta_2': 0.9999911776919882, 'epsilon': 4.126470493146032e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 3.57698759033257e-05, 'tol': 0.00011106791633348039, 'validation_fraction': 0.8007952076780651}
observation time 0.000004, current best 45.540604 at iter 12
suggestion time taken 0.002434 iter 13 next_points [{'alpha': 1.2349881391071474e-05, 'batch_size': 43, 'beta_1': 0.9368095725966504, 'beta_2': 0.9942411916643511, 'epsilon': 9.795845387755984e-07, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.0010771439282617479, 'tol': 0.000499127696922136, 'validation_fraction': 0.2566358957640659}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.304970 value 71.764454 suggestion {'alpha': 1.2349881391071474e-05, 'batch_size': 43, 'beta_1': 0.9368095725966504, 'beta_2': 0.9942411916643511, 'epsilon': 9.795845387755984e-07, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.0010771439282617479, 'tol': 0.000499127696922136, 'validation_fraction': 0.2566358957640659}
observation time 0.000004, current best 45.540604 at iter 13
suggestion time taken 0.002442 iter 14 next_points [{'alpha': 0.0004899251296046971, 'batch_size': 222, 'beta_1': 0.9881193207039762, 'beta_2': 0.9979326751637172, 'epsilon': 1.013764633054648e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 3.664312480889199e-05, 'tol': 0.004661345075284315, 'validation_fraction': 0.6711679847799802}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.058792 value 151.608054 suggestion {'alpha': 0.0004899251296046971, 'batch_size': 222, 'beta_1': 0.9881193207039762, 'beta_2': 0.9979326751637172, 'epsilon': 1.013764633054648e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 3.664312480889199e-05, 'tol': 0.004661345075284315, 'validation_fraction': 0.6711679847799802}
observation time 0.000003, current best 45.540604 at iter 14
saving meta data: {'args': {'--uuid': '9f6f7a9017f25382b038f11e4e887065', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_050539', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

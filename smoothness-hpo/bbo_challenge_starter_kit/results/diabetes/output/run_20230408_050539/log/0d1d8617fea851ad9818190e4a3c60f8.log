running: {'--uuid': '0d1d8617fea851ad9818190e4a3c60f8', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_050539', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d diabetes -o random-search -u 0d1d8617fea851ad9818190e4a3c60f8 -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230408_050539
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study random-search MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002442 iter 0 next_points [{'alpha': 0.00040426377956868606, 'batch_size': 92, 'beta_1': 0.5273918031667667, 'beta_2': 0.9996888491648752, 'epsilon': 3.307666634754017e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.001374755980972424, 'tol': 0.08402321413637324, 'validation_fraction': 0.1250092407104598}]
function_evaluation time 0.053457 value 28896.952911 suggestion {'alpha': 0.00040426377956868606, 'batch_size': 92, 'beta_1': 0.5273918031667667, 'beta_2': 0.9996888491648752, 'epsilon': 3.307666634754017e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.001374755980972424, 'tol': 0.08402321413637324, 'validation_fraction': 0.1250092407104598}
observation time 0.000005, current best 28896.952911 at iter 0
suggestion time taken 0.002416 iter 1 next_points [{'alpha': 2.5910083221211465e-05, 'batch_size': 217, 'beta_1': 0.8692622052592728, 'beta_2': 0.9999823818140874, 'epsilon': 7.79662271396387e-09, 'hidden_layer_sizes': 191, 'learning_rate_init': 1.116233118176741e-05, 'tol': 0.00018670633809484625, 'validation_fraction': 0.46159968153063136}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.069959 value 29095.324405 suggestion {'alpha': 2.5910083221211465e-05, 'batch_size': 217, 'beta_1': 0.8692622052592728, 'beta_2': 0.9999823818140874, 'epsilon': 7.79662271396387e-09, 'hidden_layer_sizes': 191, 'learning_rate_init': 1.116233118176741e-05, 'tol': 0.00018670633809484625, 'validation_fraction': 0.46159968153063136}
observation time 0.000003, current best 28896.952911 at iter 1
suggestion time taken 0.002463 iter 2 next_points [{'alpha': 1.0314651589283519e-05, 'batch_size': 246, 'beta_1': 0.9776486877394567, 'beta_2': 0.9282854251115413, 'epsilon': 7.654949251776926e-07, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.01833247229656391, 'tol': 0.0010554040407044362, 'validation_fraction': 0.8334769702680808}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.445536 value 4506.046556 suggestion {'alpha': 1.0314651589283519e-05, 'batch_size': 246, 'beta_1': 0.9776486877394567, 'beta_2': 0.9282854251115413, 'epsilon': 7.654949251776926e-07, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.01833247229656391, 'tol': 0.0010554040407044362, 'validation_fraction': 0.8334769702680808}
observation time 0.000004, current best 4506.046556 at iter 2
suggestion time taken 0.002668 iter 3 next_points [{'alpha': 3.005339052164808, 'batch_size': 45, 'beta_1': 0.9107303494679555, 'beta_2': 0.9998609225368168, 'epsilon': 4.079245893961122e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 7.472163155644092e-05, 'tol': 0.008772152573464493, 'validation_fraction': 0.6535419513827688}]
function_evaluation time 0.086236 value 29096.480800 suggestion {'alpha': 3.005339052164808, 'batch_size': 45, 'beta_1': 0.9107303494679555, 'beta_2': 0.9998609225368168, 'epsilon': 4.079245893961122e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 7.472163155644092e-05, 'tol': 0.008772152573464493, 'validation_fraction': 0.6535419513827688}
observation time 0.000004, current best 4506.046556 at iter 3
suggestion time taken 0.002486 iter 4 next_points [{'alpha': 0.017177269942008945, 'batch_size': 136, 'beta_1': 0.6107092527646911, 'beta_2': 0.9999585516696183, 'epsilon': 3.474547055087424e-08, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.0037217738257245172, 'tol': 0.04627043927518163, 'validation_fraction': 0.1596905767390617}]
function_evaluation time 0.044505 value 28778.797004 suggestion {'alpha': 0.017177269942008945, 'batch_size': 136, 'beta_1': 0.6107092527646911, 'beta_2': 0.9999585516696183, 'epsilon': 3.474547055087424e-08, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.0037217738257245172, 'tol': 0.04627043927518163, 'validation_fraction': 0.1596905767390617}
observation time 0.000005, current best 4506.046556 at iter 4
suggestion time taken 0.002653 iter 5 next_points [{'alpha': 0.0010083744359847767, 'batch_size': 185, 'beta_1': 0.5936689591636327, 'beta_2': 0.9999916077433912, 'epsilon': 1.6456455433988006e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0016848161013447635, 'tol': 0.05231167871322763, 'validation_fraction': 0.6026990266573817}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.059473 value 28999.377006 suggestion {'alpha': 0.0010083744359847767, 'batch_size': 185, 'beta_1': 0.5936689591636327, 'beta_2': 0.9999916077433912, 'epsilon': 1.6456455433988006e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0016848161013447635, 'tol': 0.05231167871322763, 'validation_fraction': 0.6026990266573817}
observation time 0.000004, current best 4506.046556 at iter 5
suggestion time taken 0.002400 iter 6 next_points [{'alpha': 0.24250100532886348, 'batch_size': 175, 'beta_1': 0.9022595933184088, 'beta_2': 0.9994119554883728, 'epsilon': 1.2137163636241576e-09, 'hidden_layer_sizes': 118, 'learning_rate_init': 1.543256572635411e-05, 'tol': 0.06363218010113789, 'validation_fraction': 0.5962088305082865}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.054978 value 29112.016540 suggestion {'alpha': 0.24250100532886348, 'batch_size': 175, 'beta_1': 0.9022595933184088, 'beta_2': 0.9994119554883728, 'epsilon': 1.2137163636241576e-09, 'hidden_layer_sizes': 118, 'learning_rate_init': 1.543256572635411e-05, 'tol': 0.06363218010113789, 'validation_fraction': 0.5962088305082865}
observation time 0.000003, current best 4506.046556 at iter 6
suggestion time taken 0.002701 iter 7 next_points [{'alpha': 0.008634662045404334, 'batch_size': 118, 'beta_1': 0.7483438956653659, 'beta_2': 0.9999719929135501, 'epsilon': 4.101070647198567e-09, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.04582315506523614, 'tol': 0.0006326719232346995, 'validation_fraction': 0.6174716051437367}]
function_evaluation time 0.292377 value 3546.785169 suggestion {'alpha': 0.008634662045404334, 'batch_size': 118, 'beta_1': 0.7483438956653659, 'beta_2': 0.9999719929135501, 'epsilon': 4.101070647198567e-09, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.04582315506523614, 'tol': 0.0006326719232346995, 'validation_fraction': 0.6174716051437367}
observation time 0.000003, current best 3546.785169 at iter 7
suggestion time taken 0.002358 iter 8 next_points [{'alpha': 5.1207558419261704e-05, 'batch_size': 169, 'beta_1': 0.936635685088359, 'beta_2': 0.9915980052684317, 'epsilon': 2.4492625620518415e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.00033519276879647575, 'tol': 2.1212240533316524e-05, 'validation_fraction': 0.6632653260536723}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.602652 value 28818.126013 suggestion {'alpha': 5.1207558419261704e-05, 'batch_size': 169, 'beta_1': 0.936635685088359, 'beta_2': 0.9915980052684317, 'epsilon': 2.4492625620518415e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.00033519276879647575, 'tol': 2.1212240533316524e-05, 'validation_fraction': 0.6632653260536723}
observation time 0.000004, current best 3546.785169 at iter 8
suggestion time taken 0.002425 iter 9 next_points [{'alpha': 4.853789276437056, 'batch_size': 134, 'beta_1': 0.9310017799811867, 'beta_2': 0.9933358473800413, 'epsilon': 2.40219744840217e-07, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.002039353540689376, 'tol': 0.010108638902323188, 'validation_fraction': 0.7333980413652171}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.058341 value 28981.851258 suggestion {'alpha': 4.853789276437056, 'batch_size': 134, 'beta_1': 0.9310017799811867, 'beta_2': 0.9933358473800413, 'epsilon': 2.40219744840217e-07, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.002039353540689376, 'tol': 0.010108638902323188, 'validation_fraction': 0.7333980413652171}
observation time 0.000004, current best 3546.785169 at iter 9
suggestion time taken 0.002366 iter 10 next_points [{'alpha': 1.8791981613427329, 'batch_size': 15, 'beta_1': 0.8587011173206863, 'beta_2': 0.9999275166162274, 'epsilon': 8.635471968830917e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.0036414588267244443, 'tol': 0.00026137608785685467, 'validation_fraction': 0.6373646108812614}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.367997 value 3447.835881 suggestion {'alpha': 1.8791981613427329, 'batch_size': 15, 'beta_1': 0.8587011173206863, 'beta_2': 0.9999275166162274, 'epsilon': 8.635471968830917e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.0036414588267244443, 'tol': 0.00026137608785685467, 'validation_fraction': 0.6373646108812614}
observation time 0.000003, current best 3447.835881 at iter 10
suggestion time taken 0.002440 iter 11 next_points [{'alpha': 1.527717390079017e-05, 'batch_size': 231, 'beta_1': 0.979843695009609, 'beta_2': 0.999374163981735, 'epsilon': 7.649199268105164e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.006446690419716657, 'tol': 1.2162135283392917e-05, 'validation_fraction': 0.1262039933776137}]
function_evaluation time 0.832356 value 4162.055418 suggestion {'alpha': 1.527717390079017e-05, 'batch_size': 231, 'beta_1': 0.979843695009609, 'beta_2': 0.999374163981735, 'epsilon': 7.649199268105164e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.006446690419716657, 'tol': 1.2162135283392917e-05, 'validation_fraction': 0.1262039933776137}
observation time 0.000004, current best 3447.835881 at iter 11
suggestion time taken 0.002389 iter 12 next_points [{'alpha': 5.224851897295489e-05, 'batch_size': 123, 'beta_1': 0.9261633247832285, 'beta_2': 0.9998393377929617, 'epsilon': 1.0188307421808932e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.001706260629492723, 'tol': 0.005721676565297703, 'validation_fraction': 0.32634247956247453}]
function_evaluation time 0.068875 value 28971.232760 suggestion {'alpha': 5.224851897295489e-05, 'batch_size': 123, 'beta_1': 0.9261633247832285, 'beta_2': 0.9998393377929617, 'epsilon': 1.0188307421808932e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.001706260629492723, 'tol': 0.005721676565297703, 'validation_fraction': 0.32634247956247453}
observation time 0.000004, current best 3447.835881 at iter 12
suggestion time taken 0.002662 iter 13 next_points [{'alpha': 0.036410007302766056, 'batch_size': 73, 'beta_1': 0.9616089715555534, 'beta_2': 0.9795573774049982, 'epsilon': 1.9763098098113574e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 4.6476449250358824e-05, 'tol': 0.018597486605786404, 'validation_fraction': 0.1262956096067114}]
function_evaluation time 0.063456 value 29056.844444 suggestion {'alpha': 0.036410007302766056, 'batch_size': 73, 'beta_1': 0.9616089715555534, 'beta_2': 0.9795573774049982, 'epsilon': 1.9763098098113574e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 4.6476449250358824e-05, 'tol': 0.018597486605786404, 'validation_fraction': 0.1262956096067114}
observation time 0.000004, current best 3447.835881 at iter 13
suggestion time taken 0.002385 iter 14 next_points [{'alpha': 0.07999310013357759, 'batch_size': 166, 'beta_1': 0.9887598924914994, 'beta_2': 0.9999710351087624, 'epsilon': 6.856378648582292e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 3.9246136005546475e-05, 'tol': 1.5937237992432636e-05, 'validation_fraction': 0.5527893202620877}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.886951 value 29068.510102 suggestion {'alpha': 0.07999310013357759, 'batch_size': 166, 'beta_1': 0.9887598924914994, 'beta_2': 0.9999710351087624, 'epsilon': 6.856378648582292e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 3.9246136005546475e-05, 'tol': 1.5937237992432636e-05, 'validation_fraction': 0.5527893202620877}
observation time 0.000003, current best 3447.835881 at iter 14
saving meta data: {'args': {'--uuid': '0d1d8617fea851ad9818190e4a3c60f8', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_050539', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

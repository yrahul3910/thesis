running: {'--uuid': 'c841557ae215504b99e2faedd7b5748c', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_050539', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d diabetes -o random-search -u c841557ae215504b99e2faedd7b5748c -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230408_050539
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study random-search MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002408 iter 0 next_points [{'alpha': 0.0011459152739607351, 'batch_size': 216, 'beta_1': 0.9721533331897664, 'beta_2': 0.9999587267338537, 'epsilon': 8.868770674340078e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.00580004643936051, 'tol': 0.03672959599988012, 'validation_fraction': 0.2996321624491668}]
function_evaluation time 0.056668 value 28876.732831 suggestion {'alpha': 0.0011459152739607351, 'batch_size': 216, 'beta_1': 0.9721533331897664, 'beta_2': 0.9999587267338537, 'epsilon': 8.868770674340078e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.00580004643936051, 'tol': 0.03672959599988012, 'validation_fraction': 0.2996321624491668}
observation time 0.000005, current best 28876.732831 at iter 0
suggestion time taken 0.002420 iter 1 next_points [{'alpha': 0.0004538744441103546, 'batch_size': 232, 'beta_1': 0.6371660929064519, 'beta_2': 0.9930619131526224, 'epsilon': 4.039055292223249e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 2.0052273282672236e-05, 'tol': 0.007311808479525159, 'validation_fraction': 0.7288523867661444}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.051852 value 29081.766463 suggestion {'alpha': 0.0004538744441103546, 'batch_size': 232, 'beta_1': 0.6371660929064519, 'beta_2': 0.9930619131526224, 'epsilon': 4.039055292223249e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 2.0052273282672236e-05, 'tol': 0.007311808479525159, 'validation_fraction': 0.7288523867661444}
observation time 0.000004, current best 28876.732831 at iter 1
suggestion time taken 0.002448 iter 2 next_points [{'alpha': 0.00037515843892802186, 'batch_size': 161, 'beta_1': 0.9019793636250484, 'beta_2': 0.999379768695313, 'epsilon': 1.293189766611996e-08, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0588838223874617, 'tol': 9.996537790073183e-05, 'validation_fraction': 0.8299257253952551}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.252267 value 3708.282319 suggestion {'alpha': 0.00037515843892802186, 'batch_size': 161, 'beta_1': 0.9019793636250484, 'beta_2': 0.999379768695313, 'epsilon': 1.293189766611996e-08, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0588838223874617, 'tol': 9.996537790073183e-05, 'validation_fraction': 0.8299257253952551}
observation time 0.000005, current best 3708.282319 at iter 2
suggestion time taken 0.002567 iter 3 next_points [{'alpha': 0.00022946403425423177, 'batch_size': 14, 'beta_1': 0.9744278299425418, 'beta_2': 0.9989950601083769, 'epsilon': 7.601466684936334e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0028073698701655578, 'tol': 0.0009232134953923754, 'validation_fraction': 0.41133825891775794}]
function_evaluation time 2.353440 value 3152.067404 suggestion {'alpha': 0.00022946403425423177, 'batch_size': 14, 'beta_1': 0.9744278299425418, 'beta_2': 0.9989950601083769, 'epsilon': 7.601466684936334e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0028073698701655578, 'tol': 0.0009232134953923754, 'validation_fraction': 0.41133825891775794}
observation time 0.000004, current best 3152.067404 at iter 3
suggestion time taken 0.002593 iter 4 next_points [{'alpha': 5.860387050578855e-05, 'batch_size': 36, 'beta_1': 0.9498007488980567, 'beta_2': 0.9998251057771407, 'epsilon': 5.340161749889223e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.00022035752420506883, 'tol': 0.0011022808977669482, 'validation_fraction': 0.6687795485091353}]
function_evaluation time 0.083364 value 29098.627160 suggestion {'alpha': 5.860387050578855e-05, 'batch_size': 36, 'beta_1': 0.9498007488980567, 'beta_2': 0.9998251057771407, 'epsilon': 5.340161749889223e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.00022035752420506883, 'tol': 0.0011022808977669482, 'validation_fraction': 0.6687795485091353}
observation time 0.000005, current best 3152.067404 at iter 4
suggestion time taken 0.002673 iter 5 next_points [{'alpha': 1.2558683038231377e-05, 'batch_size': 42, 'beta_1': 0.7590375712541689, 'beta_2': 0.9995563520052396, 'epsilon': 3.7492623336869177e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.00024394821345074676, 'tol': 0.0006472263178950025, 'validation_fraction': 0.35686333334199694}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.702466 value 26430.703911 suggestion {'alpha': 1.2558683038231377e-05, 'batch_size': 42, 'beta_1': 0.7590375712541689, 'beta_2': 0.9995563520052396, 'epsilon': 3.7492623336869177e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.00024394821345074676, 'tol': 0.0006472263178950025, 'validation_fraction': 0.35686333334199694}
observation time 0.000005, current best 3152.067404 at iter 5
suggestion time taken 0.002452 iter 6 next_points [{'alpha': 1.4998053823246503e-05, 'batch_size': 29, 'beta_1': 0.848359725627535, 'beta_2': 0.9999952029037911, 'epsilon': 4.7023404633132573e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.05888975537759057, 'tol': 0.0004184926681495905, 'validation_fraction': 0.7451950098084}]
function_evaluation time 0.363657 value 3026.778551 suggestion {'alpha': 1.4998053823246503e-05, 'batch_size': 29, 'beta_1': 0.848359725627535, 'beta_2': 0.9999952029037911, 'epsilon': 4.7023404633132573e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.05888975537759057, 'tol': 0.0004184926681495905, 'validation_fraction': 0.7451950098084}
observation time 0.000004, current best 3026.778551 at iter 6
suggestion time taken 0.002517 iter 7 next_points [{'alpha': 0.009080918249020268, 'batch_size': 22, 'beta_1': 0.9701539441767618, 'beta_2': 0.9999898558789896, 'epsilon': 9.85242558578302e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 4.92461765267476e-05, 'tol': 0.006669360066723128, 'validation_fraction': 0.3372957094396901}]
function_evaluation time 0.111652 value 29124.564486 suggestion {'alpha': 0.009080918249020268, 'batch_size': 22, 'beta_1': 0.9701539441767618, 'beta_2': 0.9999898558789896, 'epsilon': 9.85242558578302e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 4.92461765267476e-05, 'tol': 0.006669360066723128, 'validation_fraction': 0.3372957094396901}
observation time 0.000003, current best 3026.778551 at iter 7
suggestion time taken 0.002578 iter 8 next_points [{'alpha': 0.7399074377454635, 'batch_size': 81, 'beta_1': 0.985464919220462, 'beta_2': 0.9998000923912286, 'epsilon': 2.297962401149434e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0002997423626547036, 'tol': 1.0647836966242763e-05, 'validation_fraction': 0.48785218445329104}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.260157 value 28198.467524 suggestion {'alpha': 0.7399074377454635, 'batch_size': 81, 'beta_1': 0.985464919220462, 'beta_2': 0.9998000923912286, 'epsilon': 2.297962401149434e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0002997423626547036, 'tol': 1.0647836966242763e-05, 'validation_fraction': 0.48785218445329104}
observation time 0.000004, current best 3026.778551 at iter 8
suggestion time taken 0.002482 iter 9 next_points [{'alpha': 0.004763002883040457, 'batch_size': 146, 'beta_1': 0.9619883598444126, 'beta_2': 0.9999765344376836, 'epsilon': 1.64408444674675e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 5.6354627238714035e-05, 'tol': 0.0030848147363853494, 'validation_fraction': 0.5823397995913515}]
function_evaluation time 0.049552 value 29178.013603 suggestion {'alpha': 0.004763002883040457, 'batch_size': 146, 'beta_1': 0.9619883598444126, 'beta_2': 0.9999765344376836, 'epsilon': 1.64408444674675e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 5.6354627238714035e-05, 'tol': 0.0030848147363853494, 'validation_fraction': 0.5823397995913515}
observation time 0.000003, current best 3026.778551 at iter 9
suggestion time taken 0.002486 iter 10 next_points [{'alpha': 0.0011900011197637185, 'batch_size': 176, 'beta_1': 0.7611180574515334, 'beta_2': 0.9840742149451609, 'epsilon': 2.1426519131105847e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.00016037338752377265, 'tol': 0.036733034728200796, 'validation_fraction': 0.8733076955029355}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.053890 value 29132.408721 suggestion {'alpha': 0.0011900011197637185, 'batch_size': 176, 'beta_1': 0.7611180574515334, 'beta_2': 0.9840742149451609, 'epsilon': 2.1426519131105847e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.00016037338752377265, 'tol': 0.036733034728200796, 'validation_fraction': 0.8733076955029355}
observation time 0.000005, current best 3026.778551 at iter 10
suggestion time taken 0.002460 iter 11 next_points [{'alpha': 8.395081609709218, 'batch_size': 111, 'beta_1': 0.8215397275645765, 'beta_2': 0.9695211447171179, 'epsilon': 6.632787918724109e-09, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.00042446893076831117, 'tol': 1.3885803966911874e-05, 'validation_fraction': 0.11188479243671783}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.575087 value 26636.649813 suggestion {'alpha': 8.395081609709218, 'batch_size': 111, 'beta_1': 0.8215397275645765, 'beta_2': 0.9695211447171179, 'epsilon': 6.632787918724109e-09, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.00042446893076831117, 'tol': 1.3885803966911874e-05, 'validation_fraction': 0.11188479243671783}
observation time 0.000005, current best 3026.778551 at iter 11
suggestion time taken 0.002425 iter 12 next_points [{'alpha': 0.15909735981712683, 'batch_size': 110, 'beta_1': 0.9263998722924657, 'beta_2': 0.9999984242356367, 'epsilon': 1.2728871345992673e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0001865888151919121, 'tol': 0.005871247735114974, 'validation_fraction': 0.8722002724610225}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.055949 value 29148.821056 suggestion {'alpha': 0.15909735981712683, 'batch_size': 110, 'beta_1': 0.9263998722924657, 'beta_2': 0.9999984242356367, 'epsilon': 1.2728871345992673e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0001865888151919121, 'tol': 0.005871247735114974, 'validation_fraction': 0.8722002724610225}
observation time 0.000004, current best 3026.778551 at iter 12
suggestion time taken 0.002496 iter 13 next_points [{'alpha': 0.0013894077971488593, 'batch_size': 145, 'beta_1': 0.6866119511392941, 'beta_2': 0.9998278973893023, 'epsilon': 4.359955446525153e-09, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.021853870656932037, 'tol': 0.05803330247125286, 'validation_fraction': 0.4885184254161291}]
function_evaluation time 0.089631 value 26883.807421 suggestion {'alpha': 0.0013894077971488593, 'batch_size': 145, 'beta_1': 0.6866119511392941, 'beta_2': 0.9998278973893023, 'epsilon': 4.359955446525153e-09, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.021853870656932037, 'tol': 0.05803330247125286, 'validation_fraction': 0.4885184254161291}
observation time 0.000003, current best 3026.778551 at iter 13
suggestion time taken 0.002457 iter 14 next_points [{'alpha': 4.971141499074859e-05, 'batch_size': 158, 'beta_1': 0.9772380768831307, 'beta_2': 0.9977082870426327, 'epsilon': 1.5844754148565618e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.006683352240571778, 'tol': 7.583886479349714e-05, 'validation_fraction': 0.8135798291244221}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.555318 value 14490.531573 suggestion {'alpha': 4.971141499074859e-05, 'batch_size': 158, 'beta_1': 0.9772380768831307, 'beta_2': 0.9977082870426327, 'epsilon': 1.5844754148565618e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.006683352240571778, 'tol': 7.583886479349714e-05, 'validation_fraction': 0.8135798291244221}
observation time 0.000004, current best 3026.778551 at iter 14
saving meta data: {'args': {'--uuid': 'c841557ae215504b99e2faedd7b5748c', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_050539', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

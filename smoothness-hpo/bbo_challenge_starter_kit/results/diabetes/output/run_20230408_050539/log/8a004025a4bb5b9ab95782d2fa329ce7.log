running: {'--uuid': '8a004025a4bb5b9ab95782d2fa329ce7', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_050539', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d diabetes -o hyperopt -u 8a004025a4bb5b9ab95782d2fa329ce7 -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230408_050539
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study hyperopt MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002315 iter 0 next_points [{'alpha': 0.30207676293853153, 'batch_size': 200, 'beta_1': 0.8662020956578359, 'beta_2': 0.9569054598823867, 'epsilon': 2.6431678508819636e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.0004582213923159154, 'tol': 0.004633236163357148, 'validation_fraction': 0.25996929166113236}]
function_evaluation time 0.137179 value 29018.057713 suggestion {'alpha': 0.30207676293853153, 'batch_size': 200, 'beta_1': 0.8662020956578359, 'beta_2': 0.9569054598823867, 'epsilon': 2.6431678508819636e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.0004582213923159154, 'tol': 0.004633236163357148, 'validation_fraction': 0.25996929166113236}
observation time 0.000066, current best 29018.057713 at iter 0
suggestion time taken 0.002164 iter 1 next_points [{'alpha': 0.047283135771259865, 'batch_size': 242, 'beta_1': 0.8233743978586529, 'beta_2': 0.9398659018367677, 'epsilon': 4.990107213145559e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.003197518662138595, 'tol': 0.05458092949258511, 'validation_fraction': 0.3395477968828737}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.060987 value 28972.096351 suggestion {'alpha': 0.047283135771259865, 'batch_size': 242, 'beta_1': 0.8233743978586529, 'beta_2': 0.9398659018367677, 'epsilon': 4.990107213145559e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.003197518662138595, 'tol': 0.05458092949258511, 'validation_fraction': 0.3395477968828737}
observation time 0.000069, current best 28972.096351 at iter 1
suggestion time taken 0.002133 iter 2 next_points [{'alpha': 0.9188196003421916, 'batch_size': 176, 'beta_1': 0.5226526799234131, 'beta_2': 0.9767140378455968, 'epsilon': 1.3466694045911344e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 5.7401167560843755e-05, 'tol': 0.015937763160143753, 'validation_fraction': 0.7827150207406691}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.056385 value 29106.323741 suggestion {'alpha': 0.9188196003421916, 'batch_size': 176, 'beta_1': 0.5226526799234131, 'beta_2': 0.9767140378455968, 'epsilon': 1.3466694045911344e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 5.7401167560843755e-05, 'tol': 0.015937763160143753, 'validation_fraction': 0.7827150207406691}
observation time 0.000073, current best 28972.096351 at iter 2
suggestion time taken 0.002148 iter 3 next_points [{'alpha': 0.004338027256786189, 'batch_size': 149, 'beta_1': 0.7268685539854071, 'beta_2': 0.9054561674383903, 'epsilon': 3.0356919015349363e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.030017296794223505, 'tol': 0.00026729957942188566, 'validation_fraction': 0.6659559933616227}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.543057 value 3111.504518 suggestion {'alpha': 0.004338027256786189, 'batch_size': 149, 'beta_1': 0.7268685539854071, 'beta_2': 0.9054561674383903, 'epsilon': 3.0356919015349363e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.030017296794223505, 'tol': 0.00026729957942188566, 'validation_fraction': 0.6659559933616227}
observation time 0.000070, current best 3111.504518 at iter 3
suggestion time taken 0.002164 iter 4 next_points [{'alpha': 0.0003798079095841857, 'batch_size': 58, 'beta_1': 0.9421322523359861, 'beta_2': 0.91406041072624, 'epsilon': 1.874960427083712e-09, 'hidden_layer_sizes': 117, 'learning_rate_init': 3.5214239816378384e-05, 'tol': 0.00028069779304862303, 'validation_fraction': 0.13511461873279337}]
function_evaluation time 0.076175 value 29092.599577 suggestion {'alpha': 0.0003798079095841857, 'batch_size': 58, 'beta_1': 0.9421322523359861, 'beta_2': 0.91406041072624, 'epsilon': 1.874960427083712e-09, 'hidden_layer_sizes': 117, 'learning_rate_init': 3.5214239816378384e-05, 'tol': 0.00028069779304862303, 'validation_fraction': 0.13511461873279337}
observation time 0.000070, current best 3111.504518 at iter 4
suggestion time taken 0.002343 iter 5 next_points [{'alpha': 0.000350421006838273, 'batch_size': 142, 'beta_1': 0.5808557161738628, 'beta_2': 0.9407540502676751, 'epsilon': 1.409173190207381e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.0004385714812382692, 'tol': 6.180579132442548e-05, 'validation_fraction': 0.19258591645636258}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.391665 value 27675.896923 suggestion {'alpha': 0.000350421006838273, 'batch_size': 142, 'beta_1': 0.5808557161738628, 'beta_2': 0.9407540502676751, 'epsilon': 1.409173190207381e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.0004385714812382692, 'tol': 6.180579132442548e-05, 'validation_fraction': 0.19258591645636258}
observation time 0.000072, current best 3111.504518 at iter 5
suggestion time taken 0.002171 iter 6 next_points [{'alpha': 2.5788939021325863e-05, 'batch_size': 164, 'beta_1': 0.8534146818618381, 'beta_2': 0.9515374515365588, 'epsilon': 4.8379334374711686e-08, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.00011390828782144552, 'tol': 0.0028700021006735914, 'validation_fraction': 0.10054803255292238}]
function_evaluation time 0.093798 value 29113.947451 suggestion {'alpha': 2.5788939021325863e-05, 'batch_size': 164, 'beta_1': 0.8534146818618381, 'beta_2': 0.9515374515365588, 'epsilon': 4.8379334374711686e-08, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.00011390828782144552, 'tol': 0.0028700021006735914, 'validation_fraction': 0.10054803255292238}
observation time 0.000072, current best 3111.504518 at iter 6
suggestion time taken 0.002326 iter 7 next_points [{'alpha': 0.05495961375802992, 'batch_size': 85, 'beta_1': 0.860988766843274, 'beta_2': 0.9482936633514261, 'epsilon': 7.391908943238018e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.0027815200450646465, 'tol': 0.01704215957136708, 'validation_fraction': 0.10445281132138313}]
function_evaluation time 0.111905 value 28413.352080 suggestion {'alpha': 0.05495961375802992, 'batch_size': 85, 'beta_1': 0.860988766843274, 'beta_2': 0.9482936633514261, 'epsilon': 7.391908943238018e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.0027815200450646465, 'tol': 0.01704215957136708, 'validation_fraction': 0.10445281132138313}
observation time 0.000076, current best 3111.504518 at iter 7
suggestion time taken 0.002153 iter 8 next_points [{'alpha': 8.583985710289928, 'batch_size': 135, 'beta_1': 0.9538562726388125, 'beta_2': 0.9997368218677322, 'epsilon': 1.532336564725405e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 6.076714363845597e-05, 'tol': 9.2666021547695e-05, 'validation_fraction': 0.6941835060486449}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.056230 value 29118.680517 suggestion {'alpha': 8.583985710289928, 'batch_size': 135, 'beta_1': 0.9538562726388125, 'beta_2': 0.9997368218677322, 'epsilon': 1.532336564725405e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 6.076714363845597e-05, 'tol': 9.2666021547695e-05, 'validation_fraction': 0.6941835060486449}
observation time 0.000075, current best 3111.504518 at iter 8
suggestion time taken 0.002153 iter 9 next_points [{'alpha': 0.15391488970415287, 'batch_size': 74, 'beta_1': 0.9840742724599307, 'beta_2': 0.9577897406485498, 'epsilon': 1.010134968509628e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 4.054346787314661e-05, 'tol': 0.006643751919154337, 'validation_fraction': 0.10613909051929808}]
function_evaluation time 0.063441 value 29121.128329 suggestion {'alpha': 0.15391488970415287, 'batch_size': 74, 'beta_1': 0.9840742724599307, 'beta_2': 0.9577897406485498, 'epsilon': 1.010134968509628e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 4.054346787314661e-05, 'tol': 0.006643751919154337, 'validation_fraction': 0.10613909051929808}
observation time 0.000068, current best 3111.504518 at iter 9
suggestion time taken 0.002178 iter 10 next_points [{'alpha': 0.30296862827376175, 'batch_size': 202, 'beta_1': 0.6121128180896923, 'beta_2': 0.9896785446594042, 'epsilon': 1.2512174042637699e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.009618724411408146, 'tol': 0.00013298689621678772, 'validation_fraction': 0.24529409174402403}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.134480 value 3163.971602 suggestion {'alpha': 0.30296862827376175, 'batch_size': 202, 'beta_1': 0.6121128180896923, 'beta_2': 0.9896785446594042, 'epsilon': 1.2512174042637699e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.009618724411408146, 'tol': 0.00013298689621678772, 'validation_fraction': 0.24529409174402403}
observation time 0.000074, current best 3111.504518 at iter 10
suggestion time taken 0.002163 iter 11 next_points [{'alpha': 0.5555423615602444, 'batch_size': 166, 'beta_1': 0.9288166421327497, 'beta_2': 0.9074768482290203, 'epsilon': 1.4014268369768529e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.007919503285659848, 'tol': 1.0743837040900062e-05, 'validation_fraction': 0.6127442681348421}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.642668 value 10363.489649 suggestion {'alpha': 0.5555423615602444, 'batch_size': 166, 'beta_1': 0.9288166421327497, 'beta_2': 0.9074768482290203, 'epsilon': 1.4014268369768529e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.007919503285659848, 'tol': 1.0743837040900062e-05, 'validation_fraction': 0.6127442681348421}
observation time 0.000077, current best 3111.504518 at iter 11
suggestion time taken 0.002174 iter 12 next_points [{'alpha': 0.24760667748449486, 'batch_size': 164, 'beta_1': 0.610985231191889, 'beta_2': 0.9783239559328414, 'epsilon': 1.0058421715541426e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.00032185368611901575, 'tol': 0.040442437785516046, 'validation_fraction': 0.5812629243106489}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.053644 value 29083.485935 suggestion {'alpha': 0.24760667748449486, 'batch_size': 164, 'beta_1': 0.610985231191889, 'beta_2': 0.9783239559328414, 'epsilon': 1.0058421715541426e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.00032185368611901575, 'tol': 0.040442437785516046, 'validation_fraction': 0.5812629243106489}
observation time 0.000083, current best 3111.504518 at iter 12
suggestion time taken 0.002169 iter 13 next_points [{'alpha': 0.017700379799638382, 'batch_size': 62, 'beta_1': 0.7750362013042759, 'beta_2': 0.9630528199181604, 'epsilon': 1.212652233186672e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0035992410007087182, 'tol': 0.009659522458876963, 'validation_fraction': 0.22294780861396554}]
function_evaluation time 0.862547 value 4125.074429 suggestion {'alpha': 0.017700379799638382, 'batch_size': 62, 'beta_1': 0.7750362013042759, 'beta_2': 0.9630528199181604, 'epsilon': 1.212652233186672e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0035992410007087182, 'tol': 0.009659522458876963, 'validation_fraction': 0.22294780861396554}
observation time 0.000069, current best 3111.504518 at iter 13
suggestion time taken 0.002141 iter 14 next_points [{'alpha': 0.14766618644433926, 'batch_size': 81, 'beta_1': 0.9751290589994523, 'beta_2': 0.9823326471207569, 'epsilon': 5.0744387032566467e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.07306425462940092, 'tol': 0.004650365674433281, 'validation_fraction': 0.2704752935459166}]
function_evaluation time 0.255290 value 3296.386691 suggestion {'alpha': 0.14766618644433926, 'batch_size': 81, 'beta_1': 0.9751290589994523, 'beta_2': 0.9823326471207569, 'epsilon': 5.0744387032566467e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.07306425462940092, 'tol': 0.004650365674433281, 'validation_fraction': 0.2704752935459166}
observation time 0.000075, current best 3111.504518 at iter 14
saving meta data: {'args': {'--uuid': '8a004025a4bb5b9ab95782d2fa329ce7', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_050539', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': 'f9dbf0ae03d758b19f82e043d4db637d', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_005909', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d breast -o hyperopt -u f9dbf0ae03d758b19f82e043d4db637d -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_005909
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_acc betwen [-0.80659341 -0.56703297 -0.66593407 -0.87912088 -0.85934066] and [-0.67692308 -0.41758242 -0.54505495 -0.78241758 -0.84395604]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_breast_acc  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
max                  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
starting sklearn study hyperopt MLP-adam breast acc 15 1
with data root: None
suggestion time taken 0.002420 iter 0 next_points [{'alpha': 6.18107174113324e-05, 'batch_size': 147, 'beta_1': 0.9889985001015413, 'beta_2': 0.9939179300475618, 'epsilon': 8.130186564606624e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.01743297262926097, 'tol': 2.359026038193888e-05, 'validation_fraction': 0.726331919424393}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.173836 value -0.903297 suggestion {'alpha': 6.18107174113324e-05, 'batch_size': 147, 'beta_1': 0.9889985001015413, 'beta_2': 0.9939179300475618, 'epsilon': 8.130186564606624e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.01743297262926097, 'tol': 2.359026038193888e-05, 'validation_fraction': 0.726331919424393}
observation time 0.000062, current best -0.903297 at iter 0
suggestion time taken 0.002365 iter 1 next_points [{'alpha': 0.017883244689227976, 'batch_size': 121, 'beta_1': 0.7020107267866582, 'beta_2': 0.9645084820836045, 'epsilon': 8.89356845609289e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 5.7313110056344096e-05, 'tol': 0.00018433890308565282, 'validation_fraction': 0.6448291791223868}]
function_evaluation time 0.233102 value -0.584615 suggestion {'alpha': 0.017883244689227976, 'batch_size': 121, 'beta_1': 0.7020107267866582, 'beta_2': 0.9645084820836045, 'epsilon': 8.89356845609289e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 5.7313110056344096e-05, 'tol': 0.00018433890308565282, 'validation_fraction': 0.6448291791223868}
observation time 0.000060, current best -0.903297 at iter 1
suggestion time taken 0.002315 iter 2 next_points [{'alpha': 2.2108525739928838e-05, 'batch_size': 239, 'beta_1': 0.8753159524571816, 'beta_2': 0.9461894345281181, 'epsilon': 8.884456062297834e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 2.7424201083278846e-05, 'tol': 1.950044385465338e-05, 'validation_fraction': 0.2631100967777914}]
function_evaluation time 0.124150 value -0.417582 suggestion {'alpha': 2.2108525739928838e-05, 'batch_size': 239, 'beta_1': 0.8753159524571816, 'beta_2': 0.9461894345281181, 'epsilon': 8.884456062297834e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 2.7424201083278846e-05, 'tol': 1.950044385465338e-05, 'validation_fraction': 0.2631100967777914}
observation time 0.000061, current best -0.903297 at iter 2
suggestion time taken 0.002110 iter 3 next_points [{'alpha': 5.26881991761114e-05, 'batch_size': 35, 'beta_1': 0.6146743390759237, 'beta_2': 0.9794111493118306, 'epsilon': 4.4399420590801164e-07, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.03909774725791442, 'tol': 0.003798183418913205, 'validation_fraction': 0.32393237036511785}]
function_evaluation time 0.390567 value -0.890110 suggestion {'alpha': 5.26881991761114e-05, 'batch_size': 35, 'beta_1': 0.6146743390759237, 'beta_2': 0.9794111493118306, 'epsilon': 4.4399420590801164e-07, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.03909774725791442, 'tol': 0.003798183418913205, 'validation_fraction': 0.32393237036511785}
observation time 0.000061, current best -0.903297 at iter 3
suggestion time taken 0.002117 iter 4 next_points [{'alpha': 0.33275327043069275, 'batch_size': 179, 'beta_1': 0.6000468982498004, 'beta_2': 0.9930508796354774, 'epsilon': 1.2962786662161577e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 5.9427371873634946e-05, 'tol': 4.471805967988695e-05, 'validation_fraction': 0.23245132949051533}]
function_evaluation time 0.159679 value -0.472527 suggestion {'alpha': 0.33275327043069275, 'batch_size': 179, 'beta_1': 0.6000468982498004, 'beta_2': 0.9930508796354774, 'epsilon': 1.2962786662161577e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 5.9427371873634946e-05, 'tol': 4.471805967988695e-05, 'validation_fraction': 0.23245132949051533}
observation time 0.000057, current best -0.903297 at iter 4
suggestion time taken 0.002100 iter 5 next_points [{'alpha': 1.191298864721186e-05, 'batch_size': 86, 'beta_1': 0.8287166945948753, 'beta_2': 0.9391858666252066, 'epsilon': 2.000167613380338e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.002333953929262654, 'tol': 0.012163806373176522, 'validation_fraction': 0.6085794719636307}]
function_evaluation time 0.207828 value -0.903297 suggestion {'alpha': 1.191298864721186e-05, 'batch_size': 86, 'beta_1': 0.8287166945948753, 'beta_2': 0.9391858666252066, 'epsilon': 2.000167613380338e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.002333953929262654, 'tol': 0.012163806373176522, 'validation_fraction': 0.6085794719636307}
observation time 0.000058, current best -0.903297 at iter 5
suggestion time taken 0.002073 iter 6 next_points [{'alpha': 1.4800836785092453, 'batch_size': 202, 'beta_1': 0.7759886352523814, 'beta_2': 0.9282422355601683, 'epsilon': 6.306733237378198e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 7.897882480144077e-05, 'tol': 0.057977736624062366, 'validation_fraction': 0.20928934894691076}]
function_evaluation time 0.176638 value -0.591209 suggestion {'alpha': 1.4800836785092453, 'batch_size': 202, 'beta_1': 0.7759886352523814, 'beta_2': 0.9282422355601683, 'epsilon': 6.306733237378198e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 7.897882480144077e-05, 'tol': 0.057977736624062366, 'validation_fraction': 0.20928934894691076}
observation time 0.000075, current best -0.903297 at iter 6
suggestion time taken 0.002176 iter 7 next_points [{'alpha': 0.4062611805464891, 'batch_size': 168, 'beta_1': 0.7230739255035682, 'beta_2': 0.9177812664454823, 'epsilon': 2.965975239641752e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 8.438643210693146e-05, 'tol': 0.05842880920980643, 'validation_fraction': 0.7380488014121488}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.093588 value -0.417582 suggestion {'alpha': 0.4062611805464891, 'batch_size': 168, 'beta_1': 0.7230739255035682, 'beta_2': 0.9177812664454823, 'epsilon': 2.965975239641752e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 8.438643210693146e-05, 'tol': 0.05842880920980643, 'validation_fraction': 0.7380488014121488}
observation time 0.000073, current best -0.903297 at iter 7
suggestion time taken 0.002153 iter 8 next_points [{'alpha': 0.21491754059208784, 'batch_size': 70, 'beta_1': 0.5861258910807662, 'beta_2': 0.9036576764894976, 'epsilon': 1.2115378434257248e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0003174149966013114, 'tol': 3.772842381603955e-05, 'validation_fraction': 0.21309856091231175}]
function_evaluation time 0.242696 value -0.767033 suggestion {'alpha': 0.21491754059208784, 'batch_size': 70, 'beta_1': 0.5861258910807662, 'beta_2': 0.9036576764894976, 'epsilon': 1.2115378434257248e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0003174149966013114, 'tol': 3.772842381603955e-05, 'validation_fraction': 0.21309856091231175}
observation time 0.000079, current best -0.903297 at iter 8
suggestion time taken 0.002146 iter 9 next_points [{'alpha': 1.2223950546718323, 'batch_size': 249, 'beta_1': 0.7975673584724119, 'beta_2': 0.9100932653593781, 'epsilon': 1.66083809780721e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.002625129415233533, 'tol': 1.9508557735697236e-05, 'validation_fraction': 0.35679498706872126}]
function_evaluation time 0.281865 value -0.905495 suggestion {'alpha': 1.2223950546718323, 'batch_size': 249, 'beta_1': 0.7975673584724119, 'beta_2': 0.9100932653593781, 'epsilon': 1.66083809780721e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.002625129415233533, 'tol': 1.9508557735697236e-05, 'validation_fraction': 0.35679498706872126}
observation time 0.000057, current best -0.905495 at iter 9
suggestion time taken 0.002096 iter 10 next_points [{'alpha': 0.2895283942738643, 'batch_size': 114, 'beta_1': 0.7298607011944259, 'beta_2': 0.9316312423404775, 'epsilon': 2.129034955455313e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.0001607960760930668, 'tol': 0.0015796346276347303, 'validation_fraction': 0.23092760851088184}]
function_evaluation time 0.171671 value -0.690110 suggestion {'alpha': 0.2895283942738643, 'batch_size': 114, 'beta_1': 0.7298607011944259, 'beta_2': 0.9316312423404775, 'epsilon': 2.129034955455313e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.0001607960760930668, 'tol': 0.0015796346276347303, 'validation_fraction': 0.23092760851088184}
observation time 0.000061, current best -0.905495 at iter 10
suggestion time taken 0.002282 iter 11 next_points [{'alpha': 0.027283204256088097, 'batch_size': 219, 'beta_1': 0.970052361232299, 'beta_2': 0.9678307334965519, 'epsilon': 1.6234198959270906e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.025917471912114347, 'tol': 5.239804804990053e-05, 'validation_fraction': 0.11830012716371453}]
function_evaluation time 0.197748 value -0.863736 suggestion {'alpha': 0.027283204256088097, 'batch_size': 219, 'beta_1': 0.970052361232299, 'beta_2': 0.9678307334965519, 'epsilon': 1.6234198959270906e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.025917471912114347, 'tol': 5.239804804990053e-05, 'validation_fraction': 0.11830012716371453}
observation time 0.000061, current best -0.905495 at iter 11
suggestion time taken 0.002156 iter 12 next_points [{'alpha': 0.028362169528627027, 'batch_size': 217, 'beta_1': 0.7539194939247386, 'beta_2': 0.9956800821368451, 'epsilon': 8.302066831680152e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.0012232609205827419, 'tol': 0.0002411694596383515, 'validation_fraction': 0.5734121279055029}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.284224 value -0.852747 suggestion {'alpha': 0.028362169528627027, 'batch_size': 217, 'beta_1': 0.7539194939247386, 'beta_2': 0.9956800821368451, 'epsilon': 8.302066831680152e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.0012232609205827419, 'tol': 0.0002411694596383515, 'validation_fraction': 0.5734121279055029}
observation time 0.000065, current best -0.905495 at iter 12
suggestion time taken 0.002086 iter 13 next_points [{'alpha': 1.53648413181592, 'batch_size': 64, 'beta_1': 0.7819194428265499, 'beta_2': 0.9396335284520744, 'epsilon': 3.4727417171056276e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.08845298163429438, 'tol': 0.000127099860218745, 'validation_fraction': 0.8084616243977781}]
function_evaluation time 0.217380 value -0.843956 suggestion {'alpha': 1.53648413181592, 'batch_size': 64, 'beta_1': 0.7819194428265499, 'beta_2': 0.9396335284520744, 'epsilon': 3.4727417171056276e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.08845298163429438, 'tol': 0.000127099860218745, 'validation_fraction': 0.8084616243977781}
observation time 0.000066, current best -0.905495 at iter 13
suggestion time taken 0.002182 iter 14 next_points [{'alpha': 0.001659301488308502, 'batch_size': 236, 'beta_1': 0.9736363677567449, 'beta_2': 0.9160073249430906, 'epsilon': 1.7114095025175514e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0010878355001485303, 'tol': 0.00019109602605945706, 'validation_fraction': 0.22847019318656842}]
function_evaluation time 0.293792 value -0.854945 suggestion {'alpha': 0.001659301488308502, 'batch_size': 236, 'beta_1': 0.9736363677567449, 'beta_2': 0.9160073249430906, 'epsilon': 1.7114095025175514e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0010878355001485303, 'tol': 0.00019109602605945706, 'validation_fraction': 0.22847019318656842}
observation time 0.000063, current best -0.905495 at iter 14
saving meta data: {'args': {'--uuid': 'f9dbf0ae03d758b19f82e043d4db637d', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_005909', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

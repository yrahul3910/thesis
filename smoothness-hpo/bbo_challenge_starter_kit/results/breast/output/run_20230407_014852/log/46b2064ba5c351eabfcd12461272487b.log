running: {'--uuid': '46b2064ba5c351eabfcd12461272487b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_014852', '--opt': 'random-search', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d breast -o random-search -u 46b2064ba5c351eabfcd12461272487b -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_014852
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_nll betwen [ 4.58589285 14.6438765   8.74044796  0.67466158  3.06872636] and [ 8.10456652 20.07092365 12.33228572  5.26978359  3.49043108]
  warnings.warn(

Signature errors:
                            0         1         2         3         4       max
MLP-adam_breast_nll  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
max                  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
starting sklearn study random-search MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.002474 iter 0 next_points [{'alpha': 4.293313635520431, 'batch_size': 65, 'beta_1': 0.9788213536535194, 'beta_2': 0.9796240305527715, 'epsilon': 1.0629907596384579e-08, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.02545377525564634, 'tol': 0.0020397149120147144, 'validation_fraction': 0.6577396348156713}]
function_evaluation time 0.236856 value 1.060263 suggestion {'alpha': 4.293313635520431, 'batch_size': 65, 'beta_1': 0.9788213536535194, 'beta_2': 0.9796240305527715, 'epsilon': 1.0629907596384579e-08, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.02545377525564634, 'tol': 0.0020397149120147144, 'validation_fraction': 0.6577396348156713}
observation time 0.000003, current best 1.060263 at iter 0
suggestion time taken 0.002386 iter 1 next_points [{'alpha': 0.11576780521782203, 'batch_size': 166, 'beta_1': 0.9104957275196145, 'beta_2': 0.9998279484661566, 'epsilon': 3.7502066222019553e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.028987941665212565, 'tol': 6.057899246129707e-05, 'validation_fraction': 0.6007554183064019}]
function_evaluation time 0.239618 value 1.120754 suggestion {'alpha': 0.11576780521782203, 'batch_size': 166, 'beta_1': 0.9104957275196145, 'beta_2': 0.9998279484661566, 'epsilon': 3.7502066222019553e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.028987941665212565, 'tol': 6.057899246129707e-05, 'validation_fraction': 0.6007554183064019}
observation time 0.000004, current best 1.060263 at iter 1
suggestion time taken 0.002702 iter 2 next_points [{'alpha': 3.6149530337339076e-05, 'batch_size': 32, 'beta_1': 0.9833727539938666, 'beta_2': 0.9999658564563122, 'epsilon': 2.511525514529699e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.01670085264422712, 'tol': 0.00012812760899954853, 'validation_fraction': 0.37814624859913004}]
function_evaluation time 0.316658 value 1.182274 suggestion {'alpha': 3.6149530337339076e-05, 'batch_size': 32, 'beta_1': 0.9833727539938666, 'beta_2': 0.9999658564563122, 'epsilon': 2.511525514529699e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.01670085264422712, 'tol': 0.00012812760899954853, 'validation_fraction': 0.37814624859913004}
observation time 0.000003, current best 1.060263 at iter 2
suggestion time taken 0.002353 iter 3 next_points [{'alpha': 0.04448760335362721, 'batch_size': 87, 'beta_1': 0.9719014895779712, 'beta_2': 0.9999717118385105, 'epsilon': 8.579083503009315e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0006595236397344405, 'tol': 1.573013460653952e-05, 'validation_fraction': 0.49464584363059655}]
function_evaluation time 0.303415 value 5.403432 suggestion {'alpha': 0.04448760335362721, 'batch_size': 87, 'beta_1': 0.9719014895779712, 'beta_2': 0.9999717118385105, 'epsilon': 8.579083503009315e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0006595236397344405, 'tol': 1.573013460653952e-05, 'validation_fraction': 0.49464584363059655}
observation time 0.000003, current best 1.060263 at iter 3
suggestion time taken 0.002398 iter 4 next_points [{'alpha': 0.014370812396355409, 'batch_size': 209, 'beta_1': 0.9879879515847765, 'beta_2': 0.9883227367386943, 'epsilon': 1.0047772874459581e-07, 'hidden_layer_sizes': 113, 'learning_rate_init': 3.855078115420781e-05, 'tol': 6.120663965763786e-05, 'validation_fraction': 0.5509914812172106}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.134073 value 16.448647 suggestion {'alpha': 0.014370812396355409, 'batch_size': 209, 'beta_1': 0.9879879515847765, 'beta_2': 0.9883227367386943, 'epsilon': 1.0047772874459581e-07, 'hidden_layer_sizes': 113, 'learning_rate_init': 3.855078115420781e-05, 'tol': 6.120663965763786e-05, 'validation_fraction': 0.5509914812172106}
observation time 0.000002, current best 1.060263 at iter 4
suggestion time taken 0.002421 iter 5 next_points [{'alpha': 6.702376211425732, 'batch_size': 82, 'beta_1': 0.8896782677649092, 'beta_2': 0.9747792907325303, 'epsilon': 2.9159451439444355e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 4.915075608873569e-05, 'tol': 0.057683736349748986, 'validation_fraction': 0.42503723185373093}]
function_evaluation time 0.149767 value 12.523869 suggestion {'alpha': 6.702376211425732, 'batch_size': 82, 'beta_1': 0.8896782677649092, 'beta_2': 0.9747792907325303, 'epsilon': 2.9159451439444355e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 4.915075608873569e-05, 'tol': 0.057683736349748986, 'validation_fraction': 0.42503723185373093}
observation time 0.000003, current best 1.060263 at iter 5
suggestion time taken 0.002423 iter 6 next_points [{'alpha': 0.0010646669091382455, 'batch_size': 133, 'beta_1': 0.9869829091386995, 'beta_2': 0.9999805715382901, 'epsilon': 6.138361710436017e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 1.9356336800916192e-05, 'tol': 6.08970142079292e-05, 'validation_fraction': 0.14701166998898402}]
function_evaluation time 0.086628 value 16.759126 suggestion {'alpha': 0.0010646669091382455, 'batch_size': 133, 'beta_1': 0.9869829091386995, 'beta_2': 0.9999805715382901, 'epsilon': 6.138361710436017e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 1.9356336800916192e-05, 'tol': 6.08970142079292e-05, 'validation_fraction': 0.14701166998898402}
observation time 0.000003, current best 1.060263 at iter 6
suggestion time taken 0.002428 iter 7 next_points [{'alpha': 0.11972130580717712, 'batch_size': 152, 'beta_1': 0.7013991094924735, 'beta_2': 0.9997639893190841, 'epsilon': 2.750155695956528e-09, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.04872143923974271, 'tol': 0.0015309945565245683, 'validation_fraction': 0.11478870300420155}]
function_evaluation time 0.269967 value 0.354882 suggestion {'alpha': 0.11972130580717712, 'batch_size': 152, 'beta_1': 0.7013991094924735, 'beta_2': 0.9997639893190841, 'epsilon': 2.750155695956528e-09, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.04872143923974271, 'tol': 0.0015309945565245683, 'validation_fraction': 0.11478870300420155}
observation time 0.000003, current best 0.354882 at iter 7
suggestion time taken 0.002412 iter 8 next_points [{'alpha': 0.00022158537398599175, 'batch_size': 48, 'beta_1': 0.966622736796187, 'beta_2': 0.9998998635126416, 'epsilon': 4.7020469952573655e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 7.260990049489933e-05, 'tol': 0.000756100009759603, 'validation_fraction': 0.6214673840612988}]
function_evaluation time 0.170525 value 12.749904 suggestion {'alpha': 0.00022158537398599175, 'batch_size': 48, 'beta_1': 0.966622736796187, 'beta_2': 0.9998998635126416, 'epsilon': 4.7020469952573655e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 7.260990049489933e-05, 'tol': 0.000756100009759603, 'validation_fraction': 0.6214673840612988}
observation time 0.000003, current best 0.354882 at iter 8
suggestion time taken 0.002393 iter 9 next_points [{'alpha': 6.4576357599420104, 'batch_size': 127, 'beta_1': 0.987246184273677, 'beta_2': 0.9957981252872118, 'epsilon': 6.254965624341692e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.0024868080855992842, 'tol': 0.027389770489948187, 'validation_fraction': 0.5394281289565149}]
function_evaluation time 0.241875 value 0.712257 suggestion {'alpha': 6.4576357599420104, 'batch_size': 127, 'beta_1': 0.987246184273677, 'beta_2': 0.9957981252872118, 'epsilon': 6.254965624341692e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.0024868080855992842, 'tol': 0.027389770489948187, 'validation_fraction': 0.5394281289565149}
observation time 0.000002, current best 0.354882 at iter 9
suggestion time taken 0.002420 iter 10 next_points [{'alpha': 0.6153211357643414, 'batch_size': 12, 'beta_1': 0.7172094192435015, 'beta_2': 0.9615575114235256, 'epsilon': 1.970306402607378e-07, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0009086444939764612, 'tol': 0.010934540486049563, 'validation_fraction': 0.1169793398548093}]
function_evaluation time 0.668941 value 0.306406 suggestion {'alpha': 0.6153211357643414, 'batch_size': 12, 'beta_1': 0.7172094192435015, 'beta_2': 0.9615575114235256, 'epsilon': 1.970306402607378e-07, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0009086444939764612, 'tol': 0.010934540486049563, 'validation_fraction': 0.1169793398548093}
observation time 0.000003, current best 0.306406 at iter 10
suggestion time taken 0.002368 iter 11 next_points [{'alpha': 0.01859803947620419, 'batch_size': 19, 'beta_1': 0.6811302004600787, 'beta_2': 0.9953547433332324, 'epsilon': 5.636758571689927e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0076709340257975255, 'tol': 0.0005522572992002714, 'validation_fraction': 0.5695170075438748}]
function_evaluation time 0.420303 value 0.826322 suggestion {'alpha': 0.01859803947620419, 'batch_size': 19, 'beta_1': 0.6811302004600787, 'beta_2': 0.9953547433332324, 'epsilon': 5.636758571689927e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0076709340257975255, 'tol': 0.0005522572992002714, 'validation_fraction': 0.5695170075438748}
observation time 0.000002, current best 0.306406 at iter 11
suggestion time taken 0.002643 iter 12 next_points [{'alpha': 4.5795203244640815e-05, 'batch_size': 127, 'beta_1': 0.6630063619310858, 'beta_2': 0.9999988136173741, 'epsilon': 9.408297857350165e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0008872223811447226, 'tol': 0.00019077301518970657, 'validation_fraction': 0.8025456629817389}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.126493 value 10.105275 suggestion {'alpha': 4.5795203244640815e-05, 'batch_size': 127, 'beta_1': 0.6630063619310858, 'beta_2': 0.9999988136173741, 'epsilon': 9.408297857350165e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0008872223811447226, 'tol': 0.00019077301518970657, 'validation_fraction': 0.8025456629817389}
observation time 0.000002, current best 0.306406 at iter 12
suggestion time taken 0.002424 iter 13 next_points [{'alpha': 7.673515887420536, 'batch_size': 86, 'beta_1': 0.9873158844849439, 'beta_2': 0.9999908199063409, 'epsilon': 5.8269984856233723e-08, 'hidden_layer_sizes': 168, 'learning_rate_init': 4.809517839435827e-05, 'tol': 0.00016781545839665262, 'validation_fraction': 0.3436522640843681}]
function_evaluation time 0.168024 value 22.189326 suggestion {'alpha': 7.673515887420536, 'batch_size': 86, 'beta_1': 0.9873158844849439, 'beta_2': 0.9999908199063409, 'epsilon': 5.8269984856233723e-08, 'hidden_layer_sizes': 168, 'learning_rate_init': 4.809517839435827e-05, 'tol': 0.00016781545839665262, 'validation_fraction': 0.3436522640843681}
observation time 0.000002, current best 0.306406 at iter 13
suggestion time taken 0.002547 iter 14 next_points [{'alpha': 0.0004251531663884973, 'batch_size': 87, 'beta_1': 0.9614217532187888, 'beta_2': 0.9999989720845998, 'epsilon': 2.9387835449569608e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.07710819791516973, 'tol': 0.0002002445982652974, 'validation_fraction': 0.7118170588663145}]
function_evaluation time 0.164596 value 2.956844 suggestion {'alpha': 0.0004251531663884973, 'batch_size': 87, 'beta_1': 0.9614217532187888, 'beta_2': 0.9999989720845998, 'epsilon': 2.9387835449569608e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.07710819791516973, 'tol': 0.0002002445982652974, 'validation_fraction': 0.7118170588663145}
observation time 0.000003, current best 0.306406 at iter 14
saving meta data: {'args': {'--uuid': '46b2064ba5c351eabfcd12461272487b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_014852', '--opt': 'random-search', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])}
saving results
saving timing
saving suggest log
done

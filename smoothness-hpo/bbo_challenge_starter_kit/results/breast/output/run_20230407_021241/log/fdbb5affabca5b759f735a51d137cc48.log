running: {'--uuid': 'fdbb5affabca5b759f735a51d137cc48', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'turbo', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d breast -o turbo -u fdbb5affabca5b759f735a51d137cc48 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_021241
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_acc betwen [-0.80659341 -0.56703297 -0.66593407 -0.87912088 -0.85934066] and [-0.67692308 -0.41758242 -0.54505495 -0.78241758 -0.84395604]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_breast_acc  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
max                  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
starting sklearn study turbo MLP-adam breast acc 15 1
with data root: None
suggestion time taken 0.002166 iter 0 next_points [{'alpha': 0.0020123912176762773, 'batch_size': 249, 'beta_1': 0.9878059458381313, 'beta_2': 0.9992309920402946, 'epsilon': 5.657661918024934e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.00024104346588998618, 'tol': 1.8868212403213317e-05, 'validation_fraction': 0.10865733388266743}]
function_evaluation time 0.256160 value -0.628571 suggestion {'alpha': 0.0020123912176762773, 'batch_size': 249, 'beta_1': 0.9878059458381313, 'beta_2': 0.9992309920402946, 'epsilon': 5.657661918024934e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.00024104346588998618, 'tol': 1.8868212403213317e-05, 'validation_fraction': 0.10865733388266743}
observation time 0.001390, current best -0.628571 at iter 0
suggestion time taken 0.002044 iter 1 next_points [{'alpha': 1.2187647984324392, 'batch_size': 70, 'beta_1': 0.9253101249267909, 'beta_2': 0.9999949204194025, 'epsilon': 1.0932613092217691e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 8.307046550677216e-05, 'tol': 6.622411661062057e-05, 'validation_fraction': 0.8992238384535971}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.156072 value -0.454945 suggestion {'alpha': 1.2187647984324392, 'batch_size': 70, 'beta_1': 0.9253101249267909, 'beta_2': 0.9999949204194025, 'epsilon': 1.0932613092217691e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 8.307046550677216e-05, 'tol': 6.622411661062057e-05, 'validation_fraction': 0.8992238384535971}
observation time 0.001415, current best -0.628571 at iter 1
suggestion time taken 0.001728 iter 2 next_points [{'alpha': 2.6128918315067193, 'batch_size': 58, 'beta_1': 0.9849907503669398, 'beta_2': 0.97980140822759, 'epsilon': 4.480529367036508e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.03406503369478304, 'tol': 4.2316279996414407e-05, 'validation_fraction': 0.8264054420705533}]
function_evaluation time 0.287062 value -0.901099 suggestion {'alpha': 2.6128918315067193, 'batch_size': 58, 'beta_1': 0.9849907503669398, 'beta_2': 0.97980140822759, 'epsilon': 4.480529367036508e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.03406503369478304, 'tol': 4.2316279996414407e-05, 'validation_fraction': 0.8264054420705533}
observation time 0.001333, current best -0.901099 at iter 2
suggestion time taken 0.001763 iter 3 next_points [{'alpha': 0.03984652677649605, 'batch_size': 192, 'beta_1': 0.9592247450457984, 'beta_2': 0.9836141316209873, 'epsilon': 3.0701357292331984e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.00014723555195508747, 'tol': 0.00058553822579537, 'validation_fraction': 0.6099879334110566}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.151202 value -0.582418 suggestion {'alpha': 0.03984652677649605, 'batch_size': 192, 'beta_1': 0.9592247450457984, 'beta_2': 0.9836141316209873, 'epsilon': 3.0701357292331984e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.00014723555195508747, 'tol': 0.00058553822579537, 'validation_fraction': 0.6099879334110566}
observation time 0.001396, current best -0.901099 at iter 3
suggestion time taken 0.001723 iter 4 next_points [{'alpha': 0.8543800721969155, 'batch_size': 94, 'beta_1': 0.949195101507388, 'beta_2': 0.9999972064314367, 'epsilon': 1.3584831949836256e-07, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.060012897334603674, 'tol': 0.008244898862631592, 'validation_fraction': 0.5010578510679634}]
function_evaluation time 0.224448 value -0.892308 suggestion {'alpha': 0.8543800721969155, 'batch_size': 94, 'beta_1': 0.949195101507388, 'beta_2': 0.9999972064314367, 'epsilon': 1.3584831949836256e-07, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.060012897334603674, 'tol': 0.008244898862631592, 'validation_fraction': 0.5010578510679634}
observation time 0.001384, current best -0.901099 at iter 4
suggestion time taken 0.001751 iter 5 next_points [{'alpha': 0.08112313549638789, 'batch_size': 232, 'beta_1': 0.7970684035015062, 'beta_2': 0.9998419059125271, 'epsilon': 1.4841293837050338e-08, 'hidden_layer_sizes': 141, 'learning_rate_init': 2.0712940764918516e-05, 'tol': 0.08836587779867663, 'validation_fraction': 0.6680066867168327}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.103392 value -0.582418 suggestion {'alpha': 0.08112313549638789, 'batch_size': 232, 'beta_1': 0.7970684035015062, 'beta_2': 0.9998419059125271, 'epsilon': 1.4841293837050338e-08, 'hidden_layer_sizes': 141, 'learning_rate_init': 2.0712940764918516e-05, 'tol': 0.08836587779867663, 'validation_fraction': 0.6680066867168327}
observation time 0.001406, current best -0.901099 at iter 5
suggestion time taken 0.001750 iter 6 next_points [{'alpha': 0.4249313458268514, 'batch_size': 180, 'beta_1': 0.5192429700002462, 'beta_2': 0.9999914035869298, 'epsilon': 7.055144258586918e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 2.9504222556888247e-05, 'tol': 0.009270856879439923, 'validation_fraction': 0.7297150619479581}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.081771 value -0.582418 suggestion {'alpha': 0.4249313458268514, 'batch_size': 180, 'beta_1': 0.5192429700002462, 'beta_2': 0.9999914035869298, 'epsilon': 7.055144258586918e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 2.9504222556888247e-05, 'tol': 0.009270856879439923, 'validation_fraction': 0.7297150619479581}
observation time 0.001373, current best -0.901099 at iter 6
suggestion time taken 0.002036 iter 7 next_points [{'alpha': 4.97225020313498e-05, 'batch_size': 151, 'beta_1': 0.7632112986758097, 'beta_2': 0.9999420119758403, 'epsilon': 7.716050172329486e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.004409345901808147, 'tol': 0.0002697624100071607, 'validation_fraction': 0.25748315480202805}]
function_evaluation time 0.236970 value -0.881319 suggestion {'alpha': 4.97225020313498e-05, 'batch_size': 151, 'beta_1': 0.7632112986758097, 'beta_2': 0.9999420119758403, 'epsilon': 7.716050172329486e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.004409345901808147, 'tol': 0.0002697624100071607, 'validation_fraction': 0.25748315480202805}
observation time 0.001362, current best -0.901099 at iter 7
suggestion time taken 0.001716 iter 8 next_points [{'alpha': 0.023500587089200657, 'batch_size': 139, 'beta_1': 0.8205775556869841, 'beta_2': 0.9996468222740008, 'epsilon': 5.054517140185284e-08, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.00041473874217100065, 'tol': 0.002952949940333044, 'validation_fraction': 0.8739242350375398}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.079307 value -0.472527 suggestion {'alpha': 0.023500587089200657, 'batch_size': 139, 'beta_1': 0.8205775556869841, 'beta_2': 0.9996468222740008, 'epsilon': 5.054517140185284e-08, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.00041473874217100065, 'tol': 0.002952949940333044, 'validation_fraction': 0.8739242350375398}
observation time 0.001396, current best -0.901099 at iter 8
suggestion time taken 0.001749 iter 9 next_points [{'alpha': 0.0051195889522892635, 'batch_size': 76, 'beta_1': 0.8711128837202341, 'beta_2': 0.9471526754610763, 'epsilon': 1.0549966790155865e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 1.6091533371044653e-05, 'tol': 0.016384460709304497, 'validation_fraction': 0.18784559145938381}]
function_evaluation time 0.106688 value -0.527473 suggestion {'alpha': 0.0051195889522892635, 'batch_size': 76, 'beta_1': 0.8711128837202341, 'beta_2': 0.9471526754610763, 'epsilon': 1.0549966790155865e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 1.6091533371044653e-05, 'tol': 0.016384460709304497, 'validation_fraction': 0.18784559145938381}
observation time 0.001354, current best -0.901099 at iter 9
suggestion time taken 0.001738 iter 10 next_points [{'alpha': 0.00016245109196487683, 'batch_size': 14, 'beta_1': 0.8919122089336513, 'beta_2': 0.9942189097454561, 'epsilon': 3.8435933958511696e-09, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.09976097524472877, 'tol': 0.004184118615165739, 'validation_fraction': 0.5526115621931373}]
function_evaluation time 0.511592 value -0.749451 suggestion {'alpha': 0.00016245109196487683, 'batch_size': 14, 'beta_1': 0.8919122089336513, 'beta_2': 0.9942189097454561, 'epsilon': 3.8435933958511696e-09, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.09976097524472877, 'tol': 0.004184118615165739, 'validation_fraction': 0.5526115621931373}
observation time 0.001368, current best -0.901099 at iter 10
suggestion time taken 0.001744 iter 11 next_points [{'alpha': 0.23929873183843858, 'batch_size': 222, 'beta_1': 0.5974243125188584, 'beta_2': 0.9999779274338314, 'epsilon': 9.569224246460895e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0008549627832720137, 'tol': 0.00040586079884686487, 'validation_fraction': 0.37067762517719005}]
function_evaluation time 0.268866 value -0.837363 suggestion {'alpha': 0.23929873183843858, 'batch_size': 222, 'beta_1': 0.5974243125188584, 'beta_2': 0.9999779274338314, 'epsilon': 9.569224246460895e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0008549627832720137, 'tol': 0.00040586079884686487, 'validation_fraction': 0.37067762517719005}
observation time 0.001387, current best -0.901099 at iter 11
suggestion time taken 0.001669 iter 12 next_points [{'alpha': 8.616489793174658, 'batch_size': 29, 'beta_1': 0.94594057696143, 'beta_2': 0.91100524913205, 'epsilon': 1.9296185519643337e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.001430445246765029, 'tol': 8.577320195078504e-05, 'validation_fraction': 0.16642716711459743}]
function_evaluation time 0.298406 value -0.907692 suggestion {'alpha': 8.616489793174658, 'batch_size': 29, 'beta_1': 0.94594057696143, 'beta_2': 0.91100524913205, 'epsilon': 1.9296185519643337e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.001430445246765029, 'tol': 8.577320195078504e-05, 'validation_fraction': 0.16642716711459743}
observation time 0.001395, current best -0.907692 at iter 12
suggestion time taken 0.001694 iter 13 next_points [{'alpha': 2.4819042336985992e-05, 'batch_size': 122, 'beta_1': 0.8997201476965452, 'beta_2': 0.9999028953977718, 'epsilon': 3.975260886868443e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.020720702190080743, 'tol': 0.00012911402304857523, 'validation_fraction': 0.3337965976242641}]
function_evaluation time 0.327910 value -0.907692 suggestion {'alpha': 2.4819042336985992e-05, 'batch_size': 122, 'beta_1': 0.8997201476965452, 'beta_2': 0.9999028953977718, 'epsilon': 3.975260886868443e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.020720702190080743, 'tol': 0.00012911402304857523, 'validation_fraction': 0.3337965976242641}
observation time 0.001342, current best -0.907692 at iter 13
suggestion time taken 0.001710 iter 14 next_points [{'alpha': 0.010075756840260143, 'batch_size': 106, 'beta_1': 0.6782819015995937, 'beta_2': 0.9999813225543887, 'epsilon': 2.1573329093015963e-07, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0005007483247985447, 'tol': 0.0008931707048264607, 'validation_fraction': 0.4199901377970048}]
function_evaluation time 0.298961 value -0.852747 suggestion {'alpha': 0.010075756840260143, 'batch_size': 106, 'beta_1': 0.6782819015995937, 'beta_2': 0.9999813225543887, 'epsilon': 2.1573329093015963e-07, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0005007483247985447, 'tol': 0.0008931707048264607, 'validation_fraction': 0.4199901377970048}
observation time 0.001399, current best -0.907692 at iter 14
saving meta data: {'args': {'--uuid': 'fdbb5affabca5b759f735a51d137cc48', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'turbo', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

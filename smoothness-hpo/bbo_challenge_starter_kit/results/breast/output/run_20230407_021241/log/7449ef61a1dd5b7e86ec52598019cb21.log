running: {'--uuid': '7449ef61a1dd5b7e86ec52598019cb21', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d breast -o hyperopt -u 7449ef61a1dd5b7e86ec52598019cb21 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_021241
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_nll betwen [ 4.58589285 14.6438765   8.74044796  0.67466158  3.06872636] and [ 8.10456652 20.07092365 12.33228572  5.26978359  3.49043108]
  warnings.warn(

Signature errors:
                            0         1         2         3         4       max
MLP-adam_breast_nll  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
max                  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
starting sklearn study hyperopt MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.002183 iter 0 next_points [{'alpha': 0.0031283908692677515, 'batch_size': 146, 'beta_1': 0.6539693268087551, 'beta_2': 0.95600273065849, 'epsilon': 2.742571851178634e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.0008384953127329276, 'tol': 0.0005616550353796631, 'validation_fraction': 0.5974122328068451}]
function_evaluation time 0.328359 value 7.460275 suggestion {'alpha': 0.0031283908692677515, 'batch_size': 146, 'beta_1': 0.6539693268087551, 'beta_2': 0.95600273065849, 'epsilon': 2.742571851178634e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.0008384953127329276, 'tol': 0.0005616550353796631, 'validation_fraction': 0.5974122328068451}
observation time 0.000064, current best 7.460275 at iter 0
suggestion time taken 0.002320 iter 1 next_points [{'alpha': 0.0017753155413456495, 'batch_size': 229, 'beta_1': 0.8773141506396003, 'beta_2': 0.9277826439787806, 'epsilon': 2.337403812623853e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.008960544865810108, 'tol': 0.044959048810312686, 'validation_fraction': 0.6151492091219363}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.144111 value 0.750308 suggestion {'alpha': 0.0017753155413456495, 'batch_size': 229, 'beta_1': 0.8773141506396003, 'beta_2': 0.9277826439787806, 'epsilon': 2.337403812623853e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.008960544865810108, 'tol': 0.044959048810312686, 'validation_fraction': 0.6151492091219363}
observation time 0.000051, current best 0.750308 at iter 1
suggestion time taken 0.002059 iter 2 next_points [{'alpha': 0.0036133922591665125, 'batch_size': 210, 'beta_1': 0.9853990668114609, 'beta_2': 0.917148922611255, 'epsilon': 4.126763829290013e-09, 'hidden_layer_sizes': 97, 'learning_rate_init': 1.7120513128555988e-05, 'tol': 1.0579896136667588e-05, 'validation_fraction': 0.11042486759849633}]
function_evaluation time 0.127506 value 13.070775 suggestion {'alpha': 0.0036133922591665125, 'batch_size': 210, 'beta_1': 0.9853990668114609, 'beta_2': 0.917148922611255, 'epsilon': 4.126763829290013e-09, 'hidden_layer_sizes': 97, 'learning_rate_init': 1.7120513128555988e-05, 'tol': 1.0579896136667588e-05, 'validation_fraction': 0.11042486759849633}
observation time 0.000048, current best 0.750308 at iter 2
suggestion time taken 0.002030 iter 3 next_points [{'alpha': 0.004934545715682585, 'batch_size': 217, 'beta_1': 0.5533040766149434, 'beta_2': 0.9020294914329356, 'epsilon': 1.4454435818761375e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.00032664495434902034, 'tol': 7.012854215851663e-05, 'validation_fraction': 0.30871133516703547}]
function_evaluation time 0.193342 value 14.946510 suggestion {'alpha': 0.004934545715682585, 'batch_size': 217, 'beta_1': 0.5533040766149434, 'beta_2': 0.9020294914329356, 'epsilon': 1.4454435818761375e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.00032664495434902034, 'tol': 7.012854215851663e-05, 'validation_fraction': 0.30871133516703547}
observation time 0.000049, current best 0.750308 at iter 3
suggestion time taken 0.002026 iter 4 next_points [{'alpha': 8.856179365460322, 'batch_size': 68, 'beta_1': 0.6960978979618876, 'beta_2': 0.9549464558678599, 'epsilon': 5.274226013367254e-07, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.04608433523975114, 'tol': 7.125304897757597e-05, 'validation_fraction': 0.10487809562220561}]
function_evaluation time 0.345464 value 0.637425 suggestion {'alpha': 8.856179365460322, 'batch_size': 68, 'beta_1': 0.6960978979618876, 'beta_2': 0.9549464558678599, 'epsilon': 5.274226013367254e-07, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.04608433523975114, 'tol': 7.125304897757597e-05, 'validation_fraction': 0.10487809562220561}
observation time 0.000050, current best 0.637425 at iter 4
suggestion time taken 0.002112 iter 5 next_points [{'alpha': 2.1888400921152655e-05, 'batch_size': 140, 'beta_1': 0.5197281122824061, 'beta_2': 0.9185118030510284, 'epsilon': 1.0638381956038012e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.014890655460792813, 'tol': 0.007188488472090132, 'validation_fraction': 0.29497278006864486}]
function_evaluation time 0.340815 value 1.431772 suggestion {'alpha': 2.1888400921152655e-05, 'batch_size': 140, 'beta_1': 0.5197281122824061, 'beta_2': 0.9185118030510284, 'epsilon': 1.0638381956038012e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.014890655460792813, 'tol': 0.007188488472090132, 'validation_fraction': 0.29497278006864486}
observation time 0.000051, current best 0.637425 at iter 5
suggestion time taken 0.002040 iter 6 next_points [{'alpha': 4.6784538865991106e-05, 'batch_size': 216, 'beta_1': 0.6334815830070899, 'beta_2': 0.9092326694900271, 'epsilon': 9.81969757814872e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.06800482459473527, 'tol': 0.06526161217033453, 'validation_fraction': 0.5706317362772764}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.165842 value 0.825878 suggestion {'alpha': 4.6784538865991106e-05, 'batch_size': 216, 'beta_1': 0.6334815830070899, 'beta_2': 0.9092326694900271, 'epsilon': 9.81969757814872e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.06800482459473527, 'tol': 0.06526161217033453, 'validation_fraction': 0.5706317362772764}
observation time 0.000052, current best 0.637425 at iter 6
suggestion time taken 0.002074 iter 7 next_points [{'alpha': 0.04007053899598795, 'batch_size': 48, 'beta_1': 0.9407410547852079, 'beta_2': 0.9279657613552389, 'epsilon': 5.7411185754843774e-08, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.00045619247172678753, 'tol': 0.000610290524906536, 'validation_fraction': 0.21283531110348772}]
function_evaluation time 0.532900 value 0.366198 suggestion {'alpha': 0.04007053899598795, 'batch_size': 48, 'beta_1': 0.9407410547852079, 'beta_2': 0.9279657613552389, 'epsilon': 5.7411185754843774e-08, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.00045619247172678753, 'tol': 0.000610290524906536, 'validation_fraction': 0.21283531110348772}
observation time 0.000060, current best 0.366198 at iter 7
suggestion time taken 0.002115 iter 8 next_points [{'alpha': 0.009417855148262782, 'batch_size': 109, 'beta_1': 0.7476442688969057, 'beta_2': 0.9514533568093728, 'epsilon': 1.510341347460032e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 9.636663877987232e-05, 'tol': 0.006496649720168334, 'validation_fraction': 0.2527571892625202}]
function_evaluation time 0.247340 value 5.969368 suggestion {'alpha': 0.009417855148262782, 'batch_size': 109, 'beta_1': 0.7476442688969057, 'beta_2': 0.9514533568093728, 'epsilon': 1.510341347460032e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 9.636663877987232e-05, 'tol': 0.006496649720168334, 'validation_fraction': 0.2527571892625202}
observation time 0.000059, current best 0.366198 at iter 8
suggestion time taken 0.002073 iter 9 next_points [{'alpha': 3.292669452188683e-05, 'batch_size': 168, 'beta_1': 0.548887521331113, 'beta_2': 0.9988680395692087, 'epsilon': 1.3085560698249404e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0005031613875004577, 'tol': 7.215709877150166e-05, 'validation_fraction': 0.20604551111965416}]
function_evaluation time 0.317803 value 7.518614 suggestion {'alpha': 3.292669452188683e-05, 'batch_size': 168, 'beta_1': 0.548887521331113, 'beta_2': 0.9988680395692087, 'epsilon': 1.3085560698249404e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0005031613875004577, 'tol': 7.215709877150166e-05, 'validation_fraction': 0.20604551111965416}
observation time 0.000054, current best 0.366198 at iter 9
suggestion time taken 0.002082 iter 10 next_points [{'alpha': 6.30750067515424e-05, 'batch_size': 12, 'beta_1': 0.6751788910648262, 'beta_2': 0.9206651107568153, 'epsilon': 2.3411571314242677e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.007352463492339928, 'tol': 0.0006790019063078298, 'validation_fraction': 0.13149078648622703}]
function_evaluation time 0.526532 value 0.784917 suggestion {'alpha': 6.30750067515424e-05, 'batch_size': 12, 'beta_1': 0.6751788910648262, 'beta_2': 0.9206651107568153, 'epsilon': 2.3411571314242677e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.007352463492339928, 'tol': 0.0006790019063078298, 'validation_fraction': 0.13149078648622703}
observation time 0.000059, current best 0.366198 at iter 10
suggestion time taken 0.002067 iter 11 next_points [{'alpha': 1.422798052900255, 'batch_size': 29, 'beta_1': 0.6124888614169869, 'beta_2': 0.980794486669448, 'epsilon': 4.2065483096559465e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.002150297857266705, 'tol': 0.00030102596521486334, 'validation_fraction': 0.30796525287296855}]
function_evaluation time 0.312812 value 0.372600 suggestion {'alpha': 1.422798052900255, 'batch_size': 29, 'beta_1': 0.6124888614169869, 'beta_2': 0.980794486669448, 'epsilon': 4.2065483096559465e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.002150297857266705, 'tol': 0.00030102596521486334, 'validation_fraction': 0.30796525287296855}
observation time 0.000054, current best 0.366198 at iter 11
suggestion time taken 0.002051 iter 12 next_points [{'alpha': 1.2519864768415074, 'batch_size': 236, 'beta_1': 0.5594921633854429, 'beta_2': 0.9055813102897989, 'epsilon': 3.168600997783156e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.009244191070522038, 'tol': 0.0005877245080399362, 'validation_fraction': 0.5699257867740126}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.204421 value 0.684174 suggestion {'alpha': 1.2519864768415074, 'batch_size': 236, 'beta_1': 0.5594921633854429, 'beta_2': 0.9055813102897989, 'epsilon': 3.168600997783156e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.009244191070522038, 'tol': 0.0005877245080399362, 'validation_fraction': 0.5699257867740126}
observation time 0.000058, current best 0.366198 at iter 12
suggestion time taken 0.003222 iter 13 next_points [{'alpha': 0.7835262531554268, 'batch_size': 155, 'beta_1': 0.6160333193183378, 'beta_2': 0.9582248258305958, 'epsilon': 4.72112345268457e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 2.1104012978038694e-05, 'tol': 0.028440833011428256, 'validation_fraction': 0.2731319966425545}]
function_evaluation time 0.154572 value 12.039184 suggestion {'alpha': 0.7835262531554268, 'batch_size': 155, 'beta_1': 0.6160333193183378, 'beta_2': 0.9582248258305958, 'epsilon': 4.72112345268457e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 2.1104012978038694e-05, 'tol': 0.028440833011428256, 'validation_fraction': 0.2731319966425545}
observation time 0.000048, current best 0.366198 at iter 13
suggestion time taken 0.002048 iter 14 next_points [{'alpha': 0.001771259709053289, 'batch_size': 154, 'beta_1': 0.7503596125923344, 'beta_2': 0.9868628361519055, 'epsilon': 1.9200834651957767e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.04011403045577621, 'tol': 0.00018738672949074464, 'validation_fraction': 0.5110103772019167}]
function_evaluation time 0.252729 value 0.980753 suggestion {'alpha': 0.001771259709053289, 'batch_size': 154, 'beta_1': 0.7503596125923344, 'beta_2': 0.9868628361519055, 'epsilon': 1.9200834651957767e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.04011403045577621, 'tol': 0.00018738672949074464, 'validation_fraction': 0.5110103772019167}
observation time 0.000062, current best 0.366198 at iter 14
saving meta data: {'args': {'--uuid': '7449ef61a1dd5b7e86ec52598019cb21', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])}
saving results
saving timing
saving suggest log
done

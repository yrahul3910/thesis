running: {'--uuid': 'cb4f41e237f55075bd3bbf86547c3dda', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'opentuner', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d breast -o opentuner -u cb4f41e237f55075bd3bbf86547c3dda -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_021241
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_nll betwen [ 4.58589285 14.6438765   8.74044796  0.67466158  3.06872636] and [ 8.10456652 20.07092365 12.33228572  5.26978359  3.49043108]
  warnings.warn(

Signature errors:
                            0         1         2         3         4       max
MLP-adam_breast_nll  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
max                  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
starting sklearn study opentuner MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.016465 iter 0 next_points [{'hidden_layer_sizes': 64, 'alpha': 4.571398608826156, 'batch_size': 217, 'learning_rate_init': 0.05158981818854785, 'tol': 0.03526837267652099, 'validation_fraction': 0.7845401500824256, 'beta_1': 0.9862138952684113, 'beta_2': 0.9728591113506098, 'epsilon': 3.2024788790327343e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.138868 value 0.967391 suggestion {'hidden_layer_sizes': 64, 'alpha': 4.571398608826156, 'batch_size': 217, 'learning_rate_init': 0.05158981818854785, 'tol': 0.03526837267652099, 'validation_fraction': 0.7845401500824256, 'beta_1': 0.9862138952684113, 'beta_2': 0.9728591113506098, 'epsilon': 3.2024788790327343e-07}
observation time 0.003940, current best 0.967391 at iter 0
suggestion time taken 0.007311 iter 1 next_points [{'hidden_layer_sizes': 64, 'alpha': 7.3116710631847965, 'batch_size': 217, 'learning_rate_init': 0.02399770822553331, 'tol': 0.051693791346764266, 'validation_fraction': 0.7845401500824256, 'beta_1': 0.9862138952684113, 'beta_2': 0.9728591113506098, 'epsilon': 3.183294502722968e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.117487 value 5.650785 suggestion {'hidden_layer_sizes': 64, 'alpha': 7.3116710631847965, 'batch_size': 217, 'learning_rate_init': 0.02399770822553331, 'tol': 0.051693791346764266, 'validation_fraction': 0.7845401500824256, 'beta_1': 0.9862138952684113, 'beta_2': 0.9728591113506098, 'epsilon': 3.183294502722968e-07}
observation time 0.001739, current best 0.967391 at iter 1
suggestion time taken 0.047242 iter 2 next_points [{'epsilon': 3.38786180804045e-07, 'batch_size': 61, 'learning_rate_init': 0.07582644806876064, 'hidden_layer_sizes': 116, 'beta_1': 0.5637687860334996, 'beta_2': 0.9602849945635711, 'tol': 0.023797859266284572, 'validation_fraction': 0.12177647001544899, 'alpha': 0.6914485102678095}]
function_evaluation time 0.216169 value 0.317625 suggestion {'epsilon': 3.38786180804045e-07, 'batch_size': 61, 'learning_rate_init': 0.07582644806876064, 'hidden_layer_sizes': 116, 'beta_1': 0.5637687860334996, 'beta_2': 0.9602849945635711, 'tol': 0.023797859266284572, 'validation_fraction': 0.12177647001544899, 'alpha': 0.6914485102678095}
observation time 0.001726, current best 0.317625 at iter 2
suggestion time taken 0.021518 iter 3 next_points [{'epsilon': 6.946748029318096e-07, 'batch_size': 228, 'learning_rate_init': 0.059736395857707895, 'hidden_layer_sizes': 88, 'beta_1': 0.6828649427544069, 'beta_2': 0.9337407668608205, 'tol': 0.02494402307563919, 'validation_fraction': 0.354432785602509, 'alpha': 3.9551568831623576}]
function_evaluation time 0.185318 value 0.485889 suggestion {'epsilon': 6.946748029318096e-07, 'batch_size': 228, 'learning_rate_init': 0.059736395857707895, 'hidden_layer_sizes': 88, 'beta_1': 0.6828649427544069, 'beta_2': 0.9337407668608205, 'tol': 0.02494402307563919, 'validation_fraction': 0.354432785602509, 'alpha': 3.9551568831623576}
observation time 0.001914, current best 0.317625 at iter 3
suggestion time taken 0.006788 iter 4 next_points [{'epsilon': 3.38786180804045e-07, 'batch_size': 61, 'learning_rate_init': 0.07582644806876064, 'hidden_layer_sizes': 116, 'beta_1': 0.7816965115289716, 'beta_2': 0.9602849945635711, 'tol': 0.062235979062622286, 'validation_fraction': 0.12177647001544899, 'alpha': 0.6914485102678095}]
function_evaluation time 0.216655 value 0.467471 suggestion {'epsilon': 3.38786180804045e-07, 'batch_size': 61, 'learning_rate_init': 0.07582644806876064, 'hidden_layer_sizes': 116, 'beta_1': 0.7816965115289716, 'beta_2': 0.9602849945635711, 'tol': 0.062235979062622286, 'validation_fraction': 0.12177647001544899, 'alpha': 0.6914485102678095}
observation time 0.001726, current best 0.317625 at iter 4
suggestion time taken 0.004913 iter 5 next_points [{'epsilon': 9.14321841267134e-07, 'batch_size': 204, 'learning_rate_init': 0.05968575784762458, 'hidden_layer_sizes': 99, 'beta_1': 0.6240776127976992, 'beta_2': 0.9792330049294646, 'tol': 0.06716361411214693, 'validation_fraction': 0.6052675984981807, 'alpha': 5.9840167535964355}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.158441 value 0.654877 suggestion {'epsilon': 9.14321841267134e-07, 'batch_size': 204, 'learning_rate_init': 0.05968575784762458, 'hidden_layer_sizes': 99, 'beta_1': 0.6240776127976992, 'beta_2': 0.9792330049294646, 'tol': 0.06716361411214693, 'validation_fraction': 0.6052675984981807, 'alpha': 5.9840167535964355}
observation time 0.001691, current best 0.317625 at iter 5
suggestion time taken 0.005440 iter 6 next_points [{'epsilon': 7.132621845656596e-07, 'batch_size': 23, 'learning_rate_init': 0.014036883882062746, 'hidden_layer_sizes': 102, 'beta_1': 0.5883417932973872, 'beta_2': 0.9719588864857114, 'tol': 0.07692122024847096, 'validation_fraction': 0.1598963222650469, 'alpha': 0.72635169093418}]
function_evaluation time 0.343997 value 1.249387 suggestion {'epsilon': 7.132621845656596e-07, 'batch_size': 23, 'learning_rate_init': 0.014036883882062746, 'hidden_layer_sizes': 102, 'beta_1': 0.5883417932973872, 'beta_2': 0.9719588864857114, 'tol': 0.07692122024847096, 'validation_fraction': 0.1598963222650469, 'alpha': 0.72635169093418}
observation time 0.001754, current best 0.317625 at iter 6
suggestion time taken 0.006569 iter 7 next_points [{'epsilon': 3.38786180804045e-07, 'batch_size': 61, 'learning_rate_init': 0.07582644806876064, 'hidden_layer_sizes': 116, 'beta_1': 0.5637687860334996, 'beta_2': 0.9602849945635711, 'tol': 0.023797859266284572, 'validation_fraction': 0.8523464533998161, 'alpha': 0.6914485102678095}]
function_evaluation time 0.154754 value 0.495884 suggestion {'epsilon': 3.38786180804045e-07, 'batch_size': 61, 'learning_rate_init': 0.07582644806876064, 'hidden_layer_sizes': 116, 'beta_1': 0.5637687860334996, 'beta_2': 0.9602849945635711, 'tol': 0.023797859266284572, 'validation_fraction': 0.8523464533998161, 'alpha': 0.6914485102678095}
observation time 0.001953, current best 0.317625 at iter 7
suggestion time taken 0.005320 iter 8 next_points [{'epsilon': 2.1526665619550533e-07, 'batch_size': 192, 'learning_rate_init': 0.005680500213893703, 'hidden_layer_sizes': 146, 'beta_1': 0.5576077838739395, 'beta_2': 0.9370993229239172, 'tol': 0.014490549564293676, 'validation_fraction': 0.8416752574434463, 'alpha': 3.8200385837822464}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.140357 value 1.013985 suggestion {'epsilon': 2.1526665619550533e-07, 'batch_size': 192, 'learning_rate_init': 0.005680500213893703, 'hidden_layer_sizes': 146, 'beta_1': 0.5576077838739395, 'beta_2': 0.9370993229239172, 'tol': 0.014490549564293676, 'validation_fraction': 0.8416752574434463, 'alpha': 3.8200385837822464}
observation time 0.001715, current best 0.317625 at iter 8
suggestion time taken 0.006593 iter 9 next_points [{'epsilon': 3.38786180804045e-07, 'batch_size': 61, 'learning_rate_init': 0.07582644806876064, 'hidden_layer_sizes': 116, 'beta_1': 0.9391070208529455, 'beta_2': 0.9049821018880505, 'tol': 0.023797859266284572, 'validation_fraction': 0.28514128099567976, 'alpha': 0.6914485102678095}]
function_evaluation time 0.238942 value 2.953673 suggestion {'epsilon': 3.38786180804045e-07, 'batch_size': 61, 'learning_rate_init': 0.07582644806876064, 'hidden_layer_sizes': 116, 'beta_1': 0.9391070208529455, 'beta_2': 0.9049821018880505, 'tol': 0.023797859266284572, 'validation_fraction': 0.28514128099567976, 'alpha': 0.6914485102678095}
observation time 0.001805, current best 0.317625 at iter 9
suggestion time taken 0.005028 iter 10 next_points [{'epsilon': 8.765998370801876e-07, 'batch_size': 140, 'learning_rate_init': 0.0316175114798009, 'hidden_layer_sizes': 145, 'beta_1': 0.5731467766374798, 'beta_2': 0.9113074562635854, 'tol': 0.07431026000857315, 'validation_fraction': 0.4005256239038769, 'alpha': 0.4418525632620209}]
function_evaluation time 0.194256 value 1.071516 suggestion {'epsilon': 8.765998370801876e-07, 'batch_size': 140, 'learning_rate_init': 0.0316175114798009, 'hidden_layer_sizes': 145, 'beta_1': 0.5731467766374798, 'beta_2': 0.9113074562635854, 'tol': 0.07431026000857315, 'validation_fraction': 0.4005256239038769, 'alpha': 0.4418525632620209}
observation time 0.001924, current best 0.317625 at iter 10
suggestion time taken 0.006931 iter 11 next_points [{'epsilon': 3.38786180804045e-07, 'batch_size': 61, 'learning_rate_init': 0.025893801992201416, 'hidden_layer_sizes': 116, 'beta_1': 0.5637687860334996, 'beta_2': 0.9602849945635711, 'tol': 0.023797859266284572, 'validation_fraction': 0.12177647001544899, 'alpha': 0.9833905345123636}]
function_evaluation time 0.218549 value 1.103353 suggestion {'epsilon': 3.38786180804045e-07, 'batch_size': 61, 'learning_rate_init': 0.025893801992201416, 'hidden_layer_sizes': 116, 'beta_1': 0.5637687860334996, 'beta_2': 0.9602849945635711, 'tol': 0.023797859266284572, 'validation_fraction': 0.12177647001544899, 'alpha': 0.9833905345123636}
observation time 0.002004, current best 0.317625 at iter 11
suggestion time taken 0.005942 iter 12 next_points [{'epsilon': 4.912748556023795e-07, 'batch_size': 127, 'learning_rate_init': 0.0042745754064021264, 'hidden_layer_sizes': 158, 'beta_1': 0.9348969643783829, 'beta_2': 0.9635999880175448, 'tol': 0.046155867055080506, 'validation_fraction': 0.4275564560836732, 'alpha': 8.421673226075933}]
function_evaluation time 0.199091 value 0.802933 suggestion {'epsilon': 4.912748556023795e-07, 'batch_size': 127, 'learning_rate_init': 0.0042745754064021264, 'hidden_layer_sizes': 158, 'beta_1': 0.9348969643783829, 'beta_2': 0.9635999880175448, 'tol': 0.046155867055080506, 'validation_fraction': 0.4275564560836732, 'alpha': 8.421673226075933}
observation time 0.001887, current best 0.317625 at iter 12
suggestion time taken 0.006902 iter 13 next_points [{'epsilon': 3.38786180804045e-07, 'batch_size': 75, 'learning_rate_init': 0.07291340667819239, 'hidden_layer_sizes': 116, 'beta_1': 0.5637687860334996, 'beta_2': 0.9622037453792679, 'tol': 0.023797859266284572, 'validation_fraction': 0.12177647001544899, 'alpha': 0.6914485102678095}]
function_evaluation time 0.220461 value 0.669640 suggestion {'epsilon': 3.38786180804045e-07, 'batch_size': 75, 'learning_rate_init': 0.07291340667819239, 'hidden_layer_sizes': 116, 'beta_1': 0.5637687860334996, 'beta_2': 0.9622037453792679, 'tol': 0.023797859266284572, 'validation_fraction': 0.12177647001544899, 'alpha': 0.6914485102678095}
observation time 0.001755, current best 0.317625 at iter 13
suggestion time taken 0.007134 iter 14 next_points [{'epsilon': 3.38786180804045e-07, 'batch_size': 61, 'learning_rate_init': 0.06426660628919516, 'hidden_layer_sizes': 116, 'beta_1': 0.5637687860334996, 'beta_2': 0.9602849945635711, 'tol': 0.023797859266284572, 'validation_fraction': 0.12177647001544899, 'alpha': 0.6914485102678095}]
function_evaluation time 0.217659 value 0.380717 suggestion {'epsilon': 3.38786180804045e-07, 'batch_size': 61, 'learning_rate_init': 0.06426660628919516, 'hidden_layer_sizes': 116, 'beta_1': 0.5637687860334996, 'beta_2': 0.9602849945635711, 'tol': 0.023797859266284572, 'validation_fraction': 0.12177647001544899, 'alpha': 0.6914485102678095}
observation time 0.001894, current best 0.317625 at iter 14
saving meta data: {'args': {'--uuid': 'cb4f41e237f55075bd3bbf86547c3dda', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'opentuner', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '7a461c97235257dbade50f5d9f6d2649', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d breast -o hyperopt -u 7a461c97235257dbade50f5d9f6d2649 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_021241
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_acc betwen [-0.80659341 -0.56703297 -0.66593407 -0.87912088 -0.85934066] and [-0.67692308 -0.41758242 -0.54505495 -0.78241758 -0.84395604]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_breast_acc  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
max                  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
starting sklearn study hyperopt MLP-adam breast acc 15 1
with data root: None
suggestion time taken 0.002246 iter 0 next_points [{'alpha': 0.0016204125994534655, 'batch_size': 215, 'beta_1': 0.8928715022978444, 'beta_2': 0.972120062814719, 'epsilon': 3.935936560119021e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.002142213781293336, 'tol': 0.061381127865078246, 'validation_fraction': 0.2356762588261822}]
function_evaluation time 0.142866 value -0.835165 suggestion {'alpha': 0.0016204125994534655, 'batch_size': 215, 'beta_1': 0.8928715022978444, 'beta_2': 0.972120062814719, 'epsilon': 3.935936560119021e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.002142213781293336, 'tol': 0.061381127865078246, 'validation_fraction': 0.2356762588261822}
observation time 0.000051, current best -0.835165 at iter 0
suggestion time taken 0.002249 iter 1 next_points [{'alpha': 3.7126631014821205, 'batch_size': 245, 'beta_1': 0.5604847108122596, 'beta_2': 0.9426000105355795, 'epsilon': 5.6043488674966765e-08, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.002496829887234845, 'tol': 0.05204577138139018, 'validation_fraction': 0.8129402067176577}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.132629 value -0.865934 suggestion {'alpha': 3.7126631014821205, 'batch_size': 245, 'beta_1': 0.5604847108122596, 'beta_2': 0.9426000105355795, 'epsilon': 5.6043488674966765e-08, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.002496829887234845, 'tol': 0.05204577138139018, 'validation_fraction': 0.8129402067176577}
observation time 0.000047, current best -0.865934 at iter 1
suggestion time taken 0.002030 iter 2 next_points [{'alpha': 0.39852332919256195, 'batch_size': 37, 'beta_1': 0.714367887676333, 'beta_2': 0.918033997342228, 'epsilon': 1.7872565993848224e-07, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.09786964900365976, 'tol': 7.95801367816179e-05, 'validation_fraction': 0.2229879547690208}]
function_evaluation time 0.307313 value -0.817582 suggestion {'alpha': 0.39852332919256195, 'batch_size': 37, 'beta_1': 0.714367887676333, 'beta_2': 0.918033997342228, 'epsilon': 1.7872565993848224e-07, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.09786964900365976, 'tol': 7.95801367816179e-05, 'validation_fraction': 0.2229879547690208}
observation time 0.000049, current best -0.865934 at iter 2
suggestion time taken 0.002226 iter 3 next_points [{'alpha': 1.3612140294976761e-05, 'batch_size': 153, 'beta_1': 0.6461755414751577, 'beta_2': 0.9589105946234974, 'epsilon': 7.410167982396575e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0053070652668937394, 'tol': 0.00010020729220352156, 'validation_fraction': 0.12729000567072069}]
function_evaluation time 0.237358 value -0.894505 suggestion {'alpha': 1.3612140294976761e-05, 'batch_size': 153, 'beta_1': 0.6461755414751577, 'beta_2': 0.9589105946234974, 'epsilon': 7.410167982396575e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0053070652668937394, 'tol': 0.00010020729220352156, 'validation_fraction': 0.12729000567072069}
observation time 0.000049, current best -0.894505 at iter 3
suggestion time taken 0.002025 iter 4 next_points [{'alpha': 0.0017653942951487856, 'batch_size': 200, 'beta_1': 0.7594452955051445, 'beta_2': 0.9832082654344028, 'epsilon': 1.0752453430129085e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 2.514154358626297e-05, 'tol': 0.008387288886295008, 'validation_fraction': 0.8647240819290158}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.083751 value -0.527473 suggestion {'alpha': 0.0017653942951487856, 'batch_size': 200, 'beta_1': 0.7594452955051445, 'beta_2': 0.9832082654344028, 'epsilon': 1.0752453430129085e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 2.514154358626297e-05, 'tol': 0.008387288886295008, 'validation_fraction': 0.8647240819290158}
observation time 0.000054, current best -0.894505 at iter 4
suggestion time taken 0.002087 iter 5 next_points [{'alpha': 0.0037292846058411874, 'batch_size': 192, 'beta_1': 0.5086740297517608, 'beta_2': 0.9890904194632026, 'epsilon': 7.942812752207439e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 4.0065785979456144e-05, 'tol': 0.0002922547713305443, 'validation_fraction': 0.3101608765226971}]
function_evaluation time 0.106857 value -0.465934 suggestion {'alpha': 0.0037292846058411874, 'batch_size': 192, 'beta_1': 0.5086740297517608, 'beta_2': 0.9890904194632026, 'epsilon': 7.942812752207439e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 4.0065785979456144e-05, 'tol': 0.0002922547713305443, 'validation_fraction': 0.3101608765226971}
observation time 0.000060, current best -0.894505 at iter 5
suggestion time taken 0.002301 iter 6 next_points [{'alpha': 0.05687297209922556, 'batch_size': 149, 'beta_1': 0.8022479993508853, 'beta_2': 0.9446798063007543, 'epsilon': 2.9712221675402515e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 2.1284404889329233e-05, 'tol': 0.0008946448617007144, 'validation_fraction': 0.17609977640990662}]
function_evaluation time 0.146990 value -0.571429 suggestion {'alpha': 0.05687297209922556, 'batch_size': 149, 'beta_1': 0.8022479993508853, 'beta_2': 0.9446798063007543, 'epsilon': 2.9712221675402515e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 2.1284404889329233e-05, 'tol': 0.0008946448617007144, 'validation_fraction': 0.17609977640990662}
observation time 0.000051, current best -0.894505 at iter 6
suggestion time taken 0.002084 iter 7 next_points [{'alpha': 1.0273664463304704e-05, 'batch_size': 14, 'beta_1': 0.7123890175766205, 'beta_2': 0.9373131910696146, 'epsilon': 2.090886820733233e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.00020043538378569924, 'tol': 0.0015288659123604558, 'validation_fraction': 0.19435339434957916}]
function_evaluation time 0.786250 value -0.901099 suggestion {'alpha': 1.0273664463304704e-05, 'batch_size': 14, 'beta_1': 0.7123890175766205, 'beta_2': 0.9373131910696146, 'epsilon': 2.090886820733233e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.00020043538378569924, 'tol': 0.0015288659123604558, 'validation_fraction': 0.19435339434957916}
observation time 0.000056, current best -0.901099 at iter 7
suggestion time taken 0.002089 iter 8 next_points [{'alpha': 0.0008484322224298251, 'batch_size': 161, 'beta_1': 0.9694630445278556, 'beta_2': 0.9937499649723283, 'epsilon': 2.0743272356567915e-07, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.05257357871752391, 'tol': 7.202368404856344e-05, 'validation_fraction': 0.1327435498603542}]
function_evaluation time 0.247714 value -0.903297 suggestion {'alpha': 0.0008484322224298251, 'batch_size': 161, 'beta_1': 0.9694630445278556, 'beta_2': 0.9937499649723283, 'epsilon': 2.0743272356567915e-07, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.05257357871752391, 'tol': 7.202368404856344e-05, 'validation_fraction': 0.1327435498603542}
observation time 0.000057, current best -0.903297 at iter 8
suggestion time taken 0.002069 iter 9 next_points [{'alpha': 0.0009217662530750172, 'batch_size': 196, 'beta_1': 0.6902940225236706, 'beta_2': 0.9343436419667396, 'epsilon': 6.950648854062422e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.001553801785796253, 'tol': 0.00067271499573694, 'validation_fraction': 0.35475588811310926}]
function_evaluation time 0.294097 value -0.916484 suggestion {'alpha': 0.0009217662530750172, 'batch_size': 196, 'beta_1': 0.6902940225236706, 'beta_2': 0.9343436419667396, 'epsilon': 6.950648854062422e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.001553801785796253, 'tol': 0.00067271499573694, 'validation_fraction': 0.35475588811310926}
observation time 0.000063, current best -0.916484 at iter 9
suggestion time taken 0.002081 iter 10 next_points [{'alpha': 3.039849331508358, 'batch_size': 174, 'beta_1': 0.8241061442361937, 'beta_2': 0.9248865439929836, 'epsilon': 4.39892086808454e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.00026813173693617675, 'tol': 0.00024440939145709266, 'validation_fraction': 0.21046754033254972}]
function_evaluation time 0.160734 value -0.635165 suggestion {'alpha': 3.039849331508358, 'batch_size': 174, 'beta_1': 0.8241061442361937, 'beta_2': 0.9248865439929836, 'epsilon': 4.39892086808454e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.00026813173693617675, 'tol': 0.00024440939145709266, 'validation_fraction': 0.21046754033254972}
observation time 0.000054, current best -0.916484 at iter 10
suggestion time taken 0.002095 iter 11 next_points [{'alpha': 0.00013440145803975405, 'batch_size': 143, 'beta_1': 0.5938710864309664, 'beta_2': 0.9094528987564287, 'epsilon': 4.3633143154056737e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.00019218371532563717, 'tol': 0.036209537455075214, 'validation_fraction': 0.2491989962245418}]
function_evaluation time 0.141208 value -0.687912 suggestion {'alpha': 0.00013440145803975405, 'batch_size': 143, 'beta_1': 0.5938710864309664, 'beta_2': 0.9094528987564287, 'epsilon': 4.3633143154056737e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.00019218371532563717, 'tol': 0.036209537455075214, 'validation_fraction': 0.2491989962245418}
observation time 0.000061, current best -0.916484 at iter 11
suggestion time taken 0.002097 iter 12 next_points [{'alpha': 4.443184486732831, 'batch_size': 235, 'beta_1': 0.8462332621760824, 'beta_2': 0.9143458323999865, 'epsilon': 5.114242173035266e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.006620603254232401, 'tol': 0.01415882692620461, 'validation_fraction': 0.4172762393795415}]
function_evaluation time 0.180595 value -0.848352 suggestion {'alpha': 4.443184486732831, 'batch_size': 235, 'beta_1': 0.8462332621760824, 'beta_2': 0.9143458323999865, 'epsilon': 5.114242173035266e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.006620603254232401, 'tol': 0.01415882692620461, 'validation_fraction': 0.4172762393795415}
observation time 0.000062, current best -0.916484 at iter 12
suggestion time taken 0.002092 iter 13 next_points [{'alpha': 1.997064873933466e-05, 'batch_size': 69, 'beta_1': 0.8008758545154542, 'beta_2': 0.9370174330610187, 'epsilon': 1.8309451212247878e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.00020872844897816198, 'tol': 0.038627720923734614, 'validation_fraction': 0.2033335331195467}]
function_evaluation time 0.139759 value -0.663736 suggestion {'alpha': 1.997064873933466e-05, 'batch_size': 69, 'beta_1': 0.8008758545154542, 'beta_2': 0.9370174330610187, 'epsilon': 1.8309451212247878e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.00020872844897816198, 'tol': 0.038627720923734614, 'validation_fraction': 0.2033335331195467}
observation time 0.000054, current best -0.916484 at iter 13
suggestion time taken 0.002082 iter 14 next_points [{'alpha': 0.03613141412952421, 'batch_size': 61, 'beta_1': 0.547305668325785, 'beta_2': 0.9148802376755868, 'epsilon': 6.537405426798979e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.007222599468967413, 'tol': 0.010735761850466164, 'validation_fraction': 0.13140459642022714}]
function_evaluation time 0.233339 value -0.918681 suggestion {'alpha': 0.03613141412952421, 'batch_size': 61, 'beta_1': 0.547305668325785, 'beta_2': 0.9148802376755868, 'epsilon': 6.537405426798979e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.007222599468967413, 'tol': 0.010735761850466164, 'validation_fraction': 0.13140459642022714}
observation time 0.000061, current best -0.918681 at iter 14
saving meta data: {'args': {'--uuid': '7a461c97235257dbade50f5d9f6d2649', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

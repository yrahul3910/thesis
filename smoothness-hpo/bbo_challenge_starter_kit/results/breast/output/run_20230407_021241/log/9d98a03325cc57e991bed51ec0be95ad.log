running: {'--uuid': '9d98a03325cc57e991bed51ec0be95ad', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'opentuner', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d breast -o opentuner -u 9d98a03325cc57e991bed51ec0be95ad -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_021241
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_nll betwen [ 4.58589285 14.6438765   8.74044796  0.67466158  3.06872636] and [ 8.10456652 20.07092365 12.33228572  5.26978359  3.49043108]
  warnings.warn(

Signature errors:
                            0         1         2         3         4       max
MLP-adam_breast_nll  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
max                  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
starting sklearn study opentuner MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.055409 iter 0 next_points [{'hidden_layer_sizes': 151, 'alpha': 5.436932216226261, 'batch_size': 166, 'learning_rate_init': 0.07982959565611585, 'tol': 0.04159333045124607, 'validation_fraction': 0.529852365655238, 'beta_1': 0.8834182367363124, 'beta_2': 0.9462540579524502, 'epsilon': 9.96546656445967e-07}]
function_evaluation time 0.199843 value 0.469135 suggestion {'hidden_layer_sizes': 151, 'alpha': 5.436932216226261, 'batch_size': 166, 'learning_rate_init': 0.07982959565611585, 'tol': 0.04159333045124607, 'validation_fraction': 0.529852365655238, 'beta_1': 0.8834182367363124, 'beta_2': 0.9462540579524502, 'epsilon': 9.96546656445967e-07}
observation time 0.004224, current best 0.469135 at iter 0
suggestion time taken 0.007750 iter 1 next_points [{'hidden_layer_sizes': 151, 'alpha': 5.436932216226261, 'batch_size': 166, 'learning_rate_init': 0.07982959565611585, 'tol': 0.04159333045124607, 'validation_fraction': 0.43152288274284845, 'beta_1': 0.8834182367363124, 'beta_2': 0.9462540579524502, 'epsilon': 9.859735391753712e-07}]
function_evaluation time 0.171870 value 4.185132 suggestion {'hidden_layer_sizes': 151, 'alpha': 5.436932216226261, 'batch_size': 166, 'learning_rate_init': 0.07982959565611585, 'tol': 0.04159333045124607, 'validation_fraction': 0.43152288274284845, 'beta_1': 0.8834182367363124, 'beta_2': 0.9462540579524502, 'epsilon': 9.859735391753712e-07}
observation time 0.001714, current best 0.469135 at iter 1
suggestion time taken 0.006553 iter 2 next_points [{'hidden_layer_sizes': 151, 'alpha': 5.436932216226261, 'batch_size': 166, 'learning_rate_init': 0.07982959565611585, 'tol': 0.04159333045124607, 'validation_fraction': 0.3593210515432411, 'beta_1': 0.8834182367363124, 'beta_2': 0.9441558162820395, 'epsilon': 9.96546656445967e-07}]
function_evaluation time 0.183284 value 3.171395 suggestion {'hidden_layer_sizes': 151, 'alpha': 5.436932216226261, 'batch_size': 166, 'learning_rate_init': 0.07982959565611585, 'tol': 0.04159333045124607, 'validation_fraction': 0.3593210515432411, 'beta_1': 0.8834182367363124, 'beta_2': 0.9441558162820395, 'epsilon': 9.96546656445967e-07}
observation time 0.002754, current best 0.469135 at iter 2
suggestion time taken 0.021179 iter 3 next_points [{'beta_2': 0.9006655585547263, 'hidden_layer_sizes': 115, 'tol': 0.0352576183259054, 'alpha': 1.3010669469269707, 'validation_fraction': 0.27042922204886444, 'learning_rate_init': 0.010273624288864958, 'beta_1': 0.8604383568724294, 'epsilon': 5.633108704547374e-08, 'batch_size': 41}]
function_evaluation time 0.311389 value 0.932298 suggestion {'beta_2': 0.9006655585547263, 'hidden_layer_sizes': 115, 'tol': 0.0352576183259054, 'alpha': 1.3010669469269707, 'validation_fraction': 0.27042922204886444, 'learning_rate_init': 0.010273624288864958, 'beta_1': 0.8604383568724294, 'epsilon': 5.633108704547374e-08, 'batch_size': 41}
observation time 0.001880, current best 0.469135 at iter 3
suggestion time taken 0.004998 iter 4 next_points [{'hidden_layer_sizes': 144, 'alpha': 2.409650033423388, 'batch_size': 166, 'learning_rate_init': 0.03710359627764508, 'tol': 0.03197948209631279, 'validation_fraction': 0.12389014839714596, 'beta_1': 0.8202363833649196, 'beta_2': 0.9327681199403811, 'epsilon': 5.311442633776076e-07}]
function_evaluation time 0.212564 value 1.671417 suggestion {'hidden_layer_sizes': 144, 'alpha': 2.409650033423388, 'batch_size': 166, 'learning_rate_init': 0.03710359627764508, 'tol': 0.03197948209631279, 'validation_fraction': 0.12389014839714596, 'beta_1': 0.8202363833649196, 'beta_2': 0.9327681199403811, 'epsilon': 5.311442633776076e-07}
observation time 0.001721, current best 0.469135 at iter 4
suggestion time taken 0.004959 iter 5 next_points [{'hidden_layer_sizes': 112, 'alpha': 0.2772224395278097, 'batch_size': 242, 'learning_rate_init': 0.0013906429118112807, 'tol': 0.053031363366349664, 'validation_fraction': 0.632325982677837, 'beta_1': 0.6045763810891678, 'beta_2': 0.9270781116427679, 'epsilon': 4.1406600717661015e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.116632 value 3.138264 suggestion {'hidden_layer_sizes': 112, 'alpha': 0.2772224395278097, 'batch_size': 242, 'learning_rate_init': 0.0013906429118112807, 'tol': 0.053031363366349664, 'validation_fraction': 0.632325982677837, 'beta_1': 0.6045763810891678, 'beta_2': 0.9270781116427679, 'epsilon': 4.1406600717661015e-07}
observation time 0.001866, current best 0.469135 at iter 5
suggestion time taken 0.004961 iter 6 next_points [{'hidden_layer_sizes': 62, 'alpha': 8.306106506361074, 'batch_size': 227, 'learning_rate_init': 0.09548599878224866, 'tol': 0.0008516262731885116, 'validation_fraction': 0.4323736308873921, 'beta_1': 0.7731768139889723, 'beta_2': 0.9368954802184505, 'epsilon': 2.0235758949102466e-07}]
function_evaluation time 0.201707 value 0.375849 suggestion {'hidden_layer_sizes': 62, 'alpha': 8.306106506361074, 'batch_size': 227, 'learning_rate_init': 0.09548599878224866, 'tol': 0.0008516262731885116, 'validation_fraction': 0.4323736308873921, 'beta_1': 0.7731768139889723, 'beta_2': 0.9368954802184505, 'epsilon': 2.0235758949102466e-07}
observation time 0.001777, current best 0.375849 at iter 6
suggestion time taken 0.004974 iter 7 next_points [{'hidden_layer_sizes': 135, 'alpha': 1.5804453117064923, 'batch_size': 144, 'learning_rate_init': 0.08314211844191736, 'tol': 0.09161878392892901, 'validation_fraction': 0.4728735633776995, 'beta_1': 0.9162053574007553, 'beta_2': 0.9895503567136255, 'epsilon': 2.9904223644624985e-07}]
function_evaluation time 0.183098 value 0.460856 suggestion {'hidden_layer_sizes': 135, 'alpha': 1.5804453117064923, 'batch_size': 144, 'learning_rate_init': 0.08314211844191736, 'tol': 0.09161878392892901, 'validation_fraction': 0.4728735633776995, 'beta_1': 0.9162053574007553, 'beta_2': 0.9895503567136255, 'epsilon': 2.9904223644624985e-07}
observation time 0.001717, current best 0.375849 at iter 7
suggestion time taken 0.004941 iter 8 next_points [{'hidden_layer_sizes': 106, 'alpha': 1.3384990137129535, 'batch_size': 144, 'learning_rate_init': 0.030442251638167873, 'tol': 0.012465466397890191, 'validation_fraction': 0.7406340602950507, 'beta_1': 0.9161591907344437, 'beta_2': 0.9702148390237623, 'epsilon': 8.914840727019802e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.186824 value 0.888346 suggestion {'hidden_layer_sizes': 106, 'alpha': 1.3384990137129535, 'batch_size': 144, 'learning_rate_init': 0.030442251638167873, 'tol': 0.012465466397890191, 'validation_fraction': 0.7406340602950507, 'beta_1': 0.9161591907344437, 'beta_2': 0.9702148390237623, 'epsilon': 8.914840727019802e-07}
observation time 0.001909, current best 0.375849 at iter 8
suggestion time taken 0.005105 iter 9 next_points [{'hidden_layer_sizes': 123, 'alpha': 0.9953854668050605, 'batch_size': 24, 'learning_rate_init': 0.09081989844612852, 'tol': 0.08861442666990486, 'validation_fraction': 0.1482659505704433, 'beta_1': 0.6331433427733175, 'beta_2': 0.9081219379918636, 'epsilon': 7.358271622298341e-07}]
function_evaluation time 0.314571 value 0.486030 suggestion {'hidden_layer_sizes': 123, 'alpha': 0.9953854668050605, 'batch_size': 24, 'learning_rate_init': 0.09081989844612852, 'tol': 0.08861442666990486, 'validation_fraction': 0.1482659505704433, 'beta_1': 0.6331433427733175, 'beta_2': 0.9081219379918636, 'epsilon': 7.358271622298341e-07}
observation time 0.002136, current best 0.375849 at iter 9
suggestion time taken 0.005185 iter 10 next_points [{'hidden_layer_sizes': 96, 'alpha': 5.3654718289483885, 'batch_size': 237, 'learning_rate_init': 0.09886926523425325, 'tol': 0.065544161334873, 'validation_fraction': 0.46406017899841545, 'beta_1': 0.6632417814361626, 'beta_2': 0.9577513181735788, 'epsilon': 1.7297155988135648e-07}]
function_evaluation time 0.128955 value 3.062922 suggestion {'hidden_layer_sizes': 96, 'alpha': 5.3654718289483885, 'batch_size': 237, 'learning_rate_init': 0.09886926523425325, 'tol': 0.065544161334873, 'validation_fraction': 0.46406017899841545, 'beta_1': 0.6632417814361626, 'beta_2': 0.9577513181735788, 'epsilon': 1.7297155988135648e-07}
observation time 0.002004, current best 0.375849 at iter 10
suggestion time taken 0.005158 iter 11 next_points [{'hidden_layer_sizes': 134, 'alpha': 3.65204580627234, 'batch_size': 128, 'learning_rate_init': 0.032068243549440094, 'tol': 0.046814369614280364, 'validation_fraction': 0.40360759782490685, 'beta_1': 0.5216116206881926, 'beta_2': 0.9777921322027491, 'epsilon': 3.197230710466338e-07}]
function_evaluation time 0.199046 value 0.663240 suggestion {'hidden_layer_sizes': 134, 'alpha': 3.65204580627234, 'batch_size': 128, 'learning_rate_init': 0.032068243549440094, 'tol': 0.046814369614280364, 'validation_fraction': 0.40360759782490685, 'beta_1': 0.5216116206881926, 'beta_2': 0.9777921322027491, 'epsilon': 3.197230710466338e-07}
observation time 0.001839, current best 0.375849 at iter 11
suggestion time taken 0.005064 iter 12 next_points [{'hidden_layer_sizes': 85, 'alpha': 6.207249455652996, 'batch_size': 56, 'learning_rate_init': 0.06231795902802267, 'tol': 0.09279716346322224, 'validation_fraction': 0.26145605352922374, 'beta_1': 0.6836808632844262, 'beta_2': 0.9305722999382439, 'epsilon': 4.13731605781147e-07}]
function_evaluation time 0.143779 value 0.637566 suggestion {'hidden_layer_sizes': 85, 'alpha': 6.207249455652996, 'batch_size': 56, 'learning_rate_init': 0.06231795902802267, 'tol': 0.09279716346322224, 'validation_fraction': 0.26145605352922374, 'beta_1': 0.6836808632844262, 'beta_2': 0.9305722999382439, 'epsilon': 4.13731605781147e-07}
observation time 0.001819, current best 0.375849 at iter 12
suggestion time taken 0.006951 iter 13 next_points [{'hidden_layer_sizes': 62, 'alpha': 8.306106506361074, 'batch_size': 231, 'learning_rate_init': 0.09983767774269407, 'tol': 0.0008516262731885116, 'validation_fraction': 0.4323736308873921, 'beta_1': 0.7731768139889723, 'beta_2': 0.9108768943732575, 'epsilon': 2.0235758949102466e-07}]
function_evaluation time 0.212566 value 0.420898 suggestion {'hidden_layer_sizes': 62, 'alpha': 8.306106506361074, 'batch_size': 231, 'learning_rate_init': 0.09983767774269407, 'tol': 0.0008516262731885116, 'validation_fraction': 0.4323736308873921, 'beta_1': 0.7731768139889723, 'beta_2': 0.9108768943732575, 'epsilon': 2.0235758949102466e-07}
observation time 0.002125, current best 0.375849 at iter 13
suggestion time taken 0.006094 iter 14 next_points [{'beta_2': 0.9694971154665032, 'hidden_layer_sizes': 100, 'tol': 0.026436948038765774, 'alpha': 0.03901544800058215, 'validation_fraction': 0.37517012292478513, 'learning_rate_init': 0.01667089688452299, 'beta_1': 0.6729401635236579, 'epsilon': 9.843400413938876e-07, 'batch_size': 77}]
function_evaluation time 0.175864 value 0.852370 suggestion {'beta_2': 0.9694971154665032, 'hidden_layer_sizes': 100, 'tol': 0.026436948038765774, 'alpha': 0.03901544800058215, 'validation_fraction': 0.37517012292478513, 'learning_rate_init': 0.01667089688452299, 'beta_1': 0.6729401635236579, 'epsilon': 9.843400413938876e-07, 'batch_size': 77}
observation time 0.001725, current best 0.375849 at iter 14
saving meta data: {'args': {'--uuid': '9d98a03325cc57e991bed51ec0be95ad', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'opentuner', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])}
saving results
saving timing
saving suggest log
done

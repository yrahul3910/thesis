running: {'--uuid': '99a626a5ed0b56cd979bd5a1b83b3905', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'turbo', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d breast -o turbo -u 99a626a5ed0b56cd979bd5a1b83b3905 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_021241
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_nll betwen [ 4.58589285 14.6438765   8.74044796  0.67466158  3.06872636] and [ 8.10456652 20.07092365 12.33228572  5.26978359  3.49043108]
  warnings.warn(

Signature errors:
                            0         1         2         3         4       max
MLP-adam_breast_nll  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
max                  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
starting sklearn study turbo MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.002182 iter 0 next_points [{'alpha': 3.019816008304977e-05, 'batch_size': 189, 'beta_1': 0.5663663844428908, 'beta_2': 0.9780865869786214, 'epsilon': 1.4329002383128505e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.008332697500174692, 'tol': 0.055578101173912, 'validation_fraction': 0.4701458341827676}]
function_evaluation time 0.143825 value 1.590812 suggestion {'alpha': 3.019816008304977e-05, 'batch_size': 189, 'beta_1': 0.5663663844428908, 'beta_2': 0.9780865869786214, 'epsilon': 1.4329002383128505e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.008332697500174692, 'tol': 0.055578101173912, 'validation_fraction': 0.4701458341827676}
observation time 0.001480, current best 1.590812 at iter 0
suggestion time taken 0.001749 iter 1 next_points [{'alpha': 0.03841383776537005, 'batch_size': 41, 'beta_1': 0.9246236932570153, 'beta_2': 0.9999822147693556, 'epsilon': 1.3124447637062314e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.0431945750176553, 'tol': 0.0007256213709836508, 'validation_fraction': 0.4957638190619832}]
function_evaluation time 0.520927 value 0.682717 suggestion {'alpha': 0.03841383776537005, 'batch_size': 41, 'beta_1': 0.9246236932570153, 'beta_2': 0.9999822147693556, 'epsilon': 1.3124447637062314e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.0431945750176553, 'tol': 0.0007256213709836508, 'validation_fraction': 0.4957638190619832}
observation time 0.001409, current best 0.682717 at iter 1
suggestion time taken 0.001797 iter 2 next_points [{'alpha': 0.8330199869710252, 'batch_size': 137, 'beta_1': 0.7485392721108449, 'beta_2': 0.9553374434223862, 'epsilon': 8.687377718893341e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 1.283270323827746e-05, 'tol': 0.0013147973238277256, 'validation_fraction': 0.6981719162975948}]
function_evaluation time 0.263443 value 7.642467 suggestion {'alpha': 0.8330199869710252, 'batch_size': 137, 'beta_1': 0.7485392721108449, 'beta_2': 0.9553374434223862, 'epsilon': 8.687377718893341e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 1.283270323827746e-05, 'tol': 0.0013147973238277256, 'validation_fraction': 0.6981719162975948}
observation time 0.001435, current best 0.682717 at iter 2
suggestion time taken 0.001749 iter 3 next_points [{'alpha': 2.9748563018299086, 'batch_size': 233, 'beta_1': 0.9444019663433113, 'beta_2': 0.9281896065214594, 'epsilon': 3.0794939466161916e-07, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.0003280516065711306, 'tol': 2.5655545486262203e-05, 'validation_fraction': 0.1731180465188754}]
function_evaluation time 0.222636 value 9.924781 suggestion {'alpha': 2.9748563018299086, 'batch_size': 233, 'beta_1': 0.9444019663433113, 'beta_2': 0.9281896065214594, 'epsilon': 3.0794939466161916e-07, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.0003280516065711306, 'tol': 2.5655545486262203e-05, 'validation_fraction': 0.1731180465188754}
observation time 0.001430, current best 0.682717 at iter 3
suggestion time taken 0.001808 iter 4 next_points [{'alpha': 1.7038885279358633, 'batch_size': 246, 'beta_1': 0.9886961962384598, 'beta_2': 0.999992995544386, 'epsilon': 5.588931917839157e-07, 'hidden_layer_sizes': 177, 'learning_rate_init': 3.2250140841719605e-05, 'tol': 0.06331229790794289, 'validation_fraction': 0.6023881879861565}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.117253 value 14.826984 suggestion {'alpha': 1.7038885279358633, 'batch_size': 246, 'beta_1': 0.9886961962384598, 'beta_2': 0.999992995544386, 'epsilon': 5.588931917839157e-07, 'hidden_layer_sizes': 177, 'learning_rate_init': 3.2250140841719605e-05, 'tol': 0.06331229790794289, 'validation_fraction': 0.6023881879861565}
observation time 0.001400, current best 0.682717 at iter 4
suggestion time taken 0.001762 iter 5 next_points [{'alpha': 5.93749786393098, 'batch_size': 15, 'beta_1': 0.5471539966935972, 'beta_2': 0.9998989833279379, 'epsilon': 2.9294659885608723e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0223174711140033, 'tol': 7.622546317268134e-05, 'validation_fraction': 0.5420327505407903}]
function_evaluation time 0.537859 value 0.376873 suggestion {'alpha': 5.93749786393098, 'batch_size': 15, 'beta_1': 0.5471539966935972, 'beta_2': 0.9998989833279379, 'epsilon': 2.9294659885608723e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0223174711140033, 'tol': 7.622546317268134e-05, 'validation_fraction': 0.5420327505407903}
observation time 0.001396, current best 0.376873 at iter 5
suggestion time taken 0.001776 iter 6 next_points [{'alpha': 0.00017204591912108933, 'batch_size': 60, 'beta_1': 0.9872418889988638, 'beta_2': 0.9991100652130789, 'epsilon': 3.528887183131372e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 9.926784120935707e-05, 'tol': 1.0092694505278088e-05, 'validation_fraction': 0.8411296489055435}]
function_evaluation time 0.180919 value 10.163005 suggestion {'alpha': 0.00017204591912108933, 'batch_size': 60, 'beta_1': 0.9872418889988638, 'beta_2': 0.9991100652130789, 'epsilon': 3.528887183131372e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 9.926784120935707e-05, 'tol': 1.0092694505278088e-05, 'validation_fraction': 0.8411296489055435}
observation time 0.001445, current best 0.376873 at iter 6
suggestion time taken 0.001837 iter 7 next_points [{'alpha': 0.0007633482007028638, 'batch_size': 121, 'beta_1': 0.9619189759994107, 'beta_2': 0.9999957041683364, 'epsilon': 2.523660544040676e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.014008167442128697, 'tol': 0.02864073006798029, 'validation_fraction': 0.40715259685408733}]
function_evaluation time 0.189893 value 0.867414 suggestion {'alpha': 0.0007633482007028638, 'batch_size': 121, 'beta_1': 0.9619189759994107, 'beta_2': 0.9999957041683364, 'epsilon': 2.523660544040676e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.014008167442128697, 'tol': 0.02864073006798029, 'validation_fraction': 0.40715259685408733}
observation time 0.001441, current best 0.376873 at iter 7
suggestion time taken 0.001780 iter 8 next_points [{'alpha': 0.23924265639352246, 'batch_size': 131, 'beta_1': 0.9103480558082832, 'beta_2': 0.9956853879200497, 'epsilon': 4.538864298817131e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.002615110630924638, 'tol': 0.0003059948180699707, 'validation_fraction': 0.12198327226635775}]
function_evaluation time 0.306913 value 0.517995 suggestion {'alpha': 0.23924265639352246, 'batch_size': 131, 'beta_1': 0.9103480558082832, 'beta_2': 0.9956853879200497, 'epsilon': 4.538864298817131e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.002615110630924638, 'tol': 0.0003059948180699707, 'validation_fraction': 0.12198327226635775}
observation time 0.001456, current best 0.376873 at iter 8
suggestion time taken 0.001721 iter 9 next_points [{'alpha': 0.007368476032291648, 'batch_size': 108, 'beta_1': 0.9685324435324283, 'beta_2': 0.9999739204567529, 'epsilon': 5.931963899591998e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0010093770561840048, 'tol': 0.00013121895227324087, 'validation_fraction': 0.7889264305737183}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.210602 value 2.552634 suggestion {'alpha': 0.007368476032291648, 'batch_size': 108, 'beta_1': 0.9685324435324283, 'beta_2': 0.9999739204567529, 'epsilon': 5.931963899591998e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0010093770561840048, 'tol': 0.00013121895227324087, 'validation_fraction': 0.7889264305737183}
observation time 0.001392, current best 0.376873 at iter 9
suggestion time taken 0.001739 iter 10 next_points [{'alpha': 1.029823199419073e-05, 'batch_size': 77, 'beta_1': 0.7838425654442548, 'beta_2': 0.9999975004622919, 'epsilon': 1.8770030459657614e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.07518013627364431, 'tol': 0.00019446772522424403, 'validation_fraction': 0.8725593300653673}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.195706 value 0.700473 suggestion {'alpha': 1.029823199419073e-05, 'batch_size': 77, 'beta_1': 0.7838425654442548, 'beta_2': 0.9999975004622919, 'epsilon': 1.8770030459657614e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.07518013627364431, 'tol': 0.00019446772522424403, 'validation_fraction': 0.8725593300653673}
observation time 0.001424, current best 0.376873 at iter 10
suggestion time taken 0.001712 iter 11 next_points [{'alpha': 0.00025490729196391975, 'batch_size': 203, 'beta_1': 0.8639298608742809, 'beta_2': 0.9999561617235028, 'epsilon': 3.971656781575368e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.8948149532364266e-05, 'tol': 0.0008163794804990244, 'validation_fraction': 0.671088726236422}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.093076 value 17.831847 suggestion {'alpha': 0.00025490729196391975, 'batch_size': 203, 'beta_1': 0.8639298608742809, 'beta_2': 0.9999561617235028, 'epsilon': 3.971656781575368e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.8948149532364266e-05, 'tol': 0.0008163794804990244, 'validation_fraction': 0.671088726236422}
observation time 0.001379, current best 0.376873 at iter 11
suggestion time taken 0.001765 iter 12 next_points [{'alpha': 0.0010104772233399924, 'batch_size': 166, 'beta_1': 0.8968131553199523, 'beta_2': 0.9999984234997144, 'epsilon': 5.457632087220124e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0001373738608435939, 'tol': 5.313943652873784e-05, 'validation_fraction': 0.1910252701112838}]
function_evaluation time 0.121018 value 12.230563 suggestion {'alpha': 0.0010104772233399924, 'batch_size': 166, 'beta_1': 0.8968131553199523, 'beta_2': 0.9999984234997144, 'epsilon': 5.457632087220124e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0001373738608435939, 'tol': 5.313943652873784e-05, 'validation_fraction': 0.1910252701112838}
observation time 0.001408, current best 0.376873 at iter 12
suggestion time taken 0.001789 iter 13 next_points [{'alpha': 0.0019381710539872312, 'batch_size': 71, 'beta_1': 0.9746255306341701, 'beta_2': 0.9880153975329232, 'epsilon': 8.443174696901222e-07, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0035075245766240455, 'tol': 0.0035837871072897883, 'validation_fraction': 0.7412678073988708}]
function_evaluation time 0.279337 value 0.851037 suggestion {'alpha': 0.0019381710539872312, 'batch_size': 71, 'beta_1': 0.9746255306341701, 'beta_2': 0.9880153975329232, 'epsilon': 8.443174696901222e-07, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0035075245766240455, 'tol': 0.0035837871072897883, 'validation_fraction': 0.7412678073988708}
observation time 0.001409, current best 0.376873 at iter 13
suggestion time taken 0.001698 iter 14 next_points [{'alpha': 8.483108390340612e-05, 'batch_size': 216, 'beta_1': 0.7134433395708574, 'beta_2': 0.9997674968917422, 'epsilon': 2.2562757093970218e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.02663282351223396, 'tol': 2.7498656384479006e-05, 'validation_fraction': 0.146169825006405}]
function_evaluation time 0.255016 value 1.224804 suggestion {'alpha': 8.483108390340612e-05, 'batch_size': 216, 'beta_1': 0.7134433395708574, 'beta_2': 0.9997674968917422, 'epsilon': 2.2562757093970218e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.02663282351223396, 'tol': 2.7498656384479006e-05, 'validation_fraction': 0.146169825006405}
observation time 0.001402, current best 0.376873 at iter 14
saving meta data: {'args': {'--uuid': '99a626a5ed0b56cd979bd5a1b83b3905', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'turbo', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': 'cc742f9aa78c520e8d2ad91e32a42314', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'random-search', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d breast -o random-search -u cc742f9aa78c520e8d2ad91e32a42314 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_021241
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_acc betwen [-0.80659341 -0.56703297 -0.66593407 -0.87912088 -0.85934066] and [-0.67692308 -0.41758242 -0.54505495 -0.78241758 -0.84395604]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_breast_acc  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
max                  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
starting sklearn study random-search MLP-adam breast acc 15 1
with data root: None
suggestion time taken 0.002515 iter 0 next_points [{'alpha': 3.0564409659208227, 'batch_size': 209, 'beta_1': 0.9760266051917229, 'beta_2': 0.9997354731881198, 'epsilon': 4.513992737701447e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 3.7930097976868315e-05, 'tol': 0.015783393384016544, 'validation_fraction': 0.3439512302111103}]
function_evaluation time 0.199207 value -0.509890 suggestion {'alpha': 3.0564409659208227, 'batch_size': 209, 'beta_1': 0.9760266051917229, 'beta_2': 0.9997354731881198, 'epsilon': 4.513992737701447e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 3.7930097976868315e-05, 'tol': 0.015783393384016544, 'validation_fraction': 0.3439512302111103}
observation time 0.000005, current best -0.509890 at iter 0
suggestion time taken 0.002713 iter 1 next_points [{'alpha': 1.7822642498604534e-05, 'batch_size': 160, 'beta_1': 0.5168774586120903, 'beta_2': 0.9998408479574441, 'epsilon': 5.353965001125486e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.015526357657584361, 'tol': 1.1232606483290257e-05, 'validation_fraction': 0.16697983504607572}]
function_evaluation time 0.230415 value -0.885714 suggestion {'alpha': 1.7822642498604534e-05, 'batch_size': 160, 'beta_1': 0.5168774586120903, 'beta_2': 0.9998408479574441, 'epsilon': 5.353965001125486e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.015526357657584361, 'tol': 1.1232606483290257e-05, 'validation_fraction': 0.16697983504607572}
observation time 0.000004, current best -0.885714 at iter 1
suggestion time taken 0.002515 iter 2 next_points [{'alpha': 0.15287829720847534, 'batch_size': 51, 'beta_1': 0.5683454969560703, 'beta_2': 0.9999974661330647, 'epsilon': 7.152194276008888e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.001402452277321979, 'tol': 0.03620229820663118, 'validation_fraction': 0.8989877574540116}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.126585 value -0.773626 suggestion {'alpha': 0.15287829720847534, 'batch_size': 51, 'beta_1': 0.5683454969560703, 'beta_2': 0.9999974661330647, 'epsilon': 7.152194276008888e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.001402452277321979, 'tol': 0.03620229820663118, 'validation_fraction': 0.8989877574540116}
observation time 0.000004, current best -0.885714 at iter 2
suggestion time taken 0.002426 iter 3 next_points [{'alpha': 0.0004957903363643853, 'batch_size': 145, 'beta_1': 0.8224589049179031, 'beta_2': 0.9999987652776174, 'epsilon': 2.5714912405807907e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.00948831084181993, 'tol': 0.007764033657464681, 'validation_fraction': 0.8089561879108371}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.159642 value -0.912088 suggestion {'alpha': 0.0004957903363643853, 'batch_size': 145, 'beta_1': 0.8224589049179031, 'beta_2': 0.9999987652776174, 'epsilon': 2.5714912405807907e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.00948831084181993, 'tol': 0.007764033657464681, 'validation_fraction': 0.8089561879108371}
observation time 0.000004, current best -0.912088 at iter 3
suggestion time taken 0.002467 iter 4 next_points [{'alpha': 1.6359164987079862, 'batch_size': 87, 'beta_1': 0.849307428242906, 'beta_2': 0.9359867158571461, 'epsilon': 2.956983792757706e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.00011878624505955407, 'tol': 0.018852588231475276, 'validation_fraction': 0.8755760675606594}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.093971 value -0.527473 suggestion {'alpha': 1.6359164987079862, 'batch_size': 87, 'beta_1': 0.849307428242906, 'beta_2': 0.9359867158571461, 'epsilon': 2.956983792757706e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.00011878624505955407, 'tol': 0.018852588231475276, 'validation_fraction': 0.8755760675606594}
observation time 0.000004, current best -0.912088 at iter 4
suggestion time taken 0.002766 iter 5 next_points [{'alpha': 7.25994108826743e-05, 'batch_size': 188, 'beta_1': 0.9209289467979714, 'beta_2': 0.9999892258512573, 'epsilon': 2.167356972886591e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 2.311838399906636e-05, 'tol': 0.0002527638410252988, 'validation_fraction': 0.8095511117803823}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.103661 value -0.529670 suggestion {'alpha': 7.25994108826743e-05, 'batch_size': 188, 'beta_1': 0.9209289467979714, 'beta_2': 0.9999892258512573, 'epsilon': 2.167356972886591e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 2.311838399906636e-05, 'tol': 0.0002527638410252988, 'validation_fraction': 0.8095511117803823}
observation time 0.000004, current best -0.912088 at iter 5
suggestion time taken 0.002449 iter 6 next_points [{'alpha': 7.717590273172963, 'batch_size': 120, 'beta_1': 0.5377573738229638, 'beta_2': 0.9084926070349302, 'epsilon': 4.578215188861411e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 2.5413936234912417e-05, 'tol': 0.004524583538831201, 'validation_fraction': 0.7985586994936494}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.123902 value -0.417582 suggestion {'alpha': 7.717590273172963, 'batch_size': 120, 'beta_1': 0.5377573738229638, 'beta_2': 0.9084926070349302, 'epsilon': 4.578215188861411e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 2.5413936234912417e-05, 'tol': 0.004524583538831201, 'validation_fraction': 0.7985586994936494}
observation time 0.000004, current best -0.912088 at iter 6
suggestion time taken 0.002442 iter 7 next_points [{'alpha': 0.00012439695342234916, 'batch_size': 27, 'beta_1': 0.9865648243163133, 'beta_2': 0.9999073303177821, 'epsilon': 5.853120361022306e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.004193992328233604, 'tol': 0.0008476774361462197, 'validation_fraction': 0.514290963752216}]
function_evaluation time 0.476512 value -0.914286 suggestion {'alpha': 0.00012439695342234916, 'batch_size': 27, 'beta_1': 0.9865648243163133, 'beta_2': 0.9999073303177821, 'epsilon': 5.853120361022306e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.004193992328233604, 'tol': 0.0008476774361462197, 'validation_fraction': 0.514290963752216}
observation time 0.000004, current best -0.914286 at iter 7
suggestion time taken 0.002395 iter 8 next_points [{'alpha': 5.4020036832078695e-05, 'batch_size': 87, 'beta_1': 0.7166500200244266, 'beta_2': 0.9999548497878634, 'epsilon': 1.8398095673966521e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.010972047747046148, 'tol': 0.046380925631873716, 'validation_fraction': 0.8107584842163474}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.180793 value -0.901099 suggestion {'alpha': 5.4020036832078695e-05, 'batch_size': 87, 'beta_1': 0.7166500200244266, 'beta_2': 0.9999548497878634, 'epsilon': 1.8398095673966521e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.010972047747046148, 'tol': 0.046380925631873716, 'validation_fraction': 0.8107584842163474}
observation time 0.000004, current best -0.914286 at iter 8
suggestion time taken 0.002462 iter 9 next_points [{'alpha': 1.3910190092738619e-05, 'batch_size': 62, 'beta_1': 0.7890289905859146, 'beta_2': 0.9999942500245194, 'epsilon': 6.535830558646612e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.0010090710850363422, 'tol': 0.01647208616233332, 'validation_fraction': 0.7215488856710854}]
function_evaluation time 0.158768 value -0.843956 suggestion {'alpha': 1.3910190092738619e-05, 'batch_size': 62, 'beta_1': 0.7890289905859146, 'beta_2': 0.9999942500245194, 'epsilon': 6.535830558646612e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.0010090710850363422, 'tol': 0.01647208616233332, 'validation_fraction': 0.7215488856710854}
observation time 0.000004, current best -0.914286 at iter 9
suggestion time taken 0.002462 iter 10 next_points [{'alpha': 1.2261222982891591e-05, 'batch_size': 215, 'beta_1': 0.9878587203191319, 'beta_2': 0.9984696210914157, 'epsilon': 4.825198707119442e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 5.1523869242277076e-05, 'tol': 2.438200302783425e-05, 'validation_fraction': 0.46420791321174776}]
function_evaluation time 0.120679 value -0.527473 suggestion {'alpha': 1.2261222982891591e-05, 'batch_size': 215, 'beta_1': 0.9878587203191319, 'beta_2': 0.9984696210914157, 'epsilon': 4.825198707119442e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 5.1523869242277076e-05, 'tol': 2.438200302783425e-05, 'validation_fraction': 0.46420791321174776}
observation time 0.000004, current best -0.914286 at iter 10
suggestion time taken 0.002476 iter 11 next_points [{'alpha': 0.17966161210641743, 'batch_size': 34, 'beta_1': 0.841108861769533, 'beta_2': 0.9999237632306363, 'epsilon': 5.505963774532267e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.008698143187281163, 'tol': 0.06658783905107826, 'validation_fraction': 0.8833997359582322}]
function_evaluation time 0.153694 value -0.909890 suggestion {'alpha': 0.17966161210641743, 'batch_size': 34, 'beta_1': 0.841108861769533, 'beta_2': 0.9999237632306363, 'epsilon': 5.505963774532267e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.008698143187281163, 'tol': 0.06658783905107826, 'validation_fraction': 0.8833997359582322}
observation time 0.000003, current best -0.914286 at iter 11
suggestion time taken 0.002387 iter 12 next_points [{'alpha': 1.037429975679853, 'batch_size': 151, 'beta_1': 0.8307557939765938, 'beta_2': 0.9336851256313589, 'epsilon': 1.1364766068175584e-09, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.000498887226120888, 'tol': 0.004909839069312431, 'validation_fraction': 0.5265021556850138}]
function_evaluation time 0.338645 value -0.912088 suggestion {'alpha': 1.037429975679853, 'batch_size': 151, 'beta_1': 0.8307557939765938, 'beta_2': 0.9336851256313589, 'epsilon': 1.1364766068175584e-09, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.000498887226120888, 'tol': 0.004909839069312431, 'validation_fraction': 0.5265021556850138}
observation time 0.000004, current best -0.914286 at iter 12
suggestion time taken 0.002385 iter 13 next_points [{'alpha': 0.00025980286898378055, 'batch_size': 245, 'beta_1': 0.7696025495024079, 'beta_2': 0.9999943088210413, 'epsilon': 1.796262973443296e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.0004037744489631444, 'tol': 0.00013599181558671575, 'validation_fraction': 0.8705396628393554}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.114689 value -0.529670 suggestion {'alpha': 0.00025980286898378055, 'batch_size': 245, 'beta_1': 0.7696025495024079, 'beta_2': 0.9999943088210413, 'epsilon': 1.796262973443296e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.0004037744489631444, 'tol': 0.00013599181558671575, 'validation_fraction': 0.8705396628393554}
observation time 0.000005, current best -0.914286 at iter 13
suggestion time taken 0.002455 iter 14 next_points [{'alpha': 0.0036890225222083873, 'batch_size': 113, 'beta_1': 0.6544704465661162, 'beta_2': 0.9935365446025703, 'epsilon': 8.794862888633463e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 8.245108055260578e-05, 'tol': 6.335369260103325e-05, 'validation_fraction': 0.37482872524000793}]
function_evaluation time 0.141652 value -0.483516 suggestion {'alpha': 0.0036890225222083873, 'batch_size': 113, 'beta_1': 0.6544704465661162, 'beta_2': 0.9935365446025703, 'epsilon': 8.794862888633463e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 8.245108055260578e-05, 'tol': 6.335369260103325e-05, 'validation_fraction': 0.37482872524000793}
observation time 0.000004, current best -0.914286 at iter 14
saving meta data: {'args': {'--uuid': 'cc742f9aa78c520e8d2ad91e32a42314', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'random-search', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': 'ce7c9bf266645aa1abe12f1ac3755fa5', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'turbo', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d breast -o turbo -u ce7c9bf266645aa1abe12f1ac3755fa5 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_021241
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_acc betwen [-0.80659341 -0.56703297 -0.66593407 -0.87912088 -0.85934066] and [-0.67692308 -0.41758242 -0.54505495 -0.78241758 -0.84395604]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_breast_acc  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
max                  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
starting sklearn study turbo MLP-adam breast acc 15 1
with data root: None
suggestion time taken 0.002394 iter 0 next_points [{'alpha': 0.005765791512292794, 'batch_size': 101, 'beta_1': 0.7784932973640883, 'beta_2': 0.9709447402306622, 'epsilon': 2.5602364526352796e-07, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.01134790975644111, 'tol': 0.0033157027663279987, 'validation_fraction': 0.4370741527711202}]
function_evaluation time 0.160681 value -0.901099 suggestion {'alpha': 0.005765791512292794, 'batch_size': 101, 'beta_1': 0.7784932973640883, 'beta_2': 0.9709447402306622, 'epsilon': 2.5602364526352796e-07, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.01134790975644111, 'tol': 0.0033157027663279987, 'validation_fraction': 0.4370741527711202}
observation time 0.001371, current best -0.901099 at iter 0
suggestion time taken 0.001726 iter 1 next_points [{'alpha': 0.17030103546561684, 'batch_size': 39, 'beta_1': 0.742774778286981, 'beta_2': 0.9999233968859584, 'epsilon': 5.309944545001726e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.006046022360772907, 'tol': 1.1700104663919065e-05, 'validation_fraction': 0.25479987059607234}]
function_evaluation time 0.366870 value -0.898901 suggestion {'alpha': 0.17030103546561684, 'batch_size': 39, 'beta_1': 0.742774778286981, 'beta_2': 0.9999233968859584, 'epsilon': 5.309944545001726e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.006046022360772907, 'tol': 1.1700104663919065e-05, 'validation_fraction': 0.25479987059607234}
observation time 0.001363, current best -0.901099 at iter 1
suggestion time taken 0.001718 iter 2 next_points [{'alpha': 0.00037248936522993315, 'batch_size': 65, 'beta_1': 0.8879987979830213, 'beta_2': 0.9994235343910715, 'epsilon': 1.3246705985226094e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.08672276673526239, 'tol': 0.00014900419212519395, 'validation_fraction': 0.8146049986675401}]
function_evaluation time 0.183386 value -0.793407 suggestion {'alpha': 0.00037248936522993315, 'batch_size': 65, 'beta_1': 0.8879987979830213, 'beta_2': 0.9994235343910715, 'epsilon': 1.3246705985226094e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.08672276673526239, 'tol': 0.00014900419212519395, 'validation_fraction': 0.8146049986675401}
observation time 0.001328, current best -0.901099 at iter 2
suggestion time taken 0.001734 iter 3 next_points [{'alpha': 0.008832054572737644, 'batch_size': 185, 'beta_1': 0.9329562363747073, 'beta_2': 0.9957439623502571, 'epsilon': 4.244564742089599e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.0003771554726595717, 'tol': 0.001235530691719532, 'validation_fraction': 0.7069210804230713}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.097658 value -0.531868 suggestion {'alpha': 0.008832054572737644, 'batch_size': 185, 'beta_1': 0.9329562363747073, 'beta_2': 0.9957439623502571, 'epsilon': 4.244564742089599e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.0003771554726595717, 'tol': 0.001235530691719532, 'validation_fraction': 0.7069210804230713}
observation time 0.001295, current best -0.901099 at iter 3
suggestion time taken 0.001768 iter 4 next_points [{'alpha': 0.3386113624556104, 'batch_size': 188, 'beta_1': 0.9688394237549444, 'beta_2': 0.9999871177463298, 'epsilon': 5.519016368938595e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 7.547061230408041e-05, 'tol': 0.004661698996049493, 'validation_fraction': 0.15504796997514877}]
function_evaluation time 0.155676 value -0.523077 suggestion {'alpha': 0.3386113624556104, 'batch_size': 188, 'beta_1': 0.9688394237549444, 'beta_2': 0.9999871177463298, 'epsilon': 5.519016368938595e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 7.547061230408041e-05, 'tol': 0.004661698996049493, 'validation_fraction': 0.15504796997514877}
observation time 0.001378, current best -0.901099 at iter 4
suggestion time taken 0.001697 iter 5 next_points [{'alpha': 0.06417124406961465, 'batch_size': 55, 'beta_1': 0.6640196404032094, 'beta_2': 0.9999388994990672, 'epsilon': 4.199118966327796e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0029318858430149647, 'tol': 0.009224146155629324, 'validation_fraction': 0.7602498994330805}]
function_evaluation time 0.179967 value -0.846154 suggestion {'alpha': 0.06417124406961465, 'batch_size': 55, 'beta_1': 0.6640196404032094, 'beta_2': 0.9999388994990672, 'epsilon': 4.199118966327796e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0029318858430149647, 'tol': 0.009224146155629324, 'validation_fraction': 0.7602498994330805}
observation time 0.001414, current best -0.901099 at iter 5
suggestion time taken 0.001709 iter 6 next_points [{'alpha': 8.575371336284165e-05, 'batch_size': 113, 'beta_1': 0.9891864904504392, 'beta_2': 0.9999963203330074, 'epsilon': 1.0116327876437982e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.022180858229349242, 'tol': 0.020778406403222836, 'validation_fraction': 0.8621541332279195}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.165422 value -0.883516 suggestion {'alpha': 8.575371336284165e-05, 'batch_size': 113, 'beta_1': 0.9891864904504392, 'beta_2': 0.9999963203330074, 'epsilon': 1.0116327876437982e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.022180858229349242, 'tol': 0.020778406403222836, 'validation_fraction': 0.8621541332279195}
observation time 0.001349, current best -0.901099 at iter 6
suggestion time taken 0.001958 iter 7 next_points [{'alpha': 4.976492215721201, 'batch_size': 160, 'beta_1': 0.9388513610672153, 'beta_2': 0.999788480194249, 'epsilon': 4.11466693452007e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.024215469064846742, 'tol': 0.025913731567524485, 'validation_fraction': 0.5643119693404675}]
function_evaluation time 0.204556 value -0.846154 suggestion {'alpha': 4.976492215721201, 'batch_size': 160, 'beta_1': 0.9388513610672153, 'beta_2': 0.999788480194249, 'epsilon': 4.11466693452007e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.024215469064846742, 'tol': 0.025913731567524485, 'validation_fraction': 0.5643119693404675}
observation time 0.001299, current best -0.901099 at iter 7
suggestion time taken 0.001741 iter 8 next_points [{'alpha': 0.0009339664160975804, 'batch_size': 206, 'beta_1': 0.975187575944002, 'beta_2': 0.9864070469715922, 'epsilon': 2.09189836647532e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0008246466007358513, 'tol': 0.00010146041966387188, 'validation_fraction': 0.47785962982107594}]
function_evaluation time 0.161563 value -0.714286 suggestion {'alpha': 0.0009339664160975804, 'batch_size': 206, 'beta_1': 0.975187575944002, 'beta_2': 0.9864070469715922, 'epsilon': 2.09189836647532e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0008246466007358513, 'tol': 0.00010146041966387188, 'validation_fraction': 0.47785962982107594}
observation time 0.001379, current best -0.901099 at iter 8
suggestion time taken 0.001699 iter 9 next_points [{'alpha': 0.00016954032416660928, 'batch_size': 222, 'beta_1': 0.8168654569077379, 'beta_2': 0.9999661017267019, 'epsilon': 1.9043177269461256e-09, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.005226616432205152, 'tol': 0.0013203329263683171, 'validation_fraction': 0.8430034211204133}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.227112 value -0.909890 suggestion {'alpha': 0.00016954032416660928, 'batch_size': 222, 'beta_1': 0.8168654569077379, 'beta_2': 0.9999661017267019, 'epsilon': 1.9043177269461256e-09, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.005226616432205152, 'tol': 0.0013203329263683171, 'validation_fraction': 0.8430034211204133}
observation time 0.001331, current best -0.909890 at iter 9
suggestion time taken 0.001705 iter 10 next_points [{'alpha': 0.6340561824117706, 'batch_size': 173, 'beta_1': 0.9557760690771153, 'beta_2': 0.9991395623188232, 'epsilon': 3.4703582411022086e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.053758903307353785, 'tol': 0.0007323003101628632, 'validation_fraction': 0.10359026836771239}]
function_evaluation time 0.276323 value -0.892308 suggestion {'alpha': 0.6340561824117706, 'batch_size': 173, 'beta_1': 0.9557760690771153, 'beta_2': 0.9991395623188232, 'epsilon': 3.4703582411022086e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.053758903307353785, 'tol': 0.0007323003101628632, 'validation_fraction': 0.10359026836771239}
observation time 0.001363, current best -0.909890 at iter 10
suggestion time taken 0.001697 iter 11 next_points [{'alpha': 2.2826509519107113e-05, 'batch_size': 93, 'beta_1': 0.6177951710109868, 'beta_2': 0.9997349364267204, 'epsilon': 5.807674717978343e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.0002339147394379632, 'tol': 0.07090006145189381, 'validation_fraction': 0.1309216513071279}]
function_evaluation time 0.191960 value -0.850549 suggestion {'alpha': 2.2826509519107113e-05, 'batch_size': 93, 'beta_1': 0.6177951710109868, 'beta_2': 0.9997349364267204, 'epsilon': 5.807674717978343e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.0002339147394379632, 'tol': 0.07090006145189381, 'validation_fraction': 0.1309216513071279}
observation time 0.001368, current best -0.909890 at iter 11
suggestion time taken 0.001696 iter 12 next_points [{'alpha': 1.3097966906563178e-05, 'batch_size': 138, 'beta_1': 0.548783925716214, 'beta_2': 0.9595154045321612, 'epsilon': 7.037083256775088e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0006002933662361018, 'tol': 0.005598929779915071, 'validation_fraction': 0.20503620739156844}]
function_evaluation time 0.451238 value -0.885714 suggestion {'alpha': 1.3097966906563178e-05, 'batch_size': 138, 'beta_1': 0.548783925716214, 'beta_2': 0.9595154045321612, 'epsilon': 7.037083256775088e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0006002933662361018, 'tol': 0.005598929779915071, 'validation_fraction': 0.20503620739156844}
observation time 0.001371, current best -0.909890 at iter 12
suggestion time taken 0.001980 iter 13 next_points [{'alpha': 0.04332159172777248, 'batch_size': 242, 'beta_1': 0.9050646351531336, 'beta_2': 0.9999980216365842, 'epsilon': 1.3757023537529583e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.0015194607316903874, 'tol': 5.3100307298402954e-05, 'validation_fraction': 0.29513787439658173}]
function_evaluation time 0.202961 value -0.786813 suggestion {'alpha': 0.04332159172777248, 'batch_size': 242, 'beta_1': 0.9050646351531336, 'beta_2': 0.9999980216365842, 'epsilon': 1.3757023537529583e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.0015194607316903874, 'tol': 5.3100307298402954e-05, 'validation_fraction': 0.29513787439658173}
observation time 0.001382, current best -0.909890 at iter 13
suggestion time taken 0.001691 iter 14 next_points [{'alpha': 0.019568396994120406, 'batch_size': 230, 'beta_1': 0.8683862505612542, 'beta_2': 0.9928919994822126, 'epsilon': 8.745876435969434e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 3.726485276998023e-05, 'tol': 3.0469773664643576e-05, 'validation_fraction': 0.41126488745909856}]
function_evaluation time 0.110191 value -0.523077 suggestion {'alpha': 0.019568396994120406, 'batch_size': 230, 'beta_1': 0.8683862505612542, 'beta_2': 0.9928919994822126, 'epsilon': 8.745876435969434e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 3.726485276998023e-05, 'tol': 3.0469773664643576e-05, 'validation_fraction': 0.41126488745909856}
observation time 0.001364, current best -0.909890 at iter 14
saving meta data: {'args': {'--uuid': 'ce7c9bf266645aa1abe12f1ac3755fa5', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'turbo', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

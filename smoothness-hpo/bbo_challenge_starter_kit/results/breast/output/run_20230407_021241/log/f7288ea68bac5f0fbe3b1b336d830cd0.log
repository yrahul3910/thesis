running: {'--uuid': 'f7288ea68bac5f0fbe3b1b336d830cd0', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'random-search', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d breast -o random-search -u f7288ea68bac5f0fbe3b1b336d830cd0 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_021241
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_nll betwen [ 4.58589285 14.6438765   8.74044796  0.67466158  3.06872636] and [ 8.10456652 20.07092365 12.33228572  5.26978359  3.49043108]
  warnings.warn(

Signature errors:
                            0         1         2         3         4       max
MLP-adam_breast_nll  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
max                  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
starting sklearn study random-search MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.002587 iter 0 next_points [{'alpha': 9.560296666495485e-05, 'batch_size': 160, 'beta_1': 0.5382409889384836, 'beta_2': 0.9999988662458636, 'epsilon': 6.6118752114904766e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.00041678128894794556, 'tol': 0.00013518553101194098, 'validation_fraction': 0.43034264141388245}]
function_evaluation time 0.357109 value 5.447839 suggestion {'alpha': 9.560296666495485e-05, 'batch_size': 160, 'beta_1': 0.5382409889384836, 'beta_2': 0.9999988662458636, 'epsilon': 6.6118752114904766e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.00041678128894794556, 'tol': 0.00013518553101194098, 'validation_fraction': 0.43034264141388245}
observation time 0.000005, current best 5.447839 at iter 0
suggestion time taken 0.002641 iter 1 next_points [{'alpha': 1.1339049152271667, 'batch_size': 142, 'beta_1': 0.9372739781332375, 'beta_2': 0.9999859025482726, 'epsilon': 1.8383334384397143e-07, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.004531068722909592, 'tol': 0.0354509453087337, 'validation_fraction': 0.8090838135831449}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.120647 value 5.753533 suggestion {'alpha': 1.1339049152271667, 'batch_size': 142, 'beta_1': 0.9372739781332375, 'beta_2': 0.9999859025482726, 'epsilon': 1.8383334384397143e-07, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.004531068722909592, 'tol': 0.0354509453087337, 'validation_fraction': 0.8090838135831449}
observation time 0.000004, current best 5.447839 at iter 1
suggestion time taken 0.002519 iter 2 next_points [{'alpha': 0.010029972161529004, 'batch_size': 166, 'beta_1': 0.608162971400886, 'beta_2': 0.9999854694434841, 'epsilon': 1.5760840934878848e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.0027124272802339796, 'tol': 0.002391992468528262, 'validation_fraction': 0.4340717563710901}]
function_evaluation time 0.349007 value 0.335991 suggestion {'alpha': 0.010029972161529004, 'batch_size': 166, 'beta_1': 0.608162971400886, 'beta_2': 0.9999854694434841, 'epsilon': 1.5760840934878848e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.0027124272802339796, 'tol': 0.002391992468528262, 'validation_fraction': 0.4340717563710901}
observation time 0.000004, current best 0.335991 at iter 2
suggestion time taken 0.002429 iter 3 next_points [{'alpha': 0.0001844003399996697, 'batch_size': 108, 'beta_1': 0.5302463250894204, 'beta_2': 0.9990933154938489, 'epsilon': 5.556455543829739e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.026171908729424896, 'tol': 0.0051032328756518384, 'validation_fraction': 0.3364233702468651}]
function_evaluation time 0.142244 value 0.954897 suggestion {'alpha': 0.0001844003399996697, 'batch_size': 108, 'beta_1': 0.5302463250894204, 'beta_2': 0.9990933154938489, 'epsilon': 5.556455543829739e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.026171908729424896, 'tol': 0.0051032328756518384, 'validation_fraction': 0.3364233702468651}
observation time 0.000003, current best 0.335991 at iter 3
suggestion time taken 0.002528 iter 4 next_points [{'alpha': 2.694557677533137, 'batch_size': 59, 'beta_1': 0.571475911098338, 'beta_2': 0.9999946178081194, 'epsilon': 1.4938078056012525e-08, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.00027349577709163844, 'tol': 0.00019835092002843332, 'validation_fraction': 0.8928339517665388}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.182374 value 9.705391 suggestion {'alpha': 2.694557677533137, 'batch_size': 59, 'beta_1': 0.571475911098338, 'beta_2': 0.9999946178081194, 'epsilon': 1.4938078056012525e-08, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.00027349577709163844, 'tol': 0.00019835092002843332, 'validation_fraction': 0.8928339517665388}
observation time 0.000003, current best 0.335991 at iter 4
suggestion time taken 0.002826 iter 5 next_points [{'alpha': 3.4186499712332834e-05, 'batch_size': 38, 'beta_1': 0.816604696277541, 'beta_2': 0.9951444943006853, 'epsilon': 6.970293704381738e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 6.837873704589512e-05, 'tol': 2.3430565212219426e-05, 'validation_fraction': 0.13108560064574135}]
function_evaluation time 0.428789 value 7.578375 suggestion {'alpha': 3.4186499712332834e-05, 'batch_size': 38, 'beta_1': 0.816604696277541, 'beta_2': 0.9951444943006853, 'epsilon': 6.970293704381738e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 6.837873704589512e-05, 'tol': 2.3430565212219426e-05, 'validation_fraction': 0.13108560064574135}
observation time 0.000005, current best 0.335991 at iter 5
suggestion time taken 0.002448 iter 6 next_points [{'alpha': 1.2426850554933372e-05, 'batch_size': 46, 'beta_1': 0.9255021240010171, 'beta_2': 0.9955604545353146, 'epsilon': 2.7722271068138558e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.0005610348833244728, 'tol': 7.334859455108377e-05, 'validation_fraction': 0.15707032394318668}]
function_evaluation time 0.391761 value 0.252433 suggestion {'alpha': 1.2426850554933372e-05, 'batch_size': 46, 'beta_1': 0.9255021240010171, 'beta_2': 0.9955604545353146, 'epsilon': 2.7722271068138558e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.0005610348833244728, 'tol': 7.334859455108377e-05, 'validation_fraction': 0.15707032394318668}
observation time 0.000004, current best 0.252433 at iter 6
suggestion time taken 0.002418 iter 7 next_points [{'alpha': 0.00043308039089046384, 'batch_size': 21, 'beta_1': 0.9255937906498419, 'beta_2': 0.9925401916338835, 'epsilon': 2.023253737050137e-07, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.007139934042840414, 'tol': 0.0014290689812875737, 'validation_fraction': 0.2694306987635907}]
function_evaluation time 0.747038 value 0.699236 suggestion {'alpha': 0.00043308039089046384, 'batch_size': 21, 'beta_1': 0.9255937906498419, 'beta_2': 0.9925401916338835, 'epsilon': 2.023253737050137e-07, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.007139934042840414, 'tol': 0.0014290689812875737, 'validation_fraction': 0.2694306987635907}
observation time 0.000004, current best 0.252433 at iter 7
suggestion time taken 0.002442 iter 8 next_points [{'alpha': 5.67095947503049, 'batch_size': 246, 'beta_1': 0.9888824266460794, 'beta_2': 0.9999940556396966, 'epsilon': 7.089565790691537e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.05439056843554602, 'tol': 0.0001591364838794146, 'validation_fraction': 0.523160216301812}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.193751 value 3.380255 suggestion {'alpha': 5.67095947503049, 'batch_size': 246, 'beta_1': 0.9888824266460794, 'beta_2': 0.9999940556396966, 'epsilon': 7.089565790691537e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.05439056843554602, 'tol': 0.0001591364838794146, 'validation_fraction': 0.523160216301812}
observation time 0.000003, current best 0.252433 at iter 8
suggestion time taken 0.002429 iter 9 next_points [{'alpha': 1.757005870457201e-05, 'batch_size': 120, 'beta_1': 0.7499889755528347, 'beta_2': 0.9998668494340941, 'epsilon': 1.273868047058211e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.0006699767904980823, 'tol': 0.00444170078746882, 'validation_fraction': 0.7920266175724157}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.197822 value 7.462788 suggestion {'alpha': 1.757005870457201e-05, 'batch_size': 120, 'beta_1': 0.7499889755528347, 'beta_2': 0.9998668494340941, 'epsilon': 1.273868047058211e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.0006699767904980823, 'tol': 0.00444170078746882, 'validation_fraction': 0.7920266175724157}
observation time 0.000004, current best 0.252433 at iter 9
suggestion time taken 0.002470 iter 10 next_points [{'alpha': 9.17452964336103, 'batch_size': 248, 'beta_1': 0.8235104103271675, 'beta_2': 0.999902200671701, 'epsilon': 1.3664096708887994e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.00012485430005241112, 'tol': 0.0003018329331404304, 'validation_fraction': 0.15203479029420525}]
function_evaluation time 0.224923 value 12.453714 suggestion {'alpha': 9.17452964336103, 'batch_size': 248, 'beta_1': 0.8235104103271675, 'beta_2': 0.999902200671701, 'epsilon': 1.3664096708887994e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.00012485430005241112, 'tol': 0.0003018329331404304, 'validation_fraction': 0.15203479029420525}
observation time 0.000004, current best 0.252433 at iter 10
suggestion time taken 0.002464 iter 11 next_points [{'alpha': 2.1146081158742347, 'batch_size': 235, 'beta_1': 0.9759942808063744, 'beta_2': 0.9914943655852972, 'epsilon': 1.2982836466625886e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0018763840765449959, 'tol': 4.1042125541953384e-05, 'validation_fraction': 0.18050466361533588}]
function_evaluation time 0.260074 value 3.302047 suggestion {'alpha': 2.1146081158742347, 'batch_size': 235, 'beta_1': 0.9759942808063744, 'beta_2': 0.9914943655852972, 'epsilon': 1.2982836466625886e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0018763840765449959, 'tol': 4.1042125541953384e-05, 'validation_fraction': 0.18050466361533588}
observation time 0.000004, current best 0.252433 at iter 11
suggestion time taken 0.002458 iter 12 next_points [{'alpha': 0.0005236019613798228, 'batch_size': 161, 'beta_1': 0.5146739914963637, 'beta_2': 0.9999827592330363, 'epsilon': 5.1342974381611746e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.00011353695676708217, 'tol': 5.0719289773081405e-05, 'validation_fraction': 0.24591257661960234}]
function_evaluation time 0.208376 value 20.978075 suggestion {'alpha': 0.0005236019613798228, 'batch_size': 161, 'beta_1': 0.5146739914963637, 'beta_2': 0.9999827592330363, 'epsilon': 5.1342974381611746e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.00011353695676708217, 'tol': 5.0719289773081405e-05, 'validation_fraction': 0.24591257661960234}
observation time 0.000004, current best 0.252433 at iter 12
suggestion time taken 0.002443 iter 13 next_points [{'alpha': 0.0032923547290025237, 'batch_size': 228, 'beta_1': 0.9853562210695682, 'beta_2': 0.9626335420522156, 'epsilon': 8.20498117106977e-09, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.0009019716354402443, 'tol': 0.0030872941807505412, 'validation_fraction': 0.6730572079795644}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.265449 value 2.217947 suggestion {'alpha': 0.0032923547290025237, 'batch_size': 228, 'beta_1': 0.9853562210695682, 'beta_2': 0.9626335420522156, 'epsilon': 8.20498117106977e-09, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.0009019716354402443, 'tol': 0.0030872941807505412, 'validation_fraction': 0.6730572079795644}
observation time 0.000005, current best 0.252433 at iter 13
suggestion time taken 0.002504 iter 14 next_points [{'alpha': 2.3454412492868295e-05, 'batch_size': 174, 'beta_1': 0.9773309818234591, 'beta_2': 0.999946872429146, 'epsilon': 2.5802950382297048e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.00024773784641341374, 'tol': 0.006494192339239479, 'validation_fraction': 0.4407066392848252}]
function_evaluation time 0.184680 value 10.138865 suggestion {'alpha': 2.3454412492868295e-05, 'batch_size': 174, 'beta_1': 0.9773309818234591, 'beta_2': 0.999946872429146, 'epsilon': 2.5802950382297048e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.00024773784641341374, 'tol': 0.006494192339239479, 'validation_fraction': 0.4407066392848252}
observation time 0.000004, current best 0.252433 at iter 14
saving meta data: {'args': {'--uuid': 'f7288ea68bac5f0fbe3b1b336d830cd0', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'random-search', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])}
saving results
saving timing
saving suggest log
done

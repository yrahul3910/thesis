running: {'--uuid': '9a7d4b123b61592388cd684fd41b0afa', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d breast -o hyperopt -u 9a7d4b123b61592388cd684fd41b0afa -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_021241
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_nll betwen [ 4.58589285 14.6438765   8.74044796  0.67466158  3.06872636] and [ 8.10456652 20.07092365 12.33228572  5.26978359  3.49043108]
  warnings.warn(

Signature errors:
                            0         1         2         3         4       max
MLP-adam_breast_nll  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
max                  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
starting sklearn study hyperopt MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.002390 iter 0 next_points [{'alpha': 0.006940260950358712, 'batch_size': 148, 'beta_1': 0.6218708802719901, 'beta_2': 0.9978707938760849, 'epsilon': 7.048935850412704e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.014631711958995852, 'tol': 0.0040076457242863225, 'validation_fraction': 0.12641470690519332}]
function_evaluation time 0.135652 value 0.731980 suggestion {'alpha': 0.006940260950358712, 'batch_size': 148, 'beta_1': 0.6218708802719901, 'beta_2': 0.9978707938760849, 'epsilon': 7.048935850412704e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.014631711958995852, 'tol': 0.0040076457242863225, 'validation_fraction': 0.12641470690519332}
observation time 0.000063, current best 0.731980 at iter 0
suggestion time taken 0.002140 iter 1 next_points [{'alpha': 6.893928401062268e-05, 'batch_size': 166, 'beta_1': 0.798461823064193, 'beta_2': 0.9749744003768048, 'epsilon': 1.0718128943349053e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0002678257911309585, 'tol': 0.03341959247907541, 'validation_fraction': 0.44724100858238575}]
function_evaluation time 0.187644 value 8.393944 suggestion {'alpha': 6.893928401062268e-05, 'batch_size': 166, 'beta_1': 0.798461823064193, 'beta_2': 0.9749744003768048, 'epsilon': 1.0718128943349053e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0002678257911309585, 'tol': 0.03341959247907541, 'validation_fraction': 0.44724100858238575}
observation time 0.000059, current best 0.731980 at iter 1
suggestion time taken 0.002289 iter 2 next_points [{'alpha': 0.2368092898381786, 'batch_size': 40, 'beta_1': 0.579504751499433, 'beta_2': 0.9993124869294338, 'epsilon': 2.582821954414503e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.00021014339015207223, 'tol': 0.03257141693342791, 'validation_fraction': 0.6738646005099752}]
function_evaluation time 0.207107 value 7.399172 suggestion {'alpha': 0.2368092898381786, 'batch_size': 40, 'beta_1': 0.579504751499433, 'beta_2': 0.9993124869294338, 'epsilon': 2.582821954414503e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.00021014339015207223, 'tol': 0.03257141693342791, 'validation_fraction': 0.6738646005099752}
observation time 0.000059, current best 0.731980 at iter 2
suggestion time taken 0.002053 iter 3 next_points [{'alpha': 8.929549145045118e-05, 'batch_size': 239, 'beta_1': 0.5106593184059371, 'beta_2': 0.9795198103491704, 'epsilon': 5.120784013709255e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 9.609122318031551e-05, 'tol': 0.004574530029431852, 'validation_fraction': 0.2825028573001731}]
function_evaluation time 0.108634 value 18.696518 suggestion {'alpha': 8.929549145045118e-05, 'batch_size': 239, 'beta_1': 0.5106593184059371, 'beta_2': 0.9795198103491704, 'epsilon': 5.120784013709255e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 9.609122318031551e-05, 'tol': 0.004574530029431852, 'validation_fraction': 0.2825028573001731}
observation time 0.000061, current best 0.731980 at iter 3
suggestion time taken 0.002300 iter 4 next_points [{'alpha': 2.4054001622068362e-05, 'batch_size': 12, 'beta_1': 0.5493312372234915, 'beta_2': 0.9602723306755354, 'epsilon': 1.319164882871088e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.005253922589216781, 'tol': 0.004725519774170737, 'validation_fraction': 0.12396126007068285}]
function_evaluation time 0.875163 value 0.893005 suggestion {'alpha': 2.4054001622068362e-05, 'batch_size': 12, 'beta_1': 0.5493312372234915, 'beta_2': 0.9602723306755354, 'epsilon': 1.319164882871088e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.005253922589216781, 'tol': 0.004725519774170737, 'validation_fraction': 0.12396126007068285}
observation time 0.000073, current best 0.731980 at iter 4
suggestion time taken 0.002192 iter 5 next_points [{'alpha': 0.001749399424195248, 'batch_size': 182, 'beta_1': 0.8070861988331378, 'beta_2': 0.9687359759111904, 'epsilon': 3.787502578544705e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.0052719767717537055, 'tol': 0.0006449147683877999, 'validation_fraction': 0.39870741414115746}]
function_evaluation time 0.238463 value 0.497821 suggestion {'alpha': 0.001749399424195248, 'batch_size': 182, 'beta_1': 0.8070861988331378, 'beta_2': 0.9687359759111904, 'epsilon': 3.787502578544705e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.0052719767717537055, 'tol': 0.0006449147683877999, 'validation_fraction': 0.39870741414115746}
observation time 0.000063, current best 0.497821 at iter 5
suggestion time taken 0.002107 iter 6 next_points [{'alpha': 3.179821018530564e-05, 'batch_size': 192, 'beta_1': 0.6304168846624939, 'beta_2': 0.9826321379764519, 'epsilon': 1.039741527448484e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.05022115972335859, 'tol': 0.0053048776651415655, 'validation_fraction': 0.7490926208501373}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.191230 value 0.865241 suggestion {'alpha': 3.179821018530564e-05, 'batch_size': 192, 'beta_1': 0.6304168846624939, 'beta_2': 0.9826321379764519, 'epsilon': 1.039741527448484e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.05022115972335859, 'tol': 0.0053048776651415655, 'validation_fraction': 0.7490926208501373}
observation time 0.000064, current best 0.497821 at iter 6
suggestion time taken 0.002110 iter 7 next_points [{'alpha': 0.011538313639124944, 'batch_size': 28, 'beta_1': 0.593414288490041, 'beta_2': 0.9246746380256466, 'epsilon': 2.655398602779421e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.010892085723671728, 'tol': 0.0009102578837549245, 'validation_fraction': 0.2537325278128373}]
function_evaluation time 0.476786 value 1.375349 suggestion {'alpha': 0.011538313639124944, 'batch_size': 28, 'beta_1': 0.593414288490041, 'beta_2': 0.9246746380256466, 'epsilon': 2.655398602779421e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.010892085723671728, 'tol': 0.0009102578837549245, 'validation_fraction': 0.2537325278128373}
observation time 0.000060, current best 0.497821 at iter 7
suggestion time taken 0.002284 iter 8 next_points [{'alpha': 0.15856240244034386, 'batch_size': 181, 'beta_1': 0.6083566629458755, 'beta_2': 0.9056074665325439, 'epsilon': 2.3500141017788543e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0014562557481255984, 'tol': 0.02959036878069558, 'validation_fraction': 0.18493010428907614}]
function_evaluation time 0.150225 value 2.953678 suggestion {'alpha': 0.15856240244034386, 'batch_size': 181, 'beta_1': 0.6083566629458755, 'beta_2': 0.9056074665325439, 'epsilon': 2.3500141017788543e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0014562557481255984, 'tol': 0.02959036878069558, 'validation_fraction': 0.18493010428907614}
observation time 0.000073, current best 0.497821 at iter 8
suggestion time taken 0.002142 iter 9 next_points [{'alpha': 0.0034363983117919033, 'batch_size': 230, 'beta_1': 0.6122588987325137, 'beta_2': 0.9320868864805358, 'epsilon': 2.3632779054787645e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.00021807700876747755, 'tol': 0.0008836489263192994, 'validation_fraction': 0.1807931474741739}]
function_evaluation time 0.234126 value 5.095876 suggestion {'alpha': 0.0034363983117919033, 'batch_size': 230, 'beta_1': 0.6122588987325137, 'beta_2': 0.9320868864805358, 'epsilon': 2.3632779054787645e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.00021807700876747755, 'tol': 0.0008836489263192994, 'validation_fraction': 0.1807931474741739}
observation time 0.000065, current best 0.497821 at iter 9
suggestion time taken 0.002105 iter 10 next_points [{'alpha': 0.06295932966843756, 'batch_size': 106, 'beta_1': 0.7285479271392452, 'beta_2': 0.9680641527566832, 'epsilon': 1.7528137791601686e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.011945200198744415, 'tol': 0.0008953263002981314, 'validation_fraction': 0.5920120950026858}]
function_evaluation time 0.305864 value 0.802284 suggestion {'alpha': 0.06295932966843756, 'batch_size': 106, 'beta_1': 0.7285479271392452, 'beta_2': 0.9680641527566832, 'epsilon': 1.7528137791601686e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.011945200198744415, 'tol': 0.0008953263002981314, 'validation_fraction': 0.5920120950026858}
observation time 0.000065, current best 0.497821 at iter 10
suggestion time taken 0.002118 iter 11 next_points [{'alpha': 0.0010108116332497778, 'batch_size': 14, 'beta_1': 0.7396964243880876, 'beta_2': 0.9153574491368965, 'epsilon': 7.749965968903775e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.0001468474570277833, 'tol': 0.08413252874071801, 'validation_fraction': 0.1393056643432686}]
function_evaluation time 0.544281 value 0.364459 suggestion {'alpha': 0.0010108116332497778, 'batch_size': 14, 'beta_1': 0.7396964243880876, 'beta_2': 0.9153574491368965, 'epsilon': 7.749965968903775e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.0001468474570277833, 'tol': 0.08413252874071801, 'validation_fraction': 0.1393056643432686}
observation time 0.000067, current best 0.364459 at iter 11
suggestion time taken 0.002282 iter 12 next_points [{'alpha': 1.1311724530087046e-05, 'batch_size': 126, 'beta_1': 0.6326455303990239, 'beta_2': 0.9628374599462768, 'epsilon': 2.107325728718814e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 1.3452566411620823e-05, 'tol': 0.005722075185818864, 'validation_fraction': 0.7572226709050869}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.096991 value 21.303916 suggestion {'alpha': 1.1311724530087046e-05, 'batch_size': 126, 'beta_1': 0.6326455303990239, 'beta_2': 0.9628374599462768, 'epsilon': 2.107325728718814e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 1.3452566411620823e-05, 'tol': 0.005722075185818864, 'validation_fraction': 0.7572226709050869}
observation time 0.000074, current best 0.364459 at iter 12
suggestion time taken 0.002165 iter 13 next_points [{'alpha': 0.10354534097517355, 'batch_size': 245, 'beta_1': 0.9848497757502889, 'beta_2': 0.9375319812841221, 'epsilon': 2.082095079766654e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 9.165751113420975e-05, 'tol': 0.024906398609184442, 'validation_fraction': 0.14099055914276912}]
function_evaluation time 0.199157 value 4.591959 suggestion {'alpha': 0.10354534097517355, 'batch_size': 245, 'beta_1': 0.9848497757502889, 'beta_2': 0.9375319812841221, 'epsilon': 2.082095079766654e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 9.165751113420975e-05, 'tol': 0.024906398609184442, 'validation_fraction': 0.14099055914276912}
observation time 0.000068, current best 0.364459 at iter 13
suggestion time taken 0.002089 iter 14 next_points [{'alpha': 0.3968930697653805, 'batch_size': 247, 'beta_1': 0.7860318774181746, 'beta_2': 0.9627924475453319, 'epsilon': 3.2175269815181533e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0003961704201888961, 'tol': 0.01198716978340402, 'validation_fraction': 0.5358265463411335}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.136742 value 5.782224 suggestion {'alpha': 0.3968930697653805, 'batch_size': 247, 'beta_1': 0.7860318774181746, 'beta_2': 0.9627924475453319, 'epsilon': 3.2175269815181533e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0003961704201888961, 'tol': 0.01198716978340402, 'validation_fraction': 0.5358265463411335}
observation time 0.000063, current best 0.364459 at iter 14
saving meta data: {'args': {'--uuid': '9a7d4b123b61592388cd684fd41b0afa', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])}
saving results
saving timing
saving suggest log
done

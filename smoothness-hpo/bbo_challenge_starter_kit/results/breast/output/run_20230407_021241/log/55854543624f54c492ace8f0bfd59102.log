running: {'--uuid': '55854543624f54c492ace8f0bfd59102', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d breast -o hyperopt -u 55854543624f54c492ace8f0bfd59102 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_021241
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_nll betwen [ 4.58589285 14.6438765   8.74044796  0.67466158  3.06872636] and [ 8.10456652 20.07092365 12.33228572  5.26978359  3.49043108]
  warnings.warn(

Signature errors:
                            0         1         2         3         4       max
MLP-adam_breast_nll  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
max                  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
starting sklearn study hyperopt MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.002317 iter 0 next_points [{'alpha': 0.010272099694811132, 'batch_size': 224, 'beta_1': 0.6721290144822597, 'beta_2': 0.9353627939593343, 'epsilon': 6.796227956609158e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 2.1371681655450458e-05, 'tol': 4.4502372104548436e-05, 'validation_fraction': 0.8720327804276814}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.083558 value 14.208855 suggestion {'alpha': 0.010272099694811132, 'batch_size': 224, 'beta_1': 0.6721290144822597, 'beta_2': 0.9353627939593343, 'epsilon': 6.796227956609158e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 2.1371681655450458e-05, 'tol': 4.4502372104548436e-05, 'validation_fraction': 0.8720327804276814}
observation time 0.000063, current best 14.208855 at iter 0
suggestion time taken 0.002118 iter 1 next_points [{'alpha': 1.3302360669154372, 'batch_size': 165, 'beta_1': 0.6193095693554447, 'beta_2': 0.9308595252331728, 'epsilon': 6.508320505129964e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.0033525899367237216, 'tol': 0.02068788035894768, 'validation_fraction': 0.30368293673238494}]
function_evaluation time 0.206504 value 0.418513 suggestion {'alpha': 1.3302360669154372, 'batch_size': 165, 'beta_1': 0.6193095693554447, 'beta_2': 0.9308595252331728, 'epsilon': 6.508320505129964e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.0033525899367237216, 'tol': 0.02068788035894768, 'validation_fraction': 0.30368293673238494}
observation time 0.000057, current best 0.418513 at iter 1
suggestion time taken 0.002253 iter 2 next_points [{'alpha': 0.007813738375548116, 'batch_size': 124, 'beta_1': 0.9124383563838042, 'beta_2': 0.9956309347902177, 'epsilon': 2.9727993519811926e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0027358284564950003, 'tol': 0.0007631090417206263, 'validation_fraction': 0.3121001748160225}]
function_evaluation time 0.279163 value 0.578999 suggestion {'alpha': 0.007813738375548116, 'batch_size': 124, 'beta_1': 0.9124383563838042, 'beta_2': 0.9956309347902177, 'epsilon': 2.9727993519811926e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0027358284564950003, 'tol': 0.0007631090417206263, 'validation_fraction': 0.3121001748160225}
observation time 0.000061, current best 0.418513 at iter 2
suggestion time taken 0.002270 iter 3 next_points [{'alpha': 0.03141568936786653, 'batch_size': 128, 'beta_1': 0.7333676906263555, 'beta_2': 0.9114585517171171, 'epsilon': 1.0938343439343159e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.001074695714052425, 'tol': 0.006699013793849089, 'validation_fraction': 0.10768447773272613}]
function_evaluation time 0.318550 value 0.366956 suggestion {'alpha': 0.03141568936786653, 'batch_size': 128, 'beta_1': 0.7333676906263555, 'beta_2': 0.9114585517171171, 'epsilon': 1.0938343439343159e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.001074695714052425, 'tol': 0.006699013793849089, 'validation_fraction': 0.10768447773272613}
observation time 0.000071, current best 0.366956 at iter 3
suggestion time taken 0.002367 iter 4 next_points [{'alpha': 0.0004659211578764614, 'batch_size': 178, 'beta_1': 0.8124776860336725, 'beta_2': 0.943882244209014, 'epsilon': 4.635423308336659e-08, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.0005986640626642236, 'tol': 0.005010276872189152, 'validation_fraction': 0.10934275201757804}]
function_evaluation time 0.276578 value 2.949947 suggestion {'alpha': 0.0004659211578764614, 'batch_size': 178, 'beta_1': 0.8124776860336725, 'beta_2': 0.943882244209014, 'epsilon': 4.635423308336659e-08, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.0005986640626642236, 'tol': 0.005010276872189152, 'validation_fraction': 0.10934275201757804}
observation time 0.000073, current best 0.366956 at iter 4
suggestion time taken 0.002162 iter 5 next_points [{'alpha': 0.0018950648178065659, 'batch_size': 212, 'beta_1': 0.7519238440475594, 'beta_2': 0.9619695786634652, 'epsilon': 4.2328996499558707e-07, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.00015368686519330612, 'tol': 0.005381133083586195, 'validation_fraction': 0.559736307697689}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.112321 value 16.986309 suggestion {'alpha': 0.0018950648178065659, 'batch_size': 212, 'beta_1': 0.7519238440475594, 'beta_2': 0.9619695786634652, 'epsilon': 4.2328996499558707e-07, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.00015368686519330612, 'tol': 0.005381133083586195, 'validation_fraction': 0.559736307697689}
observation time 0.000072, current best 0.366956 at iter 5
suggestion time taken 0.002156 iter 6 next_points [{'alpha': 1.5771364904122231, 'batch_size': 107, 'beta_1': 0.6072078419384089, 'beta_2': 0.9715892929833443, 'epsilon': 9.647208850786214e-09, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.00026457593681016803, 'tol': 0.000615887636994987, 'validation_fraction': 0.33980249154344266}]
function_evaluation time 0.387474 value 2.871849 suggestion {'alpha': 1.5771364904122231, 'batch_size': 107, 'beta_1': 0.6072078419384089, 'beta_2': 0.9715892929833443, 'epsilon': 9.647208850786214e-09, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.00026457593681016803, 'tol': 0.000615887636994987, 'validation_fraction': 0.33980249154344266}
observation time 0.000071, current best 0.366956 at iter 6
suggestion time taken 0.002200 iter 7 next_points [{'alpha': 0.3761533942158958, 'batch_size': 104, 'beta_1': 0.7440565216284618, 'beta_2': 0.9651684856570842, 'epsilon': 2.5394535385126453e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 1.6661351451253644e-05, 'tol': 7.687649908289876e-05, 'validation_fraction': 0.47355743341218576}]
function_evaluation time 0.212652 value 7.498265 suggestion {'alpha': 0.3761533942158958, 'batch_size': 104, 'beta_1': 0.7440565216284618, 'beta_2': 0.9651684856570842, 'epsilon': 2.5394535385126453e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 1.6661351451253644e-05, 'tol': 7.687649908289876e-05, 'validation_fraction': 0.47355743341218576}
observation time 0.000074, current best 0.366956 at iter 7
suggestion time taken 0.002371 iter 8 next_points [{'alpha': 0.00017559272674519034, 'batch_size': 201, 'beta_1': 0.6220955234358018, 'beta_2': 0.9663052903144737, 'epsilon': 3.010253914211452e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 7.47147676478326e-05, 'tol': 0.0031572529982631433, 'validation_fraction': 0.2743615579925481}]
function_evaluation time 0.143988 value 16.484650 suggestion {'alpha': 0.00017559272674519034, 'batch_size': 201, 'beta_1': 0.6220955234358018, 'beta_2': 0.9663052903144737, 'epsilon': 3.010253914211452e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 7.47147676478326e-05, 'tol': 0.0031572529982631433, 'validation_fraction': 0.2743615579925481}
observation time 0.000076, current best 0.366956 at iter 8
suggestion time taken 0.002156 iter 9 next_points [{'alpha': 0.8623844144680091, 'batch_size': 173, 'beta_1': 0.6149451918182499, 'beta_2': 0.9793763548668507, 'epsilon': 2.1998763402061054e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0022981820691582917, 'tol': 0.03031880122849186, 'validation_fraction': 0.15893547042652692}]
function_evaluation time 0.198663 value 0.494320 suggestion {'alpha': 0.8623844144680091, 'batch_size': 173, 'beta_1': 0.6149451918182499, 'beta_2': 0.9793763548668507, 'epsilon': 2.1998763402061054e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0022981820691582917, 'tol': 0.03031880122849186, 'validation_fraction': 0.15893547042652692}
observation time 0.000074, current best 0.366956 at iter 9
suggestion time taken 0.002161 iter 10 next_points [{'alpha': 0.000132895523773496, 'batch_size': 33, 'beta_1': 0.669850373983421, 'beta_2': 0.9092915065548084, 'epsilon': 2.2776137745200414e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.04188495358538851, 'tol': 0.00222581837523031, 'validation_fraction': 0.20567991820002357}]
function_evaluation time 0.316985 value 0.599729 suggestion {'alpha': 0.000132895523773496, 'batch_size': 33, 'beta_1': 0.669850373983421, 'beta_2': 0.9092915065548084, 'epsilon': 2.2776137745200414e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.04188495358538851, 'tol': 0.00222581837523031, 'validation_fraction': 0.20567991820002357}
observation time 0.000080, current best 0.366956 at iter 10
suggestion time taken 0.002144 iter 11 next_points [{'alpha': 1.08782339596795e-05, 'batch_size': 191, 'beta_1': 0.5744760809933547, 'beta_2': 0.9641696971824378, 'epsilon': 1.8926923649042213e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.054893488934330055, 'tol': 0.06433782641204851, 'validation_fraction': 0.24483231579618905}]
function_evaluation time 0.172559 value 0.773991 suggestion {'alpha': 1.08782339596795e-05, 'batch_size': 191, 'beta_1': 0.5744760809933547, 'beta_2': 0.9641696971824378, 'epsilon': 1.8926923649042213e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.054893488934330055, 'tol': 0.06433782641204851, 'validation_fraction': 0.24483231579618905}
observation time 0.000075, current best 0.366956 at iter 11
suggestion time taken 0.002161 iter 12 next_points [{'alpha': 0.00043303371748795386, 'batch_size': 184, 'beta_1': 0.9402206952675729, 'beta_2': 0.9098683235647993, 'epsilon': 1.2250613196984483e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.00014241744607451081, 'tol': 0.02565608921195659, 'validation_fraction': 0.71112096924073}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.119671 value 11.436642 suggestion {'alpha': 0.00043303371748795386, 'batch_size': 184, 'beta_1': 0.9402206952675729, 'beta_2': 0.9098683235647993, 'epsilon': 1.2250613196984483e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.00014241744607451081, 'tol': 0.02565608921195659, 'validation_fraction': 0.71112096924073}
observation time 0.000077, current best 0.366956 at iter 12
suggestion time taken 0.002126 iter 13 next_points [{'alpha': 0.02534610111573676, 'batch_size': 196, 'beta_1': 0.9316769113344827, 'beta_2': 0.9091001135839738, 'epsilon': 1.4463007139644696e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 2.452416442133257e-05, 'tol': 0.011337819912263231, 'validation_fraction': 0.43272438531553264}]
function_evaluation time 0.116169 value 12.651251 suggestion {'alpha': 0.02534610111573676, 'batch_size': 196, 'beta_1': 0.9316769113344827, 'beta_2': 0.9091001135839738, 'epsilon': 1.4463007139644696e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 2.452416442133257e-05, 'tol': 0.011337819912263231, 'validation_fraction': 0.43272438531553264}
observation time 0.000082, current best 0.366956 at iter 13
suggestion time taken 0.002161 iter 14 next_points [{'alpha': 0.0018339923280415221, 'batch_size': 132, 'beta_1': 0.7348299286351085, 'beta_2': 0.9991384442845425, 'epsilon': 2.8339546956385892e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.00011471795626718904, 'tol': 0.014567346247618521, 'validation_fraction': 0.3368552627137504}]
function_evaluation time 0.213056 value 8.155662 suggestion {'alpha': 0.0018339923280415221, 'batch_size': 132, 'beta_1': 0.7348299286351085, 'beta_2': 0.9991384442845425, 'epsilon': 2.8339546956385892e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.00011471795626718904, 'tol': 0.014567346247618521, 'validation_fraction': 0.3368552627137504}
observation time 0.000078, current best 0.366956 at iter 14
saving meta data: {'args': {'--uuid': '55854543624f54c492ace8f0bfd59102', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])}
saving results
saving timing
saving suggest log
done

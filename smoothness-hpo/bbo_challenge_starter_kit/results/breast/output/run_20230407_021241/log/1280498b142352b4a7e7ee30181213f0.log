running: {'--uuid': '1280498b142352b4a7e7ee30181213f0', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'random-search', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d breast -o random-search -u 1280498b142352b4a7e7ee30181213f0 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_021241
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_nll betwen [ 4.58589285 14.6438765   8.74044796  0.67466158  3.06872636] and [ 8.10456652 20.07092365 12.33228572  5.26978359  3.49043108]
  warnings.warn(

Signature errors:
                            0         1         2         3         4       max
MLP-adam_breast_nll  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
max                  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
starting sklearn study random-search MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.002504 iter 0 next_points [{'alpha': 0.00014778048280541796, 'batch_size': 85, 'beta_1': 0.9768194633503299, 'beta_2': 0.9985311248239411, 'epsilon': 1.3416407037351166e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 6.762236372409916e-05, 'tol': 0.0036320377157102596, 'validation_fraction': 0.8648082948245502}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.097139 value 16.146046 suggestion {'alpha': 0.00014778048280541796, 'batch_size': 85, 'beta_1': 0.9768194633503299, 'beta_2': 0.9985311248239411, 'epsilon': 1.3416407037351166e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 6.762236372409916e-05, 'tol': 0.0036320377157102596, 'validation_fraction': 0.8648082948245502}
observation time 0.000006, current best 16.146046 at iter 0
suggestion time taken 0.002468 iter 1 next_points [{'alpha': 0.3610808260545668, 'batch_size': 247, 'beta_1': 0.5784633644911769, 'beta_2': 0.9920453567432855, 'epsilon': 1.0857359037231645e-09, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.006044625981982852, 'tol': 0.09712995354523657, 'validation_fraction': 0.8570597266041137}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.148037 value 0.638546 suggestion {'alpha': 0.3610808260545668, 'batch_size': 247, 'beta_1': 0.5784633644911769, 'beta_2': 0.9920453567432855, 'epsilon': 1.0857359037231645e-09, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.006044625981982852, 'tol': 0.09712995354523657, 'validation_fraction': 0.8570597266041137}
observation time 0.000003, current best 0.638546 at iter 1
suggestion time taken 0.002436 iter 2 next_points [{'alpha': 0.0014148176349867631, 'batch_size': 71, 'beta_1': 0.9743825043917499, 'beta_2': 0.9923250142032948, 'epsilon': 9.528121943915586e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.002708743006163625, 'tol': 2.6104327053726657e-05, 'validation_fraction': 0.14633125381562334}]
function_evaluation time 0.322442 value 0.911662 suggestion {'alpha': 0.0014148176349867631, 'batch_size': 71, 'beta_1': 0.9743825043917499, 'beta_2': 0.9923250142032948, 'epsilon': 9.528121943915586e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.002708743006163625, 'tol': 2.6104327053726657e-05, 'validation_fraction': 0.14633125381562334}
observation time 0.000004, current best 0.638546 at iter 2
suggestion time taken 0.002461 iter 3 next_points [{'alpha': 0.1828621231853016, 'batch_size': 222, 'beta_1': 0.9773951823819238, 'beta_2': 0.999880332008434, 'epsilon': 2.178722244864082e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.001757925574970808, 'tol': 0.0021247407452601435, 'validation_fraction': 0.10378639941013162}]
function_evaluation time 0.264055 value 3.385251 suggestion {'alpha': 0.1828621231853016, 'batch_size': 222, 'beta_1': 0.9773951823819238, 'beta_2': 0.999880332008434, 'epsilon': 2.178722244864082e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.001757925574970808, 'tol': 0.0021247407452601435, 'validation_fraction': 0.10378639941013162}
observation time 0.000003, current best 0.638546 at iter 3
suggestion time taken 0.002442 iter 4 next_points [{'alpha': 0.00011473099756641616, 'batch_size': 114, 'beta_1': 0.9437143957472447, 'beta_2': 0.9960596346973071, 'epsilon': 3.635717223010954e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.003316950097334135, 'tol': 0.00044706826944402786, 'validation_fraction': 0.4776791000898757}]
function_evaluation time 0.257817 value 0.724538 suggestion {'alpha': 0.00011473099756641616, 'batch_size': 114, 'beta_1': 0.9437143957472447, 'beta_2': 0.9960596346973071, 'epsilon': 3.635717223010954e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.003316950097334135, 'tol': 0.00044706826944402786, 'validation_fraction': 0.4776791000898757}
observation time 0.000003, current best 0.638546 at iter 4
suggestion time taken 0.002410 iter 5 next_points [{'alpha': 0.016844368634016164, 'batch_size': 151, 'beta_1': 0.9716517269560815, 'beta_2': 0.9998301856101754, 'epsilon': 1.662514995498329e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 8.041008133931398e-05, 'tol': 0.0069119306081171904, 'validation_fraction': 0.8288699755711836}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.102815 value 20.086944 suggestion {'alpha': 0.016844368634016164, 'batch_size': 151, 'beta_1': 0.9716517269560815, 'beta_2': 0.9998301856101754, 'epsilon': 1.662514995498329e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 8.041008133931398e-05, 'tol': 0.0069119306081171904, 'validation_fraction': 0.8288699755711836}
observation time 0.000005, current best 0.638546 at iter 5
suggestion time taken 0.002495 iter 6 next_points [{'alpha': 0.00019439923530545692, 'batch_size': 67, 'beta_1': 0.9153993514925374, 'beta_2': 0.9990831188200738, 'epsilon': 1.239656986431618e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 4.752267941996851e-05, 'tol': 0.0009333199504646557, 'validation_fraction': 0.21661967633860332}]
function_evaluation time 0.405282 value 11.535497 suggestion {'alpha': 0.00019439923530545692, 'batch_size': 67, 'beta_1': 0.9153993514925374, 'beta_2': 0.9990831188200738, 'epsilon': 1.239656986431618e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 4.752267941996851e-05, 'tol': 0.0009333199504646557, 'validation_fraction': 0.21661967633860332}
observation time 0.000003, current best 0.638546 at iter 6
suggestion time taken 0.002389 iter 7 next_points [{'alpha': 5.978862271688985, 'batch_size': 177, 'beta_1': 0.9262464363428196, 'beta_2': 0.9999892145711715, 'epsilon': 4.3917642006459865e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 7.889133368196967e-05, 'tol': 0.08752990138691522, 'validation_fraction': 0.5130033775036439}]
function_evaluation time 0.118585 value 12.643244 suggestion {'alpha': 5.978862271688985, 'batch_size': 177, 'beta_1': 0.9262464363428196, 'beta_2': 0.9999892145711715, 'epsilon': 4.3917642006459865e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 7.889133368196967e-05, 'tol': 0.08752990138691522, 'validation_fraction': 0.5130033775036439}
observation time 0.000004, current best 0.638546 at iter 7
suggestion time taken 0.002685 iter 8 next_points [{'alpha': 0.04230341143504522, 'batch_size': 82, 'beta_1': 0.9822636506001311, 'beta_2': 0.99998856681458, 'epsilon': 7.650430811970902e-09, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.052189054886879555, 'tol': 0.0013143660009659016, 'validation_fraction': 0.5135659434804092}]
function_evaluation time 0.319563 value 0.728488 suggestion {'alpha': 0.04230341143504522, 'batch_size': 82, 'beta_1': 0.9822636506001311, 'beta_2': 0.99998856681458, 'epsilon': 7.650430811970902e-09, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.052189054886879555, 'tol': 0.0013143660009659016, 'validation_fraction': 0.5135659434804092}
observation time 0.000003, current best 0.638546 at iter 8
suggestion time taken 0.002409 iter 9 next_points [{'alpha': 0.03557637216487048, 'batch_size': 213, 'beta_1': 0.9697653889496984, 'beta_2': 0.9623774825747636, 'epsilon': 3.3299300130345325e-09, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.007276361366825481, 'tol': 0.04790191607163509, 'validation_fraction': 0.8740558433408084}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.160416 value 3.571229 suggestion {'alpha': 0.03557637216487048, 'batch_size': 213, 'beta_1': 0.9697653889496984, 'beta_2': 0.9623774825747636, 'epsilon': 3.3299300130345325e-09, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.007276361366825481, 'tol': 0.04790191607163509, 'validation_fraction': 0.8740558433408084}
observation time 0.000003, current best 0.638546 at iter 9
suggestion time taken 0.002371 iter 10 next_points [{'alpha': 4.278481755758988e-05, 'batch_size': 42, 'beta_1': 0.9463269354049952, 'beta_2': 0.999628296139463, 'epsilon': 6.058172069873968e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 1.2194053382060139e-05, 'tol': 0.0031425427949234386, 'validation_fraction': 0.8430518137849893}]
function_evaluation time 0.177731 value 10.560392 suggestion {'alpha': 4.278481755758988e-05, 'batch_size': 42, 'beta_1': 0.9463269354049952, 'beta_2': 0.999628296139463, 'epsilon': 6.058172069873968e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 1.2194053382060139e-05, 'tol': 0.0031425427949234386, 'validation_fraction': 0.8430518137849893}
observation time 0.000004, current best 0.638546 at iter 10
suggestion time taken 0.002713 iter 11 next_points [{'alpha': 9.803174840435416, 'batch_size': 95, 'beta_1': 0.989426009875355, 'beta_2': 0.9999559988895174, 'epsilon': 4.863037357725356e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.0624088586118853e-05, 'tol': 4.59988594393671e-05, 'validation_fraction': 0.737853030495448}]
function_evaluation time 0.120986 value 12.848029 suggestion {'alpha': 9.803174840435416, 'batch_size': 95, 'beta_1': 0.989426009875355, 'beta_2': 0.9999559988895174, 'epsilon': 4.863037357725356e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.0624088586118853e-05, 'tol': 4.59988594393671e-05, 'validation_fraction': 0.737853030495448}
observation time 0.000003, current best 0.638546 at iter 11
suggestion time taken 0.002419 iter 12 next_points [{'alpha': 0.003452127072082004, 'batch_size': 125, 'beta_1': 0.9202524583762121, 'beta_2': 0.9996393664458395, 'epsilon': 1.2726320935626326e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 5.3414697738659236e-05, 'tol': 0.0012140874729720792, 'validation_fraction': 0.11862754939010832}]
function_evaluation time 0.228412 value 9.928272 suggestion {'alpha': 0.003452127072082004, 'batch_size': 125, 'beta_1': 0.9202524583762121, 'beta_2': 0.9996393664458395, 'epsilon': 1.2726320935626326e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 5.3414697738659236e-05, 'tol': 0.0012140874729720792, 'validation_fraction': 0.11862754939010832}
observation time 0.000003, current best 0.638546 at iter 12
suggestion time taken 0.002625 iter 13 next_points [{'alpha': 0.24495304554233838, 'batch_size': 237, 'beta_1': 0.887999529231311, 'beta_2': 0.999964173027316, 'epsilon': 6.853318988910869e-07, 'hidden_layer_sizes': 127, 'learning_rate_init': 2.7627487614561665e-05, 'tol': 0.021285493897140406, 'validation_fraction': 0.8513685586867409}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.091271 value 17.772189 suggestion {'alpha': 0.24495304554233838, 'batch_size': 237, 'beta_1': 0.887999529231311, 'beta_2': 0.999964173027316, 'epsilon': 6.853318988910869e-07, 'hidden_layer_sizes': 127, 'learning_rate_init': 2.7627487614561665e-05, 'tol': 0.021285493897140406, 'validation_fraction': 0.8513685586867409}
observation time 0.000004, current best 0.638546 at iter 13
suggestion time taken 0.002484 iter 14 next_points [{'alpha': 1.4880147983989844e-05, 'batch_size': 137, 'beta_1': 0.8499833609787825, 'beta_2': 0.9556685542839748, 'epsilon': 9.92215095967859e-09, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.003328442829302895, 'tol': 0.068719661186798, 'validation_fraction': 0.1286072954387738}]
function_evaluation time 0.184765 value 0.445965 suggestion {'alpha': 1.4880147983989844e-05, 'batch_size': 137, 'beta_1': 0.8499833609787825, 'beta_2': 0.9556685542839748, 'epsilon': 9.92215095967859e-09, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.003328442829302895, 'tol': 0.068719661186798, 'validation_fraction': 0.1286072954387738}
observation time 0.000004, current best 0.445965 at iter 14
saving meta data: {'args': {'--uuid': '1280498b142352b4a7e7ee30181213f0', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'random-search', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])}
saving results
saving timing
saving suggest log
done

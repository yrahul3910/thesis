running: {'--uuid': 'e3b3043911cd576090610f82a5ed9bb7', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'smoothness', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d breast -o smoothness -u e3b3043911cd576090610f82a5ed9bb7 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_021241
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_acc betwen [-0.80659341 -0.56703297 -0.66593407 -0.87912088 -0.85934066] and [-0.67692308 -0.41758242 -0.54505495 -0.78241758 -0.84395604]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_breast_acc  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
max                  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
starting sklearn study smoothness MLP-adam breast acc 15 1
with data root: None
suggestion time taken 11.273257 iter 0 next_points [{'alpha': 0.2616443967879076, 'batch_size': 31, 'beta_1': 0.916096232536842, 'beta_2': 0.9999656947941928, 'epsilon': 2.4940493509442518e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.0018321516240881557, 'tol': 0.0005473484713024439, 'validation_fraction': 0.4426164143884383}]
function_evaluation time 0.338319 value -0.903297 suggestion {'alpha': 0.2616443967879076, 'batch_size': 31, 'beta_1': 0.916096232536842, 'beta_2': 0.9999656947941928, 'epsilon': 2.4940493509442518e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.0018321516240881557, 'tol': 0.0005473484713024439, 'validation_fraction': 0.4426164143884383}
observation time 0.000004, current best -0.903297 at iter 0
suggestion time taken 11.349144 iter 1 next_points [{'alpha': 2.6750931148689634e-05, 'batch_size': 43, 'beta_1': 0.7718496548668451, 'beta_2': 0.9999956534842273, 'epsilon': 6.941712345754439e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.004077150025385896, 'tol': 1.7321517158212842e-05, 'validation_fraction': 0.6901272686890528}]
function_evaluation time 0.346790 value -0.907692 suggestion {'alpha': 2.6750931148689634e-05, 'batch_size': 43, 'beta_1': 0.7718496548668451, 'beta_2': 0.9999956534842273, 'epsilon': 6.941712345754439e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.004077150025385896, 'tol': 1.7321517158212842e-05, 'validation_fraction': 0.6901272686890528}
observation time 0.000004, current best -0.907692 at iter 1
suggestion time taken 11.029642 iter 2 next_points [{'alpha': 0.012606538538651846, 'batch_size': 20, 'beta_1': 0.5795149199459456, 'beta_2': 0.9997487668245819, 'epsilon': 8.682074282122697e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 1.698847830085327e-05, 'tol': 0.000279034933252491, 'validation_fraction': 0.18469692940142404}]
function_evaluation time 0.767823 value -0.639560 suggestion {'alpha': 0.012606538538651846, 'batch_size': 20, 'beta_1': 0.5795149199459456, 'beta_2': 0.9997487668245819, 'epsilon': 8.682074282122697e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 1.698847830085327e-05, 'tol': 0.000279034933252491, 'validation_fraction': 0.18469692940142404}
observation time 0.000005, current best -0.907692 at iter 2
suggestion time taken 11.391299 iter 3 next_points [{'alpha': 0.004362325308686522, 'batch_size': 11, 'beta_1': 0.9002904006134324, 'beta_2': 0.9999177294939695, 'epsilon': 3.509502804668336e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.02137339010443706, 'tol': 0.008377332235443829, 'validation_fraction': 0.10760213899564604}]
function_evaluation time 0.661199 value -0.907692 suggestion {'alpha': 0.004362325308686522, 'batch_size': 11, 'beta_1': 0.9002904006134324, 'beta_2': 0.9999177294939695, 'epsilon': 3.509502804668336e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.02137339010443706, 'tol': 0.008377332235443829, 'validation_fraction': 0.10760213899564604}
observation time 0.000004, current best -0.907692 at iter 3
suggestion time taken 11.119581 iter 4 next_points [{'alpha': 0.0001021270151824786, 'batch_size': 40, 'beta_1': 0.718356863421566, 'beta_2': 0.9816507569146958, 'epsilon': 9.99979966335439e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 8.50328683549826e-05, 'tol': 0.022051498772516838, 'validation_fraction': 0.811661373268269}]
function_evaluation time 0.111239 value -0.487912 suggestion {'alpha': 0.0001021270151824786, 'batch_size': 40, 'beta_1': 0.718356863421566, 'beta_2': 0.9816507569146958, 'epsilon': 9.99979966335439e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 8.50328683549826e-05, 'tol': 0.022051498772516838, 'validation_fraction': 0.811661373268269}
observation time 0.000005, current best -0.907692 at iter 4
suggestion time taken 11.533642 iter 5 next_points [{'alpha': 4.588814549384755, 'batch_size': 13, 'beta_1': 0.944017429345245, 'beta_2': 0.9895682199794456, 'epsilon': 4.062735992442043e-09, 'hidden_layer_sizes': 137, 'learning_rate_init': 7.611130244950288e-05, 'tol': 0.004086918857383792, 'validation_fraction': 0.5828958806066857}]
function_evaluation time 1.074073 value -0.898901 suggestion {'alpha': 4.588814549384755, 'batch_size': 13, 'beta_1': 0.944017429345245, 'beta_2': 0.9895682199794456, 'epsilon': 4.062735992442043e-09, 'hidden_layer_sizes': 137, 'learning_rate_init': 7.611130244950288e-05, 'tol': 0.004086918857383792, 'validation_fraction': 0.5828958806066857}
observation time 0.000004, current best -0.907692 at iter 5
suggestion time taken 11.239350 iter 6 next_points [{'alpha': 4.922501599395524, 'batch_size': 43, 'beta_1': 0.9214676594037058, 'beta_2': 0.9999771277560086, 'epsilon': 6.5224113001139235e-09, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.0010262114466214557, 'tol': 2.8381847230083617e-05, 'validation_fraction': 0.5102102078391834}]
function_evaluation time 0.400496 value -0.852747 suggestion {'alpha': 4.922501599395524, 'batch_size': 43, 'beta_1': 0.9214676594037058, 'beta_2': 0.9999771277560086, 'epsilon': 6.5224113001139235e-09, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.0010262114466214557, 'tol': 2.8381847230083617e-05, 'validation_fraction': 0.5102102078391834}
observation time 0.000004, current best -0.907692 at iter 6
suggestion time taken 11.224047 iter 7 next_points [{'alpha': 0.04179816501937685, 'batch_size': 17, 'beta_1': 0.9886832293383655, 'beta_2': 0.991654295806823, 'epsilon': 3.4152297295879493e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.055695288605195306, 'tol': 3.197064784689138e-05, 'validation_fraction': 0.7887697814483614}]
function_evaluation time 0.226004 value -0.797802 suggestion {'alpha': 0.04179816501937685, 'batch_size': 17, 'beta_1': 0.9886832293383655, 'beta_2': 0.991654295806823, 'epsilon': 3.4152297295879493e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.055695288605195306, 'tol': 3.197064784689138e-05, 'validation_fraction': 0.7887697814483614}
observation time 0.000005, current best -0.907692 at iter 7
suggestion time taken 11.200810 iter 8 next_points [{'alpha': 0.005416206170998845, 'batch_size': 21, 'beta_1': 0.6580299655348449, 'beta_2': 0.9143890300326897, 'epsilon': 4.595061101927405e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.00013963321491447834, 'tol': 2.751246924260133e-05, 'validation_fraction': 0.8428436706227223}]
function_evaluation time 0.272652 value -0.630769 suggestion {'alpha': 0.005416206170998845, 'batch_size': 21, 'beta_1': 0.6580299655348449, 'beta_2': 0.9143890300326897, 'epsilon': 4.595061101927405e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.00013963321491447834, 'tol': 2.751246924260133e-05, 'validation_fraction': 0.8428436706227223}
observation time 0.000004, current best -0.907692 at iter 8
suggestion time taken 11.775714 iter 9 next_points [{'alpha': 1.0089610014821897, 'batch_size': 12, 'beta_1': 0.9273404875739586, 'beta_2': 0.9999980239853752, 'epsilon': 1.5484649142239463e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.0035768760238354632, 'tol': 0.029050171563112712, 'validation_fraction': 0.5513937222833037}]
function_evaluation time 0.382715 value -0.909890 suggestion {'alpha': 1.0089610014821897, 'batch_size': 12, 'beta_1': 0.9273404875739586, 'beta_2': 0.9999980239853752, 'epsilon': 1.5484649142239463e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.0035768760238354632, 'tol': 0.029050171563112712, 'validation_fraction': 0.5513937222833037}
observation time 0.000005, current best -0.909890 at iter 9
suggestion time taken 11.372236 iter 10 next_points [{'alpha': 0.03775811022215004, 'batch_size': 19, 'beta_1': 0.9822463119945729, 'beta_2': 0.9999985013348633, 'epsilon': 2.530119013366127e-07, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.011423949174022476, 'tol': 0.09396204603282249, 'validation_fraction': 0.24258022968169077}]
function_evaluation time 0.259238 value -0.907692 suggestion {'alpha': 0.03775811022215004, 'batch_size': 19, 'beta_1': 0.9822463119945729, 'beta_2': 0.9999985013348633, 'epsilon': 2.530119013366127e-07, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.011423949174022476, 'tol': 0.09396204603282249, 'validation_fraction': 0.24258022968169077}
observation time 0.000004, current best -0.909890 at iter 10
suggestion time taken 11.266488 iter 11 next_points [{'alpha': 0.0007672643885292582, 'batch_size': 19, 'beta_1': 0.8578842965495626, 'beta_2': 0.9999939023171184, 'epsilon': 1.0451436092019425e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.008684106546221796, 'tol': 0.001734172919398233, 'validation_fraction': 0.8047606400165407}]
function_evaluation time 0.283650 value -0.907692 suggestion {'alpha': 0.0007672643885292582, 'batch_size': 19, 'beta_1': 0.8578842965495626, 'beta_2': 0.9999939023171184, 'epsilon': 1.0451436092019425e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.008684106546221796, 'tol': 0.001734172919398233, 'validation_fraction': 0.8047606400165407}
observation time 0.000004, current best -0.909890 at iter 11
suggestion time taken 11.692150 iter 12 next_points [{'alpha': 0.1427632038653357, 'batch_size': 40, 'beta_1': 0.9163706549042163, 'beta_2': 0.9999976869935397, 'epsilon': 2.2191910571913734e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.01858267842105597, 'tol': 0.04721319550829111, 'validation_fraction': 0.8453557334340147}]
function_evaluation time 0.165362 value -0.898901 suggestion {'alpha': 0.1427632038653357, 'batch_size': 40, 'beta_1': 0.9163706549042163, 'beta_2': 0.9999976869935397, 'epsilon': 2.2191910571913734e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.01858267842105597, 'tol': 0.04721319550829111, 'validation_fraction': 0.8453557334340147}
observation time 0.000005, current best -0.909890 at iter 12
suggestion time taken 11.422667 iter 13 next_points [{'alpha': 0.0003332666909201263, 'batch_size': 16, 'beta_1': 0.8420692323295431, 'beta_2': 0.9987729034051491, 'epsilon': 5.618689324678979e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.00010634573440446239, 'tol': 0.00031778424397271724, 'validation_fraction': 0.184477664496965}]
function_evaluation time 0.904541 value -0.736264 suggestion {'alpha': 0.0003332666909201263, 'batch_size': 16, 'beta_1': 0.8420692323295431, 'beta_2': 0.9987729034051491, 'epsilon': 5.618689324678979e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.00010634573440446239, 'tol': 0.00031778424397271724, 'validation_fraction': 0.184477664496965}
observation time 0.000004, current best -0.909890 at iter 13
suggestion time taken 11.399789 iter 14 next_points [{'alpha': 0.003468158222035497, 'batch_size': 11, 'beta_1': 0.6688745356130777, 'beta_2': 0.9999928820797152, 'epsilon': 3.131820401005951e-08, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.0004196695149850895, 'tol': 0.014141470667570747, 'validation_fraction': 0.8313480373476423}]
function_evaluation time 0.305613 value -0.901099 suggestion {'alpha': 0.003468158222035497, 'batch_size': 11, 'beta_1': 0.6688745356130777, 'beta_2': 0.9999928820797152, 'epsilon': 3.131820401005951e-08, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.0004196695149850895, 'tol': 0.014141470667570747, 'validation_fraction': 0.8313480373476423}
observation time 0.000004, current best -0.909890 at iter 14
saving meta data: {'args': {'--uuid': 'e3b3043911cd576090610f82a5ed9bb7', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_021241', '--opt': 'smoothness', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

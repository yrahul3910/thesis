running: {'--uuid': 'd9e33279ee6a572196935894f23834a3', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_191947', '--opt': 'smoothness', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d iris -o smoothness -u d9e33279ee6a572196935894f23834a3 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_191947
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.41666666666666663, -0.275, -0.3416666666666667, -0.725, -0.875])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_iris_acc betwen [-0.52290909 -0.27918182 -0.34166667 -0.725      -0.91715152] and [-0.41666667 -0.275      -0.26133333 -0.68915152 -0.875     ]
  warnings.warn(

Signature errors:
                          0         1         2         3         4       max
MLP-adam_iris_acc  0.106242  0.004182  0.080333  0.035848  0.042152  0.106242
max                0.106242  0.004182  0.080333  0.035848  0.042152  0.106242
starting sklearn study smoothness MLP-adam iris acc 15 1
with data root: None
suggestion time taken 11.304383 iter 0 next_points [{'alpha': 1.021602914789402, 'batch_size': 47, 'beta_1': 0.959462183777778, 'beta_2': 0.9804979366644802, 'epsilon': 5.617183076203724e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.0006379561841978327, 'tol': 4.448078827779658e-05, 'validation_fraction': 0.30015413359653814}]
function_evaluation time 0.084742 value -0.683333 suggestion {'alpha': 1.021602914789402, 'batch_size': 47, 'beta_1': 0.959462183777778, 'beta_2': 0.9804979366644802, 'epsilon': 5.617183076203724e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.0006379561841978327, 'tol': 4.448078827779658e-05, 'validation_fraction': 0.30015413359653814}
observation time 0.000005, current best -0.683333 at iter 0
suggestion time taken 11.295867 iter 1 next_points [{'alpha': 0.0007459994663775324, 'batch_size': 84, 'beta_1': 0.9426719154656444, 'beta_2': 0.9333987632284989, 'epsilon': 2.7355248950821287e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 8.356202945844803e-05, 'tol': 0.00013956229826678397, 'validation_fraction': 0.7772035043859937}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.054628 value -0.200000 suggestion {'alpha': 0.0007459994663775324, 'batch_size': 84, 'beta_1': 0.9426719154656444, 'beta_2': 0.9333987632284989, 'epsilon': 2.7355248950821287e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 8.356202945844803e-05, 'tol': 0.00013956229826678397, 'validation_fraction': 0.7772035043859937}
observation time 0.000005, current best -0.683333 at iter 1
suggestion time taken 11.181344 iter 2 next_points [{'alpha': 0.012887479665220929, 'batch_size': 15, 'beta_1': 0.9188539260575997, 'beta_2': 0.9999983933857741, 'epsilon': 5.76298914293173e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0001787375650088909, 'tol': 0.011940412147125427, 'validation_fraction': 0.4833463327830078}]
function_evaluation time 0.110024 value -0.491667 suggestion {'alpha': 0.012887479665220929, 'batch_size': 15, 'beta_1': 0.9188539260575997, 'beta_2': 0.9999983933857741, 'epsilon': 5.76298914293173e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0001787375650088909, 'tol': 0.011940412147125427, 'validation_fraction': 0.4833463327830078}
observation time 0.000005, current best -0.683333 at iter 2
suggestion time taken 11.578557 iter 3 next_points [{'alpha': 0.0011566565793492167, 'batch_size': 20, 'beta_1': 0.6971771719765826, 'beta_2': 0.9999631252183702, 'epsilon': 1.7736583761837703e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.001030198227861818, 'tol': 0.010148186309777913, 'validation_fraction': 0.44011947917097116}]
function_evaluation time 0.126818 value -0.750000 suggestion {'alpha': 0.0011566565793492167, 'batch_size': 20, 'beta_1': 0.6971771719765826, 'beta_2': 0.9999631252183702, 'epsilon': 1.7736583761837703e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.001030198227861818, 'tol': 0.010148186309777913, 'validation_fraction': 0.44011947917097116}
observation time 0.000005, current best -0.750000 at iter 3
suggestion time taken 11.233485 iter 4 next_points [{'alpha': 0.05065502112024136, 'batch_size': 17, 'beta_1': 0.9295042595980767, 'beta_2': 0.999854723058155, 'epsilon': 6.761795156486241e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 4.565354851456982e-05, 'tol': 3.537256959805821e-05, 'validation_fraction': 0.7762677168830585}]
function_evaluation time 0.102575 value -0.458333 suggestion {'alpha': 0.05065502112024136, 'batch_size': 17, 'beta_1': 0.9295042595980767, 'beta_2': 0.999854723058155, 'epsilon': 6.761795156486241e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 4.565354851456982e-05, 'tol': 3.537256959805821e-05, 'validation_fraction': 0.7762677168830585}
observation time 0.000005, current best -0.750000 at iter 4
suggestion time taken 11.402045 iter 5 next_points [{'alpha': 7.136891717462245e-05, 'batch_size': 12, 'beta_1': 0.5441427790996893, 'beta_2': 0.9806989070754072, 'epsilon': 5.809412552177604e-09, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.007610161360208412, 'tol': 2.2549165362247692e-05, 'validation_fraction': 0.8415619833651704}]
function_evaluation time 0.084305 value -0.925000 suggestion {'alpha': 7.136891717462245e-05, 'batch_size': 12, 'beta_1': 0.5441427790996893, 'beta_2': 0.9806989070754072, 'epsilon': 5.809412552177604e-09, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.007610161360208412, 'tol': 2.2549165362247692e-05, 'validation_fraction': 0.8415619833651704}
observation time 0.000005, current best -0.925000 at iter 5
suggestion time taken 10.955530 iter 6 next_points [{'alpha': 0.15530523760205106, 'batch_size': 10, 'beta_1': 0.9385666709282878, 'beta_2': 0.9778730319894605, 'epsilon': 9.176250748021396e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.019236453220723225, 'tol': 0.002603342423068788, 'validation_fraction': 0.15691575145577816}]
function_evaluation time 0.140047 value -0.883333 suggestion {'alpha': 0.15530523760205106, 'batch_size': 10, 'beta_1': 0.9385666709282878, 'beta_2': 0.9778730319894605, 'epsilon': 9.176250748021396e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.019236453220723225, 'tol': 0.002603342423068788, 'validation_fraction': 0.15691575145577816}
observation time 0.000005, current best -0.925000 at iter 6
suggestion time taken 11.015912 iter 7 next_points [{'alpha': 0.0006100047769496358, 'batch_size': 14, 'beta_1': 0.9458796419906391, 'beta_2': 0.9999495874565477, 'epsilon': 2.1625450621463818e-07, 'hidden_layer_sizes': 126, 'learning_rate_init': 4.332988585302621e-05, 'tol': 2.06650283347462e-05, 'validation_fraction': 0.17229041114236232}]
function_evaluation time 0.131821 value -0.416667 suggestion {'alpha': 0.0006100047769496358, 'batch_size': 14, 'beta_1': 0.9458796419906391, 'beta_2': 0.9999495874565477, 'epsilon': 2.1625450621463818e-07, 'hidden_layer_sizes': 126, 'learning_rate_init': 4.332988585302621e-05, 'tol': 2.06650283347462e-05, 'validation_fraction': 0.17229041114236232}
observation time 0.000005, current best -0.925000 at iter 7
suggestion time taken 11.436799 iter 8 next_points [{'alpha': 1.2459577262337653, 'batch_size': 10, 'beta_1': 0.9803029069862282, 'beta_2': 0.9936846913927558, 'epsilon': 2.6617388086384887e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.022974415371175196, 'tol': 0.00776569860776426, 'validation_fraction': 0.689510888427346}]
function_evaluation time 0.102101 value -0.950000 suggestion {'alpha': 1.2459577262337653, 'batch_size': 10, 'beta_1': 0.9803029069862282, 'beta_2': 0.9936846913927558, 'epsilon': 2.6617388086384887e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.022974415371175196, 'tol': 0.00776569860776426, 'validation_fraction': 0.689510888427346}
observation time 0.000005, current best -0.950000 at iter 8
suggestion time taken 11.079415 iter 9 next_points [{'alpha': 0.001241611850591239, 'batch_size': 22, 'beta_1': 0.8597127200698772, 'beta_2': 0.9997721679133167, 'epsilon': 2.0839747832993393e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.004201330764129839, 'tol': 0.0044984983353669105, 'validation_fraction': 0.8775522721960294}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.068083 value -0.741667 suggestion {'alpha': 0.001241611850591239, 'batch_size': 22, 'beta_1': 0.8597127200698772, 'beta_2': 0.9997721679133167, 'epsilon': 2.0839747832993393e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.004201330764129839, 'tol': 0.0044984983353669105, 'validation_fraction': 0.8775522721960294}
observation time 0.000005, current best -0.950000 at iter 9
suggestion time taken 11.070812 iter 10 next_points [{'alpha': 0.47858704060051527, 'batch_size': 27, 'beta_1': 0.9836184075178993, 'beta_2': 0.9999239282353537, 'epsilon': 6.504338683533782e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.0004557254021909252, 'tol': 2.470453378020456e-05, 'validation_fraction': 0.8931994583862011}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.046488 value -0.491667 suggestion {'alpha': 0.47858704060051527, 'batch_size': 27, 'beta_1': 0.9836184075178993, 'beta_2': 0.9999239282353537, 'epsilon': 6.504338683533782e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.0004557254021909252, 'tol': 2.470453378020456e-05, 'validation_fraction': 0.8931994583862011}
observation time 0.000005, current best -0.950000 at iter 10
suggestion time taken 11.470945 iter 11 next_points [{'alpha': 0.13580911459729966, 'batch_size': 11, 'beta_1': 0.6437041845184008, 'beta_2': 0.9999543724088688, 'epsilon': 4.383445334000732e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0005820951802910069, 'tol': 0.00018010625124575478, 'validation_fraction': 0.8616987391463236}]
function_evaluation time 0.070495 value -0.575000 suggestion {'alpha': 0.13580911459729966, 'batch_size': 11, 'beta_1': 0.6437041845184008, 'beta_2': 0.9999543724088688, 'epsilon': 4.383445334000732e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0005820951802910069, 'tol': 0.00018010625124575478, 'validation_fraction': 0.8616987391463236}
observation time 0.000005, current best -0.950000 at iter 11
suggestion time taken 11.053952 iter 12 next_points [{'alpha': 3.121547199553266, 'batch_size': 35, 'beta_1': 0.9542831443991053, 'beta_2': 0.9999927350847369, 'epsilon': 5.885511359823949e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.00017984556445466523, 'tol': 0.002056891103790981, 'validation_fraction': 0.5305719512899012}]
function_evaluation time 0.054389 value -0.358333 suggestion {'alpha': 3.121547199553266, 'batch_size': 35, 'beta_1': 0.9542831443991053, 'beta_2': 0.9999927350847369, 'epsilon': 5.885511359823949e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.00017984556445466523, 'tol': 0.002056891103790981, 'validation_fraction': 0.5305719512899012}
observation time 0.000005, current best -0.950000 at iter 12
suggestion time taken 11.119654 iter 13 next_points [{'alpha': 0.18682081799975692, 'batch_size': 24, 'beta_1': 0.9791679398680998, 'beta_2': 0.9999189408670941, 'epsilon': 7.518599906870869e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.005197328364715403, 'tol': 3.8969957914143094e-05, 'validation_fraction': 0.6702516994083316}]
function_evaluation time 0.107478 value -0.950000 suggestion {'alpha': 0.18682081799975692, 'batch_size': 24, 'beta_1': 0.9791679398680998, 'beta_2': 0.9999189408670941, 'epsilon': 7.518599906870869e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.005197328364715403, 'tol': 3.8969957914143094e-05, 'validation_fraction': 0.6702516994083316}
observation time 0.000005, current best -0.950000 at iter 13
suggestion time taken 11.343707 iter 14 next_points [{'alpha': 0.05750826751202658, 'batch_size': 14, 'beta_1': 0.5569218957269894, 'beta_2': 0.9996906084071064, 'epsilon': 7.728274679244588e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.06738269044816876, 'tol': 0.0014521836292940634, 'validation_fraction': 0.5398875059693101}]
function_evaluation time 0.125389 value -0.925000 suggestion {'alpha': 0.05750826751202658, 'batch_size': 14, 'beta_1': 0.5569218957269894, 'beta_2': 0.9996906084071064, 'epsilon': 7.728274679244588e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.06738269044816876, 'tol': 0.0014521836292940634, 'validation_fraction': 0.5398875059693101}
observation time 0.000006, current best -0.950000 at iter 14
saving meta data: {'args': {'--uuid': 'd9e33279ee6a572196935894f23834a3', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_191947', '--opt': 'smoothness', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.41666666666666663, -0.275, -0.3416666666666667, -0.725, -0.875])}
saving results
saving timing
saving suggest log
done

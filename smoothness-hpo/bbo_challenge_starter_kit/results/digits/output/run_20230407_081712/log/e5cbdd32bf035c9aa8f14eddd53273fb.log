running: {'--uuid': 'e5cbdd32bf035c9aa8f14eddd53273fb', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u e5cbdd32bf035c9aa8f14eddd53273fb -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study hyperopt MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002280 iter 0 next_points [{'alpha': 0.16015343891976871, 'batch_size': 128, 'beta_1': 0.9455356157549508, 'beta_2': 0.9031354144049591, 'epsilon': 2.2289909927299904e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.005276736048514421, 'tol': 0.04948775607900411, 'validation_fraction': 0.13394910788660508}]
function_evaluation time 0.410071 value 0.141710 suggestion {'alpha': 0.16015343891976871, 'batch_size': 128, 'beta_1': 0.9455356157549508, 'beta_2': 0.9031354144049591, 'epsilon': 2.2289909927299904e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.005276736048514421, 'tol': 0.04948775607900411, 'validation_fraction': 0.13394910788660508}
observation time 0.000057, current best 0.141710 at iter 0
suggestion time taken 0.002121 iter 1 next_points [{'alpha': 0.7286553297243585, 'batch_size': 39, 'beta_1': 0.8527271158875902, 'beta_2': 0.9390782833241785, 'epsilon': 2.8493333862536535e-08, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.010832194121234665, 'tol': 0.0010916455098137466, 'validation_fraction': 0.26311157571197363}]
function_evaluation time 1.440316 value 0.135256 suggestion {'alpha': 0.7286553297243585, 'batch_size': 39, 'beta_1': 0.8527271158875902, 'beta_2': 0.9390782833241785, 'epsilon': 2.8493333862536535e-08, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.010832194121234665, 'tol': 0.0010916455098137466, 'validation_fraction': 0.26311157571197363}
observation time 0.000058, current best 0.135256 at iter 1
suggestion time taken 0.002110 iter 2 next_points [{'alpha': 4.272456687549357, 'batch_size': 193, 'beta_1': 0.911299255754089, 'beta_2': 0.977412538854827, 'epsilon': 3.631762168785889e-09, 'hidden_layer_sizes': 200, 'learning_rate_init': 1.8551446995062765e-05, 'tol': 0.0009807894312099414, 'validation_fraction': 0.6649005657237899}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.147584 value 4.092105 suggestion {'alpha': 4.272456687549357, 'batch_size': 193, 'beta_1': 0.911299255754089, 'beta_2': 0.977412538854827, 'epsilon': 3.631762168785889e-09, 'hidden_layer_sizes': 200, 'learning_rate_init': 1.8551446995062765e-05, 'tol': 0.0009807894312099414, 'validation_fraction': 0.6649005657237899}
observation time 0.000060, current best 0.135256 at iter 2
suggestion time taken 0.002101 iter 3 next_points [{'alpha': 1.4390124537698414e-05, 'batch_size': 76, 'beta_1': 0.7383705500537774, 'beta_2': 0.9877655998863749, 'epsilon': 9.70222650058937e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.008197282697343282, 'tol': 1.4991009559112827e-05, 'validation_fraction': 0.2008703679436149}]
function_evaluation time 1.220093 value 0.111754 suggestion {'alpha': 1.4390124537698414e-05, 'batch_size': 76, 'beta_1': 0.7383705500537774, 'beta_2': 0.9877655998863749, 'epsilon': 9.70222650058937e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.008197282697343282, 'tol': 1.4991009559112827e-05, 'validation_fraction': 0.2008703679436149}
observation time 0.000059, current best 0.111754 at iter 3
suggestion time taken 0.002102 iter 4 next_points [{'alpha': 1.5564985455232552, 'batch_size': 33, 'beta_1': 0.7453963249728024, 'beta_2': 0.9769008891509127, 'epsilon': 5.610485142719631e-07, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.017547144281704296, 'tol': 0.0014491558865063893, 'validation_fraction': 0.23389990226087276}]
function_evaluation time 1.491417 value 0.184453 suggestion {'alpha': 1.5564985455232552, 'batch_size': 33, 'beta_1': 0.7453963249728024, 'beta_2': 0.9769008891509127, 'epsilon': 5.610485142719631e-07, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.017547144281704296, 'tol': 0.0014491558865063893, 'validation_fraction': 0.23389990226087276}
observation time 0.000064, current best 0.111754 at iter 4
suggestion time taken 0.002322 iter 5 next_points [{'alpha': 0.0362024384954679, 'batch_size': 67, 'beta_1': 0.5042268753913886, 'beta_2': 0.9415140262668552, 'epsilon': 1.3406395286758292e-09, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0011942144512272033, 'tol': 0.004723904949537542, 'validation_fraction': 0.10504160677301363}]
function_evaluation time 1.357786 value 0.097171 suggestion {'alpha': 0.0362024384954679, 'batch_size': 67, 'beta_1': 0.5042268753913886, 'beta_2': 0.9415140262668552, 'epsilon': 1.3406395286758292e-09, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0011942144512272033, 'tol': 0.004723904949537542, 'validation_fraction': 0.10504160677301363}
observation time 0.000068, current best 0.097171 at iter 5
suggestion time taken 0.002089 iter 6 next_points [{'alpha': 1.4857682312763601e-05, 'batch_size': 192, 'beta_1': 0.8895815106100786, 'beta_2': 0.9919403728226579, 'epsilon': 5.724835713798758e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 2.915870932662945e-05, 'tol': 2.461591737344653e-05, 'validation_fraction': 0.8501527630306643}]
function_evaluation time 0.427705 value 9.946257 suggestion {'alpha': 1.4857682312763601e-05, 'batch_size': 192, 'beta_1': 0.8895815106100786, 'beta_2': 0.9919403728226579, 'epsilon': 5.724835713798758e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 2.915870932662945e-05, 'tol': 2.461591737344653e-05, 'validation_fraction': 0.8501527630306643}
observation time 0.000056, current best 0.097171 at iter 6
suggestion time taken 0.002301 iter 7 next_points [{'alpha': 8.291395956060832e-05, 'batch_size': 248, 'beta_1': 0.7158573116835665, 'beta_2': 0.9367090812060068, 'epsilon': 2.263884503878145e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.015940798762547805, 'tol': 0.004837247925409384, 'validation_fraction': 0.3874848340837014}]
function_evaluation time 0.541587 value 0.156421 suggestion {'alpha': 8.291395956060832e-05, 'batch_size': 248, 'beta_1': 0.7158573116835665, 'beta_2': 0.9367090812060068, 'epsilon': 2.263884503878145e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.015940798762547805, 'tol': 0.004837247925409384, 'validation_fraction': 0.3874848340837014}
observation time 0.000058, current best 0.097171 at iter 7
suggestion time taken 0.002061 iter 8 next_points [{'alpha': 0.00414788428375366, 'batch_size': 37, 'beta_1': 0.8857589810078339, 'beta_2': 0.9379715390978911, 'epsilon': 9.43964002178998e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.00040261340185625727, 'tol': 0.009230491692384626, 'validation_fraction': 0.16489191025818595}]
function_evaluation time 2.179579 value 0.107763 suggestion {'alpha': 0.00414788428375366, 'batch_size': 37, 'beta_1': 0.8857589810078339, 'beta_2': 0.9379715390978911, 'epsilon': 9.43964002178998e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.00040261340185625727, 'tol': 0.009230491692384626, 'validation_fraction': 0.16489191025818595}
observation time 0.000064, current best 0.097171 at iter 8
suggestion time taken 0.002260 iter 9 next_points [{'alpha': 3.248789615001174e-05, 'batch_size': 35, 'beta_1': 0.6638957487568484, 'beta_2': 0.9318916252823324, 'epsilon': 6.44347033517835e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 1.0887147742565656e-05, 'tol': 8.989271791591012e-05, 'validation_fraction': 0.2148425536953511}]
function_evaluation time 12.420656 value 0.297453 suggestion {'alpha': 3.248789615001174e-05, 'batch_size': 35, 'beta_1': 0.6638957487568484, 'beta_2': 0.9318916252823324, 'epsilon': 6.44347033517835e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 1.0887147742565656e-05, 'tol': 8.989271791591012e-05, 'validation_fraction': 0.2148425536953511}
observation time 0.000071, current best 0.097171 at iter 9
suggestion time taken 0.002325 iter 10 next_points [{'alpha': 1.935907500446008e-05, 'batch_size': 167, 'beta_1': 0.5063817783976338, 'beta_2': 0.9878762462261036, 'epsilon': 8.714531464250655e-07, 'hidden_layer_sizes': 198, 'learning_rate_init': 2.0636588859790123e-05, 'tol': 0.00048688404476714397, 'validation_fraction': 0.5526775370029497}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 4.616702 value 2.905192 suggestion {'alpha': 1.935907500446008e-05, 'batch_size': 167, 'beta_1': 0.5063817783976338, 'beta_2': 0.9878762462261036, 'epsilon': 8.714531464250655e-07, 'hidden_layer_sizes': 198, 'learning_rate_init': 2.0636588859790123e-05, 'tol': 0.00048688404476714397, 'validation_fraction': 0.5526775370029497}
observation time 0.000054, current best 0.097171 at iter 10
suggestion time taken 0.002110 iter 11 next_points [{'alpha': 1.7301060932021845e-05, 'batch_size': 80, 'beta_1': 0.8967449840569484, 'beta_2': 0.9939507340055148, 'epsilon': 1.0691289667042589e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.029478765724608672, 'tol': 0.09892771965316945, 'validation_fraction': 0.43576830513395987}]
function_evaluation time 0.501581 value 0.191794 suggestion {'alpha': 1.7301060932021845e-05, 'batch_size': 80, 'beta_1': 0.8967449840569484, 'beta_2': 0.9939507340055148, 'epsilon': 1.0691289667042589e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.029478765724608672, 'tol': 0.09892771965316945, 'validation_fraction': 0.43576830513395987}
observation time 0.000060, current best 0.097171 at iter 11
suggestion time taken 0.002093 iter 12 next_points [{'alpha': 2.8952243527137553, 'batch_size': 98, 'beta_1': 0.6280607242194005, 'beta_2': 0.9640418325199315, 'epsilon': 1.155660183249809e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0015169144491029843, 'tol': 0.009071711212757341, 'validation_fraction': 0.42053550626020714}]
function_evaluation time 0.696228 value 0.141378 suggestion {'alpha': 2.8952243527137553, 'batch_size': 98, 'beta_1': 0.6280607242194005, 'beta_2': 0.9640418325199315, 'epsilon': 1.155660183249809e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0015169144491029843, 'tol': 0.009071711212757341, 'validation_fraction': 0.42053550626020714}
observation time 0.000056, current best 0.097171 at iter 12
suggestion time taken 0.002105 iter 13 next_points [{'alpha': 0.1909954249132111, 'batch_size': 207, 'beta_1': 0.8878632608037494, 'beta_2': 0.9262885661644542, 'epsilon': 4.896776605714452e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.0001314778854068226, 'tol': 0.001540028796163006, 'validation_fraction': 0.16415195998577578}]
function_evaluation time 2.572230 value 0.171101 suggestion {'alpha': 0.1909954249132111, 'batch_size': 207, 'beta_1': 0.8878632608037494, 'beta_2': 0.9262885661644542, 'epsilon': 4.896776605714452e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.0001314778854068226, 'tol': 0.001540028796163006, 'validation_fraction': 0.16415195998577578}
observation time 0.000068, current best 0.097171 at iter 13
suggestion time taken 0.002361 iter 14 next_points [{'alpha': 0.9072283577699642, 'batch_size': 36, 'beta_1': 0.7894517009726975, 'beta_2': 0.9951954161644138, 'epsilon': 3.081481955819904e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.0021196850824747797, 'tol': 0.0001688952582248084, 'validation_fraction': 0.5680248006784772}]
function_evaluation time 1.898904 value 0.142247 suggestion {'alpha': 0.9072283577699642, 'batch_size': 36, 'beta_1': 0.7894517009726975, 'beta_2': 0.9951954161644138, 'epsilon': 3.081481955819904e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.0021196850824747797, 'tol': 0.0001688952582248084, 'validation_fraction': 0.5680248006784772}
observation time 0.000065, current best 0.097171 at iter 14
saving meta data: {'args': {'--uuid': 'e5cbdd32bf035c9aa8f14eddd53273fb', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

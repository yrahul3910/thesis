running: {'--uuid': '4ac8c29472a052ec9b521b3058f129b9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 4ac8c29472a052ec9b521b3058f129b9 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study hyperopt MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002263 iter 0 next_points [{'alpha': 0.05047366395215052, 'batch_size': 195, 'beta_1': 0.5170681628787597, 'beta_2': 0.9506615001994744, 'epsilon': 4.303822568848344e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.002096877933807204, 'tol': 0.00011146142295987511, 'validation_fraction': 0.4563535481170309}]
function_evaluation time 1.412390 value 0.141777 suggestion {'alpha': 0.05047366395215052, 'batch_size': 195, 'beta_1': 0.5170681628787597, 'beta_2': 0.9506615001994744, 'epsilon': 4.303822568848344e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.002096877933807204, 'tol': 0.00011146142295987511, 'validation_fraction': 0.4563535481170309}
observation time 0.000056, current best 0.141777 at iter 0
suggestion time taken 0.002326 iter 1 next_points [{'alpha': 0.8123884147035381, 'batch_size': 12, 'beta_1': 0.6047829481592604, 'beta_2': 0.9064302234989575, 'epsilon': 5.706094946581199e-07, 'hidden_layer_sizes': 171, 'learning_rate_init': 1.2345680347058228e-05, 'tol': 5.00370715041765e-05, 'validation_fraction': 0.75472420440282}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 9.167694 value 2.893947 suggestion {'alpha': 0.8123884147035381, 'batch_size': 12, 'beta_1': 0.6047829481592604, 'beta_2': 0.9064302234989575, 'epsilon': 5.706094946581199e-07, 'hidden_layer_sizes': 171, 'learning_rate_init': 1.2345680347058228e-05, 'tol': 5.00370715041765e-05, 'validation_fraction': 0.75472420440282}
observation time 0.000063, current best 0.141777 at iter 1
suggestion time taken 0.002120 iter 2 next_points [{'alpha': 0.0003594891142285319, 'batch_size': 109, 'beta_1': 0.8903523515488969, 'beta_2': 0.9209454199164716, 'epsilon': 1.6781752234745716e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.014581677065282699, 'tol': 0.01240068294275383, 'validation_fraction': 0.3223020032902908}]
function_evaluation time 0.575172 value 0.196091 suggestion {'alpha': 0.0003594891142285319, 'batch_size': 109, 'beta_1': 0.8903523515488969, 'beta_2': 0.9209454199164716, 'epsilon': 1.6781752234745716e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.014581677065282699, 'tol': 0.01240068294275383, 'validation_fraction': 0.3223020032902908}
observation time 0.000065, current best 0.141777 at iter 2
suggestion time taken 0.002117 iter 3 next_points [{'alpha': 0.3991756868813731, 'batch_size': 118, 'beta_1': 0.7257774444359569, 'beta_2': 0.9478731121252676, 'epsilon': 1.5720543398737444e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.002413395395064561, 'tol': 2.4881966443714215e-05, 'validation_fraction': 0.6001409688500775}]
function_evaluation time 1.234375 value 0.164076 suggestion {'alpha': 0.3991756868813731, 'batch_size': 118, 'beta_1': 0.7257774444359569, 'beta_2': 0.9478731121252676, 'epsilon': 1.5720543398737444e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.002413395395064561, 'tol': 2.4881966443714215e-05, 'validation_fraction': 0.6001409688500775}
observation time 0.000068, current best 0.141777 at iter 3
suggestion time taken 0.002137 iter 4 next_points [{'alpha': 0.2013166135883916, 'batch_size': 130, 'beta_1': 0.6085889485187583, 'beta_2': 0.9203381894697812, 'epsilon': 1.1286037057346174e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 3.846926711280419e-05, 'tol': 0.0020676168850476163, 'validation_fraction': 0.1834206826268142}]
function_evaluation time 4.960059 value 0.270849 suggestion {'alpha': 0.2013166135883916, 'batch_size': 130, 'beta_1': 0.6085889485187583, 'beta_2': 0.9203381894697812, 'epsilon': 1.1286037057346174e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 3.846926711280419e-05, 'tol': 0.0020676168850476163, 'validation_fraction': 0.1834206826268142}
observation time 0.000065, current best 0.141777 at iter 4
suggestion time taken 0.002175 iter 5 next_points [{'alpha': 1.1070097399995718, 'batch_size': 192, 'beta_1': 0.6313526515048892, 'beta_2': 0.9450988611358686, 'epsilon': 9.229344896922522e-08, 'hidden_layer_sizes': 180, 'learning_rate_init': 1.3333015222214755e-05, 'tol': 0.0008995043113376219, 'validation_fraction': 0.10947168863040266}]
function_evaluation time 1.906689 value 7.870482 suggestion {'alpha': 1.1070097399995718, 'batch_size': 192, 'beta_1': 0.6313526515048892, 'beta_2': 0.9450988611358686, 'epsilon': 9.229344896922522e-08, 'hidden_layer_sizes': 180, 'learning_rate_init': 1.3333015222214755e-05, 'tol': 0.0008995043113376219, 'validation_fraction': 0.10947168863040266}
observation time 0.000064, current best 0.141777 at iter 5
suggestion time taken 0.002359 iter 6 next_points [{'alpha': 0.00014349085232607492, 'batch_size': 193, 'beta_1': 0.5711719748416667, 'beta_2': 0.9287825041895518, 'epsilon': 6.605455273162124e-07, 'hidden_layer_sizes': 127, 'learning_rate_init': 3.5251916859245954e-05, 'tol': 9.944773073563898e-05, 'validation_fraction': 0.7126818760461067}]
function_evaluation time 0.837652 value 7.269364 suggestion {'alpha': 0.00014349085232607492, 'batch_size': 193, 'beta_1': 0.5711719748416667, 'beta_2': 0.9287825041895518, 'epsilon': 6.605455273162124e-07, 'hidden_layer_sizes': 127, 'learning_rate_init': 3.5251916859245954e-05, 'tol': 9.944773073563898e-05, 'validation_fraction': 0.7126818760461067}
observation time 0.000064, current best 0.141777 at iter 6
suggestion time taken 0.002143 iter 7 next_points [{'alpha': 6.926759245828843, 'batch_size': 116, 'beta_1': 0.6788352333426386, 'beta_2': 0.9685203791747697, 'epsilon': 4.939245538602696e-07, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.001906382777791286, 'tol': 0.0003520903739392533, 'validation_fraction': 0.20748618798357105}]
function_evaluation time 1.347693 value 0.131196 suggestion {'alpha': 6.926759245828843, 'batch_size': 116, 'beta_1': 0.6788352333426386, 'beta_2': 0.9685203791747697, 'epsilon': 4.939245538602696e-07, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.001906382777791286, 'tol': 0.0003520903739392533, 'validation_fraction': 0.20748618798357105}
observation time 0.000066, current best 0.131196 at iter 7
suggestion time taken 0.002111 iter 8 next_points [{'alpha': 0.058178479967384476, 'batch_size': 170, 'beta_1': 0.5690434842381561, 'beta_2': 0.9736921051099868, 'epsilon': 1.1287792215301335e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 3.603831459050051e-05, 'tol': 0.010314357850356405, 'validation_fraction': 0.3212886793793095}]
function_evaluation time 1.297349 value 4.325486 suggestion {'alpha': 0.058178479967384476, 'batch_size': 170, 'beta_1': 0.5690434842381561, 'beta_2': 0.9736921051099868, 'epsilon': 1.1287792215301335e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 3.603831459050051e-05, 'tol': 0.010314357850356405, 'validation_fraction': 0.3212886793793095}
observation time 0.000061, current best 0.131196 at iter 8
suggestion time taken 0.002133 iter 9 next_points [{'alpha': 0.0006078760671063873, 'batch_size': 207, 'beta_1': 0.912810413917221, 'beta_2': 0.9425013970902836, 'epsilon': 1.173276958604825e-09, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.0006709220062027135, 'tol': 0.0001942962045013348, 'validation_fraction': 0.2288452136082876}]
function_evaluation time 1.524736 value 0.134836 suggestion {'alpha': 0.0006078760671063873, 'batch_size': 207, 'beta_1': 0.912810413917221, 'beta_2': 0.9425013970902836, 'epsilon': 1.173276958604825e-09, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.0006709220062027135, 'tol': 0.0001942962045013348, 'validation_fraction': 0.2288452136082876}
observation time 0.000063, current best 0.131196 at iter 9
suggestion time taken 0.002385 iter 10 next_points [{'alpha': 0.6742088251679513, 'batch_size': 103, 'beta_1': 0.7524478620498884, 'beta_2': 0.9590643303929453, 'epsilon': 1.8484904782608436e-09, 'hidden_layer_sizes': 175, 'learning_rate_init': 3.580712438463278e-05, 'tol': 0.003654346758942792, 'validation_fraction': 0.3168853617088058}]
function_evaluation time 4.364166 value 0.336196 suggestion {'alpha': 0.6742088251679513, 'batch_size': 103, 'beta_1': 0.7524478620498884, 'beta_2': 0.9590643303929453, 'epsilon': 1.8484904782608436e-09, 'hidden_layer_sizes': 175, 'learning_rate_init': 3.580712438463278e-05, 'tol': 0.003654346758942792, 'validation_fraction': 0.3168853617088058}
observation time 0.000069, current best 0.131196 at iter 10
suggestion time taken 0.002201 iter 11 next_points [{'alpha': 0.01223867671099551, 'batch_size': 191, 'beta_1': 0.8278000621798777, 'beta_2': 0.9839975854060858, 'epsilon': 1.3113389356429952e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.027624643516059297, 'tol': 0.05471030027672917, 'validation_fraction': 0.23234165452342173}]
function_evaluation time 0.377683 value 0.171053 suggestion {'alpha': 0.01223867671099551, 'batch_size': 191, 'beta_1': 0.8278000621798777, 'beta_2': 0.9839975854060858, 'epsilon': 1.3113389356429952e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.027624643516059297, 'tol': 0.05471030027672917, 'validation_fraction': 0.23234165452342173}
observation time 0.000062, current best 0.131196 at iter 11
suggestion time taken 0.002339 iter 12 next_points [{'alpha': 0.9534014983746996, 'batch_size': 153, 'beta_1': 0.634396688697776, 'beta_2': 0.9134898851488236, 'epsilon': 9.403128733462805e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.0011103917378074812, 'tol': 0.0007827222142547013, 'validation_fraction': 0.2864500116462378}]
function_evaluation time 1.233731 value 0.125855 suggestion {'alpha': 0.9534014983746996, 'batch_size': 153, 'beta_1': 0.634396688697776, 'beta_2': 0.9134898851488236, 'epsilon': 9.403128733462805e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.0011103917378074812, 'tol': 0.0007827222142547013, 'validation_fraction': 0.2864500116462378}
observation time 0.000068, current best 0.125855 at iter 12
suggestion time taken 0.002405 iter 13 next_points [{'alpha': 2.1755945780709656, 'batch_size': 225, 'beta_1': 0.6111893624484491, 'beta_2': 0.9521545602159435, 'epsilon': 7.854717236830569e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.001091778749310422, 'tol': 0.0032579639866724894, 'validation_fraction': 0.45121229609149}]
function_evaluation time 1.057642 value 0.171187 suggestion {'alpha': 2.1755945780709656, 'batch_size': 225, 'beta_1': 0.6111893624484491, 'beta_2': 0.9521545602159435, 'epsilon': 7.854717236830569e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.001091778749310422, 'tol': 0.0032579639866724894, 'validation_fraction': 0.45121229609149}
observation time 0.000072, current best 0.125855 at iter 13
suggestion time taken 0.002333 iter 14 next_points [{'alpha': 0.22973114208975012, 'batch_size': 95, 'beta_1': 0.8767953799152953, 'beta_2': 0.9348743947036683, 'epsilon': 4.699189494411434e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 2.1441050360834745e-05, 'tol': 0.0007986170155195156, 'validation_fraction': 0.28416697110860595}]
function_evaluation time 4.082146 value 2.547351 suggestion {'alpha': 0.22973114208975012, 'batch_size': 95, 'beta_1': 0.8767953799152953, 'beta_2': 0.9348743947036683, 'epsilon': 4.699189494411434e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 2.1441050360834745e-05, 'tol': 0.0007986170155195156, 'validation_fraction': 0.28416697110860595}
observation time 0.000073, current best 0.125855 at iter 14
saving meta data: {'args': {'--uuid': '4ac8c29472a052ec9b521b3058f129b9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

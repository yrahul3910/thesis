running: {'--uuid': '264bec8fd19057379d13b51ac503a270', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 264bec8fd19057379d13b51ac503a270 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study hyperopt MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002421 iter 0 next_points [{'alpha': 7.316178357258696, 'batch_size': 240, 'beta_1': 0.5683572964659647, 'beta_2': 0.9040046431413983, 'epsilon': 4.605314920108085e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.00510954023552158, 'tol': 3.154202078857381e-05, 'validation_fraction': 0.21142381532740903}]
function_evaluation time 0.964260 value 0.123615 suggestion {'alpha': 7.316178357258696, 'batch_size': 240, 'beta_1': 0.5683572964659647, 'beta_2': 0.9040046431413983, 'epsilon': 4.605314920108085e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.00510954023552158, 'tol': 3.154202078857381e-05, 'validation_fraction': 0.21142381532740903}
observation time 0.000080, current best 0.123615 at iter 0
suggestion time taken 0.002382 iter 1 next_points [{'alpha': 0.00235657144988828, 'batch_size': 83, 'beta_1': 0.5625879280577676, 'beta_2': 0.9135453390687799, 'epsilon': 2.1281519638569077e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.019637538950346676, 'tol': 0.00015716363046072642, 'validation_fraction': 0.14363227924298855}]
function_evaluation time 0.758125 value 0.222791 suggestion {'alpha': 0.00235657144988828, 'batch_size': 83, 'beta_1': 0.5625879280577676, 'beta_2': 0.9135453390687799, 'epsilon': 2.1281519638569077e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.019637538950346676, 'tol': 0.00015716363046072642, 'validation_fraction': 0.14363227924298855}
observation time 0.000068, current best 0.123615 at iter 1
suggestion time taken 0.002167 iter 2 next_points [{'alpha': 0.051576927058011, 'batch_size': 213, 'beta_1': 0.5044048768504648, 'beta_2': 0.9186725399498178, 'epsilon': 7.33330690045923e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.003503030027070073, 'tol': 0.0012116653783682148, 'validation_fraction': 0.24476383751854783}]
function_evaluation time 0.994224 value 0.119743 suggestion {'alpha': 0.051576927058011, 'batch_size': 213, 'beta_1': 0.5044048768504648, 'beta_2': 0.9186725399498178, 'epsilon': 7.33330690045923e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.003503030027070073, 'tol': 0.0012116653783682148, 'validation_fraction': 0.24476383751854783}
observation time 0.000068, current best 0.119743 at iter 2
suggestion time taken 0.002184 iter 3 next_points [{'alpha': 0.3983898848296967, 'batch_size': 99, 'beta_1': 0.5302440794452761, 'beta_2': 0.9040780250864072, 'epsilon': 7.149821934357439e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.0030452765051507584, 'tol': 0.09991061838040385, 'validation_fraction': 0.35548311893121326}]
function_evaluation time 0.404145 value 0.135022 suggestion {'alpha': 0.3983898848296967, 'batch_size': 99, 'beta_1': 0.5302440794452761, 'beta_2': 0.9040780250864072, 'epsilon': 7.149821934357439e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.0030452765051507584, 'tol': 0.09991061838040385, 'validation_fraction': 0.35548311893121326}
observation time 0.000071, current best 0.119743 at iter 3
suggestion time taken 0.002125 iter 4 next_points [{'alpha': 0.011102884516628537, 'batch_size': 221, 'beta_1': 0.6141696261653511, 'beta_2': 0.9672791430690989, 'epsilon': 6.70161464185469e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.0009154863559533832, 'tol': 0.00046929002847109785, 'validation_fraction': 0.16530838268777323}]
function_evaluation time 1.237808 value 0.148197 suggestion {'alpha': 0.011102884516628537, 'batch_size': 221, 'beta_1': 0.6141696261653511, 'beta_2': 0.9672791430690989, 'epsilon': 6.70161464185469e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.0009154863559533832, 'tol': 0.00046929002847109785, 'validation_fraction': 0.16530838268777323}
observation time 0.000059, current best 0.119743 at iter 4
suggestion time taken 0.002168 iter 5 next_points [{'alpha': 0.00031252576425536165, 'batch_size': 24, 'beta_1': 0.7168524301616509, 'beta_2': 0.9192271187900298, 'epsilon': 1.6485922713734982e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 6.701959241734308e-05, 'tol': 0.05902149171414047, 'validation_fraction': 0.25455602909842606}]
function_evaluation time 2.012577 value 0.269007 suggestion {'alpha': 0.00031252576425536165, 'batch_size': 24, 'beta_1': 0.7168524301616509, 'beta_2': 0.9192271187900298, 'epsilon': 1.6485922713734982e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 6.701959241734308e-05, 'tol': 0.05902149171414047, 'validation_fraction': 0.25455602909842606}
observation time 0.000072, current best 0.119743 at iter 5
suggestion time taken 0.002198 iter 6 next_points [{'alpha': 0.010625077472940796, 'batch_size': 68, 'beta_1': 0.7058612765113949, 'beta_2': 0.917409574768477, 'epsilon': 5.818816525684248e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0001413803589033625, 'tol': 0.00040582410614886915, 'validation_fraction': 0.3870011324917374}]
function_evaluation time 3.658267 value 0.214542 suggestion {'alpha': 0.010625077472940796, 'batch_size': 68, 'beta_1': 0.7058612765113949, 'beta_2': 0.917409574768477, 'epsilon': 5.818816525684248e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0001413803589033625, 'tol': 0.00040582410614886915, 'validation_fraction': 0.3870011324917374}
observation time 0.000066, current best 0.119743 at iter 6
suggestion time taken 0.002146 iter 7 next_points [{'alpha': 1.2174049746295874, 'batch_size': 37, 'beta_1': 0.6517341674771425, 'beta_2': 0.9262882747199667, 'epsilon': 2.7242420131524244e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00020827512980721655, 'tol': 0.0071807655384049625, 'validation_fraction': 0.28577940516553557}]
function_evaluation time 2.047280 value 0.147201 suggestion {'alpha': 1.2174049746295874, 'batch_size': 37, 'beta_1': 0.6517341674771425, 'beta_2': 0.9262882747199667, 'epsilon': 2.7242420131524244e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00020827512980721655, 'tol': 0.0071807655384049625, 'validation_fraction': 0.28577940516553557}
observation time 0.000065, current best 0.119743 at iter 7
suggestion time taken 0.002316 iter 8 next_points [{'alpha': 0.0690901654172051, 'batch_size': 232, 'beta_1': 0.7037939984533176, 'beta_2': 0.9539240873314269, 'epsilon': 4.3287635349489414e-07, 'hidden_layer_sizes': 184, 'learning_rate_init': 1.1586292841206485e-05, 'tol': 0.0003989071168884161, 'validation_fraction': 0.3723824265215279}]
function_evaluation time 3.188753 value 3.648735 suggestion {'alpha': 0.0690901654172051, 'batch_size': 232, 'beta_1': 0.7037939984533176, 'beta_2': 0.9539240873314269, 'epsilon': 4.3287635349489414e-07, 'hidden_layer_sizes': 184, 'learning_rate_init': 1.1586292841206485e-05, 'tol': 0.0003989071168884161, 'validation_fraction': 0.3723824265215279}
observation time 0.000058, current best 0.119743 at iter 8
suggestion time taken 0.002127 iter 9 next_points [{'alpha': 0.38033667623710493, 'batch_size': 129, 'beta_1': 0.7855409486711297, 'beta_2': 0.9073061427533985, 'epsilon': 1.1598886759366387e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.007315809461719695, 'tol': 0.005139413939777452, 'validation_fraction': 0.13666650351316015}]
function_evaluation time 1.059445 value 0.133532 suggestion {'alpha': 0.38033667623710493, 'batch_size': 129, 'beta_1': 0.7855409486711297, 'beta_2': 0.9073061427533985, 'epsilon': 1.1598886759366387e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.007315809461719695, 'tol': 0.005139413939777452, 'validation_fraction': 0.13666650351316015}
observation time 0.000061, current best 0.119743 at iter 9
suggestion time taken 0.002124 iter 10 next_points [{'alpha': 1.8923063991090274, 'batch_size': 100, 'beta_1': 0.6679258124864919, 'beta_2': 0.9900708328009145, 'epsilon': 4.913438063505689e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.005364696628363824, 'tol': 7.935329428944703e-05, 'validation_fraction': 0.7186393334331417}]
function_evaluation time 0.834820 value 0.193785 suggestion {'alpha': 1.8923063991090274, 'batch_size': 100, 'beta_1': 0.6679258124864919, 'beta_2': 0.9900708328009145, 'epsilon': 4.913438063505689e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.005364696628363824, 'tol': 7.935329428944703e-05, 'validation_fraction': 0.7186393334331417}
observation time 0.000062, current best 0.119743 at iter 10
suggestion time taken 0.002123 iter 11 next_points [{'alpha': 0.039320476099903454, 'batch_size': 92, 'beta_1': 0.5416098197526731, 'beta_2': 0.9731105893395009, 'epsilon': 1.613126360266827e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 3.2556534170808265e-05, 'tol': 2.1129601463451307e-05, 'validation_fraction': 0.8662482511177597}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.632832 value 5.187145 suggestion {'alpha': 0.039320476099903454, 'batch_size': 92, 'beta_1': 0.5416098197526731, 'beta_2': 0.9731105893395009, 'epsilon': 1.613126360266827e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 3.2556534170808265e-05, 'tol': 2.1129601463451307e-05, 'validation_fraction': 0.8662482511177597}
observation time 0.000057, current best 0.119743 at iter 11
suggestion time taken 0.002074 iter 12 next_points [{'alpha': 0.00011036751029282333, 'batch_size': 247, 'beta_1': 0.5703842065301165, 'beta_2': 0.9056936458938837, 'epsilon': 3.006180403859975e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 1.0107308560379394e-05, 'tol': 0.09878180990010067, 'validation_fraction': 0.3637951264776995}]
function_evaluation time 0.357063 value 8.961968 suggestion {'alpha': 0.00011036751029282333, 'batch_size': 247, 'beta_1': 0.5703842065301165, 'beta_2': 0.9056936458938837, 'epsilon': 3.006180403859975e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 1.0107308560379394e-05, 'tol': 0.09878180990010067, 'validation_fraction': 0.3637951264776995}
observation time 0.000060, current best 0.119743 at iter 12
suggestion time taken 0.002101 iter 13 next_points [{'alpha': 0.0008130986394639122, 'batch_size': 164, 'beta_1': 0.5361229793529211, 'beta_2': 0.9415407060054146, 'epsilon': 1.2916311345371881e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.08069664739628045, 'tol': 0.00014591554563054993, 'validation_fraction': 0.1599360372198736}]
function_evaluation time 1.079916 value 0.879469 suggestion {'alpha': 0.0008130986394639122, 'batch_size': 164, 'beta_1': 0.5361229793529211, 'beta_2': 0.9415407060054146, 'epsilon': 1.2916311345371881e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.08069664739628045, 'tol': 0.00014591554563054993, 'validation_fraction': 0.1599360372198736}
observation time 0.000060, current best 0.119743 at iter 13
suggestion time taken 0.002106 iter 14 next_points [{'alpha': 0.0033977183492470285, 'batch_size': 146, 'beta_1': 0.6894561645409324, 'beta_2': 0.9779946230865734, 'epsilon': 9.971174864580121e-09, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.00010032520898390372, 'tol': 0.00016622304878120077, 'validation_fraction': 0.2673246879579642}]
function_evaluation time 3.201737 value 0.177411 suggestion {'alpha': 0.0033977183492470285, 'batch_size': 146, 'beta_1': 0.6894561645409324, 'beta_2': 0.9779946230865734, 'epsilon': 9.971174864580121e-09, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.00010032520898390372, 'tol': 0.00016622304878120077, 'validation_fraction': 0.2673246879579642}
observation time 0.000071, current best 0.119743 at iter 14
saving meta data: {'args': {'--uuid': '264bec8fd19057379d13b51ac503a270', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '2f18ea5c63d95e27adb08ccc6599643c', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 2f18ea5c63d95e27adb08ccc6599643c -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study hyperopt MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002236 iter 0 next_points [{'alpha': 7.728761988313112, 'batch_size': 156, 'beta_1': 0.5766657311755556, 'beta_2': 0.9984240496181975, 'epsilon': 9.414498895246918e-07, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.00012270897668701606, 'tol': 0.004166521641860732, 'validation_fraction': 0.7870685430059434}]
function_evaluation time 1.745903 value 2.166832 suggestion {'alpha': 7.728761988313112, 'batch_size': 156, 'beta_1': 0.5766657311755556, 'beta_2': 0.9984240496181975, 'epsilon': 9.414498895246918e-07, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.00012270897668701606, 'tol': 0.004166521641860732, 'validation_fraction': 0.7870685430059434}
observation time 0.000052, current best 2.166832 at iter 0
suggestion time taken 0.002247 iter 1 next_points [{'alpha': 1.41886907489193, 'batch_size': 75, 'beta_1': 0.6423591130651813, 'beta_2': 0.9416107370016145, 'epsilon': 1.3102836633634993e-08, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.043527572610116215, 'tol': 0.00025631640545794, 'validation_fraction': 0.31072857539638965}]
function_evaluation time 0.967821 value 0.207904 suggestion {'alpha': 1.41886907489193, 'batch_size': 75, 'beta_1': 0.6423591130651813, 'beta_2': 0.9416107370016145, 'epsilon': 1.3102836633634993e-08, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.043527572610116215, 'tol': 0.00025631640545794, 'validation_fraction': 0.31072857539638965}
observation time 0.000066, current best 0.207904 at iter 1
suggestion time taken 0.002368 iter 2 next_points [{'alpha': 6.18477223730547e-05, 'batch_size': 223, 'beta_1': 0.7335020796748496, 'beta_2': 0.950224097765337, 'epsilon': 1.017035745661511e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.00022566665874384082, 'tol': 0.0842301142308183, 'validation_fraction': 0.21182669632557768}]
function_evaluation time 0.426734 value 1.118848 suggestion {'alpha': 6.18477223730547e-05, 'batch_size': 223, 'beta_1': 0.7335020796748496, 'beta_2': 0.950224097765337, 'epsilon': 1.017035745661511e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.00022566665874384082, 'tol': 0.0842301142308183, 'validation_fraction': 0.21182669632557768}
observation time 0.000052, current best 0.207904 at iter 2
suggestion time taken 0.002074 iter 3 next_points [{'alpha': 0.12154941332184872, 'batch_size': 155, 'beta_1': 0.8271251912163817, 'beta_2': 0.9689370733012685, 'epsilon': 2.529625989018029e-07, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.04489568215058803, 'tol': 4.9953716816473665e-05, 'validation_fraction': 0.33066445793891436}]
function_evaluation time 0.698346 value 0.258412 suggestion {'alpha': 0.12154941332184872, 'batch_size': 155, 'beta_1': 0.8271251912163817, 'beta_2': 0.9689370733012685, 'epsilon': 2.529625989018029e-07, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.04489568215058803, 'tol': 4.9953716816473665e-05, 'validation_fraction': 0.33066445793891436}
observation time 0.000053, current best 0.207904 at iter 3
suggestion time taken 0.002275 iter 4 next_points [{'alpha': 0.03934012471220522, 'batch_size': 220, 'beta_1': 0.5656182548048891, 'beta_2': 0.9038558396011789, 'epsilon': 3.666841632957133e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.0005566759632683816, 'tol': 1.5805405947796335e-05, 'validation_fraction': 0.4256198309795411}]
function_evaluation time 1.893322 value 0.127576 suggestion {'alpha': 0.03934012471220522, 'batch_size': 220, 'beta_1': 0.5656182548048891, 'beta_2': 0.9038558396011789, 'epsilon': 3.666841632957133e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.0005566759632683816, 'tol': 1.5805405947796335e-05, 'validation_fraction': 0.4256198309795411}
observation time 0.000054, current best 0.127576 at iter 4
suggestion time taken 0.002114 iter 5 next_points [{'alpha': 0.00019222874068752484, 'batch_size': 95, 'beta_1': 0.5513274895389946, 'beta_2': 0.9866643628041948, 'epsilon': 2.3781869174887328e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.08339534479304707, 'tol': 0.004455707564781053, 'validation_fraction': 0.3167824223868614}]
function_evaluation time 0.912964 value 0.812019 suggestion {'alpha': 0.00019222874068752484, 'batch_size': 95, 'beta_1': 0.5513274895389946, 'beta_2': 0.9866643628041948, 'epsilon': 2.3781869174887328e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.08339534479304707, 'tol': 0.004455707564781053, 'validation_fraction': 0.3167824223868614}
observation time 0.000060, current best 0.127576 at iter 5
suggestion time taken 0.002267 iter 6 next_points [{'alpha': 0.0019040488318993864, 'batch_size': 130, 'beta_1': 0.5861415823253848, 'beta_2': 0.950473718895672, 'epsilon': 3.229390533558003e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.001583257651931517, 'tol': 0.026594696583606803, 'validation_fraction': 0.21241869114512077}]
function_evaluation time 0.526700 value 0.129827 suggestion {'alpha': 0.0019040488318993864, 'batch_size': 130, 'beta_1': 0.5861415823253848, 'beta_2': 0.950473718895672, 'epsilon': 3.229390533558003e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.001583257651931517, 'tol': 0.026594696583606803, 'validation_fraction': 0.21241869114512077}
observation time 0.000054, current best 0.127576 at iter 6
suggestion time taken 0.002083 iter 7 next_points [{'alpha': 0.03270289534988701, 'batch_size': 204, 'beta_1': 0.5223816565486398, 'beta_2': 0.9015834323525854, 'epsilon': 2.504620228117105e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.0014143868298919125, 'tol': 0.005913566664734981, 'validation_fraction': 0.5952318163386406}]
function_evaluation time 0.668278 value 0.172656 suggestion {'alpha': 0.03270289534988701, 'batch_size': 204, 'beta_1': 0.5223816565486398, 'beta_2': 0.9015834323525854, 'epsilon': 2.504620228117105e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.0014143868298919125, 'tol': 0.005913566664734981, 'validation_fraction': 0.5952318163386406}
observation time 0.000055, current best 0.127576 at iter 7
suggestion time taken 0.002076 iter 8 next_points [{'alpha': 0.08479814170922972, 'batch_size': 140, 'beta_1': 0.5166722302920276, 'beta_2': 0.9427850963518026, 'epsilon': 3.023851763515548e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 1.265582429402971e-05, 'tol': 0.007061283072534931, 'validation_fraction': 0.23291175763996907}]
function_evaluation time 1.011021 value 6.702728 suggestion {'alpha': 0.08479814170922972, 'batch_size': 140, 'beta_1': 0.5166722302920276, 'beta_2': 0.9427850963518026, 'epsilon': 3.023851763515548e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 1.265582429402971e-05, 'tol': 0.007061283072534931, 'validation_fraction': 0.23291175763996907}
observation time 0.000058, current best 0.127576 at iter 8
suggestion time taken 0.002105 iter 9 next_points [{'alpha': 0.02238136898955823, 'batch_size': 23, 'beta_1': 0.9529354993713617, 'beta_2': 0.9495316876611453, 'epsilon': 4.7998484748138886e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.016926017095648175, 'tol': 0.0002847058554435687, 'validation_fraction': 0.19321071303006812}]
function_evaluation time 1.760944 value 0.343000 suggestion {'alpha': 0.02238136898955823, 'batch_size': 23, 'beta_1': 0.9529354993713617, 'beta_2': 0.9495316876611453, 'epsilon': 4.7998484748138886e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.016926017095648175, 'tol': 0.0002847058554435687, 'validation_fraction': 0.19321071303006812}
observation time 0.000057, current best 0.127576 at iter 9
suggestion time taken 0.002083 iter 10 next_points [{'alpha': 1.085548722401327e-05, 'batch_size': 52, 'beta_1': 0.5850110475768655, 'beta_2': 0.947464743911604, 'epsilon': 9.104117560968198e-07, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.033773284153257664, 'tol': 4.455551838225009e-05, 'validation_fraction': 0.12611114658835615}]
function_evaluation time 1.435153 value 0.313614 suggestion {'alpha': 1.085548722401327e-05, 'batch_size': 52, 'beta_1': 0.5850110475768655, 'beta_2': 0.947464743911604, 'epsilon': 9.104117560968198e-07, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.033773284153257664, 'tol': 4.455551838225009e-05, 'validation_fraction': 0.12611114658835615}
observation time 0.000061, current best 0.127576 at iter 10
suggestion time taken 0.002116 iter 11 next_points [{'alpha': 0.07859277692811105, 'batch_size': 231, 'beta_1': 0.7900660604586461, 'beta_2': 0.9865329207055996, 'epsilon': 1.3156235983466279e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.01550441903391045, 'tol': 0.0017357067742793776, 'validation_fraction': 0.5259430610919409}]
function_evaluation time 0.463183 value 0.244019 suggestion {'alpha': 0.07859277692811105, 'batch_size': 231, 'beta_1': 0.7900660604586461, 'beta_2': 0.9865329207055996, 'epsilon': 1.3156235983466279e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.01550441903391045, 'tol': 0.0017357067742793776, 'validation_fraction': 0.5259430610919409}
observation time 0.000061, current best 0.127576 at iter 11
suggestion time taken 0.002107 iter 12 next_points [{'alpha': 0.0001961083836682613, 'batch_size': 182, 'beta_1': 0.9725322500500035, 'beta_2': 0.9037007997111703, 'epsilon': 2.6161281862754787e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0464703059829087, 'tol': 1.1261960415443122e-05, 'validation_fraction': 0.47504211155846005}]
function_evaluation time 0.690455 value 1.794975 suggestion {'alpha': 0.0001961083836682613, 'batch_size': 182, 'beta_1': 0.9725322500500035, 'beta_2': 0.9037007997111703, 'epsilon': 2.6161281862754787e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0464703059829087, 'tol': 1.1261960415443122e-05, 'validation_fraction': 0.47504211155846005}
observation time 0.000068, current best 0.127576 at iter 12
suggestion time taken 0.002147 iter 13 next_points [{'alpha': 0.7966124015879849, 'batch_size': 16, 'beta_1': 0.649044751564242, 'beta_2': 0.9139219087321783, 'epsilon': 4.055671587268395e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.00042039617841037997, 'tol': 0.00018585519703447534, 'validation_fraction': 0.6605059283820321}]
function_evaluation time 2.679908 value 0.182267 suggestion {'alpha': 0.7966124015879849, 'batch_size': 16, 'beta_1': 0.649044751564242, 'beta_2': 0.9139219087321783, 'epsilon': 4.055671587268395e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.00042039617841037997, 'tol': 0.00018585519703447534, 'validation_fraction': 0.6605059283820321}
observation time 0.000082, current best 0.127576 at iter 13
suggestion time taken 0.002163 iter 14 next_points [{'alpha': 0.004023584380198111, 'batch_size': 37, 'beta_1': 0.8332088605717042, 'beta_2': 0.9900610505112969, 'epsilon': 1.7007410409683922e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.0009955094454591864, 'tol': 0.0004437771403581152, 'validation_fraction': 0.48785295834541625}]
function_evaluation time 2.284822 value 0.139329 suggestion {'alpha': 0.004023584380198111, 'batch_size': 37, 'beta_1': 0.8332088605717042, 'beta_2': 0.9900610505112969, 'epsilon': 1.7007410409683922e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.0009955094454591864, 'tol': 0.0004437771403581152, 'validation_fraction': 0.48785295834541625}
observation time 0.000063, current best 0.127576 at iter 14
saving meta data: {'args': {'--uuid': '2f18ea5c63d95e27adb08ccc6599643c', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

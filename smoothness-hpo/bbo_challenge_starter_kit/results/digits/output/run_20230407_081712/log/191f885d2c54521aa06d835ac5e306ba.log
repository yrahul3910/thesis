running: {'--uuid': '191f885d2c54521aa06d835ac5e306ba', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u 191f885d2c54521aa06d835ac5e306ba -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002079 iter 0 next_points [{'alpha': 0.0021368416347587117, 'batch_size': 150, 'beta_1': 0.9208063942659445, 'beta_2': 0.9912053734173817, 'epsilon': 1.3001606815682324e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0013307057866620536, 'tol': 0.0002003128376588059, 'validation_fraction': 0.16575264384646035}]
function_evaluation time 1.234905 value -0.959635 suggestion {'alpha': 0.0021368416347587117, 'batch_size': 150, 'beta_1': 0.9208063942659445, 'beta_2': 0.9912053734173817, 'epsilon': 1.3001606815682324e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0013307057866620536, 'tol': 0.0002003128376588059, 'validation_fraction': 0.16575264384646035}
observation time 0.001344, current best -0.959635 at iter 0
suggestion time taken 0.001783 iter 1 next_points [{'alpha': 0.0004984153010694559, 'batch_size': 13, 'beta_1': 0.9782851642347168, 'beta_2': 0.9999983691949567, 'epsilon': 8.484847569423008e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.00017661465736769813, 'tol': 2.0555622016970627e-05, 'validation_fraction': 0.8304816685634112}]
function_evaluation time 4.188005 value -0.892134 suggestion {'alpha': 0.0004984153010694559, 'batch_size': 13, 'beta_1': 0.9782851642347168, 'beta_2': 0.9999983691949567, 'epsilon': 8.484847569423008e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.00017661465736769813, 'tol': 2.0555622016970627e-05, 'validation_fraction': 0.8304816685634112}
observation time 0.001366, current best -0.959635 at iter 1
suggestion time taken 0.001878 iter 2 next_points [{'alpha': 7.013564042028774, 'batch_size': 171, 'beta_1': 0.971706069581193, 'beta_2': 0.9998423297444184, 'epsilon': 3.9879009037377296e-08, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.00029935990511882117, 'tol': 5.4715194971842755e-05, 'validation_fraction': 0.288614239195444}]
function_evaluation time 2.420482 value -0.942240 suggestion {'alpha': 7.013564042028774, 'batch_size': 171, 'beta_1': 0.971706069581193, 'beta_2': 0.9998423297444184, 'epsilon': 3.9879009037377296e-08, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.00029935990511882117, 'tol': 5.4715194971842755e-05, 'validation_fraction': 0.288614239195444}
observation time 0.001344, current best -0.959635 at iter 2
suggestion time taken 0.001693 iter 3 next_points [{'alpha': 0.007354678732370532, 'batch_size': 85, 'beta_1': 0.9584366467652804, 'beta_2': 0.9999709342102794, 'epsilon': 2.0783239635194234e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.07713352618775204, 'tol': 0.00012397164911747853, 'validation_fraction': 0.1080308269719956}]
function_evaluation time 1.448868 value -0.608280 suggestion {'alpha': 0.007354678732370532, 'batch_size': 85, 'beta_1': 0.9584366467652804, 'beta_2': 0.9999709342102794, 'epsilon': 2.0783239635194234e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.07713352618775204, 'tol': 0.00012397164911747853, 'validation_fraction': 0.1080308269719956}
observation time 0.001338, current best -0.959635 at iter 3
suggestion time taken 0.001710 iter 4 next_points [{'alpha': 0.10245514316469562, 'batch_size': 215, 'beta_1': 0.9378203162582313, 'beta_2': 0.9999944485934131, 'epsilon': 3.208608436718801e-07, 'hidden_layer_sizes': 185, 'learning_rate_init': 2.2153390528477726e-05, 'tol': 0.0005174060768224321, 'validation_fraction': 0.7621680776592342}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.516131 value -0.324131 suggestion {'alpha': 0.10245514316469562, 'batch_size': 215, 'beta_1': 0.9378203162582313, 'beta_2': 0.9999944485934131, 'epsilon': 3.208608436718801e-07, 'hidden_layer_sizes': 185, 'learning_rate_init': 2.2153390528477726e-05, 'tol': 0.0005174060768224321, 'validation_fraction': 0.7621680776592342}
observation time 0.001344, current best -0.959635 at iter 4
suggestion time taken 0.001714 iter 5 next_points [{'alpha': 1.2087524690808058, 'batch_size': 190, 'beta_1': 0.9822543619106296, 'beta_2': 0.9999190363027758, 'epsilon': 8.636012712871993e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.007178205643486775, 'tol': 0.00010056498643213012, 'validation_fraction': 0.6934931133129814}]
function_evaluation time 0.841777 value -0.937352 suggestion {'alpha': 1.2087524690808058, 'batch_size': 190, 'beta_1': 0.9822543619106296, 'beta_2': 0.9999190363027758, 'epsilon': 8.636012712871993e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.007178205643486775, 'tol': 0.00010056498643213012, 'validation_fraction': 0.6934931133129814}
observation time 0.001321, current best -0.959635 at iter 5
suggestion time taken 0.002004 iter 6 next_points [{'alpha': 0.167202449305247, 'batch_size': 106, 'beta_1': 0.9061465283305871, 'beta_2': 0.9971176999135427, 'epsilon': 1.0336085721958375e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.002313271558124044, 'tol': 0.001275607585395371, 'validation_fraction': 0.19953617859881376}]
function_evaluation time 1.397795 value -0.963821 suggestion {'alpha': 0.167202449305247, 'batch_size': 106, 'beta_1': 0.9061465283305871, 'beta_2': 0.9971176999135427, 'epsilon': 1.0336085721958375e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.002313271558124044, 'tol': 0.001275607585395371, 'validation_fraction': 0.19953617859881376}
observation time 0.001335, current best -0.963821 at iter 6
suggestion time taken 0.001670 iter 7 next_points [{'alpha': 0.00036282875732937856, 'batch_size': 32, 'beta_1': 0.6122085830038364, 'beta_2': 0.9994180648006075, 'epsilon': 4.575589918424158e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 9.337473969793483e-05, 'tol': 0.019177900569457413, 'validation_fraction': 0.4317698595000662}]
function_evaluation time 1.643942 value -0.787069 suggestion {'alpha': 0.00036282875732937856, 'batch_size': 32, 'beta_1': 0.6122085830038364, 'beta_2': 0.9994180648006075, 'epsilon': 4.575589918424158e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 9.337473969793483e-05, 'tol': 0.019177900569457413, 'validation_fraction': 0.4317698595000662}
observation time 0.001320, current best -0.963821 at iter 7
suggestion time taken 0.001695 iter 8 next_points [{'alpha': 0.019617179471752472, 'batch_size': 64, 'beta_1': 0.986049218635155, 'beta_2': 0.9165859260734437, 'epsilon': 7.403816254269309e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.0006212086454629706, 'tol': 0.008948797732128493, 'validation_fraction': 0.525149455613648}]
function_evaluation time 0.918662 value -0.919294 suggestion {'alpha': 0.019617179471752472, 'batch_size': 64, 'beta_1': 0.986049218635155, 'beta_2': 0.9165859260734437, 'epsilon': 7.403816254269309e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.0006212086454629706, 'tol': 0.008948797732128493, 'validation_fraction': 0.525149455613648}
observation time 0.001319, current best -0.963821 at iter 8
suggestion time taken 0.001889 iter 9 next_points [{'alpha': 0.0012701086337629885, 'batch_size': 36, 'beta_1': 0.8473566596432492, 'beta_2': 0.9999832970388695, 'epsilon': 3.73793999623365e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.05589971324598306, 'tol': 3.77504228927005e-05, 'validation_fraction': 0.6384601187764107}]
function_evaluation time 1.035852 value -0.889324 suggestion {'alpha': 0.0012701086337629885, 'batch_size': 36, 'beta_1': 0.8473566596432492, 'beta_2': 0.9999832970388695, 'epsilon': 3.73793999623365e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.05589971324598306, 'tol': 3.77504228927005e-05, 'validation_fraction': 0.6384601187764107}
observation time 0.001274, current best -0.963821 at iter 9
suggestion time taken 0.001716 iter 10 next_points [{'alpha': 0.05091783455145874, 'batch_size': 59, 'beta_1': 0.8408657823193023, 'beta_2': 0.9999969815763281, 'epsilon': 9.24172616707868e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 2.7669018714229387e-05, 'tol': 0.002369630506020098, 'validation_fraction': 0.2535411272105968}]
function_evaluation time 7.220710 value -0.860833 suggestion {'alpha': 0.05091783455145874, 'batch_size': 59, 'beta_1': 0.8408657823193023, 'beta_2': 0.9999969815763281, 'epsilon': 9.24172616707868e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 2.7669018714229387e-05, 'tol': 0.002369630506020098, 'validation_fraction': 0.2535411272105968}
observation time 0.001344, current best -0.963821 at iter 10
suggestion time taken 0.001934 iter 11 next_points [{'alpha': 0.00683247318995319, 'batch_size': 206, 'beta_1': 0.7541818708786433, 'beta_2': 0.99956629411992, 'epsilon': 3.655702066735931e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 1.4134820531671382e-05, 'tol': 1.2152669940098627e-05, 'validation_fraction': 0.5790841822512587}]
function_evaluation time 1.085493 value -0.161399 suggestion {'alpha': 0.00683247318995319, 'batch_size': 206, 'beta_1': 0.7541818708786433, 'beta_2': 0.99956629411992, 'epsilon': 3.655702066735931e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 1.4134820531671382e-05, 'tol': 1.2152669940098627e-05, 'validation_fraction': 0.5790841822512587}
observation time 0.001400, current best -0.963821 at iter 11
suggestion time taken 0.001985 iter 12 next_points [{'alpha': 8.983144958691182e-05, 'batch_size': 178, 'beta_1': 0.7971948169379369, 'beta_2': 0.9999900481654967, 'epsilon': 2.4832050531662268e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.025448037760068726, 'tol': 0.004658988647975762, 'validation_fraction': 0.8513638804812111}]
function_evaluation time 0.432990 value -0.889363 suggestion {'alpha': 8.983144958691182e-05, 'batch_size': 178, 'beta_1': 0.7971948169379369, 'beta_2': 0.9999900481654967, 'epsilon': 2.4832050531662268e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.025448037760068726, 'tol': 0.004658988647975762, 'validation_fraction': 0.8513638804812111}
observation time 0.001402, current best -0.963821 at iter 12
suggestion time taken 0.001674 iter 13 next_points [{'alpha': 8.421730651264492e-05, 'batch_size': 243, 'beta_1': 0.6931309060215463, 'beta_2': 0.9999395190058143, 'epsilon': 9.681571753814987e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.0035514463066773157, 'tol': 0.0003823529344838838, 'validation_fraction': 0.333704248632244}]
function_evaluation time 1.054553 value -0.954077 suggestion {'alpha': 8.421730651264492e-05, 'batch_size': 243, 'beta_1': 0.6931309060215463, 'beta_2': 0.9999395190058143, 'epsilon': 9.681571753814987e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.0035514463066773157, 'tol': 0.0003823529344838838, 'validation_fraction': 0.333704248632244}
observation time 0.001323, current best -0.963821 at iter 13
suggestion time taken 0.001860 iter 14 next_points [{'alpha': 0.781838812301473, 'batch_size': 235, 'beta_1': 0.6574187599353367, 'beta_2': 0.9982755011907658, 'epsilon': 6.431770018033108e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.014736784515921622, 'tol': 0.025662164458891634, 'validation_fraction': 0.8936176347897588}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.233741 value -0.867100 suggestion {'alpha': 0.781838812301473, 'batch_size': 235, 'beta_1': 0.6574187599353367, 'beta_2': 0.9982755011907658, 'epsilon': 6.431770018033108e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.014736784515921622, 'tol': 0.025662164458891634, 'validation_fraction': 0.8936176347897588}
observation time 0.001333, current best -0.963821 at iter 14
saving meta data: {'args': {'--uuid': '191f885d2c54521aa06d835ac5e306ba', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

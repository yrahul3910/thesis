running: {'--uuid': '3d58022ce01a51849993cac4422994b9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 3d58022ce01a51849993cac4422994b9 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002271 iter 0 next_points [{'alpha': 0.0002676483209799685, 'batch_size': 195, 'beta_1': 0.7406924019481579, 'beta_2': 0.9159205975656165, 'epsilon': 1.189583942594789e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.0011031844886130386, 'tol': 5.907176572527297e-05, 'validation_fraction': 0.14075087611362866}]
function_evaluation time 1.385696 value -0.969389 suggestion {'alpha': 0.0002676483209799685, 'batch_size': 195, 'beta_1': 0.7406924019481579, 'beta_2': 0.9159205975656165, 'epsilon': 1.189583942594789e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.0011031844886130386, 'tol': 5.907176572527297e-05, 'validation_fraction': 0.14075087611362866}
observation time 0.000077, current best -0.969389 at iter 0
suggestion time taken 0.002138 iter 1 next_points [{'alpha': 3.8212747276468964, 'batch_size': 127, 'beta_1': 0.6667918956279582, 'beta_2': 0.9184773107711265, 'epsilon': 3.7885746491531874e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.002772873374676846, 'tol': 0.0001458849378980607, 'validation_fraction': 0.1308123512236978}]
function_evaluation time 0.718181 value -0.964508 suggestion {'alpha': 3.8212747276468964, 'batch_size': 127, 'beta_1': 0.6667918956279582, 'beta_2': 0.9184773107711265, 'epsilon': 3.7885746491531874e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.002772873374676846, 'tol': 0.0001458849378980607, 'validation_fraction': 0.1308123512236978}
observation time 0.000056, current best -0.969389 at iter 1
suggestion time taken 0.002099 iter 2 next_points [{'alpha': 0.05566111243487178, 'batch_size': 128, 'beta_1': 0.8669450945824613, 'beta_2': 0.9180094445982154, 'epsilon': 4.294878432605109e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.00026584434455958995, 'tol': 0.031006849229365602, 'validation_fraction': 0.160438211207454}]
function_evaluation time 0.931694 value -0.934606 suggestion {'alpha': 0.05566111243487178, 'batch_size': 128, 'beta_1': 0.8669450945824613, 'beta_2': 0.9180094445982154, 'epsilon': 4.294878432605109e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.00026584434455958995, 'tol': 0.031006849229365602, 'validation_fraction': 0.160438211207454}
observation time 0.000062, current best -0.969389 at iter 2
suggestion time taken 0.002076 iter 3 next_points [{'alpha': 0.0001326115059821016, 'batch_size': 187, 'beta_1': 0.7679284873256871, 'beta_2': 0.9075519049748201, 'epsilon': 2.6349274365294216e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0005811218388806432, 'tol': 1.5886551491896743e-05, 'validation_fraction': 0.7496952253178983}]
function_evaluation time 1.937777 value -0.930418 suggestion {'alpha': 0.0001326115059821016, 'batch_size': 187, 'beta_1': 0.7679284873256871, 'beta_2': 0.9075519049748201, 'epsilon': 2.6349274365294216e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0005811218388806432, 'tol': 1.5886551491896743e-05, 'validation_fraction': 0.7496952253178983}
observation time 0.000059, current best -0.969389 at iter 3
suggestion time taken 0.002060 iter 4 next_points [{'alpha': 0.00022571880454402414, 'batch_size': 193, 'beta_1': 0.7131466393859345, 'beta_2': 0.9313901241456173, 'epsilon': 1.8698904907788497e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 3.450064758012373e-05, 'tol': 0.0003604264290995298, 'validation_fraction': 0.19065180281438632}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.585748 value -0.566565 suggestion {'alpha': 0.00022571880454402414, 'batch_size': 193, 'beta_1': 0.7131466393859345, 'beta_2': 0.9313901241456173, 'epsilon': 1.8698904907788497e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 3.450064758012373e-05, 'tol': 0.0003604264290995298, 'validation_fraction': 0.19065180281438632}
observation time 0.000063, current best -0.969389 at iter 4
suggestion time taken 0.002148 iter 5 next_points [{'alpha': 0.07516369103760819, 'batch_size': 117, 'beta_1': 0.694210170042045, 'beta_2': 0.9251787510804552, 'epsilon': 4.0452854129233827e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.017557889594201476, 'tol': 0.025588876627397342, 'validation_fraction': 0.14839064469282964}]
function_evaluation time 0.396939 value -0.948507 suggestion {'alpha': 0.07516369103760819, 'batch_size': 117, 'beta_1': 0.694210170042045, 'beta_2': 0.9251787510804552, 'epsilon': 4.0452854129233827e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.017557889594201476, 'tol': 0.025588876627397342, 'validation_fraction': 0.14839064469282964}
observation time 0.000062, current best -0.969389 at iter 5
suggestion time taken 0.002082 iter 6 next_points [{'alpha': 0.17629890503025944, 'batch_size': 200, 'beta_1': 0.9389450428436072, 'beta_2': 0.9563640426505374, 'epsilon': 1.0289150668800644e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0003846616827317654, 'tol': 2.529449637332019e-05, 'validation_fraction': 0.1120672753743662}]
function_evaluation time 1.195754 value -0.931095 suggestion {'alpha': 0.17629890503025944, 'batch_size': 200, 'beta_1': 0.9389450428436072, 'beta_2': 0.9563640426505374, 'epsilon': 1.0289150668800644e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0003846616827317654, 'tol': 2.529449637332019e-05, 'validation_fraction': 0.1120672753743662}
observation time 0.000067, current best -0.969389 at iter 6
suggestion time taken 0.002150 iter 7 next_points [{'alpha': 0.00010989272011845185, 'batch_size': 89, 'beta_1': 0.960220405042368, 'beta_2': 0.9618587136383031, 'epsilon': 5.360229070766177e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.07333239551785885, 'tol': 0.03623175325427666, 'validation_fraction': 0.37827605089757854}]
function_evaluation time 0.614983 value -0.732871 suggestion {'alpha': 0.00010989272011845185, 'batch_size': 89, 'beta_1': 0.960220405042368, 'beta_2': 0.9618587136383031, 'epsilon': 5.360229070766177e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.07333239551785885, 'tol': 0.03623175325427666, 'validation_fraction': 0.37827605089757854}
observation time 0.000061, current best -0.969389 at iter 7
suggestion time taken 0.002251 iter 8 next_points [{'alpha': 4.216345753984598e-05, 'batch_size': 65, 'beta_1': 0.5302019813876839, 'beta_2': 0.9554208855989135, 'epsilon': 9.050638955465656e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0006272520282883993, 'tol': 2.5758679700144258e-05, 'validation_fraction': 0.2574259516014702}]
function_evaluation time 1.878285 value -0.954077 suggestion {'alpha': 4.216345753984598e-05, 'batch_size': 65, 'beta_1': 0.5302019813876839, 'beta_2': 0.9554208855989135, 'epsilon': 9.050638955465656e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0006272520282883993, 'tol': 2.5758679700144258e-05, 'validation_fraction': 0.2574259516014702}
observation time 0.000068, current best -0.969389 at iter 8
suggestion time taken 0.002318 iter 9 next_points [{'alpha': 0.10094156540974383, 'batch_size': 107, 'beta_1': 0.5106118823958524, 'beta_2': 0.9774487839432289, 'epsilon': 9.425472852073744e-07, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.003991597162426743, 'tol': 0.02247468738758934, 'validation_fraction': 0.16735187672033874}]
function_evaluation time 0.364833 value -0.948495 suggestion {'alpha': 0.10094156540974383, 'batch_size': 107, 'beta_1': 0.5106118823958524, 'beta_2': 0.9774487839432289, 'epsilon': 9.425472852073744e-07, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.003991597162426743, 'tol': 0.02247468738758934, 'validation_fraction': 0.16735187672033874}
observation time 0.000067, current best -0.969389 at iter 9
suggestion time taken 0.002108 iter 10 next_points [{'alpha': 7.0261735012439885, 'batch_size': 112, 'beta_1': 0.7413596004608812, 'beta_2': 0.9619754715517633, 'epsilon': 2.471841121899505e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.004152698855018159, 'tol': 0.014829544060075622, 'validation_fraction': 0.8410635193387801}]
function_evaluation time 0.405471 value -0.897019 suggestion {'alpha': 7.0261735012439885, 'batch_size': 112, 'beta_1': 0.7413596004608812, 'beta_2': 0.9619754715517633, 'epsilon': 2.471841121899505e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.004152698855018159, 'tol': 0.014829544060075622, 'validation_fraction': 0.8410635193387801}
observation time 0.000062, current best -0.969389 at iter 10
suggestion time taken 0.002228 iter 11 next_points [{'alpha': 1.3362563420089004, 'batch_size': 54, 'beta_1': 0.5872663171968099, 'beta_2': 0.9400658567647381, 'epsilon': 1.4557551660845841e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0003400952084506263, 'tol': 0.0004896049392886151, 'validation_fraction': 0.31911156723057377}]
function_evaluation time 2.503127 value -0.965205 suggestion {'alpha': 1.3362563420089004, 'batch_size': 54, 'beta_1': 0.5872663171968099, 'beta_2': 0.9400658567647381, 'epsilon': 1.4557551660845841e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0003400952084506263, 'tol': 0.0004896049392886151, 'validation_fraction': 0.31911156723057377}
observation time 0.000076, current best -0.969389 at iter 11
suggestion time taken 0.002176 iter 12 next_points [{'alpha': 0.00459952013941131, 'batch_size': 14, 'beta_1': 0.5049904650423774, 'beta_2': 0.9257159735503177, 'epsilon': 1.314629425420498e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.00040152808906034906, 'tol': 2.9711751818518913e-05, 'validation_fraction': 0.2938961961522373}]
function_evaluation time 3.826558 value -0.966618 suggestion {'alpha': 0.00459952013941131, 'batch_size': 14, 'beta_1': 0.5049904650423774, 'beta_2': 0.9257159735503177, 'epsilon': 1.314629425420498e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.00040152808906034906, 'tol': 2.9711751818518913e-05, 'validation_fraction': 0.2938961961522373}
observation time 0.000066, current best -0.969389 at iter 12
suggestion time taken 0.002331 iter 13 next_points [{'alpha': 8.812509556923479e-05, 'batch_size': 82, 'beta_1': 0.5486039130963714, 'beta_2': 0.9747441457321709, 'epsilon': 1.3042923840202952e-07, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.0005584326685692016, 'tol': 0.00229565498842442, 'validation_fraction': 0.1758850579458859}]
function_evaluation time 2.211565 value -0.974269 suggestion {'alpha': 8.812509556923479e-05, 'batch_size': 82, 'beta_1': 0.5486039130963714, 'beta_2': 0.9747441457321709, 'epsilon': 1.3042923840202952e-07, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.0005584326685692016, 'tol': 0.00229565498842442, 'validation_fraction': 0.1758850579458859}
observation time 0.000064, current best -0.974269 at iter 13
suggestion time taken 0.002084 iter 14 next_points [{'alpha': 0.0023467636719263457, 'batch_size': 20, 'beta_1': 0.9311551527522243, 'beta_2': 0.9878389844812183, 'epsilon': 2.614306442366193e-09, 'hidden_layer_sizes': 103, 'learning_rate_init': 1.609335372746692e-05, 'tol': 0.005880302042604578, 'validation_fraction': 0.16782743383200713}]
function_evaluation time 5.866957 value -0.731018 suggestion {'alpha': 0.0023467636719263457, 'batch_size': 20, 'beta_1': 0.9311551527522243, 'beta_2': 0.9878389844812183, 'epsilon': 2.614306442366193e-09, 'hidden_layer_sizes': 103, 'learning_rate_init': 1.609335372746692e-05, 'tol': 0.005880302042604578, 'validation_fraction': 0.16782743383200713}
observation time 0.000071, current best -0.974269 at iter 14
saving meta data: {'args': {'--uuid': '3d58022ce01a51849993cac4422994b9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

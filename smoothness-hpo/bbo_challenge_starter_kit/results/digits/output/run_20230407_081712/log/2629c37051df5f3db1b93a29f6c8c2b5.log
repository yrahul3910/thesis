running: {'--uuid': '2629c37051df5f3db1b93a29f6c8c2b5', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 2629c37051df5f3db1b93a29f6c8c2b5 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study hyperopt MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002279 iter 0 next_points [{'alpha': 0.3020677237456873, 'batch_size': 54, 'beta_1': 0.5283838430472766, 'beta_2': 0.9098015044317278, 'epsilon': 9.9284889137567e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0073750011829986795, 'tol': 0.03410060880205537, 'validation_fraction': 0.28417360618467297}]
function_evaluation time 0.931149 value 0.144502 suggestion {'alpha': 0.3020677237456873, 'batch_size': 54, 'beta_1': 0.5283838430472766, 'beta_2': 0.9098015044317278, 'epsilon': 9.9284889137567e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0073750011829986795, 'tol': 0.03410060880205537, 'validation_fraction': 0.28417360618467297}
observation time 0.000066, current best 0.144502 at iter 0
suggestion time taken 0.002139 iter 1 next_points [{'alpha': 8.720819207556112, 'batch_size': 124, 'beta_1': 0.5533945847963712, 'beta_2': 0.9756244963564149, 'epsilon': 1.5634436327605604e-09, 'hidden_layer_sizes': 151, 'learning_rate_init': 7.180650491163659e-05, 'tol': 1.7949257360170952e-05, 'validation_fraction': 0.12958217938226071}]
function_evaluation time 3.777342 value 0.310793 suggestion {'alpha': 8.720819207556112, 'batch_size': 124, 'beta_1': 0.5533945847963712, 'beta_2': 0.9756244963564149, 'epsilon': 1.5634436327605604e-09, 'hidden_layer_sizes': 151, 'learning_rate_init': 7.180650491163659e-05, 'tol': 1.7949257360170952e-05, 'validation_fraction': 0.12958217938226071}
observation time 0.000061, current best 0.144502 at iter 1
suggestion time taken 0.002114 iter 2 next_points [{'alpha': 0.00041089862695908207, 'batch_size': 178, 'beta_1': 0.6572570358163883, 'beta_2': 0.96490998927288, 'epsilon': 4.5997641668867833e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.00020272658575375512, 'tol': 1.4338933759490077e-05, 'validation_fraction': 0.7614251851103953}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.810895 value 0.322340 suggestion {'alpha': 0.00041089862695908207, 'batch_size': 178, 'beta_1': 0.6572570358163883, 'beta_2': 0.96490998927288, 'epsilon': 4.5997641668867833e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.00020272658575375512, 'tol': 1.4338933759490077e-05, 'validation_fraction': 0.7614251851103953}
observation time 0.000059, current best 0.144502 at iter 2
suggestion time taken 0.002109 iter 3 next_points [{'alpha': 0.0012331983291030818, 'batch_size': 129, 'beta_1': 0.5210342480904842, 'beta_2': 0.9744769236901027, 'epsilon': 1.5790392686903228e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.043440028522039785, 'tol': 0.007117614853297662, 'validation_fraction': 0.11825892755863392}]
function_evaluation time 0.756774 value 0.183217 suggestion {'alpha': 0.0012331983291030818, 'batch_size': 129, 'beta_1': 0.5210342480904842, 'beta_2': 0.9744769236901027, 'epsilon': 1.5790392686903228e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.043440028522039785, 'tol': 0.007117614853297662, 'validation_fraction': 0.11825892755863392}
observation time 0.000062, current best 0.144502 at iter 3
suggestion time taken 0.002104 iter 4 next_points [{'alpha': 0.09303599537341126, 'batch_size': 137, 'beta_1': 0.8540200800086671, 'beta_2': 0.9071458276272808, 'epsilon': 2.725257305177999e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00020674605173480058, 'tol': 1.4405589052212508e-05, 'validation_fraction': 0.16031234526574434}]
function_evaluation time 1.821068 value 0.225091 suggestion {'alpha': 0.09303599537341126, 'batch_size': 137, 'beta_1': 0.8540200800086671, 'beta_2': 0.9071458276272808, 'epsilon': 2.725257305177999e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00020674605173480058, 'tol': 1.4405589052212508e-05, 'validation_fraction': 0.16031234526574434}
observation time 0.000071, current best 0.144502 at iter 4
suggestion time taken 0.002171 iter 5 next_points [{'alpha': 0.0001721215361420567, 'batch_size': 81, 'beta_1': 0.8459828774730804, 'beta_2': 0.9598667278334321, 'epsilon': 2.2518246134533276e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 3.4616153915333165e-05, 'tol': 0.0350014540909901, 'validation_fraction': 0.20514464409442204}]
function_evaluation time 0.510493 value 5.469188 suggestion {'alpha': 0.0001721215361420567, 'batch_size': 81, 'beta_1': 0.8459828774730804, 'beta_2': 0.9598667278334321, 'epsilon': 2.2518246134533276e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 3.4616153915333165e-05, 'tol': 0.0350014540909901, 'validation_fraction': 0.20514464409442204}
observation time 0.000063, current best 0.144502 at iter 5
suggestion time taken 0.002083 iter 6 next_points [{'alpha': 1.4058125101828433e-05, 'batch_size': 35, 'beta_1': 0.5183731954954172, 'beta_2': 0.9499679378094634, 'epsilon': 1.367934632553338e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.043059915807645684, 'tol': 0.00037003351450617353, 'validation_fraction': 0.5588542645367517}]
function_evaluation time 1.355266 value 0.417439 suggestion {'alpha': 1.4058125101828433e-05, 'batch_size': 35, 'beta_1': 0.5183731954954172, 'beta_2': 0.9499679378094634, 'epsilon': 1.367934632553338e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.043059915807645684, 'tol': 0.00037003351450617353, 'validation_fraction': 0.5588542645367517}
observation time 0.000069, current best 0.144502 at iter 6
suggestion time taken 0.002143 iter 7 next_points [{'alpha': 0.003608086221592726, 'batch_size': 147, 'beta_1': 0.7739445965643366, 'beta_2': 0.9242572171070498, 'epsilon': 4.1108516109260585e-09, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.00043376231503704796, 'tol': 5.33403861611242e-05, 'validation_fraction': 0.6783557112726598}]
function_evaluation time 2.305386 value 0.176143 suggestion {'alpha': 0.003608086221592726, 'batch_size': 147, 'beta_1': 0.7739445965643366, 'beta_2': 0.9242572171070498, 'epsilon': 4.1108516109260585e-09, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.00043376231503704796, 'tol': 5.33403861611242e-05, 'validation_fraction': 0.6783557112726598}
observation time 0.000071, current best 0.144502 at iter 7
suggestion time taken 0.002151 iter 8 next_points [{'alpha': 0.008934225329761566, 'batch_size': 14, 'beta_1': 0.5746357595978957, 'beta_2': 0.9554498290736085, 'epsilon': 5.633992124293027e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.0005017108982404804, 'tol': 0.07471368990924866, 'validation_fraction': 0.5325244958775448}]
function_evaluation time 1.212734 value 0.176605 suggestion {'alpha': 0.008934225329761566, 'batch_size': 14, 'beta_1': 0.5746357595978957, 'beta_2': 0.9554498290736085, 'epsilon': 5.633992124293027e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.0005017108982404804, 'tol': 0.07471368990924866, 'validation_fraction': 0.5325244958775448}
observation time 0.000070, current best 0.144502 at iter 8
suggestion time taken 0.002144 iter 9 next_points [{'alpha': 2.3957120874251093e-05, 'batch_size': 138, 'beta_1': 0.6810472191934166, 'beta_2': 0.960089836230835, 'epsilon': 9.642679408143105e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 2.7254029628510152e-05, 'tol': 0.062169290094335534, 'validation_fraction': 0.7974207010702822}]
function_evaluation time 0.188509 value 8.319702 suggestion {'alpha': 2.3957120874251093e-05, 'batch_size': 138, 'beta_1': 0.6810472191934166, 'beta_2': 0.960089836230835, 'epsilon': 9.642679408143105e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 2.7254029628510152e-05, 'tol': 0.062169290094335534, 'validation_fraction': 0.7974207010702822}
observation time 0.000073, current best 0.144502 at iter 9
suggestion time taken 0.002133 iter 10 next_points [{'alpha': 0.015687588811326172, 'batch_size': 240, 'beta_1': 0.8260149041607033, 'beta_2': 0.9965102111015731, 'epsilon': 4.819112116077416e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 8.685072799902959e-05, 'tol': 0.000902019022181822, 'validation_fraction': 0.10273607974407072}]
function_evaluation time 3.881290 value 0.323708 suggestion {'alpha': 0.015687588811326172, 'batch_size': 240, 'beta_1': 0.8260149041607033, 'beta_2': 0.9965102111015731, 'epsilon': 4.819112116077416e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 8.685072799902959e-05, 'tol': 0.000902019022181822, 'validation_fraction': 0.10273607974407072}
observation time 0.000076, current best 0.144502 at iter 10
suggestion time taken 0.002183 iter 11 next_points [{'alpha': 0.007523833095595379, 'batch_size': 17, 'beta_1': 0.5342714486457609, 'beta_2': 0.9408549615823879, 'epsilon': 1.6808908704604097e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 2.2755235915369445e-05, 'tol': 0.002393762063083529, 'validation_fraction': 0.200106408518112}]
function_evaluation time 9.981259 value 0.289741 suggestion {'alpha': 0.007523833095595379, 'batch_size': 17, 'beta_1': 0.5342714486457609, 'beta_2': 0.9408549615823879, 'epsilon': 1.6808908704604097e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 2.2755235915369445e-05, 'tol': 0.002393762063083529, 'validation_fraction': 0.200106408518112}
observation time 0.000067, current best 0.144502 at iter 11
suggestion time taken 0.002308 iter 12 next_points [{'alpha': 0.8186897124618048, 'batch_size': 207, 'beta_1': 0.7088664203691164, 'beta_2': 0.9627701876845691, 'epsilon': 3.472476638583185e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.008767771374279504, 'tol': 0.006245290769373709, 'validation_fraction': 0.39976090085821475}]
function_evaluation time 0.575238 value 0.131175 suggestion {'alpha': 0.8186897124618048, 'batch_size': 207, 'beta_1': 0.7088664203691164, 'beta_2': 0.9627701876845691, 'epsilon': 3.472476638583185e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.008767771374279504, 'tol': 0.006245290769373709, 'validation_fraction': 0.39976090085821475}
observation time 0.000068, current best 0.131175 at iter 12
suggestion time taken 0.002145 iter 13 next_points [{'alpha': 0.0031538832655090645, 'batch_size': 87, 'beta_1': 0.949046488261177, 'beta_2': 0.962243881445187, 'epsilon': 4.5557368913979705e-08, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.02678188053142955, 'tol': 0.0015421959660574204, 'validation_fraction': 0.1715578363850282}]
function_evaluation time 0.947086 value 0.256500 suggestion {'alpha': 0.0031538832655090645, 'batch_size': 87, 'beta_1': 0.949046488261177, 'beta_2': 0.962243881445187, 'epsilon': 4.5557368913979705e-08, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.02678188053142955, 'tol': 0.0015421959660574204, 'validation_fraction': 0.1715578363850282}
observation time 0.000075, current best 0.131175 at iter 13
suggestion time taken 0.002332 iter 14 next_points [{'alpha': 0.0012083767220588432, 'batch_size': 212, 'beta_1': 0.6174117729683066, 'beta_2': 0.9318971604667935, 'epsilon': 7.910513428673378e-07, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.06515102538590598, 'tol': 0.0018687689974348175, 'validation_fraction': 0.3759157201587953}]
function_evaluation time 0.761229 value 0.521994 suggestion {'alpha': 0.0012083767220588432, 'batch_size': 212, 'beta_1': 0.6174117729683066, 'beta_2': 0.9318971604667935, 'epsilon': 7.910513428673378e-07, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.06515102538590598, 'tol': 0.0018687689974348175, 'validation_fraction': 0.3759157201587953}
observation time 0.000078, current best 0.131175 at iter 14
saving meta data: {'args': {'--uuid': '2629c37051df5f3db1b93a29f6c8c2b5', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

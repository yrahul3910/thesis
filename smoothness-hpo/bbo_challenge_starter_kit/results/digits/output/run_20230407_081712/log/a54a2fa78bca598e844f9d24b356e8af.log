running: {'--uuid': 'a54a2fa78bca598e844f9d24b356e8af', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'opentuner', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d digits -o opentuner -u a54a2fa78bca598e844f9d24b356e8af -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study opentuner MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.055083 iter 0 next_points [{'hidden_layer_sizes': 185, 'alpha': 0.37874021970370614, 'batch_size': 99, 'learning_rate_init': 0.04903827136682686, 'tol': 0.013942279001817038, 'validation_fraction': 0.622323267512193, 'beta_1': 0.6577841602945287, 'beta_2': 0.9032961730509881, 'epsilon': 1.7515253994457202e-07}]
function_evaluation time 0.625512 value -0.914373 suggestion {'hidden_layer_sizes': 185, 'alpha': 0.37874021970370614, 'batch_size': 99, 'learning_rate_init': 0.04903827136682686, 'tol': 0.013942279001817038, 'validation_fraction': 0.622323267512193, 'beta_1': 0.6577841602945287, 'beta_2': 0.9032961730509881, 'epsilon': 1.7515253994457202e-07}
observation time 0.004187, current best -0.914373 at iter 0
suggestion time taken 0.007450 iter 1 next_points [{'hidden_layer_sizes': 111, 'alpha': 0.37874021970370614, 'batch_size': 99, 'learning_rate_init': 0.04903827136682686, 'tol': 0.013942279001817038, 'validation_fraction': 0.622323267512193, 'beta_1': 0.6577841602945287, 'beta_2': 0.9908881690803311, 'epsilon': 1.7515253994457202e-07}]
function_evaluation time 0.547135 value -0.940858 suggestion {'hidden_layer_sizes': 111, 'alpha': 0.37874021970370614, 'batch_size': 99, 'learning_rate_init': 0.04903827136682686, 'tol': 0.013942279001817038, 'validation_fraction': 0.622323267512193, 'beta_1': 0.6577841602945287, 'beta_2': 0.9908881690803311, 'epsilon': 1.7515253994457202e-07}
observation time 0.002860, current best -0.940858 at iter 1
suggestion time taken 0.007019 iter 2 next_points [{'hidden_layer_sizes': 111, 'alpha': 0.37874021970370614, 'batch_size': 99, 'learning_rate_init': 0.0646627288431229, 'tol': 0.016142030964284505, 'validation_fraction': 0.622323267512193, 'beta_1': 0.6577841602945287, 'beta_2': 0.9908881690803311, 'epsilon': 1.7515253994457202e-07}]
function_evaluation time 0.567659 value -0.875489 suggestion {'hidden_layer_sizes': 111, 'alpha': 0.37874021970370614, 'batch_size': 99, 'learning_rate_init': 0.0646627288431229, 'tol': 0.016142030964284505, 'validation_fraction': 0.622323267512193, 'beta_1': 0.6577841602945287, 'beta_2': 0.9908881690803311, 'epsilon': 1.7515253994457202e-07}
observation time 0.001944, current best -0.940858 at iter 2
suggestion time taken 0.021876 iter 3 next_points [{'tol': 0.08588099846756629, 'alpha': 6.863373619684508, 'beta_1': 0.7136476526916091, 'learning_rate_init': 0.006937702144495562, 'epsilon': 1.0036112421726761e-07, 'hidden_layer_sizes': 155, 'validation_fraction': 0.22617613388207608, 'beta_2': 0.9605293393257818, 'batch_size': 185}]
function_evaluation time 0.431365 value -0.961031 suggestion {'tol': 0.08588099846756629, 'alpha': 6.863373619684508, 'beta_1': 0.7136476526916091, 'learning_rate_init': 0.006937702144495562, 'epsilon': 1.0036112421726761e-07, 'hidden_layer_sizes': 155, 'validation_fraction': 0.22617613388207608, 'beta_2': 0.9605293393257818, 'batch_size': 185}
observation time 0.001816, current best -0.961031 at iter 3
suggestion time taken 0.005912 iter 4 next_points [{'tol': 0.044013716861069856, 'alpha': 2.4116110975365217, 'beta_1': 0.5868760209560485, 'learning_rate_init': 0.006392691085581537, 'epsilon': 8.321607742061966e-07, 'hidden_layer_sizes': 53, 'validation_fraction': 0.5273887523071473, 'beta_2': 0.9281162791102925, 'batch_size': 115}]
function_evaluation time 0.292250 value -0.945032 suggestion {'tol': 0.044013716861069856, 'alpha': 2.4116110975365217, 'beta_1': 0.5868760209560485, 'learning_rate_init': 0.006392691085581537, 'epsilon': 8.321607742061966e-07, 'hidden_layer_sizes': 53, 'validation_fraction': 0.5273887523071473, 'beta_2': 0.9281162791102925, 'batch_size': 115}
observation time 0.001787, current best -0.961031 at iter 4
suggestion time taken 0.006613 iter 5 next_points [{'tol': 0.08588099846756629, 'alpha': 6.863373619684508, 'beta_1': 0.7136476526916091, 'learning_rate_init': 0.006937702144495562, 'epsilon': 1.0036112421726761e-07, 'hidden_layer_sizes': 84, 'validation_fraction': 0.22617613388207608, 'beta_2': 0.9605293393257818, 'batch_size': 185}]
function_evaluation time 0.338268 value -0.960349 suggestion {'tol': 0.08588099846756629, 'alpha': 6.863373619684508, 'beta_1': 0.7136476526916091, 'learning_rate_init': 0.006937702144495562, 'epsilon': 1.0036112421726761e-07, 'hidden_layer_sizes': 84, 'validation_fraction': 0.22617613388207608, 'beta_2': 0.9605293393257818, 'batch_size': 185}
observation time 0.001751, current best -0.961031 at iter 5
suggestion time taken 0.005006 iter 6 next_points [{'hidden_layer_sizes': 103, 'alpha': 3.7919110649149057, 'batch_size': 100, 'learning_rate_init': 0.0609231099376139, 'tol': 0.08348876221303818, 'validation_fraction': 0.4527094680055752, 'beta_1': 0.6324576557749183, 'beta_2': 0.921394206333536, 'epsilon': 9.583652737238093e-07}]
function_evaluation time 0.483118 value -0.839876 suggestion {'hidden_layer_sizes': 103, 'alpha': 3.7919110649149057, 'batch_size': 100, 'learning_rate_init': 0.0609231099376139, 'tol': 0.08348876221303818, 'validation_fraction': 0.4527094680055752, 'beta_1': 0.6324576557749183, 'beta_2': 0.921394206333536, 'epsilon': 9.583652737238093e-07}
observation time 0.002074, current best -0.961031 at iter 6
suggestion time taken 0.006030 iter 7 next_points [{'tol': 0.0011996716900208215, 'alpha': 1.2604160596574294, 'beta_1': 0.8346372841281965, 'learning_rate_init': 0.06535654569261011, 'epsilon': 3.130226106378965e-07, 'hidden_layer_sizes': 85, 'validation_fraction': 0.7865138476678688, 'beta_2': 0.908062447386264, 'batch_size': 19}]
function_evaluation time 0.760487 value -0.858045 suggestion {'tol': 0.0011996716900208215, 'alpha': 1.2604160596574294, 'beta_1': 0.8346372841281965, 'learning_rate_init': 0.06535654569261011, 'epsilon': 3.130226106378965e-07, 'hidden_layer_sizes': 85, 'validation_fraction': 0.7865138476678688, 'beta_2': 0.908062447386264, 'batch_size': 19}
observation time 0.001941, current best -0.961031 at iter 7
suggestion time taken 0.005055 iter 8 next_points [{'hidden_layer_sizes': 70, 'alpha': 3.2323290950207384, 'batch_size': 26, 'learning_rate_init': 0.058118385882465366, 'tol': 0.022707057199162484, 'validation_fraction': 0.6650422240316666, 'beta_1': 0.7455233198154712, 'beta_2': 0.9872446883479755, 'epsilon': 5.234768464540119e-07}]
function_evaluation time 0.747652 value -0.767770 suggestion {'hidden_layer_sizes': 70, 'alpha': 3.2323290950207384, 'batch_size': 26, 'learning_rate_init': 0.058118385882465366, 'tol': 0.022707057199162484, 'validation_fraction': 0.6650422240316666, 'beta_1': 0.7455233198154712, 'beta_2': 0.9872446883479755, 'epsilon': 5.234768464540119e-07}
observation time 0.001832, current best -0.961031 at iter 8
suggestion time taken 0.007058 iter 9 next_points [{'tol': 0.08588099846756629, 'alpha': 7.919472424179752, 'beta_1': 0.7136476526916091, 'learning_rate_init': 0.022220261206059067, 'epsilon': 1.0036112421726761e-07, 'hidden_layer_sizes': 155, 'validation_fraction': 0.22617613388207608, 'beta_2': 0.9605293393257818, 'batch_size': 185}]
function_evaluation time 0.409928 value -0.949199 suggestion {'tol': 0.08588099846756629, 'alpha': 7.919472424179752, 'beta_1': 0.7136476526916091, 'learning_rate_init': 0.022220261206059067, 'epsilon': 1.0036112421726761e-07, 'hidden_layer_sizes': 155, 'validation_fraction': 0.22617613388207608, 'beta_2': 0.9605293393257818, 'batch_size': 185}
observation time 0.002065, current best -0.961031 at iter 9
suggestion time taken 0.006094 iter 10 next_points [{'tol': 0.018416289491794902, 'alpha': 0.30998389010469934, 'beta_1': 0.8644772745357653, 'learning_rate_init': 0.03723988701636565, 'epsilon': 9.804511555138997e-07, 'hidden_layer_sizes': 162, 'validation_fraction': 0.5654775808316436, 'beta_2': 0.9722338818885261, 'batch_size': 101}]
function_evaluation time 0.529917 value -0.933186 suggestion {'tol': 0.018416289491794902, 'alpha': 0.30998389010469934, 'beta_1': 0.8644772745357653, 'learning_rate_init': 0.03723988701636565, 'epsilon': 9.804511555138997e-07, 'hidden_layer_sizes': 162, 'validation_fraction': 0.5654775808316436, 'beta_2': 0.9722338818885261, 'batch_size': 101}
observation time 0.001785, current best -0.961031 at iter 10
suggestion time taken 0.005074 iter 11 next_points [{'hidden_layer_sizes': 193, 'alpha': 7.905279416998969, 'batch_size': 35, 'learning_rate_init': 0.08318240007883097, 'tol': 0.09008122918531695, 'validation_fraction': 0.8397875189226657, 'beta_1': 0.5603668177929325, 'beta_2': 0.9826838456300506, 'epsilon': 5.394580941125705e-07}]
function_evaluation time 0.365298 value -0.253978 suggestion {'hidden_layer_sizes': 193, 'alpha': 7.905279416998969, 'batch_size': 35, 'learning_rate_init': 0.08318240007883097, 'tol': 0.09008122918531695, 'validation_fraction': 0.8397875189226657, 'beta_1': 0.5603668177929325, 'beta_2': 0.9826838456300506, 'epsilon': 5.394580941125705e-07}
observation time 0.001851, current best -0.961031 at iter 11
suggestion time taken 0.007340 iter 12 next_points [{'tol': 0.08588099846756629, 'alpha': 6.863373619684508, 'beta_1': 0.7136476526916091, 'learning_rate_init': 0.006937702144495562, 'epsilon': 7.713743758469272e-07, 'hidden_layer_sizes': 155, 'validation_fraction': 0.22617613388207608, 'beta_2': 0.9605293393257818, 'batch_size': 185}]
function_evaluation time 0.431748 value -0.960344 suggestion {'tol': 0.08588099846756629, 'alpha': 6.863373619684508, 'beta_1': 0.7136476526916091, 'learning_rate_init': 0.006937702144495562, 'epsilon': 7.713743758469272e-07, 'hidden_layer_sizes': 155, 'validation_fraction': 0.22617613388207608, 'beta_2': 0.9605293393257818, 'batch_size': 185}
observation time 0.001959, current best -0.961031 at iter 12
suggestion time taken 0.005081 iter 13 next_points [{'hidden_layer_sizes': 141, 'alpha': 7.997311206504207, 'batch_size': 200, 'learning_rate_init': 0.05797311961808254, 'tol': 0.09854606298995587, 'validation_fraction': 0.8841285078317767, 'beta_1': 0.5716342463256407, 'beta_2': 0.9742226092915602, 'epsilon': 7.147691262482093e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.231420 value -0.668796 suggestion {'hidden_layer_sizes': 141, 'alpha': 7.997311206504207, 'batch_size': 200, 'learning_rate_init': 0.05797311961808254, 'tol': 0.09854606298995587, 'validation_fraction': 0.8841285078317767, 'beta_1': 0.5716342463256407, 'beta_2': 0.9742226092915602, 'epsilon': 7.147691262482093e-07}
observation time 0.001984, current best -0.961031 at iter 13
suggestion time taken 0.007353 iter 14 next_points [{'tol': 0.08588099846756629, 'alpha': 6.863373619684508, 'beta_1': 0.7136476526916091, 'learning_rate_init': 0.006937702144495562, 'epsilon': 7.019438200192473e-08, 'hidden_layer_sizes': 155, 'validation_fraction': 0.22617613388207608, 'beta_2': 0.9605293393257818, 'batch_size': 185}]
function_evaluation time 0.425398 value -0.960332 suggestion {'tol': 0.08588099846756629, 'alpha': 6.863373619684508, 'beta_1': 0.7136476526916091, 'learning_rate_init': 0.006937702144495562, 'epsilon': 7.019438200192473e-08, 'hidden_layer_sizes': 155, 'validation_fraction': 0.22617613388207608, 'beta_2': 0.9605293393257818, 'batch_size': 185}
observation time 0.001928, current best -0.961031 at iter 14
saving meta data: {'args': {'--uuid': 'a54a2fa78bca598e844f9d24b356e8af', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'opentuner', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

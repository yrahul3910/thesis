running: {'--uuid': '2e63f83639eb59a2868d9d969b59c2e6', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u 2e63f83639eb59a2868d9d969b59c2e6 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002117 iter 0 next_points [{'alpha': 2.5351667767573874e-05, 'batch_size': 222, 'beta_1': 0.8448424153682914, 'beta_2': 0.9972585658371239, 'epsilon': 7.082589830518702e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.010084967348096911, 'tol': 0.00041031889024183274, 'validation_fraction': 0.2162656541738889}]
function_evaluation time 0.691381 value -0.963112 suggestion {'alpha': 2.5351667767573874e-05, 'batch_size': 222, 'beta_1': 0.8448424153682914, 'beta_2': 0.9972585658371239, 'epsilon': 7.082589830518702e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.010084967348096911, 'tol': 0.00041031889024183274, 'validation_fraction': 0.2162656541738889}
observation time 0.001387, current best -0.963112 at iter 0
suggestion time taken 0.001764 iter 1 next_points [{'alpha': 0.11979566394597878, 'batch_size': 96, 'beta_1': 0.797725243270113, 'beta_2': 0.9987871250175958, 'epsilon': 1.0548369035268497e-09, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0001779588664342476, 'tol': 0.001903192711882903, 'validation_fraction': 0.45001134586544095}]
function_evaluation time 2.869824 value -0.929046 suggestion {'alpha': 0.11979566394597878, 'batch_size': 96, 'beta_1': 0.797725243270113, 'beta_2': 0.9987871250175958, 'epsilon': 1.0548369035268497e-09, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0001779588664342476, 'tol': 0.001903192711882903, 'validation_fraction': 0.45001134586544095}
observation time 0.001393, current best -0.963112 at iter 1
suggestion time taken 0.001756 iter 2 next_points [{'alpha': 0.04810831898440482, 'batch_size': 201, 'beta_1': 0.8394128571939392, 'beta_2': 0.9929341855736119, 'epsilon': 2.083521370524552e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.0022228101805781574, 'tol': 0.00011008628427317315, 'validation_fraction': 0.5722879636476452}]
function_evaluation time 1.402690 value -0.954776 suggestion {'alpha': 0.04810831898440482, 'batch_size': 201, 'beta_1': 0.8394128571939392, 'beta_2': 0.9929341855736119, 'epsilon': 2.083521370524552e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.0022228101805781574, 'tol': 0.00011008628427317315, 'validation_fraction': 0.5722879636476452}
observation time 0.001395, current best -0.963112 at iter 2
suggestion time taken 0.001698 iter 3 next_points [{'alpha': 0.00010381574500204335, 'batch_size': 66, 'beta_1': 0.9205907597425613, 'beta_2': 0.9999982156748158, 'epsilon': 1.0427772385549865e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.0004852781094527215, 'tol': 0.006587927768135738, 'validation_fraction': 0.15657109946065065}]
function_evaluation time 1.460253 value -0.947104 suggestion {'alpha': 0.00010381574500204335, 'batch_size': 66, 'beta_1': 0.9205907597425613, 'beta_2': 0.9999982156748158, 'epsilon': 1.0427772385549865e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.0004852781094527215, 'tol': 0.006587927768135738, 'validation_fraction': 0.15657109946065065}
observation time 0.001334, current best -0.963112 at iter 3
suggestion time taken 0.002009 iter 4 next_points [{'alpha': 0.002897781080753225, 'batch_size': 172, 'beta_1': 0.5748184205185588, 'beta_2': 0.9998846923765375, 'epsilon': 6.1339253120826155e-09, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.0003894377608413113, 'tol': 0.00025272273985317453, 'validation_fraction': 0.8755109503844636}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.195962 value -0.832307 suggestion {'alpha': 0.002897781080753225, 'batch_size': 172, 'beta_1': 0.5748184205185588, 'beta_2': 0.9998846923765375, 'epsilon': 6.1339253120826155e-09, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.0003894377608413113, 'tol': 0.00025272273985317453, 'validation_fraction': 0.8755109503844636}
observation time 0.001323, current best -0.963112 at iter 4
suggestion time taken 0.001707 iter 5 next_points [{'alpha': 2.7845215607137517, 'batch_size': 108, 'beta_1': 0.9833082094054448, 'beta_2': 0.970790665916478, 'epsilon': 2.1368286482356648e-08, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.02411565562192364, 'tol': 2.3299621545370796e-05, 'validation_fraction': 0.3350035877698698}]
function_evaluation time 0.740829 value -0.927628 suggestion {'alpha': 2.7845215607137517, 'batch_size': 108, 'beta_1': 0.9833082094054448, 'beta_2': 0.970790665916478, 'epsilon': 2.1368286482356648e-08, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.02411565562192364, 'tol': 2.3299621545370796e-05, 'validation_fraction': 0.3350035877698698}
observation time 0.001387, current best -0.963112 at iter 5
suggestion time taken 0.001700 iter 6 next_points [{'alpha': 0.657817847642427, 'batch_size': 35, 'beta_1': 0.9898502853081025, 'beta_2': 0.9869444429959001, 'epsilon': 2.7952558642997716e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0010350470157924824, 'tol': 0.0005500580150767552, 'validation_fraction': 0.7301430461099642}]
function_evaluation time 1.325087 value -0.934582 suggestion {'alpha': 0.657817847642427, 'batch_size': 35, 'beta_1': 0.9898502853081025, 'beta_2': 0.9869444429959001, 'epsilon': 2.7952558642997716e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0010350470157924824, 'tol': 0.0005500580150767552, 'validation_fraction': 0.7301430461099642}
observation time 0.001385, current best -0.963112 at iter 6
suggestion time taken 0.001708 iter 7 next_points [{'alpha': 8.776808877457109e-05, 'batch_size': 191, 'beta_1': 0.9157793358427943, 'beta_2': 0.9999971735192811, 'epsilon': 2.4128867253845266e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 1.7308215900959516e-05, 'tol': 1.0710527739711058e-05, 'validation_fraction': 0.8930659132805061}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.171738 value -0.102352 suggestion {'alpha': 8.776808877457109e-05, 'batch_size': 191, 'beta_1': 0.9157793358427943, 'beta_2': 0.9999971735192811, 'epsilon': 2.4128867253845266e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 1.7308215900959516e-05, 'tol': 1.0710527739711058e-05, 'validation_fraction': 0.8930659132805061}
observation time 0.001352, current best -0.963112 at iter 7
suggestion time taken 0.001993 iter 8 next_points [{'alpha': 0.2316621750941436, 'batch_size': 12, 'beta_1': 0.8772000241909563, 'beta_2': 0.9999931855010529, 'epsilon': 1.5694265965242513e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.018821279733008983, 'tol': 0.022091160078470784, 'validation_fraction': 0.36577317067340204}]
function_evaluation time 1.357727 value -0.935980 suggestion {'alpha': 0.2316621750941436, 'batch_size': 12, 'beta_1': 0.8772000241909563, 'beta_2': 0.9999931855010529, 'epsilon': 1.5694265965242513e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.018821279733008983, 'tol': 0.022091160078470784, 'validation_fraction': 0.36577317067340204}
observation time 0.001312, current best -0.963112 at iter 8
suggestion time taken 0.001729 iter 9 next_points [{'alpha': 1.935777214676364, 'batch_size': 234, 'beta_1': 0.7217316201677627, 'beta_2': 0.9999767346770835, 'epsilon': 9.227339037390175e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0002794456881540668, 'tol': 0.01353330234974548, 'validation_fraction': 0.8057062905911571}]
function_evaluation time 0.477799 value -0.368777 suggestion {'alpha': 1.935777214676364, 'batch_size': 234, 'beta_1': 0.7217316201677627, 'beta_2': 0.9999767346770835, 'epsilon': 9.227339037390175e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0002794456881540668, 'tol': 0.01353330234974548, 'validation_fraction': 0.8057062905911571}
observation time 0.001323, current best -0.963112 at iter 9
suggestion time taken 0.001718 iter 10 next_points [{'alpha': 0.0004427730412375795, 'batch_size': 154, 'beta_1': 0.9504614122713972, 'beta_2': 0.995613229073216, 'epsilon': 6.111574315373556e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 2.8332332987059634e-05, 'tol': 0.00014530643412481877, 'validation_fraction': 0.11539581078808503}]
function_evaluation time 2.113972 value -0.358916 suggestion {'alpha': 0.0004427730412375795, 'batch_size': 154, 'beta_1': 0.9504614122713972, 'beta_2': 0.995613229073216, 'epsilon': 6.111574315373556e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 2.8332332987059634e-05, 'tol': 0.00014530643412481877, 'validation_fraction': 0.11539581078808503}
observation time 0.001413, current best -0.963112 at iter 10
suggestion time taken 0.001721 iter 11 next_points [{'alpha': 1.064591335401838e-05, 'batch_size': 144, 'beta_1': 0.9842140720998359, 'beta_2': 0.9995498818051706, 'epsilon': 5.026893407550921e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 1.4756166561569522e-05, 'tol': 2.8269489209401423e-05, 'validation_fraction': 0.659508623847332}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.072263 value -0.198449 suggestion {'alpha': 1.064591335401838e-05, 'batch_size': 144, 'beta_1': 0.9842140720998359, 'beta_2': 0.9995498818051706, 'epsilon': 5.026893407550921e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 1.4756166561569522e-05, 'tol': 2.8269489209401423e-05, 'validation_fraction': 0.659508623847332}
observation time 0.001381, current best -0.963112 at iter 11
suggestion time taken 0.001692 iter 12 next_points [{'alpha': 0.0010986604815452865, 'batch_size': 52, 'beta_1': 0.6488165482164305, 'beta_2': 0.9999872530801412, 'epsilon': 1.2718778813694811e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.001765605604338894, 'tol': 0.026576696984844293, 'validation_fraction': 0.2789389391936451}]
function_evaluation time 0.580975 value -0.950612 suggestion {'alpha': 0.0010986604815452865, 'batch_size': 52, 'beta_1': 0.6488165482164305, 'beta_2': 0.9999872530801412, 'epsilon': 1.2718778813694811e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.001765605604338894, 'tol': 0.026576696984844293, 'validation_fraction': 0.2789389391936451}
observation time 0.001381, current best -0.963112 at iter 12
suggestion time taken 0.001702 iter 13 next_points [{'alpha': 0.00020438189683903916, 'batch_size': 179, 'beta_1': 0.9710333185003657, 'beta_2': 0.9522066250537011, 'epsilon': 3.445763137436119e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 9.477641253261346e-05, 'tol': 0.0008392938455090487, 'validation_fraction': 0.23629496030951744}]
function_evaluation time 2.918017 value -0.945720 suggestion {'alpha': 0.00020438189683903916, 'batch_size': 179, 'beta_1': 0.9710333185003657, 'beta_2': 0.9522066250537011, 'epsilon': 3.445763137436119e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 9.477641253261346e-05, 'tol': 0.0008392938455090487, 'validation_fraction': 0.23629496030951744}
observation time 0.001410, current best -0.963112 at iter 13
suggestion time taken 0.001734 iter 14 next_points [{'alpha': 5.06532194307771, 'batch_size': 30, 'beta_1': 0.9635709805417463, 'beta_2': 0.9999965330414068, 'epsilon': 4.509591917962841e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.06846381012031295, 'tol': 0.06658702514793573, 'validation_fraction': 0.12314325625114048}]
function_evaluation time 1.419936 value -0.928334 suggestion {'alpha': 5.06532194307771, 'batch_size': 30, 'beta_1': 0.9635709805417463, 'beta_2': 0.9999965330414068, 'epsilon': 4.509591917962841e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.06846381012031295, 'tol': 0.06658702514793573, 'validation_fraction': 0.12314325625114048}
observation time 0.001429, current best -0.963112 at iter 14
saving meta data: {'args': {'--uuid': '2e63f83639eb59a2868d9d969b59c2e6', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '5aa615e4b7d85e2896b50058b379111b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'opentuner', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d digits -o opentuner -u 5aa615e4b7d85e2896b50058b379111b -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study opentuner MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.016561 iter 0 next_points [{'hidden_layer_sizes': 142, 'alpha': 1.5599529073197012, 'batch_size': 145, 'learning_rate_init': 0.042196683721730625, 'tol': 0.017724521023220575, 'validation_fraction': 0.8911577000790138, 'beta_1': 0.7033398258295889, 'beta_2': 0.9146142722366198, 'epsilon': 3.769810169867706e-07}]
function_evaluation time 0.369132 value -0.865704 suggestion {'hidden_layer_sizes': 142, 'alpha': 1.5599529073197012, 'batch_size': 145, 'learning_rate_init': 0.042196683721730625, 'tol': 0.017724521023220575, 'validation_fraction': 0.8911577000790138, 'beta_1': 0.7033398258295889, 'beta_2': 0.9146142722366198, 'epsilon': 3.769810169867706e-07}
observation time 0.004263, current best -0.865704 at iter 0
suggestion time taken 0.006902 iter 1 next_points [{'hidden_layer_sizes': 142, 'alpha': 1.5599529073197012, 'batch_size': 145, 'learning_rate_init': 0.042196683721730625, 'tol': 0.017724521023220575, 'validation_fraction': 0.8911577000790138, 'beta_1': 0.7033398258295889, 'beta_2': 0.9363297359343025, 'epsilon': 3.769810169867706e-07}]
function_evaluation time 0.372236 value -0.892814 suggestion {'hidden_layer_sizes': 142, 'alpha': 1.5599529073197012, 'batch_size': 145, 'learning_rate_init': 0.042196683721730625, 'tol': 0.017724521023220575, 'validation_fraction': 0.8911577000790138, 'beta_1': 0.7033398258295889, 'beta_2': 0.9363297359343025, 'epsilon': 3.769810169867706e-07}
observation time 0.001871, current best -0.892814 at iter 1
suggestion time taken 0.022339 iter 2 next_points [{'beta_2': 0.9631298687463323, 'beta_1': 0.6293128844599989, 'learning_rate_init': 0.05569973359076646, 'tol': 0.009090211988989672, 'batch_size': 183, 'hidden_layer_sizes': 105, 'epsilon': 3.7870294714079e-07, 'validation_fraction': 0.7008446760796189, 'alpha': 0.7872761398719016}]
function_evaluation time 0.523829 value -0.908841 suggestion {'beta_2': 0.9631298687463323, 'beta_1': 0.6293128844599989, 'learning_rate_init': 0.05569973359076646, 'tol': 0.009090211988989672, 'batch_size': 183, 'hidden_layer_sizes': 105, 'epsilon': 3.7870294714079e-07, 'validation_fraction': 0.7008446760796189, 'alpha': 0.7872761398719016}
observation time 0.001818, current best -0.908841 at iter 2
suggestion time taken 0.046054 iter 3 next_points [{'beta_2': 0.9500359535002746, 'beta_1': 0.6423933451729724, 'learning_rate_init': 0.050204661393039744, 'tol': 0.09061775216039629, 'batch_size': 53, 'hidden_layer_sizes': 88, 'epsilon': 9.063215626053656e-07, 'validation_fraction': 0.3661876427325912, 'alpha': 4.880421269303873}]
function_evaluation time 0.503875 value -0.897709 suggestion {'beta_2': 0.9500359535002746, 'beta_1': 0.6423933451729724, 'learning_rate_init': 0.050204661393039744, 'tol': 0.09061775216039629, 'batch_size': 53, 'hidden_layer_sizes': 88, 'epsilon': 9.063215626053656e-07, 'validation_fraction': 0.3661876427325912, 'alpha': 4.880421269303873}
observation time 0.001987, current best -0.908841 at iter 3
suggestion time taken 0.006940 iter 4 next_points [{'beta_2': 0.9631298687463323, 'beta_1': 0.6293128844599989, 'learning_rate_init': 0.05569973359076646, 'tol': 0.009090211988989672, 'batch_size': 183, 'hidden_layer_sizes': 105, 'epsilon': 7.496233328801717e-07, 'validation_fraction': 0.7008446760796189, 'alpha': 0.7872761398719016}]
function_evaluation time 0.547025 value -0.892847 suggestion {'beta_2': 0.9631298687463323, 'beta_1': 0.6293128844599989, 'learning_rate_init': 0.05569973359076646, 'tol': 0.009090211988989672, 'batch_size': 183, 'hidden_layer_sizes': 105, 'epsilon': 7.496233328801717e-07, 'validation_fraction': 0.7008446760796189, 'alpha': 0.7872761398719016}
observation time 0.001831, current best -0.908841 at iter 4
suggestion time taken 0.005963 iter 5 next_points [{'beta_2': 0.9508574810021693, 'beta_1': 0.8420498841852224, 'learning_rate_init': 0.039330461517055486, 'tol': 0.02249590520837368, 'batch_size': 74, 'hidden_layer_sizes': 114, 'epsilon': 3.2348203640783404e-07, 'validation_fraction': 0.7093208406591155, 'alpha': 2.010819935854386}]
function_evaluation time 0.390871 value -0.926921 suggestion {'beta_2': 0.9508574810021693, 'beta_1': 0.8420498841852224, 'learning_rate_init': 0.039330461517055486, 'tol': 0.02249590520837368, 'batch_size': 74, 'hidden_layer_sizes': 114, 'epsilon': 3.2348203640783404e-07, 'validation_fraction': 0.7093208406591155, 'alpha': 2.010819935854386}
observation time 0.002258, current best -0.926921 at iter 5
suggestion time taken 0.007174 iter 6 next_points [{'beta_2': 0.957848926852197, 'beta_1': 0.8420498841852224, 'learning_rate_init': 0.039330461517055486, 'tol': 0.02601640255806086, 'batch_size': 74, 'hidden_layer_sizes': 114, 'epsilon': 3.3750692499165304e-07, 'validation_fraction': 0.7093208406591155, 'alpha': 2.010819935854386}]
function_evaluation time 0.378580 value -0.930413 suggestion {'beta_2': 0.957848926852197, 'beta_1': 0.8420498841852224, 'learning_rate_init': 0.039330461517055486, 'tol': 0.02601640255806086, 'batch_size': 74, 'hidden_layer_sizes': 114, 'epsilon': 3.3750692499165304e-07, 'validation_fraction': 0.7093208406591155, 'alpha': 2.010819935854386}
observation time 0.001857, current best -0.930413 at iter 6
suggestion time taken 0.005964 iter 7 next_points [{'beta_2': 0.9286237501216781, 'beta_1': 0.5443838939938135, 'learning_rate_init': 0.021230020816428375, 'tol': 0.07968696893456977, 'batch_size': 46, 'hidden_layer_sizes': 70, 'epsilon': 4.935936880617598e-07, 'validation_fraction': 0.6997074663004417, 'alpha': 8.124925912906466}]
function_evaluation time 0.315811 value -0.912328 suggestion {'beta_2': 0.9286237501216781, 'beta_1': 0.5443838939938135, 'learning_rate_init': 0.021230020816428375, 'tol': 0.07968696893456977, 'batch_size': 46, 'hidden_layer_sizes': 70, 'epsilon': 4.935936880617598e-07, 'validation_fraction': 0.6997074663004417, 'alpha': 8.124925912906466}
observation time 0.002254, current best -0.930413 at iter 7
suggestion time taken 0.007275 iter 8 next_points [{'beta_2': 0.9686980006851101, 'beta_1': 0.8420498841852224, 'learning_rate_init': 0.026944730569318388, 'tol': 0.011464289592376598, 'batch_size': 74, 'hidden_layer_sizes': 114, 'epsilon': 3.3750692499165304e-07, 'validation_fraction': 0.8340062405561518, 'alpha': 2.010819935854386}]
function_evaluation time 0.325332 value -0.925530 suggestion {'beta_2': 0.9686980006851101, 'beta_1': 0.8420498841852224, 'learning_rate_init': 0.026944730569318388, 'tol': 0.011464289592376598, 'batch_size': 74, 'hidden_layer_sizes': 114, 'epsilon': 3.3750692499165304e-07, 'validation_fraction': 0.8340062405561518, 'alpha': 2.010819935854386}
observation time 0.001813, current best -0.930413 at iter 8
suggestion time taken 0.006763 iter 9 next_points [{'beta_2': 0.957848926852197, 'beta_1': 0.8953727609632143, 'learning_rate_init': 0.039330461517055486, 'tol': 0.02601640255806086, 'batch_size': 74, 'hidden_layer_sizes': 114, 'epsilon': 3.3750692499165304e-07, 'validation_fraction': 0.6602301170666292, 'alpha': 2.010819935854386}]
function_evaluation time 0.447343 value -0.926953 suggestion {'beta_2': 0.957848926852197, 'beta_1': 0.8953727609632143, 'learning_rate_init': 0.039330461517055486, 'tol': 0.02601640255806086, 'batch_size': 74, 'hidden_layer_sizes': 114, 'epsilon': 3.3750692499165304e-07, 'validation_fraction': 0.6602301170666292, 'alpha': 2.010819935854386}
observation time 0.002043, current best -0.930413 at iter 9
suggestion time taken 0.006098 iter 10 next_points [{'beta_2': 0.9914839406606434, 'beta_1': 0.9404607944674266, 'learning_rate_init': 0.0951164536466406, 'tol': 0.09675908213387101, 'batch_size': 41, 'hidden_layer_sizes': 111, 'epsilon': 3.80320727494914e-07, 'validation_fraction': 0.8374985722957317, 'alpha': 2.6385346287031592}]
function_evaluation time 0.394210 value -0.820458 suggestion {'beta_2': 0.9914839406606434, 'beta_1': 0.9404607944674266, 'learning_rate_init': 0.0951164536466406, 'tol': 0.09675908213387101, 'batch_size': 41, 'hidden_layer_sizes': 111, 'epsilon': 3.80320727494914e-07, 'validation_fraction': 0.8374985722957317, 'alpha': 2.6385346287031592}
observation time 0.001747, current best -0.930413 at iter 10
suggestion time taken 0.006812 iter 11 next_points [{'beta_2': 0.957848926852197, 'beta_1': 0.8420498841852224, 'learning_rate_init': 0.039330461517055486, 'tol': 0.02601640255806086, 'batch_size': 74, 'hidden_layer_sizes': 176, 'epsilon': 3.3750692499165304e-07, 'validation_fraction': 0.515554867830388, 'alpha': 0.27620148142656403}]
function_evaluation time 0.766801 value -0.927652 suggestion {'beta_2': 0.957848926852197, 'beta_1': 0.8420498841852224, 'learning_rate_init': 0.039330461517055486, 'tol': 0.02601640255806086, 'batch_size': 74, 'hidden_layer_sizes': 176, 'epsilon': 3.3750692499165304e-07, 'validation_fraction': 0.515554867830388, 'alpha': 0.27620148142656403}
observation time 0.002013, current best -0.930413 at iter 11
suggestion time taken 0.007303 iter 12 next_points [{'beta_2': 0.957848926852197, 'beta_1': 0.8420498841852224, 'learning_rate_init': 0.039330461517055486, 'tol': 0.02362574395953503, 'batch_size': 74, 'hidden_layer_sizes': 133, 'epsilon': 3.3750692499165304e-07, 'validation_fraction': 0.8075391887727711, 'alpha': 2.010819935854386}]
function_evaluation time 0.391962 value -0.910242 suggestion {'beta_2': 0.957848926852197, 'beta_1': 0.8420498841852224, 'learning_rate_init': 0.039330461517055486, 'tol': 0.02362574395953503, 'batch_size': 74, 'hidden_layer_sizes': 133, 'epsilon': 3.3750692499165304e-07, 'validation_fraction': 0.8075391887727711, 'alpha': 2.010819935854386}
observation time 0.001876, current best -0.930413 at iter 12
suggestion time taken 0.005856 iter 13 next_points [{'beta_2': 0.9045501972389942, 'beta_1': 0.5833931370568362, 'learning_rate_init': 0.04309263988860151, 'tol': 0.08260227493894827, 'batch_size': 215, 'hidden_layer_sizes': 111, 'epsilon': 1.9255111230517718e-07, 'validation_fraction': 0.6741938508983828, 'alpha': 0.347175169127982}]
function_evaluation time 0.258792 value -0.921392 suggestion {'beta_2': 0.9045501972389942, 'beta_1': 0.5833931370568362, 'learning_rate_init': 0.04309263988860151, 'tol': 0.08260227493894827, 'batch_size': 215, 'hidden_layer_sizes': 111, 'epsilon': 1.9255111230517718e-07, 'validation_fraction': 0.6741938508983828, 'alpha': 0.347175169127982}
observation time 0.001798, current best -0.930413 at iter 13
suggestion time taken 0.005795 iter 14 next_points [{'beta_2': 0.9680859343227032, 'beta_1': 0.5798153820140804, 'learning_rate_init': 0.07682754661921447, 'tol': 0.04932721928421862, 'batch_size': 179, 'hidden_layer_sizes': 87, 'epsilon': 5.393633641109497e-07, 'validation_fraction': 0.277941686517154, 'alpha': 3.848341772396013}]
function_evaluation time 0.351383 value -0.484512 suggestion {'beta_2': 0.9680859343227032, 'beta_1': 0.5798153820140804, 'learning_rate_init': 0.07682754661921447, 'tol': 0.04932721928421862, 'batch_size': 179, 'hidden_layer_sizes': 87, 'epsilon': 5.393633641109497e-07, 'validation_fraction': 0.277941686517154, 'alpha': 3.848341772396013}
observation time 0.001904, current best -0.930413 at iter 14
saving meta data: {'args': {'--uuid': '5aa615e4b7d85e2896b50058b379111b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'opentuner', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

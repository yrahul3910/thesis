running: {'--uuid': '891a37848fb55dd490014672136eb770', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u 891a37848fb55dd490014672136eb770 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study smoothness MLP-adam digits acc 15 1
with data root: None
suggestion time taken 11.182825 iter 0 next_points [{'alpha': 0.04338480519875595, 'batch_size': 13, 'beta_1': 0.7707943071719688, 'beta_2': 0.9999951700349168, 'epsilon': 4.077578043109819e-08, 'hidden_layer_sizes': 159, 'learning_rate_init': 1.171741488116709e-05, 'tol': 0.0006216392817287532, 'validation_fraction': 0.4940215441918918}]
function_evaluation time 18.627363 value -0.892153 suggestion {'alpha': 0.04338480519875595, 'batch_size': 13, 'beta_1': 0.7707943071719688, 'beta_2': 0.9999951700349168, 'epsilon': 4.077578043109819e-08, 'hidden_layer_sizes': 159, 'learning_rate_init': 1.171741488116709e-05, 'tol': 0.0006216392817287532, 'validation_fraction': 0.4940215441918918}
observation time 0.000004, current best -0.892153 at iter 0
suggestion time taken 11.167290 iter 1 next_points [{'alpha': 2.055803414538707e-05, 'batch_size': 20, 'beta_1': 0.5497467936019932, 'beta_2': 0.9969430594513035, 'epsilon': 1.0021428386147843e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 4.191478959250391e-05, 'tol': 6.069646920525018e-05, 'validation_fraction': 0.20414958808294426}]
function_evaluation time 9.572184 value -0.929024 suggestion {'alpha': 2.055803414538707e-05, 'batch_size': 20, 'beta_1': 0.5497467936019932, 'beta_2': 0.9969430594513035, 'epsilon': 1.0021428386147843e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 4.191478959250391e-05, 'tol': 6.069646920525018e-05, 'validation_fraction': 0.20414958808294426}
observation time 0.000005, current best -0.929024 at iter 1
suggestion time taken 10.942436 iter 2 next_points [{'alpha': 5.9407819586949175, 'batch_size': 14, 'beta_1': 0.7921707005956652, 'beta_2': 0.9997443627154339, 'epsilon': 1.5547838187447904e-08, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.021234397444522234, 'tol': 0.00011729844845087932, 'validation_fraction': 0.4211505088386767}]
function_evaluation time 2.737256 value -0.880314 suggestion {'alpha': 5.9407819586949175, 'batch_size': 14, 'beta_1': 0.7921707005956652, 'beta_2': 0.9997443627154339, 'epsilon': 1.5547838187447904e-08, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.021234397444522234, 'tol': 0.00011729844845087932, 'validation_fraction': 0.4211505088386767}
observation time 0.000005, current best -0.929024 at iter 2
suggestion time taken 10.995028 iter 3 next_points [{'alpha': 0.0011531599766103568, 'batch_size': 22, 'beta_1': 0.95629812006808, 'beta_2': 0.9974236540296886, 'epsilon': 3.5852074227971207e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 2.6076405062936327e-05, 'tol': 0.00011217474322534216, 'validation_fraction': 0.5749867803261015}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 6.509618 value -0.563250 suggestion {'alpha': 0.0011531599766103568, 'batch_size': 22, 'beta_1': 0.95629812006808, 'beta_2': 0.9974236540296886, 'epsilon': 3.5852074227971207e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 2.6076405062936327e-05, 'tol': 0.00011217474322534216, 'validation_fraction': 0.5749867803261015}
observation time 0.000004, current best -0.929024 at iter 3
suggestion time taken 10.970475 iter 4 next_points [{'alpha': 0.03200982546790329, 'batch_size': 19, 'beta_1': 0.989420020334452, 'beta_2': 0.9999981703323907, 'epsilon': 2.02330399480382e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0002223300464632358, 'tol': 0.03021942505858907, 'validation_fraction': 0.49949692874230445}]
function_evaluation time 1.273088 value -0.917209 suggestion {'alpha': 0.03200982546790329, 'batch_size': 19, 'beta_1': 0.989420020334452, 'beta_2': 0.9999981703323907, 'epsilon': 2.02330399480382e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0002223300464632358, 'tol': 0.03021942505858907, 'validation_fraction': 0.49949692874230445}
observation time 0.000005, current best -0.929024 at iter 4
suggestion time taken 11.122834 iter 5 next_points [{'alpha': 4.0348819505862465, 'batch_size': 16, 'beta_1': 0.9480060698833936, 'beta_2': 0.9999906047223208, 'epsilon': 9.771510029645415e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.006541314791253116, 'tol': 0.02378186624061761, 'validation_fraction': 0.1030399191273678}]
function_evaluation time 1.108153 value -0.942937 suggestion {'alpha': 4.0348819505862465, 'batch_size': 16, 'beta_1': 0.9480060698833936, 'beta_2': 0.9999906047223208, 'epsilon': 9.771510029645415e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.006541314791253116, 'tol': 0.02378186624061761, 'validation_fraction': 0.1030399191273678}
observation time 0.000005, current best -0.942937 at iter 5
suggestion time taken 10.909077 iter 6 next_points [{'alpha': 0.0003912239464670406, 'batch_size': 21, 'beta_1': 0.6866326357438736, 'beta_2': 0.9994271807278976, 'epsilon': 2.207116984112043e-09, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.003017634136160674, 'tol': 0.026579425330169045, 'validation_fraction': 0.1576615903798481}]
function_evaluation time 1.323646 value -0.962413 suggestion {'alpha': 0.0003912239464670406, 'batch_size': 21, 'beta_1': 0.6866326357438736, 'beta_2': 0.9994271807278976, 'epsilon': 2.207116984112043e-09, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.003017634136160674, 'tol': 0.026579425330169045, 'validation_fraction': 0.1576615903798481}
observation time 0.000004, current best -0.962413 at iter 6
suggestion time taken 11.088329 iter 7 next_points [{'alpha': 0.2655381241367531, 'batch_size': 40, 'beta_1': 0.7135362892535266, 'beta_2': 0.9999906648916658, 'epsilon': 7.350738137697593e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 1.029304717379016e-05, 'tol': 0.000885346108491868, 'validation_fraction': 0.36746998490837574}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.394282 value -0.199632 suggestion {'alpha': 0.2655381241367531, 'batch_size': 40, 'beta_1': 0.7135362892535266, 'beta_2': 0.9999906648916658, 'epsilon': 7.350738137697593e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 1.029304717379016e-05, 'tol': 0.000885346108491868, 'validation_fraction': 0.36746998490837574}
observation time 0.000004, current best -0.962413 at iter 7
suggestion time taken 10.851778 iter 8 next_points [{'alpha': 0.2667317366227738, 'batch_size': 13, 'beta_1': 0.6963149439979402, 'beta_2': 0.9976125080063595, 'epsilon': 6.517781463567815e-09, 'hidden_layer_sizes': 176, 'learning_rate_init': 3.268761522109182e-05, 'tol': 0.0001389814346469561, 'validation_fraction': 0.3336262570135704}]
function_evaluation time 12.461539 value -0.952681 suggestion {'alpha': 0.2667317366227738, 'batch_size': 13, 'beta_1': 0.6963149439979402, 'beta_2': 0.9976125080063595, 'epsilon': 6.517781463567815e-09, 'hidden_layer_sizes': 176, 'learning_rate_init': 3.268761522109182e-05, 'tol': 0.0001389814346469561, 'validation_fraction': 0.3336262570135704}
observation time 0.000004, current best -0.962413 at iter 8
suggestion time taken 10.911568 iter 9 next_points [{'alpha': 0.034164438785111766, 'batch_size': 17, 'beta_1': 0.75361534881145, 'beta_2': 0.9994866572742376, 'epsilon': 1.2171402004795675e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 6.753805899167045e-05, 'tol': 0.0001871533484103582, 'validation_fraction': 0.23299851136870195}]
function_evaluation time 7.667915 value -0.944338 suggestion {'alpha': 0.034164438785111766, 'batch_size': 17, 'beta_1': 0.75361534881145, 'beta_2': 0.9994866572742376, 'epsilon': 1.2171402004795675e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 6.753805899167045e-05, 'tol': 0.0001871533484103582, 'validation_fraction': 0.23299851136870195}
observation time 0.000005, current best -0.962413 at iter 9
suggestion time taken 11.222658 iter 10 next_points [{'alpha': 0.00015361832965501146, 'batch_size': 12, 'beta_1': 0.9803489417444038, 'beta_2': 0.9925649274160776, 'epsilon': 1.959067349908474e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.026825509923532453, 'tol': 0.0009207641871833887, 'validation_fraction': 0.6217858297945258}]
function_evaluation time 1.719444 value -0.898425 suggestion {'alpha': 0.00015361832965501146, 'batch_size': 12, 'beta_1': 0.9803489417444038, 'beta_2': 0.9925649274160776, 'epsilon': 1.959067349908474e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.026825509923532453, 'tol': 0.0009207641871833887, 'validation_fraction': 0.6217858297945258}
observation time 0.000005, current best -0.962413 at iter 10
suggestion time taken 10.945077 iter 11 next_points [{'alpha': 5.9905700628974484e-05, 'batch_size': 27, 'beta_1': 0.9871506577493322, 'beta_2': 0.9993121443028732, 'epsilon': 2.259024446221598e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.01861463055425707, 'tol': 0.09918992081222597, 'validation_fraction': 0.22941929985225346}]
function_evaluation time 0.839305 value -0.949194 suggestion {'alpha': 5.9905700628974484e-05, 'batch_size': 27, 'beta_1': 0.9871506577493322, 'beta_2': 0.9993121443028732, 'epsilon': 2.259024446221598e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.01861463055425707, 'tol': 0.09918992081222597, 'validation_fraction': 0.22941929985225346}
observation time 0.000005, current best -0.962413 at iter 11
suggestion time taken 10.847743 iter 12 next_points [{'alpha': 0.00039800235302143506, 'batch_size': 11, 'beta_1': 0.9147843941506009, 'beta_2': 0.9999961720690685, 'epsilon': 1.6408052331524036e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 1.0472525991217635e-05, 'tol': 0.014300540576573558, 'validation_fraction': 0.22280506758911287}]
function_evaluation time 3.996938 value -0.371622 suggestion {'alpha': 0.00039800235302143506, 'batch_size': 11, 'beta_1': 0.9147843941506009, 'beta_2': 0.9999961720690685, 'epsilon': 1.6408052331524036e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 1.0472525991217635e-05, 'tol': 0.014300540576573558, 'validation_fraction': 0.22280506758911287}
observation time 0.000005, current best -0.962413 at iter 12
suggestion time taken 11.287785 iter 13 next_points [{'alpha': 0.01716886761153307, 'batch_size': 14, 'beta_1': 0.8211333467404757, 'beta_2': 0.9976961370165028, 'epsilon': 2.862344813666399e-09, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0029258479224164094, 'tol': 0.001147596174476492, 'validation_fraction': 0.35943186258161197}]
function_evaluation time 3.172960 value -0.968702 suggestion {'alpha': 0.01716886761153307, 'batch_size': 14, 'beta_1': 0.8211333467404757, 'beta_2': 0.9976961370165028, 'epsilon': 2.862344813666399e-09, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0029258479224164094, 'tol': 0.001147596174476492, 'validation_fraction': 0.35943186258161197}
observation time 0.000004, current best -0.968702 at iter 13
suggestion time taken 11.075955 iter 14 next_points [{'alpha': 0.012399877656484318, 'batch_size': 31, 'beta_1': 0.6805617548155505, 'beta_2': 0.9996443581812835, 'epsilon': 3.6932313491132557e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.011843959427432356, 'tol': 0.0008238873607432643, 'validation_fraction': 0.8581810846060007}]
function_evaluation time 1.053353 value -0.908142 suggestion {'alpha': 0.012399877656484318, 'batch_size': 31, 'beta_1': 0.6805617548155505, 'beta_2': 0.9996443581812835, 'epsilon': 3.6932313491132557e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.011843959427432356, 'tol': 0.0008238873607432643, 'validation_fraction': 0.8581810846060007}
observation time 0.000006, current best -0.968702 at iter 14
saving meta data: {'args': {'--uuid': '891a37848fb55dd490014672136eb770', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

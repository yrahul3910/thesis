running: {'--uuid': '23a25870da845d989526a53e088ee72d', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 23a25870da845d989526a53e088ee72d -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002284 iter 0 next_points [{'alpha': 3.891832630722253e-05, 'batch_size': 19, 'beta_1': 0.5037724018257708, 'beta_2': 0.9000268121241024, 'epsilon': 4.922809199534183e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0001799627653227912, 'tol': 0.010872303410423544, 'validation_fraction': 0.5234152448693684}]
function_evaluation time 1.656629 value -0.915791 suggestion {'alpha': 3.891832630722253e-05, 'batch_size': 19, 'beta_1': 0.5037724018257708, 'beta_2': 0.9000268121241024, 'epsilon': 4.922809199534183e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0001799627653227912, 'tol': 0.010872303410423544, 'validation_fraction': 0.5234152448693684}
observation time 0.000065, current best -0.915791 at iter 0
suggestion time taken 0.002281 iter 1 next_points [{'alpha': 0.0014161349536901948, 'batch_size': 171, 'beta_1': 0.8475330470594815, 'beta_2': 0.9171265268959721, 'epsilon': 5.232572785828752e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.010732274792408493, 'tol': 0.001662373756432224, 'validation_fraction': 0.3023881634903707}]
function_evaluation time 1.046427 value -0.963821 suggestion {'alpha': 0.0014161349536901948, 'batch_size': 171, 'beta_1': 0.8475330470594815, 'beta_2': 0.9171265268959721, 'epsilon': 5.232572785828752e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.010732274792408493, 'tol': 0.001662373756432224, 'validation_fraction': 0.3023881634903707}
observation time 0.000070, current best -0.963821 at iter 1
suggestion time taken 0.002124 iter 2 next_points [{'alpha': 9.373593805630234, 'batch_size': 204, 'beta_1': 0.6224549024138328, 'beta_2': 0.9986482834655531, 'epsilon': 9.804077309102929e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.005788416903454376, 'tol': 0.00010223644682426852, 'validation_fraction': 0.2423477066787445}]
function_evaluation time 0.917822 value -0.961046 suggestion {'alpha': 9.373593805630234, 'batch_size': 204, 'beta_1': 0.6224549024138328, 'beta_2': 0.9986482834655531, 'epsilon': 9.804077309102929e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.005788416903454376, 'tol': 0.00010223644682426852, 'validation_fraction': 0.2423477066787445}
observation time 0.000072, current best -0.963821 at iter 2
suggestion time taken 0.002132 iter 3 next_points [{'alpha': 0.0006628792889442325, 'batch_size': 132, 'beta_1': 0.7116175022699858, 'beta_2': 0.9529949904596793, 'epsilon': 4.230404426387264e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.029672939088677044, 'tol': 0.0037584067251278763, 'validation_fraction': 0.47040892551502844}]
function_evaluation time 0.502936 value -0.924828 suggestion {'alpha': 0.0006628792889442325, 'batch_size': 132, 'beta_1': 0.7116175022699858, 'beta_2': 0.9529949904596793, 'epsilon': 4.230404426387264e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.029672939088677044, 'tol': 0.0037584067251278763, 'validation_fraction': 0.47040892551502844}
observation time 0.000068, current best -0.963821 at iter 3
suggestion time taken 0.002101 iter 4 next_points [{'alpha': 0.03560753225120923, 'batch_size': 238, 'beta_1': 0.79113010189399, 'beta_2': 0.9599215915443682, 'epsilon': 2.483986332242557e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.004527735661504321, 'tol': 0.05925868292421828, 'validation_fraction': 0.2537276025947608}]
function_evaluation time 0.342608 value -0.947121 suggestion {'alpha': 0.03560753225120923, 'batch_size': 238, 'beta_1': 0.79113010189399, 'beta_2': 0.9599215915443682, 'epsilon': 2.483986332242557e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.004527735661504321, 'tol': 0.05925868292421828, 'validation_fraction': 0.2537276025947608}
observation time 0.000071, current best -0.963821 at iter 4
suggestion time taken 0.002155 iter 5 next_points [{'alpha': 0.003136451056704858, 'batch_size': 120, 'beta_1': 0.8750407184410073, 'beta_2': 0.9747655319507925, 'epsilon': 9.580384894424836e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.02533872577898827, 'tol': 0.00017177822616285869, 'validation_fraction': 0.23274814228113525}]
function_evaluation time 1.052671 value -0.967296 suggestion {'alpha': 0.003136451056704858, 'batch_size': 120, 'beta_1': 0.8750407184410073, 'beta_2': 0.9747655319507925, 'epsilon': 9.580384894424836e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.02533872577898827, 'tol': 0.00017177822616285869, 'validation_fraction': 0.23274814228113525}
observation time 0.000072, current best -0.967296 at iter 5
suggestion time taken 0.002151 iter 6 next_points [{'alpha': 0.08137031375397476, 'batch_size': 217, 'beta_1': 0.75627225020417, 'beta_2': 0.9431576527457991, 'epsilon': 2.128015405353572e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0001701909099994023, 'tol': 0.0006015339880358465, 'validation_fraction': 0.34037697358306834}]
function_evaluation time 3.177758 value -0.953371 suggestion {'alpha': 0.08137031375397476, 'batch_size': 217, 'beta_1': 0.75627225020417, 'beta_2': 0.9431576527457991, 'epsilon': 2.128015405353572e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0001701909099994023, 'tol': 0.0006015339880358465, 'validation_fraction': 0.34037697358306834}
observation time 0.000069, current best -0.967296 at iter 6
suggestion time taken 0.002177 iter 7 next_points [{'alpha': 0.4283107877725831, 'batch_size': 84, 'beta_1': 0.7940242268001274, 'beta_2': 0.9645796048285697, 'epsilon': 2.0383290529134993e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 1.830415895828136e-05, 'tol': 1.408796170266485e-05, 'validation_fraction': 0.7436037525241779}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.919190 value -0.110651 suggestion {'alpha': 0.4283107877725831, 'batch_size': 84, 'beta_1': 0.7940242268001274, 'beta_2': 0.9645796048285697, 'epsilon': 2.0383290529134993e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 1.830415895828136e-05, 'tol': 1.408796170266485e-05, 'validation_fraction': 0.7436037525241779}
observation time 0.000086, current best -0.967296 at iter 7
suggestion time taken 0.002123 iter 8 next_points [{'alpha': 0.00043559712711700103, 'batch_size': 73, 'beta_1': 0.5324706735741289, 'beta_2': 0.9368997708145981, 'epsilon': 7.501868479330347e-08, 'hidden_layer_sizes': 149, 'learning_rate_init': 2.900487996471368e-05, 'tol': 5.3170525367051736e-05, 'validation_fraction': 0.17617409036261114}]
function_evaluation time 5.544855 value -0.903271 suggestion {'alpha': 0.00043559712711700103, 'batch_size': 73, 'beta_1': 0.5324706735741289, 'beta_2': 0.9368997708145981, 'epsilon': 7.501868479330347e-08, 'hidden_layer_sizes': 149, 'learning_rate_init': 2.900487996471368e-05, 'tol': 5.3170525367051736e-05, 'validation_fraction': 0.17617409036261114}
observation time 0.000065, current best -0.967296 at iter 8
suggestion time taken 0.002115 iter 9 next_points [{'alpha': 0.004035911485235797, 'batch_size': 159, 'beta_1': 0.5373346950651758, 'beta_2': 0.9259333628186693, 'epsilon': 3.948396064021681e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.02085619965506026, 'tol': 0.00022770947974490365, 'validation_fraction': 0.4181823892463877}]
function_evaluation time 0.824793 value -0.957566 suggestion {'alpha': 0.004035911485235797, 'batch_size': 159, 'beta_1': 0.5373346950651758, 'beta_2': 0.9259333628186693, 'epsilon': 3.948396064021681e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.02085619965506026, 'tol': 0.00022770947974490365, 'validation_fraction': 0.4181823892463877}
observation time 0.000078, current best -0.967296 at iter 9
suggestion time taken 0.002130 iter 10 next_points [{'alpha': 0.0007277149340569315, 'batch_size': 42, 'beta_1': 0.5089368925262192, 'beta_2': 0.9088982758869958, 'epsilon': 7.706467493974481e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.014654338882162835, 'tol': 0.0007082743759272053, 'validation_fraction': 0.4811794728165176}]
function_evaluation time 1.270134 value -0.955452 suggestion {'alpha': 0.0007277149340569315, 'batch_size': 42, 'beta_1': 0.5089368925262192, 'beta_2': 0.9088982758869958, 'epsilon': 7.706467493974481e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.014654338882162835, 'tol': 0.0007082743759272053, 'validation_fraction': 0.4811794728165176}
observation time 0.000073, current best -0.967296 at iter 10
suggestion time taken 0.002368 iter 11 next_points [{'alpha': 0.08871346877225114, 'batch_size': 90, 'beta_1': 0.7109560457530709, 'beta_2': 0.9178334700951528, 'epsilon': 7.253846990383046e-08, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.0006955589846156482, 'tol': 0.03717461925283273, 'validation_fraction': 0.49369376913945207}]
function_evaluation time 0.599041 value -0.949192 suggestion {'alpha': 0.08871346877225114, 'batch_size': 90, 'beta_1': 0.7109560457530709, 'beta_2': 0.9178334700951528, 'epsilon': 7.253846990383046e-08, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.0006955589846156482, 'tol': 0.03717461925283273, 'validation_fraction': 0.49369376913945207}
observation time 0.000073, current best -0.967296 at iter 11
suggestion time taken 0.002143 iter 12 next_points [{'alpha': 0.03726159022909972, 'batch_size': 168, 'beta_1': 0.5100907024829642, 'beta_2': 0.9290455362358152, 'epsilon': 1.2622432728677273e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.00038814248143979104, 'tol': 4.555224051503732e-05, 'validation_fraction': 0.7435570245321941}]
function_evaluation time 2.396361 value -0.949204 suggestion {'alpha': 0.03726159022909972, 'batch_size': 168, 'beta_1': 0.5100907024829642, 'beta_2': 0.9290455362358152, 'epsilon': 1.2622432728677273e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.00038814248143979104, 'tol': 4.555224051503732e-05, 'validation_fraction': 0.7435570245321941}
observation time 0.000072, current best -0.967296 at iter 12
suggestion time taken 0.002155 iter 13 next_points [{'alpha': 5.09341909060443e-05, 'batch_size': 199, 'beta_1': 0.653453271818387, 'beta_2': 0.9149388073581104, 'epsilon': 3.470823346955883e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0009530136790216542, 'tol': 0.003638587748272086, 'validation_fraction': 0.481357270991356}]
function_evaluation time 0.913409 value -0.945734 suggestion {'alpha': 5.09341909060443e-05, 'batch_size': 199, 'beta_1': 0.653453271818387, 'beta_2': 0.9149388073581104, 'epsilon': 3.470823346955883e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0009530136790216542, 'tol': 0.003638587748272086, 'validation_fraction': 0.481357270991356}
observation time 0.000071, current best -0.967296 at iter 13
suggestion time taken 0.002142 iter 14 next_points [{'alpha': 0.01977926259449332, 'batch_size': 191, 'beta_1': 0.5068191792550639, 'beta_2': 0.9408917392800729, 'epsilon': 1.1266469399297025e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.0066848476975127115, 'tol': 0.03354431522483789, 'validation_fraction': 0.12479392218411421}]
function_evaluation time 0.567782 value -0.965200 suggestion {'alpha': 0.01977926259449332, 'batch_size': 191, 'beta_1': 0.5068191792550639, 'beta_2': 0.9408917392800729, 'epsilon': 1.1266469399297025e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.0066848476975127115, 'tol': 0.03354431522483789, 'validation_fraction': 0.12479392218411421}
observation time 0.000072, current best -0.967296 at iter 14
saving meta data: {'args': {'--uuid': '23a25870da845d989526a53e088ee72d', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

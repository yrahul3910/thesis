running: {'--uuid': '2f7acc77cb2c50cda2351a623e651eaa', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 2f7acc77cb2c50cda2351a623e651eaa -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study hyperopt MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002440 iter 0 next_points [{'alpha': 0.05590773099151223, 'batch_size': 224, 'beta_1': 0.7329637298376595, 'beta_2': 0.9349895562878704, 'epsilon': 8.205247110604795e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.011946418124418589, 'tol': 0.00024459278283269105, 'validation_fraction': 0.10196104468348623}]
function_evaluation time 0.601677 value 0.157830 suggestion {'alpha': 0.05590773099151223, 'batch_size': 224, 'beta_1': 0.7329637298376595, 'beta_2': 0.9349895562878704, 'epsilon': 8.205247110604795e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.011946418124418589, 'tol': 0.00024459278283269105, 'validation_fraction': 0.10196104468348623}
observation time 0.000069, current best 0.157830 at iter 0
suggestion time taken 0.002141 iter 1 next_points [{'alpha': 8.595605475967371, 'batch_size': 71, 'beta_1': 0.8883332010217714, 'beta_2': 0.9451785237483455, 'epsilon': 1.9436652474527274e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0001098598641617186, 'tol': 0.0008672300564250131, 'validation_fraction': 0.10791969406969514}]
function_evaluation time 2.326598 value 0.236979 suggestion {'alpha': 8.595605475967371, 'batch_size': 71, 'beta_1': 0.8883332010217714, 'beta_2': 0.9451785237483455, 'epsilon': 1.9436652474527274e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0001098598641617186, 'tol': 0.0008672300564250131, 'validation_fraction': 0.10791969406969514}
observation time 0.000072, current best 0.157830 at iter 1
suggestion time taken 0.002145 iter 2 next_points [{'alpha': 0.0788839514294766, 'batch_size': 71, 'beta_1': 0.9693664034458088, 'beta_2': 0.924743954624307, 'epsilon': 1.3141312655728245e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.019552770438878084, 'tol': 4.564491027612266e-05, 'validation_fraction': 0.25197612906397054}]
function_evaluation time 0.900601 value 0.376655 suggestion {'alpha': 0.0788839514294766, 'batch_size': 71, 'beta_1': 0.9693664034458088, 'beta_2': 0.924743954624307, 'epsilon': 1.3141312655728245e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.019552770438878084, 'tol': 4.564491027612266e-05, 'validation_fraction': 0.25197612906397054}
observation time 0.000064, current best 0.157830 at iter 2
suggestion time taken 0.002101 iter 3 next_points [{'alpha': 0.03221741355916411, 'batch_size': 163, 'beta_1': 0.619772721667418, 'beta_2': 0.97764846430453, 'epsilon': 3.86259175638008e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.0015012995183225565, 'tol': 0.018995194479041654, 'validation_fraction': 0.17916100283013386}]
function_evaluation time 0.588847 value 0.194167 suggestion {'alpha': 0.03221741355916411, 'batch_size': 163, 'beta_1': 0.619772721667418, 'beta_2': 0.97764846430453, 'epsilon': 3.86259175638008e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.0015012995183225565, 'tol': 0.018995194479041654, 'validation_fraction': 0.17916100283013386}
observation time 0.000062, current best 0.157830 at iter 3
suggestion time taken 0.002125 iter 4 next_points [{'alpha': 0.00011947843219749112, 'batch_size': 35, 'beta_1': 0.9146484797995386, 'beta_2': 0.9374638607344277, 'epsilon': 4.6626861205747006e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 9.367329624271548e-05, 'tol': 0.006359136494618957, 'validation_fraction': 0.4070429068830394}]
function_evaluation time 2.529159 value 0.309259 suggestion {'alpha': 0.00011947843219749112, 'batch_size': 35, 'beta_1': 0.9146484797995386, 'beta_2': 0.9374638607344277, 'epsilon': 4.6626861205747006e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 9.367329624271548e-05, 'tol': 0.006359136494618957, 'validation_fraction': 0.4070429068830394}
observation time 0.000064, current best 0.157830 at iter 4
suggestion time taken 0.002129 iter 5 next_points [{'alpha': 0.0002721890297993618, 'batch_size': 10, 'beta_1': 0.5195229399516108, 'beta_2': 0.9313099126318307, 'epsilon': 7.529012600660553e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.006019253061205228, 'tol': 4.151366950753373e-05, 'validation_fraction': 0.34198839096288197}]
function_evaluation time 3.822173 value 0.307009 suggestion {'alpha': 0.0002721890297993618, 'batch_size': 10, 'beta_1': 0.5195229399516108, 'beta_2': 0.9313099126318307, 'epsilon': 7.529012600660553e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.006019253061205228, 'tol': 4.151366950753373e-05, 'validation_fraction': 0.34198839096288197}
observation time 0.000059, current best 0.157830 at iter 5
suggestion time taken 0.002317 iter 6 next_points [{'alpha': 0.08433899914592133, 'batch_size': 202, 'beta_1': 0.9860392905694486, 'beta_2': 0.9706665678522648, 'epsilon': 1.9373995712420864e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.005616940553236638, 'tol': 5.736372058284371e-05, 'validation_fraction': 0.3627132601317739}]
function_evaluation time 0.766012 value 0.272922 suggestion {'alpha': 0.08433899914592133, 'batch_size': 202, 'beta_1': 0.9860392905694486, 'beta_2': 0.9706665678522648, 'epsilon': 1.9373995712420864e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.005616940553236638, 'tol': 5.736372058284371e-05, 'validation_fraction': 0.3627132601317739}
observation time 0.000057, current best 0.157830 at iter 6
suggestion time taken 0.002277 iter 7 next_points [{'alpha': 0.004765681518590685, 'batch_size': 53, 'beta_1': 0.6425497098078101, 'beta_2': 0.9255823336004102, 'epsilon': 1.1298233337844906e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 4.909613190279443e-05, 'tol': 0.00048402562760271287, 'validation_fraction': 0.6450293297200558}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 4.750657 value 0.363928 suggestion {'alpha': 0.004765681518590685, 'batch_size': 53, 'beta_1': 0.6425497098078101, 'beta_2': 0.9255823336004102, 'epsilon': 1.1298233337844906e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 4.909613190279443e-05, 'tol': 0.00048402562760271287, 'validation_fraction': 0.6450293297200558}
observation time 0.000065, current best 0.157830 at iter 7
suggestion time taken 0.002111 iter 8 next_points [{'alpha': 0.0003992332142152323, 'batch_size': 163, 'beta_1': 0.8645683335971919, 'beta_2': 0.9229324687748456, 'epsilon': 9.316430115642902e-09, 'hidden_layer_sizes': 144, 'learning_rate_init': 2.122409626850323e-05, 'tol': 0.010046631690499552, 'validation_fraction': 0.8530123119594594}]
function_evaluation time 0.195027 value 7.829199 suggestion {'alpha': 0.0003992332142152323, 'batch_size': 163, 'beta_1': 0.8645683335971919, 'beta_2': 0.9229324687748456, 'epsilon': 9.316430115642902e-09, 'hidden_layer_sizes': 144, 'learning_rate_init': 2.122409626850323e-05, 'tol': 0.010046631690499552, 'validation_fraction': 0.8530123119594594}
observation time 0.000066, current best 0.157830 at iter 8
suggestion time taken 0.002107 iter 9 next_points [{'alpha': 0.4018939693546042, 'batch_size': 102, 'beta_1': 0.8079321973511286, 'beta_2': 0.9761115107647581, 'epsilon': 1.7094580087688232e-09, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0011098482096349917, 'tol': 7.74101559195136e-05, 'validation_fraction': 0.1995411547349189}]
function_evaluation time 1.530984 value 0.134337 suggestion {'alpha': 0.4018939693546042, 'batch_size': 102, 'beta_1': 0.8079321973511286, 'beta_2': 0.9761115107647581, 'epsilon': 1.7094580087688232e-09, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0011098482096349917, 'tol': 7.74101559195136e-05, 'validation_fraction': 0.1995411547349189}
observation time 0.000063, current best 0.134337 at iter 9
suggestion time taken 0.002086 iter 10 next_points [{'alpha': 2.29200974557788, 'batch_size': 204, 'beta_1': 0.5130554644803146, 'beta_2': 0.9568084939137802, 'epsilon': 1.3642022814373868e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.016589966257690245, 'tol': 0.026652838751426097, 'validation_fraction': 0.32020740578695855}]
function_evaluation time 0.452242 value 0.122009 suggestion {'alpha': 2.29200974557788, 'batch_size': 204, 'beta_1': 0.5130554644803146, 'beta_2': 0.9568084939137802, 'epsilon': 1.3642022814373868e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.016589966257690245, 'tol': 0.026652838751426097, 'validation_fraction': 0.32020740578695855}
observation time 0.000063, current best 0.122009 at iter 10
suggestion time taken 0.002162 iter 11 next_points [{'alpha': 3.0841315429777207, 'batch_size': 194, 'beta_1': 0.8411336640930015, 'beta_2': 0.9426710270742811, 'epsilon': 1.3664789586896434e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.07543209281785615, 'tol': 0.020588755429396453, 'validation_fraction': 0.10297013642005756}]
function_evaluation time 0.588125 value 0.264578 suggestion {'alpha': 3.0841315429777207, 'batch_size': 194, 'beta_1': 0.8411336640930015, 'beta_2': 0.9426710270742811, 'epsilon': 1.3664789586896434e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.07543209281785615, 'tol': 0.020588755429396453, 'validation_fraction': 0.10297013642005756}
observation time 0.000062, current best 0.122009 at iter 11
suggestion time taken 0.002078 iter 12 next_points [{'alpha': 0.00038710037441447905, 'batch_size': 108, 'beta_1': 0.8168761052590157, 'beta_2': 0.91649236259703, 'epsilon': 1.1293373200002145e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.007727033554672826, 'tol': 0.0014021861652439693, 'validation_fraction': 0.5196402789685968}]
function_evaluation time 0.731077 value 0.191894 suggestion {'alpha': 0.00038710037441447905, 'batch_size': 108, 'beta_1': 0.8168761052590157, 'beta_2': 0.91649236259703, 'epsilon': 1.1293373200002145e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.007727033554672826, 'tol': 0.0014021861652439693, 'validation_fraction': 0.5196402789685968}
observation time 0.000070, current best 0.122009 at iter 12
suggestion time taken 0.002130 iter 13 next_points [{'alpha': 1.1993797491206993e-05, 'batch_size': 177, 'beta_1': 0.6275253502396206, 'beta_2': 0.9529195299922262, 'epsilon': 8.645546394418834e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 1.0120676474783543e-05, 'tol': 0.09553158138143314, 'validation_fraction': 0.5634708986058925}]
function_evaluation time 0.303107 value 9.381594 suggestion {'alpha': 1.1993797491206993e-05, 'batch_size': 177, 'beta_1': 0.6275253502396206, 'beta_2': 0.9529195299922262, 'epsilon': 8.645546394418834e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 1.0120676474783543e-05, 'tol': 0.09553158138143314, 'validation_fraction': 0.5634708986058925}
observation time 0.000063, current best 0.122009 at iter 13
suggestion time taken 0.002095 iter 14 next_points [{'alpha': 1.5335391437143815e-05, 'batch_size': 114, 'beta_1': 0.6088986419797885, 'beta_2': 0.9996487216555232, 'epsilon': 1.4630080222008497e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.05139922975897189, 'tol': 0.09646381415544222, 'validation_fraction': 0.20733287917442358}]
function_evaluation time 0.506372 value 0.236285 suggestion {'alpha': 1.5335391437143815e-05, 'batch_size': 114, 'beta_1': 0.6088986419797885, 'beta_2': 0.9996487216555232, 'epsilon': 1.4630080222008497e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.05139922975897189, 'tol': 0.09646381415544222, 'validation_fraction': 0.20733287917442358}
observation time 0.000070, current best 0.122009 at iter 14
saving meta data: {'args': {'--uuid': '2f7acc77cb2c50cda2351a623e651eaa', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '107c5732e4f2539fad5c55f221db6979', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u 107c5732e4f2539fad5c55f221db6979 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002493 iter 0 next_points [{'alpha': 7.44699339284902, 'batch_size': 25, 'beta_1': 0.981091547993708, 'beta_2': 0.9999663442119672, 'epsilon': 1.1976363247356534e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.00021474303172902426, 'tol': 0.010598753098046589, 'validation_fraction': 0.708795048537161}]
function_evaluation time 1.072488 value -0.864298 suggestion {'alpha': 7.44699339284902, 'batch_size': 25, 'beta_1': 0.981091547993708, 'beta_2': 0.9999663442119672, 'epsilon': 1.1976363247356534e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.00021474303172902426, 'tol': 0.010598753098046589, 'validation_fraction': 0.708795048537161}
observation time 0.001627, current best -0.864298 at iter 0
suggestion time taken 0.001943 iter 1 next_points [{'alpha': 0.0003099386307457333, 'batch_size': 167, 'beta_1': 0.8346496903611478, 'beta_2': 0.9999962140114452, 'epsilon': 6.92553422769128e-08, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.00012197529116172624, 'tol': 0.01837374970454093, 'validation_fraction': 0.13672605541207827}]
function_evaluation time 1.543615 value -0.856637 suggestion {'alpha': 0.0003099386307457333, 'batch_size': 167, 'beta_1': 0.8346496903611478, 'beta_2': 0.9999962140114452, 'epsilon': 6.92553422769128e-08, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.00012197529116172624, 'tol': 0.01837374970454093, 'validation_fraction': 0.13672605541207827}
observation time 0.001435, current best -0.864298 at iter 1
suggestion time taken 0.001846 iter 2 next_points [{'alpha': 1.6377800072390458, 'batch_size': 144, 'beta_1': 0.9720593393014819, 'beta_2': 0.9246197971498944, 'epsilon': 1.878102952767888e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0037682246023490007, 'tol': 3.321687546477697e-05, 'validation_fraction': 0.26808911110677586}]
function_evaluation time 0.895987 value -0.961041 suggestion {'alpha': 1.6377800072390458, 'batch_size': 144, 'beta_1': 0.9720593393014819, 'beta_2': 0.9246197971498944, 'epsilon': 1.878102952767888e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0037682246023490007, 'tol': 3.321687546477697e-05, 'validation_fraction': 0.26808911110677586}
observation time 0.001410, current best -0.961041 at iter 2
suggestion time taken 0.001848 iter 3 next_points [{'alpha': 0.13444718081093746, 'batch_size': 204, 'beta_1': 0.9861275130194053, 'beta_2': 0.9720419320210428, 'epsilon': 4.973981216085552e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.007924703991327603, 'tol': 6.5933106760071e-05, 'validation_fraction': 0.22320264859194436}]
function_evaluation time 0.713129 value -0.938095 suggestion {'alpha': 0.13444718081093746, 'batch_size': 204, 'beta_1': 0.9861275130194053, 'beta_2': 0.9720419320210428, 'epsilon': 4.973981216085552e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.007924703991327603, 'tol': 6.5933106760071e-05, 'validation_fraction': 0.22320264859194436}
observation time 0.001398, current best -0.961041 at iter 3
suggestion time taken 0.001856 iter 4 next_points [{'alpha': 0.11650582143640648, 'batch_size': 21, 'beta_1': 0.5149276281668811, 'beta_2': 0.9915646988407034, 'epsilon': 5.05983592594122e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 3.3925966373736815e-05, 'tol': 0.0001684144538716278, 'validation_fraction': 0.5028892167789313}]
function_evaluation time 8.871305 value -0.930410 suggestion {'alpha': 0.11650582143640648, 'batch_size': 21, 'beta_1': 0.5149276281668811, 'beta_2': 0.9915646988407034, 'epsilon': 5.05983592594122e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 3.3925966373736815e-05, 'tol': 0.0001684144538716278, 'validation_fraction': 0.5028892167789313}
observation time 0.001385, current best -0.961041 at iter 4
suggestion time taken 0.001805 iter 5 next_points [{'alpha': 0.00011592248365776926, 'batch_size': 153, 'beta_1': 0.5642853903965442, 'beta_2': 0.9999969668990774, 'epsilon': 7.66655891515172e-09, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.031740426825285994, 'tol': 9.620887678511519e-05, 'validation_fraction': 0.8927986712334062}]
function_evaluation time 0.769901 value -0.867100 suggestion {'alpha': 0.00011592248365776926, 'batch_size': 153, 'beta_1': 0.5642853903965442, 'beta_2': 0.9999969668990774, 'epsilon': 7.66655891515172e-09, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.031740426825285994, 'tol': 9.620887678511519e-05, 'validation_fraction': 0.8927986712334062}
observation time 0.001390, current best -0.961041 at iter 5
suggestion time taken 0.001811 iter 6 next_points [{'alpha': 2.542899762514766, 'batch_size': 241, 'beta_1': 0.9349954929934082, 'beta_2': 0.9998506115848169, 'epsilon': 9.205482398721733e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 1.3365920528623306e-05, 'tol': 0.0026620458665624546, 'validation_fraction': 0.6816628997114415}]
function_evaluation time 0.227577 value -0.076512 suggestion {'alpha': 2.542899762514766, 'batch_size': 241, 'beta_1': 0.9349954929934082, 'beta_2': 0.9998506115848169, 'epsilon': 9.205482398721733e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 1.3365920528623306e-05, 'tol': 0.0026620458665624546, 'validation_fraction': 0.6816628997114415}
observation time 0.001431, current best -0.961041 at iter 6
suggestion time taken 0.001825 iter 7 next_points [{'alpha': 0.0013896677294075465, 'batch_size': 128, 'beta_1': 0.9168809288740297, 'beta_2': 0.9850808873477208, 'epsilon': 2.537066434163205e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.09242105779704779, 'tol': 0.028107197982135637, 'validation_fraction': 0.35598003457653254}]
function_evaluation time 0.415969 value -0.461370 suggestion {'alpha': 0.0013896677294075465, 'batch_size': 128, 'beta_1': 0.9168809288740297, 'beta_2': 0.9850808873477208, 'epsilon': 2.537066434163205e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.09242105779704779, 'tol': 0.028107197982135637, 'validation_fraction': 0.35598003457653254}
observation time 0.001400, current best -0.961041 at iter 7
suggestion time taken 0.001900 iter 8 next_points [{'alpha': 0.010774079550843118, 'batch_size': 188, 'beta_1': 0.9336221816800533, 'beta_2': 0.9999925273098722, 'epsilon': 4.204447372028341e-09, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.0010263637595835679, 'tol': 0.07092091706202996, 'validation_fraction': 0.4535283426266756}]
function_evaluation time 0.500260 value -0.919974 suggestion {'alpha': 0.010774079550843118, 'batch_size': 188, 'beta_1': 0.9336221816800533, 'beta_2': 0.9999925273098722, 'epsilon': 4.204447372028341e-09, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.0010263637595835679, 'tol': 0.07092091706202996, 'validation_fraction': 0.4535283426266756}
observation time 0.001575, current best -0.961041 at iter 8
suggestion time taken 0.001903 iter 9 next_points [{'alpha': 0.00217681473939157, 'batch_size': 51, 'beta_1': 0.9792430267051118, 'beta_2': 0.999998679041492, 'epsilon': 4.250402847495366e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.00043555373553256246, 'tol': 0.05760616425118423, 'validation_fraction': 0.10151723599787149}]
function_evaluation time 0.834032 value -0.922087 suggestion {'alpha': 0.00217681473939157, 'batch_size': 51, 'beta_1': 0.9792430267051118, 'beta_2': 0.999998679041492, 'epsilon': 4.250402847495366e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.00043555373553256246, 'tol': 0.05760616425118423, 'validation_fraction': 0.10151723599787149}
observation time 0.001413, current best -0.961041 at iter 9
suggestion time taken 0.001807 iter 10 next_points [{'alpha': 4.1499848005387235e-05, 'batch_size': 104, 'beta_1': 0.8069634767866343, 'beta_2': 0.999921054954521, 'epsilon': 6.282613137930051e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.05499752263842476, 'tol': 0.0003964344330816289, 'validation_fraction': 0.6076596529179322}]
function_evaluation time 0.870847 value -0.897730 suggestion {'alpha': 4.1499848005387235e-05, 'batch_size': 104, 'beta_1': 0.8069634767866343, 'beta_2': 0.999921054954521, 'epsilon': 6.282613137930051e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.05499752263842476, 'tol': 0.0003964344330816289, 'validation_fraction': 0.6076596529179322}
observation time 0.001380, current best -0.961041 at iter 10
suggestion time taken 0.001826 iter 11 next_points [{'alpha': 0.052186130519818706, 'batch_size': 66, 'beta_1': 0.8626659056795611, 'beta_2': 0.9976113194120062, 'epsilon': 1.512696089276058e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.010492310798915256, 'tol': 0.004466569799099615, 'validation_fraction': 0.8040938916716811}]
function_evaluation time 0.447806 value -0.915089 suggestion {'alpha': 0.052186130519818706, 'batch_size': 66, 'beta_1': 0.8626659056795611, 'beta_2': 0.9976113194120062, 'epsilon': 1.512696089276058e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.010492310798915256, 'tol': 0.004466569799099615, 'validation_fraction': 0.8040938916716811}
observation time 0.001460, current best -0.961041 at iter 11
suggestion time taken 0.001788 iter 12 next_points [{'alpha': 6.563814980411419e-05, 'batch_size': 218, 'beta_1': 0.9897487880124205, 'beta_2': 0.9551777424267786, 'epsilon': 7.301798483978225e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.0224837408075284, 'tol': 1.720054270555494e-05, 'validation_fraction': 0.3789254685478423}]
function_evaluation time 0.977098 value -0.918624 suggestion {'alpha': 6.563814980411419e-05, 'batch_size': 218, 'beta_1': 0.9897487880124205, 'beta_2': 0.9551777424267786, 'epsilon': 7.301798483978225e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.0224837408075284, 'tol': 1.720054270555494e-05, 'validation_fraction': 0.3789254685478423}
observation time 0.001494, current best -0.961041 at iter 12
suggestion time taken 0.001794 iter 13 next_points [{'alpha': 0.48233962196058267, 'batch_size': 234, 'beta_1': 0.9498671961796266, 'beta_2': 0.9989457205026334, 'epsilon': 1.3377502740570463e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 2.285791070586704e-05, 'tol': 0.0007830910715724103, 'validation_fraction': 0.7803584716282873}]
function_evaluation time 0.837559 value -0.114145 suggestion {'alpha': 0.48233962196058267, 'batch_size': 234, 'beta_1': 0.9498671961796266, 'beta_2': 0.9989457205026334, 'epsilon': 1.3377502740570463e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 2.285791070586704e-05, 'tol': 0.0007830910715724103, 'validation_fraction': 0.7803584716282873}
observation time 0.001444, current best -0.961041 at iter 13
suggestion time taken 0.001784 iter 14 next_points [{'alpha': 0.004214763467376631, 'batch_size': 179, 'beta_1': 0.6206919676940692, 'beta_2': 0.9999869301268332, 'epsilon': 1.6900068740537154e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 6.319418066306058e-05, 'tol': 0.00020730165012622533, 'validation_fraction': 0.8333885623977625}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.107086 value -0.441255 suggestion {'alpha': 0.004214763467376631, 'batch_size': 179, 'beta_1': 0.6206919676940692, 'beta_2': 0.9999869301268332, 'epsilon': 1.6900068740537154e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 6.319418066306058e-05, 'tol': 0.00020730165012622533, 'validation_fraction': 0.8333885623977625}
observation time 0.001496, current best -0.961041 at iter 14
saving meta data: {'args': {'--uuid': '107c5732e4f2539fad5c55f221db6979', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

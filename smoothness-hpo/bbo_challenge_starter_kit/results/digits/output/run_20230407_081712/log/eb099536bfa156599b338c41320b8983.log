running: {'--uuid': 'eb099536bfa156599b338c41320b8983', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u eb099536bfa156599b338c41320b8983 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study hyperopt MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002225 iter 0 next_points [{'alpha': 0.005920037569388171, 'batch_size': 79, 'beta_1': 0.8480882501211705, 'beta_2': 0.9333740601489898, 'epsilon': 5.3305447915070334e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.04231542964956133, 'tol': 0.005718012205619929, 'validation_fraction': 0.250145594421165}]
function_evaluation time 1.096679 value 0.444907 suggestion {'alpha': 0.005920037569388171, 'batch_size': 79, 'beta_1': 0.8480882501211705, 'beta_2': 0.9333740601489898, 'epsilon': 5.3305447915070334e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.04231542964956133, 'tol': 0.005718012205619929, 'validation_fraction': 0.250145594421165}
observation time 0.000065, current best 0.444907 at iter 0
suggestion time taken 0.002160 iter 1 next_points [{'alpha': 1.7100988644401864, 'batch_size': 249, 'beta_1': 0.8654900313836228, 'beta_2': 0.9519443296867719, 'epsilon': 3.6427201888384732e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 5.350149443351403e-05, 'tol': 0.007551938994842388, 'validation_fraction': 0.3058400993812226}]
function_evaluation time 0.388637 value 6.433168 suggestion {'alpha': 1.7100988644401864, 'batch_size': 249, 'beta_1': 0.8654900313836228, 'beta_2': 0.9519443296867719, 'epsilon': 3.6427201888384732e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 5.350149443351403e-05, 'tol': 0.007551938994842388, 'validation_fraction': 0.3058400993812226}
observation time 0.000069, current best 0.444907 at iter 1
suggestion time taken 0.002140 iter 2 next_points [{'alpha': 0.02198524312595823, 'batch_size': 208, 'beta_1': 0.8710716037912997, 'beta_2': 0.9273664114519232, 'epsilon': 1.137197974934946e-09, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.000875601598168243, 'tol': 0.0002526561199878067, 'validation_fraction': 0.8089597741870141}]
function_evaluation time 1.624667 value 0.265549 suggestion {'alpha': 0.02198524312595823, 'batch_size': 208, 'beta_1': 0.8710716037912997, 'beta_2': 0.9273664114519232, 'epsilon': 1.137197974934946e-09, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.000875601598168243, 'tol': 0.0002526561199878067, 'validation_fraction': 0.8089597741870141}
observation time 0.000067, current best 0.265549 at iter 2
suggestion time taken 0.002156 iter 3 next_points [{'alpha': 0.17942088572426765, 'batch_size': 90, 'beta_1': 0.6832680144955156, 'beta_2': 0.9045683278777217, 'epsilon': 2.556174657333999e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 9.094189782915936e-05, 'tol': 8.435169129602995e-05, 'validation_fraction': 0.8235820094458112}]
function_evaluation time 1.646185 value 5.001048 suggestion {'alpha': 0.17942088572426765, 'batch_size': 90, 'beta_1': 0.6832680144955156, 'beta_2': 0.9045683278777217, 'epsilon': 2.556174657333999e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 9.094189782915936e-05, 'tol': 8.435169129602995e-05, 'validation_fraction': 0.8235820094458112}
observation time 0.000071, current best 0.265549 at iter 3
suggestion time taken 0.002112 iter 4 next_points [{'alpha': 0.04477624340996101, 'batch_size': 48, 'beta_1': 0.960815631327976, 'beta_2': 0.9220049177471169, 'epsilon': 1.49969852548496e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.00044807099903198687, 'tol': 0.0006873141914747331, 'validation_fraction': 0.39623630308831365}]
function_evaluation time 2.015069 value 0.135746 suggestion {'alpha': 0.04477624340996101, 'batch_size': 48, 'beta_1': 0.960815631327976, 'beta_2': 0.9220049177471169, 'epsilon': 1.49969852548496e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.00044807099903198687, 'tol': 0.0006873141914747331, 'validation_fraction': 0.39623630308831365}
observation time 0.000069, current best 0.135746 at iter 4
suggestion time taken 0.002201 iter 5 next_points [{'alpha': 0.12337836271134588, 'batch_size': 135, 'beta_1': 0.508207214216665, 'beta_2': 0.9223925005679979, 'epsilon': 4.068351593094958e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.007184402165913277, 'tol': 0.00730808404512771, 'validation_fraction': 0.1932522527036373}]
function_evaluation time 0.626296 value 0.121336 suggestion {'alpha': 0.12337836271134588, 'batch_size': 135, 'beta_1': 0.508207214216665, 'beta_2': 0.9223925005679979, 'epsilon': 4.068351593094958e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.007184402165913277, 'tol': 0.00730808404512771, 'validation_fraction': 0.1932522527036373}
observation time 0.000071, current best 0.121336 at iter 5
suggestion time taken 0.002164 iter 6 next_points [{'alpha': 0.008653984311257572, 'batch_size': 201, 'beta_1': 0.5423081646312987, 'beta_2': 0.9023745763972708, 'epsilon': 6.426785744697434e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 7.486976228506854e-05, 'tol': 2.1280963547869368e-05, 'validation_fraction': 0.5365902656457051}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.660031 value 3.678851 suggestion {'alpha': 0.008653984311257572, 'batch_size': 201, 'beta_1': 0.5423081646312987, 'beta_2': 0.9023745763972708, 'epsilon': 6.426785744697434e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 7.486976228506854e-05, 'tol': 2.1280963547869368e-05, 'validation_fraction': 0.5365902656457051}
observation time 0.000070, current best 0.121336 at iter 6
suggestion time taken 0.002358 iter 7 next_points [{'alpha': 0.009199900937167582, 'batch_size': 166, 'beta_1': 0.6648948558903229, 'beta_2': 0.9049114927885868, 'epsilon': 2.223900455728131e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.00014952017574353536, 'tol': 0.030944529908066124, 'validation_fraction': 0.6276494745400113}]
function_evaluation time 0.226925 value 4.802656 suggestion {'alpha': 0.009199900937167582, 'batch_size': 166, 'beta_1': 0.6648948558903229, 'beta_2': 0.9049114927885868, 'epsilon': 2.223900455728131e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.00014952017574353536, 'tol': 0.030944529908066124, 'validation_fraction': 0.6276494745400113}
observation time 0.000081, current best 0.121336 at iter 7
suggestion time taken 0.002399 iter 8 next_points [{'alpha': 0.0001295741271029257, 'batch_size': 131, 'beta_1': 0.5304128722933814, 'beta_2': 0.928784674880257, 'epsilon': 8.747609668375081e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 3.509839825210954e-05, 'tol': 0.0005852071561559832, 'validation_fraction': 0.4133979923077462}]
function_evaluation time 5.887110 value 0.264832 suggestion {'alpha': 0.0001295741271029257, 'batch_size': 131, 'beta_1': 0.5304128722933814, 'beta_2': 0.928784674880257, 'epsilon': 8.747609668375081e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 3.509839825210954e-05, 'tol': 0.0005852071561559832, 'validation_fraction': 0.4133979923077462}
observation time 0.000070, current best 0.121336 at iter 8
suggestion time taken 0.002147 iter 9 next_points [{'alpha': 0.04581436172744204, 'batch_size': 153, 'beta_1': 0.623429484683849, 'beta_2': 0.9743223866632048, 'epsilon': 1.261726131057282e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0018952163794975399, 'tol': 0.0025638627948934042, 'validation_fraction': 0.33262876947396264}]
function_evaluation time 1.306149 value 0.141902 suggestion {'alpha': 0.04581436172744204, 'batch_size': 153, 'beta_1': 0.623429484683849, 'beta_2': 0.9743223866632048, 'epsilon': 1.261726131057282e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0018952163794975399, 'tol': 0.0025638627948934042, 'validation_fraction': 0.33262876947396264}
observation time 0.000063, current best 0.121336 at iter 9
suggestion time taken 0.002148 iter 10 next_points [{'alpha': 0.0033584987500335415, 'batch_size': 43, 'beta_1': 0.5107577384298161, 'beta_2': 0.9547370323173465, 'epsilon': 1.576738820076008e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.00894030994263608, 'tol': 2.42255624555716e-05, 'validation_fraction': 0.17674452151602196}]
function_evaluation time 2.055256 value 0.145245 suggestion {'alpha': 0.0033584987500335415, 'batch_size': 43, 'beta_1': 0.5107577384298161, 'beta_2': 0.9547370323173465, 'epsilon': 1.576738820076008e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.00894030994263608, 'tol': 2.42255624555716e-05, 'validation_fraction': 0.17674452151602196}
observation time 0.000067, current best 0.121336 at iter 10
suggestion time taken 0.002163 iter 11 next_points [{'alpha': 0.006051086804747123, 'batch_size': 55, 'beta_1': 0.9208063013197734, 'beta_2': 0.9309161616354324, 'epsilon': 2.427773560588291e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0015410373972290527, 'tol': 0.00010742902356904417, 'validation_fraction': 0.1945413110354803}]
function_evaluation time 1.414172 value 0.108338 suggestion {'alpha': 0.006051086804747123, 'batch_size': 55, 'beta_1': 0.9208063013197734, 'beta_2': 0.9309161616354324, 'epsilon': 2.427773560588291e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0015410373972290527, 'tol': 0.00010742902356904417, 'validation_fraction': 0.1945413110354803}
observation time 0.000070, current best 0.108338 at iter 11
suggestion time taken 0.002166 iter 12 next_points [{'alpha': 0.050934556263084955, 'batch_size': 122, 'beta_1': 0.5103925116386564, 'beta_2': 0.9429927488631645, 'epsilon': 1.0042723401762384e-09, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.015800096689718626, 'tol': 0.0007592270991367057, 'validation_fraction': 0.15617472959743306}]
function_evaluation time 0.923096 value 0.125185 suggestion {'alpha': 0.050934556263084955, 'batch_size': 122, 'beta_1': 0.5103925116386564, 'beta_2': 0.9429927488631645, 'epsilon': 1.0042723401762384e-09, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.015800096689718626, 'tol': 0.0007592270991367057, 'validation_fraction': 0.15617472959743306}
observation time 0.000081, current best 0.108338 at iter 12
suggestion time taken 0.002160 iter 13 next_points [{'alpha': 0.00012265390513658517, 'batch_size': 213, 'beta_1': 0.619169565151789, 'beta_2': 0.9551429895949277, 'epsilon': 6.86762916584092e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 8.906617562047173e-05, 'tol': 0.014562703275251278, 'validation_fraction': 0.1100078066052453}]
function_evaluation time 1.178873 value 5.724735 suggestion {'alpha': 0.00012265390513658517, 'batch_size': 213, 'beta_1': 0.619169565151789, 'beta_2': 0.9551429895949277, 'epsilon': 6.86762916584092e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 8.906617562047173e-05, 'tol': 0.014562703275251278, 'validation_fraction': 0.1100078066052453}
observation time 0.000069, current best 0.108338 at iter 13
suggestion time taken 0.002114 iter 14 next_points [{'alpha': 0.9559306365220637, 'batch_size': 114, 'beta_1': 0.9240693366026765, 'beta_2': 0.9021429852347627, 'epsilon': 1.354514940100465e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 1.2107397810183554e-05, 'tol': 0.00036762570282077267, 'validation_fraction': 0.26808588783059434}]
function_evaluation time 2.710571 value 5.695892 suggestion {'alpha': 0.9559306365220637, 'batch_size': 114, 'beta_1': 0.9240693366026765, 'beta_2': 0.9021429852347627, 'epsilon': 1.354514940100465e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 1.2107397810183554e-05, 'tol': 0.00036762570282077267, 'validation_fraction': 0.26808588783059434}
observation time 0.000072, current best 0.108338 at iter 14
saving meta data: {'args': {'--uuid': 'eb099536bfa156599b338c41320b8983', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

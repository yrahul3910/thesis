running: {'--uuid': 'd90b3b77c6165464a85f753fa763dd12', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u d90b3b77c6165464a85f753fa763dd12 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002224 iter 0 next_points [{'alpha': 0.12522408568269308, 'batch_size': 166, 'beta_1': 0.9869706054092957, 'beta_2': 0.9647110339589738, 'epsilon': 8.235064894290135e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.0006396541798890054, 'tol': 0.0039127160878560715, 'validation_fraction': 0.6988785096426956}]
function_evaluation time 1.019390 value -0.910235 suggestion {'alpha': 0.12522408568269308, 'batch_size': 166, 'beta_1': 0.9869706054092957, 'beta_2': 0.9647110339589738, 'epsilon': 8.235064894290135e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.0006396541798890054, 'tol': 0.0039127160878560715, 'validation_fraction': 0.6988785096426956}
observation time 0.000060, current best -0.910235 at iter 0
suggestion time taken 0.002139 iter 1 next_points [{'alpha': 0.5604011276326769, 'batch_size': 123, 'beta_1': 0.5930808174135654, 'beta_2': 0.9912021096155013, 'epsilon': 9.108534019167031e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 1.3930700266537155e-05, 'tol': 0.0007170138876573352, 'validation_fraction': 0.18971853572638278}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 4.653291 value -0.426270 suggestion {'alpha': 0.5604011276326769, 'batch_size': 123, 'beta_1': 0.5930808174135654, 'beta_2': 0.9912021096155013, 'epsilon': 9.108534019167031e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 1.3930700266537155e-05, 'tol': 0.0007170138876573352, 'validation_fraction': 0.18971853572638278}
observation time 0.000066, current best -0.910235 at iter 1
suggestion time taken 0.002110 iter 2 next_points [{'alpha': 0.00011311377223453261, 'batch_size': 137, 'beta_1': 0.9474634101498924, 'beta_2': 0.9494631755870963, 'epsilon': 1.6873156574647454e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.095622484098227, 'tol': 0.0003761995664796367, 'validation_fraction': 0.1425271342479823}]
function_evaluation time 1.715844 value -0.636844 suggestion {'alpha': 0.00011311377223453261, 'batch_size': 137, 'beta_1': 0.9474634101498924, 'beta_2': 0.9494631755870963, 'epsilon': 1.6873156574647454e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.095622484098227, 'tol': 0.0003761995664796367, 'validation_fraction': 0.1425271342479823}
observation time 0.000062, current best -0.910235 at iter 2
suggestion time taken 0.002256 iter 3 next_points [{'alpha': 1.1518424094296424e-05, 'batch_size': 117, 'beta_1': 0.6642250257879154, 'beta_2': 0.9662623561620279, 'epsilon': 1.2775618687089422e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.0020008435706578686, 'tol': 0.0002462628869302546, 'validation_fraction': 0.1252693002044609}]
function_evaluation time 1.328124 value -0.971467 suggestion {'alpha': 1.1518424094296424e-05, 'batch_size': 117, 'beta_1': 0.6642250257879154, 'beta_2': 0.9662623561620279, 'epsilon': 1.2775618687089422e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.0020008435706578686, 'tol': 0.0002462628869302546, 'validation_fraction': 0.1252693002044609}
observation time 0.000063, current best -0.971467 at iter 3
suggestion time taken 0.002080 iter 4 next_points [{'alpha': 0.00011551815917995333, 'batch_size': 188, 'beta_1': 0.6359255059036225, 'beta_2': 0.909403561491208, 'epsilon': 2.247977457087888e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.7908949847027226e-05, 'tol': 0.0007079336840570122, 'validation_fraction': 0.7610279345818454}]
function_evaluation time 0.616211 value -0.116229 suggestion {'alpha': 0.00011551815917995333, 'batch_size': 188, 'beta_1': 0.6359255059036225, 'beta_2': 0.909403561491208, 'epsilon': 2.247977457087888e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.7908949847027226e-05, 'tol': 0.0007079336840570122, 'validation_fraction': 0.7610279345818454}
observation time 0.000057, current best -0.971467 at iter 4
suggestion time taken 0.002265 iter 5 next_points [{'alpha': 1.0810529492292023, 'batch_size': 105, 'beta_1': 0.6481260475397632, 'beta_2': 0.9832125011656832, 'epsilon': 9.048337879528315e-08, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0008957037376253902, 'tol': 7.590939917116703e-05, 'validation_fraction': 0.43489512764088517}]
function_evaluation time 2.045232 value -0.953383 suggestion {'alpha': 1.0810529492292023, 'batch_size': 105, 'beta_1': 0.6481260475397632, 'beta_2': 0.9832125011656832, 'epsilon': 9.048337879528315e-08, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0008957037376253902, 'tol': 7.590939917116703e-05, 'validation_fraction': 0.43489512764088517}
observation time 0.000057, current best -0.971467 at iter 5
suggestion time taken 0.002114 iter 6 next_points [{'alpha': 4.199051826382045e-05, 'batch_size': 211, 'beta_1': 0.5279856166438998, 'beta_2': 0.923506486075531, 'epsilon': 2.677774979070126e-07, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.014759509656172835, 'tol': 0.04072758146337443, 'validation_fraction': 0.10854084225736277}]
function_evaluation time 0.416533 value -0.972171 suggestion {'alpha': 4.199051826382045e-05, 'batch_size': 211, 'beta_1': 0.5279856166438998, 'beta_2': 0.923506486075531, 'epsilon': 2.677774979070126e-07, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.014759509656172835, 'tol': 0.04072758146337443, 'validation_fraction': 0.10854084225736277}
observation time 0.000058, current best -0.972171 at iter 6
suggestion time taken 0.002126 iter 7 next_points [{'alpha': 8.379983335921958, 'batch_size': 76, 'beta_1': 0.5399647122331197, 'beta_2': 0.9191001974668456, 'epsilon': 7.678366065161249e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 1.0143303645803526e-05, 'tol': 0.004715355605773937, 'validation_fraction': 0.7705296236853417}]
function_evaluation time 0.212220 value -0.112011 suggestion {'alpha': 8.379983335921958, 'batch_size': 76, 'beta_1': 0.5399647122331197, 'beta_2': 0.9191001974668456, 'epsilon': 7.678366065161249e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 1.0143303645803526e-05, 'tol': 0.004715355605773937, 'validation_fraction': 0.7705296236853417}
observation time 0.000064, current best -0.972171 at iter 7
suggestion time taken 0.002117 iter 8 next_points [{'alpha': 0.0010342099612943494, 'batch_size': 108, 'beta_1': 0.8485051848527938, 'beta_2': 0.9662733715717449, 'epsilon': 2.6333539973441217e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.003142917228281279, 'tol': 0.00011139072637643574, 'validation_fraction': 0.3178263759687707}]
function_evaluation time 1.136245 value -0.965892 suggestion {'alpha': 0.0010342099612943494, 'batch_size': 108, 'beta_1': 0.8485051848527938, 'beta_2': 0.9662733715717449, 'epsilon': 2.6333539973441217e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.003142917228281279, 'tol': 0.00011139072637643574, 'validation_fraction': 0.3178263759687707}
observation time 0.000067, current best -0.972171 at iter 8
suggestion time taken 0.002080 iter 9 next_points [{'alpha': 1.343177075885414e-05, 'batch_size': 21, 'beta_1': 0.7344312273256118, 'beta_2': 0.9341002762835063, 'epsilon': 5.039261177798995e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.01041594014005655, 'tol': 0.03830447465480092, 'validation_fraction': 0.33061445573918463}]
function_evaluation time 0.845148 value -0.960327 suggestion {'alpha': 1.343177075885414e-05, 'batch_size': 21, 'beta_1': 0.7344312273256118, 'beta_2': 0.9341002762835063, 'epsilon': 5.039261177798995e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.01041594014005655, 'tol': 0.03830447465480092, 'validation_fraction': 0.33061445573918463}
observation time 0.000057, current best -0.972171 at iter 9
suggestion time taken 0.002102 iter 10 next_points [{'alpha': 0.0006450495006591319, 'batch_size': 91, 'beta_1': 0.583632590424798, 'beta_2': 0.9044911090885468, 'epsilon': 3.0834942892018845e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0002505186916944932, 'tol': 0.051937153085147424, 'validation_fraction': 0.2113814114744432}]
function_evaluation time 0.826085 value -0.920671 suggestion {'alpha': 0.0006450495006591319, 'batch_size': 91, 'beta_1': 0.583632590424798, 'beta_2': 0.9044911090885468, 'epsilon': 3.0834942892018845e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0002505186916944932, 'tol': 0.051937153085147424, 'validation_fraction': 0.2113814114744432}
observation time 0.000060, current best -0.972171 at iter 10
suggestion time taken 0.002096 iter 11 next_points [{'alpha': 6.5559948874323215, 'batch_size': 119, 'beta_1': 0.9374062037127753, 'beta_2': 0.9171902959672176, 'epsilon': 3.0215799825310396e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.004546671477667692, 'tol': 0.004072273707828275, 'validation_fraction': 0.8736426781096651}]
function_evaluation time 0.521590 value -0.895591 suggestion {'alpha': 6.5559948874323215, 'batch_size': 119, 'beta_1': 0.9374062037127753, 'beta_2': 0.9171902959672176, 'epsilon': 3.0215799825310396e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.004546671477667692, 'tol': 0.004072273707828275, 'validation_fraction': 0.8736426781096651}
observation time 0.000056, current best -0.972171 at iter 11
suggestion time taken 0.002250 iter 12 next_points [{'alpha': 1.1990954326277852e-05, 'batch_size': 250, 'beta_1': 0.581166424360093, 'beta_2': 0.9404289450705445, 'epsilon': 2.6593819883550917e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0011570550825009838, 'tol': 0.015747291942876496, 'validation_fraction': 0.37363960192723733}]
function_evaluation time 0.575833 value -0.950600 suggestion {'alpha': 1.1990954326277852e-05, 'batch_size': 250, 'beta_1': 0.581166424360093, 'beta_2': 0.9404289450705445, 'epsilon': 2.6593819883550917e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0011570550825009838, 'tol': 0.015747291942876496, 'validation_fraction': 0.37363960192723733}
observation time 0.000060, current best -0.972171 at iter 12
suggestion time taken 0.002145 iter 13 next_points [{'alpha': 8.316774958386421, 'batch_size': 21, 'beta_1': 0.6582142422857762, 'beta_2': 0.9276353914123822, 'epsilon': 5.755887704243474e-07, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.02285125780622742, 'tol': 0.005480939603951126, 'validation_fraction': 0.2734081609419565}]
function_evaluation time 2.077376 value -0.897696 suggestion {'alpha': 8.316774958386421, 'batch_size': 21, 'beta_1': 0.6582142422857762, 'beta_2': 0.9276353914123822, 'epsilon': 5.755887704243474e-07, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.02285125780622742, 'tol': 0.005480939603951126, 'validation_fraction': 0.2734081609419565}
observation time 0.000058, current best -0.972171 at iter 13
suggestion time taken 0.002114 iter 14 next_points [{'alpha': 7.834577993776535, 'batch_size': 41, 'beta_1': 0.7920782016711784, 'beta_2': 0.9190341103795077, 'epsilon': 1.7857393640966968e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.0026698001701905122, 'tol': 0.05439809160386776, 'validation_fraction': 0.25144218634840676}]
function_evaluation time 0.742299 value -0.949199 suggestion {'alpha': 7.834577993776535, 'batch_size': 41, 'beta_1': 0.7920782016711784, 'beta_2': 0.9190341103795077, 'epsilon': 1.7857393640966968e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.0026698001701905122, 'tol': 0.05439809160386776, 'validation_fraction': 0.25144218634840676}
observation time 0.000059, current best -0.972171 at iter 14
saving meta data: {'args': {'--uuid': 'd90b3b77c6165464a85f753fa763dd12', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '4681dcf04be45d078c09be37bd4c298c', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u 4681dcf04be45d078c09be37bd4c298c -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study smoothness MLP-adam digits nll 15 1
with data root: None
suggestion time taken 11.196064 iter 0 next_points [{'alpha': 0.06974852154742463, 'batch_size': 19, 'beta_1': 0.9201088119194272, 'beta_2': 0.9998992013882424, 'epsilon': 9.009060525452891e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00016214064463163566, 'tol': 0.0020740997025051307, 'validation_fraction': 0.21048300653773516}]
function_evaluation time 5.859714 value 0.132455 suggestion {'alpha': 0.06974852154742463, 'batch_size': 19, 'beta_1': 0.9201088119194272, 'beta_2': 0.9998992013882424, 'epsilon': 9.009060525452891e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00016214064463163566, 'tol': 0.0020740997025051307, 'validation_fraction': 0.21048300653773516}
observation time 0.000004, current best 0.132455 at iter 0
suggestion time taken 11.351543 iter 1 next_points [{'alpha': 5.429913408081033, 'batch_size': 13, 'beta_1': 0.9637691648682669, 'beta_2': 0.9674160307984009, 'epsilon': 7.308639235490699e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.0005621303842656568, 'tol': 0.03433041197220884, 'validation_fraction': 0.5877723240132577}]
function_evaluation time 1.410807 value 0.402114 suggestion {'alpha': 5.429913408081033, 'batch_size': 13, 'beta_1': 0.9637691648682669, 'beta_2': 0.9674160307984009, 'epsilon': 7.308639235490699e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.0005621303842656568, 'tol': 0.03433041197220884, 'validation_fraction': 0.5877723240132577}
observation time 0.000005, current best 0.132455 at iter 1
suggestion time taken 11.202511 iter 2 next_points [{'alpha': 0.04962717649548173, 'batch_size': 13, 'beta_1': 0.873362963093005, 'beta_2': 0.9998827237597318, 'epsilon': 3.330125300712994e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0007540299052935857, 'tol': 5.780716964877655e-05, 'validation_fraction': 0.8866509812200553}]
function_evaluation time 2.976141 value 0.369049 suggestion {'alpha': 0.04962717649548173, 'batch_size': 13, 'beta_1': 0.873362963093005, 'beta_2': 0.9998827237597318, 'epsilon': 3.330125300712994e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0007540299052935857, 'tol': 5.780716964877655e-05, 'validation_fraction': 0.8866509812200553}
observation time 0.000005, current best 0.132455 at iter 2
suggestion time taken 11.492631 iter 3 next_points [{'alpha': 0.050588188373631486, 'batch_size': 15, 'beta_1': 0.7788263715415031, 'beta_2': 0.9930674711891231, 'epsilon': 5.382295846740086e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.007730397715138182, 'tol': 0.003312908186270793, 'validation_fraction': 0.393021912909867}]
function_evaluation time 1.991175 value 0.131216 suggestion {'alpha': 0.050588188373631486, 'batch_size': 15, 'beta_1': 0.7788263715415031, 'beta_2': 0.9930674711891231, 'epsilon': 5.382295846740086e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.007730397715138182, 'tol': 0.003312908186270793, 'validation_fraction': 0.393021912909867}
observation time 0.000005, current best 0.131216 at iter 3
suggestion time taken 11.162121 iter 4 next_points [{'alpha': 2.935361738646318, 'batch_size': 15, 'beta_1': 0.7142329211225661, 'beta_2': 0.9999917156891539, 'epsilon': 3.7111707818481946e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0016289726991258829, 'tol': 0.05890817309850403, 'validation_fraction': 0.837688532310986}]
function_evaluation time 0.466029 value 0.369946 suggestion {'alpha': 2.935361738646318, 'batch_size': 15, 'beta_1': 0.7142329211225661, 'beta_2': 0.9999917156891539, 'epsilon': 3.7111707818481946e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0016289726991258829, 'tol': 0.05890817309850403, 'validation_fraction': 0.837688532310986}
observation time 0.000004, current best 0.131216 at iter 4
suggestion time taken 11.544908 iter 5 next_points [{'alpha': 0.05892444282438796, 'batch_size': 20, 'beta_1': 0.8148727575599689, 'beta_2': 0.9999975706487374, 'epsilon': 2.6116496996864307e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0028731458444111167, 'tol': 0.0002479520040100933, 'validation_fraction': 0.18019813417726166}]
function_evaluation time 2.698137 value 0.115914 suggestion {'alpha': 0.05892444282438796, 'batch_size': 20, 'beta_1': 0.8148727575599689, 'beta_2': 0.9999975706487374, 'epsilon': 2.6116496996864307e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0028731458444111167, 'tol': 0.0002479520040100933, 'validation_fraction': 0.18019813417726166}
observation time 0.000005, current best 0.115914 at iter 5
suggestion time taken 11.178573 iter 6 next_points [{'alpha': 0.03438190910645717, 'batch_size': 10, 'beta_1': 0.9236959070610073, 'beta_2': 0.9999982742173015, 'epsilon': 7.110390230502885e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.026421231206945242, 'tol': 0.04759677700816743, 'validation_fraction': 0.8382315566467228}]
function_evaluation time 0.636425 value 0.500745 suggestion {'alpha': 0.03438190910645717, 'batch_size': 10, 'beta_1': 0.9236959070610073, 'beta_2': 0.9999982742173015, 'epsilon': 7.110390230502885e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.026421231206945242, 'tol': 0.04759677700816743, 'validation_fraction': 0.8382315566467228}
observation time 0.000004, current best 0.115914 at iter 6
suggestion time taken 11.654178 iter 7 next_points [{'alpha': 3.799331007536767, 'batch_size': 10, 'beta_1': 0.6018933066936669, 'beta_2': 0.9096481420439213, 'epsilon': 2.255725167234834e-07, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.010842027329477654, 'tol': 0.00017032314399079143, 'validation_fraction': 0.49069733979565905}]
function_evaluation time 2.183273 value 0.494886 suggestion {'alpha': 3.799331007536767, 'batch_size': 10, 'beta_1': 0.6018933066936669, 'beta_2': 0.9096481420439213, 'epsilon': 2.255725167234834e-07, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.010842027329477654, 'tol': 0.00017032314399079143, 'validation_fraction': 0.49069733979565905}
observation time 0.000004, current best 0.115914 at iter 7
suggestion time taken 11.384776 iter 8 next_points [{'alpha': 0.0006381232588163084, 'batch_size': 10, 'beta_1': 0.5456722141541708, 'beta_2': 0.9758056883801622, 'epsilon': 1.9562666021532633e-09, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.00020152490060922887, 'tol': 8.702040965897345e-05, 'validation_fraction': 0.7026348563046759}]
function_evaluation time 5.668394 value 0.185092 suggestion {'alpha': 0.0006381232588163084, 'batch_size': 10, 'beta_1': 0.5456722141541708, 'beta_2': 0.9758056883801622, 'epsilon': 1.9562666021532633e-09, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.00020152490060922887, 'tol': 8.702040965897345e-05, 'validation_fraction': 0.7026348563046759}
observation time 0.000004, current best 0.115914 at iter 8
suggestion time taken 11.229761 iter 9 next_points [{'alpha': 0.00030777308452485886, 'batch_size': 17, 'beta_1': 0.9364199278083581, 'beta_2': 0.9990014677896785, 'epsilon': 4.692910006888834e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.02418884647644692, 'tol': 0.0044327035803424664, 'validation_fraction': 0.11391779091530559}]
function_evaluation time 1.664083 value 0.333933 suggestion {'alpha': 0.00030777308452485886, 'batch_size': 17, 'beta_1': 0.9364199278083581, 'beta_2': 0.9990014677896785, 'epsilon': 4.692910006888834e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.02418884647644692, 'tol': 0.0044327035803424664, 'validation_fraction': 0.11391779091530559}
observation time 0.000004, current best 0.115914 at iter 9
suggestion time taken 11.615762 iter 10 next_points [{'alpha': 0.004850097036535708, 'batch_size': 42, 'beta_1': 0.688297147961501, 'beta_2': 0.9999615544926435, 'epsilon': 7.342695716853968e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 3.84920375679635e-05, 'tol': 1.8939819291250646e-05, 'validation_fraction': 0.258643794691982}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 8.226445 value 0.370386 suggestion {'alpha': 0.004850097036535708, 'batch_size': 42, 'beta_1': 0.688297147961501, 'beta_2': 0.9999615544926435, 'epsilon': 7.342695716853968e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 3.84920375679635e-05, 'tol': 1.8939819291250646e-05, 'validation_fraction': 0.258643794691982}
observation time 0.000005, current best 0.115914 at iter 10
suggestion time taken 11.465289 iter 11 next_points [{'alpha': 0.006938241977962935, 'batch_size': 14, 'beta_1': 0.9025414455817917, 'beta_2': 0.9999986098203332, 'epsilon': 4.883968981396995e-07, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.04672094545698579, 'tol': 0.003306548886669858, 'validation_fraction': 0.31081106221225513}]
function_evaluation time 2.038703 value 0.634916 suggestion {'alpha': 0.006938241977962935, 'batch_size': 14, 'beta_1': 0.9025414455817917, 'beta_2': 0.9999986098203332, 'epsilon': 4.883968981396995e-07, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.04672094545698579, 'tol': 0.003306548886669858, 'validation_fraction': 0.31081106221225513}
observation time 0.000004, current best 0.115914 at iter 11
suggestion time taken 11.315511 iter 12 next_points [{'alpha': 3.728059034480628e-05, 'batch_size': 22, 'beta_1': 0.6547967284258349, 'beta_2': 0.955929495780407, 'epsilon': 2.75008464072166e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.019111959180096946, 'tol': 0.0007765826328055814, 'validation_fraction': 0.6901748959872969}]
function_evaluation time 1.718396 value 0.405553 suggestion {'alpha': 3.728059034480628e-05, 'batch_size': 22, 'beta_1': 0.6547967284258349, 'beta_2': 0.955929495780407, 'epsilon': 2.75008464072166e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.019111959180096946, 'tol': 0.0007765826328055814, 'validation_fraction': 0.6901748959872969}
observation time 0.000004, current best 0.115914 at iter 12
suggestion time taken 11.815582 iter 13 next_points [{'alpha': 7.044406551566264e-05, 'batch_size': 12, 'beta_1': 0.9676713378334562, 'beta_2': 0.9999985394148351, 'epsilon': 5.857252029116875e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0031625093755360163, 'tol': 0.00013839542566217443, 'validation_fraction': 0.26237866636832746}]
function_evaluation time 2.532398 value 0.118549 suggestion {'alpha': 7.044406551566264e-05, 'batch_size': 12, 'beta_1': 0.9676713378334562, 'beta_2': 0.9999985394148351, 'epsilon': 5.857252029116875e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0031625093755360163, 'tol': 0.00013839542566217443, 'validation_fraction': 0.26237866636832746}
observation time 0.000005, current best 0.115914 at iter 13
suggestion time taken 11.420789 iter 14 next_points [{'alpha': 0.0034769338858986476, 'batch_size': 15, 'beta_1': 0.9789041352038035, 'beta_2': 0.9999691191161635, 'epsilon': 1.2571047141040304e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.013753516697238217, 'tol': 0.0026418031778766395, 'validation_fraction': 0.2398540630567022}]
function_evaluation time 3.092623 value 0.268659 suggestion {'alpha': 0.0034769338858986476, 'batch_size': 15, 'beta_1': 0.9789041352038035, 'beta_2': 0.9999691191161635, 'epsilon': 1.2571047141040304e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.013753516697238217, 'tol': 0.0026418031778766395, 'validation_fraction': 0.2398540630567022}
observation time 0.000005, current best 0.115914 at iter 14
saving meta data: {'args': {'--uuid': '4681dcf04be45d078c09be37bd4c298c', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

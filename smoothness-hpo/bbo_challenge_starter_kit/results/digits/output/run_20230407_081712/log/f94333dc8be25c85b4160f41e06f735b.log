running: {'--uuid': 'f94333dc8be25c85b4160f41e06f735b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'opentuner', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d digits -o opentuner -u f94333dc8be25c85b4160f41e06f735b -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study opentuner MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.016425 iter 0 next_points [{'hidden_layer_sizes': 111, 'alpha': 0.2629630008019345, 'batch_size': 175, 'learning_rate_init': 0.026376347280264435, 'tol': 0.09604511499173467, 'validation_fraction': 0.8066307032617729, 'beta_1': 0.8802228390190385, 'beta_2': 0.9343916070382624, 'epsilon': 3.384397710143029e-07}]
function_evaluation time 0.239157 value -0.876176 suggestion {'hidden_layer_sizes': 111, 'alpha': 0.2629630008019345, 'batch_size': 175, 'learning_rate_init': 0.026376347280264435, 'tol': 0.09604511499173467, 'validation_fraction': 0.8066307032617729, 'beta_1': 0.8802228390190385, 'beta_2': 0.9343916070382624, 'epsilon': 3.384397710143029e-07}
observation time 0.004046, current best -0.876176 at iter 0
suggestion time taken 0.021419 iter 1 next_points [{'beta_1': 0.8599480885399287, 'epsilon': 3.972049239802923e-07, 'alpha': 3.6895326142375144, 'learning_rate_init': 0.08709799167852499, 'tol': 0.002058597148221587, 'validation_fraction': 0.6857643274449536, 'hidden_layer_sizes': 70, 'beta_2': 0.9157849788272833, 'batch_size': 79}]
function_evaluation time 0.650740 value -0.891432 suggestion {'beta_1': 0.8599480885399287, 'epsilon': 3.972049239802923e-07, 'alpha': 3.6895326142375144, 'learning_rate_init': 0.08709799167852499, 'tol': 0.002058597148221587, 'validation_fraction': 0.6857643274449536, 'hidden_layer_sizes': 70, 'beta_2': 0.9157849788272833, 'batch_size': 79}
observation time 0.001772, current best -0.891432 at iter 1
suggestion time taken 0.046028 iter 2 next_points [{'beta_1': 0.5804370918725474, 'epsilon': 8.735790521246779e-07, 'alpha': 3.852697939031293, 'learning_rate_init': 0.0834915780684559, 'tol': 0.08134869287425721, 'validation_fraction': 0.5764670609488386, 'hidden_layer_sizes': 82, 'beta_2': 0.9215504646353258, 'batch_size': 190}]
function_evaluation time 0.284049 value -0.587323 suggestion {'beta_1': 0.5804370918725474, 'epsilon': 8.735790521246779e-07, 'alpha': 3.852697939031293, 'learning_rate_init': 0.0834915780684559, 'tol': 0.08134869287425721, 'validation_fraction': 0.5764670609488386, 'hidden_layer_sizes': 82, 'beta_2': 0.9215504646353258, 'batch_size': 190}
observation time 0.001697, current best -0.891432 at iter 2
suggestion time taken 0.007048 iter 3 next_points [{'beta_1': 0.8599480885399287, 'epsilon': 3.5421929381382235e-07, 'alpha': 4.003385554066167, 'learning_rate_init': 0.08709799167852499, 'tol': 0.002058597148221587, 'validation_fraction': 0.6857643274449536, 'hidden_layer_sizes': 70, 'beta_2': 0.9157849788272833, 'batch_size': 89}]
function_evaluation time 0.512905 value -0.809328 suggestion {'beta_1': 0.8599480885399287, 'epsilon': 3.5421929381382235e-07, 'alpha': 4.003385554066167, 'learning_rate_init': 0.08709799167852499, 'tol': 0.002058597148221587, 'validation_fraction': 0.6857643274449536, 'hidden_layer_sizes': 70, 'beta_2': 0.9157849788272833, 'batch_size': 89}
observation time 0.001829, current best -0.891432 at iter 3
suggestion time taken 0.005937 iter 4 next_points [{'beta_1': 0.9721490844395086, 'epsilon': 6.176687575351513e-08, 'alpha': 3.993272270149156, 'learning_rate_init': 0.011305307046738978, 'tol': 0.05014511943552485, 'validation_fraction': 0.48133092520658305, 'hidden_layer_sizes': 104, 'beta_2': 0.9273345892520166, 'batch_size': 195}]
function_evaluation time 0.322674 value -0.919287 suggestion {'beta_1': 0.9721490844395086, 'epsilon': 6.176687575351513e-08, 'alpha': 3.993272270149156, 'learning_rate_init': 0.011305307046738978, 'tol': 0.05014511943552485, 'validation_fraction': 0.48133092520658305, 'hidden_layer_sizes': 104, 'beta_2': 0.9273345892520166, 'batch_size': 195}
observation time 0.001971, current best -0.919287 at iter 4
suggestion time taken 0.006746 iter 5 next_points [{'beta_1': 0.9721490844395086, 'epsilon': 6.176687575351513e-08, 'alpha': 3.993272270149156, 'learning_rate_init': 0.011305307046738978, 'tol': 0.05014511943552485, 'validation_fraction': 0.7601370395856185, 'hidden_layer_sizes': 104, 'beta_2': 0.9273345892520166, 'batch_size': 19}]
function_evaluation time 0.501155 value -0.910942 suggestion {'beta_1': 0.9721490844395086, 'epsilon': 6.176687575351513e-08, 'alpha': 3.993272270149156, 'learning_rate_init': 0.011305307046738978, 'tol': 0.05014511943552485, 'validation_fraction': 0.7601370395856185, 'hidden_layer_sizes': 104, 'beta_2': 0.9273345892520166, 'batch_size': 19}
observation time 0.001775, current best -0.919287 at iter 5
suggestion time taken 0.005886 iter 6 next_points [{'beta_1': 0.8625867915762648, 'epsilon': 4.857386829709421e-07, 'alpha': 1.1996059006057007, 'learning_rate_init': 0.09229943666695244, 'tol': 0.029483681274059027, 'validation_fraction': 0.5769466693936492, 'hidden_layer_sizes': 131, 'beta_2': 0.9337182125274078, 'batch_size': 70}]
function_evaluation time 0.609920 value -0.922755 suggestion {'beta_1': 0.8625867915762648, 'epsilon': 4.857386829709421e-07, 'alpha': 1.1996059006057007, 'learning_rate_init': 0.09229943666695244, 'tol': 0.029483681274059027, 'validation_fraction': 0.5769466693936492, 'hidden_layer_sizes': 131, 'beta_2': 0.9337182125274078, 'batch_size': 70}
observation time 0.001757, current best -0.922755 at iter 6
suggestion time taken 0.005898 iter 7 next_points [{'beta_1': 0.6230268647999618, 'epsilon': 4.843715419039208e-07, 'alpha': 2.058345656600924, 'learning_rate_init': 0.023731192719288852, 'tol': 0.040992720187344504, 'validation_fraction': 0.20695370448596437, 'hidden_layer_sizes': 157, 'beta_2': 0.9891696972901146, 'batch_size': 21}]
function_evaluation time 1.483387 value -0.909567 suggestion {'beta_1': 0.6230268647999618, 'epsilon': 4.843715419039208e-07, 'alpha': 2.058345656600924, 'learning_rate_init': 0.023731192719288852, 'tol': 0.040992720187344504, 'validation_fraction': 0.20695370448596437, 'hidden_layer_sizes': 157, 'beta_2': 0.9891696972901146, 'batch_size': 21}
observation time 0.001927, current best -0.922755 at iter 7
suggestion time taken 0.005934 iter 8 next_points [{'beta_1': 0.784904876848707, 'epsilon': 2.5708293885426294e-07, 'alpha': 0.5666997690029286, 'learning_rate_init': 0.03887016103021595, 'tol': 0.0398718010172902, 'validation_fraction': 0.7400063350068667, 'hidden_layer_sizes': 78, 'beta_2': 0.9505431891065741, 'batch_size': 239}]
function_evaluation time 0.309140 value -0.896310 suggestion {'beta_1': 0.784904876848707, 'epsilon': 2.5708293885426294e-07, 'alpha': 0.5666997690029286, 'learning_rate_init': 0.03887016103021595, 'tol': 0.0398718010172902, 'validation_fraction': 0.7400063350068667, 'hidden_layer_sizes': 78, 'beta_2': 0.9505431891065741, 'batch_size': 239}
observation time 0.001742, current best -0.922755 at iter 8
suggestion time taken 0.005827 iter 9 next_points [{'beta_1': 0.5037136548495094, 'epsilon': 8.358901787691431e-07, 'alpha': 1.2809007885541956, 'learning_rate_init': 0.08162616702891727, 'tol': 0.05433294461638954, 'validation_fraction': 0.5575672933384042, 'hidden_layer_sizes': 176, 'beta_2': 0.9789189618700687, 'batch_size': 123}]
function_evaluation time 0.366886 value -0.397433 suggestion {'beta_1': 0.5037136548495094, 'epsilon': 8.358901787691431e-07, 'alpha': 1.2809007885541956, 'learning_rate_init': 0.08162616702891727, 'tol': 0.05433294461638954, 'validation_fraction': 0.5575672933384042, 'hidden_layer_sizes': 176, 'beta_2': 0.9789189618700687, 'batch_size': 123}
observation time 0.001906, current best -0.922755 at iter 9
suggestion time taken 0.006832 iter 10 next_points [{'beta_1': 0.8891675638434272, 'epsilon': 5.590493247503426e-07, 'alpha': 1.1996059006057007, 'learning_rate_init': 0.09229943666695244, 'tol': 0.029483681274059027, 'validation_fraction': 0.5769466693936492, 'hidden_layer_sizes': 131, 'beta_2': 0.9337182125274078, 'batch_size': 70}]
function_evaluation time 0.612068 value -0.919290 suggestion {'beta_1': 0.8891675638434272, 'epsilon': 5.590493247503426e-07, 'alpha': 1.1996059006057007, 'learning_rate_init': 0.09229943666695244, 'tol': 0.029483681274059027, 'validation_fraction': 0.5769466693936492, 'hidden_layer_sizes': 131, 'beta_2': 0.9337182125274078, 'batch_size': 70}
observation time 0.001803, current best -0.922755 at iter 10
suggestion time taken 0.005832 iter 11 next_points [{'beta_1': 0.711017805495755, 'epsilon': 1.9277149424010053e-07, 'alpha': 6.191615769903541, 'learning_rate_init': 0.072542099955114, 'tol': 0.009992782062814, 'validation_fraction': 0.3244748482070454, 'hidden_layer_sizes': 103, 'beta_2': 0.9466295068293711, 'batch_size': 176}]
function_evaluation time 0.723196 value -0.835838 suggestion {'beta_1': 0.711017805495755, 'epsilon': 1.9277149424010053e-07, 'alpha': 6.191615769903541, 'learning_rate_init': 0.072542099955114, 'tol': 0.009992782062814, 'validation_fraction': 0.3244748482070454, 'hidden_layer_sizes': 103, 'beta_2': 0.9466295068293711, 'batch_size': 176}
observation time 0.001928, current best -0.922755 at iter 11
suggestion time taken 0.005837 iter 12 next_points [{'beta_1': 0.689917817787154, 'epsilon': 8.333812468180591e-07, 'alpha': 0.4649582959441078, 'learning_rate_init': 0.09771669929464737, 'tol': 0.04480887328018806, 'validation_fraction': 0.28462858007493996, 'hidden_layer_sizes': 186, 'beta_2': 0.9768527621556216, 'batch_size': 26}]
function_evaluation time 1.088585 value -0.362720 suggestion {'beta_1': 0.689917817787154, 'epsilon': 8.333812468180591e-07, 'alpha': 0.4649582959441078, 'learning_rate_init': 0.09771669929464737, 'tol': 0.04480887328018806, 'validation_fraction': 0.28462858007493996, 'hidden_layer_sizes': 186, 'beta_2': 0.9768527621556216, 'batch_size': 26}
observation time 0.001767, current best -0.922755 at iter 12
suggestion time taken 0.006889 iter 13 next_points [{'beta_1': 0.8625867915762648, 'epsilon': 4.857386829709421e-07, 'alpha': 1.1996059006057007, 'learning_rate_init': 0.04328021986421387, 'tol': 0.029483681274059027, 'validation_fraction': 0.5769466693936492, 'hidden_layer_sizes': 131, 'beta_2': 0.9337182125274078, 'batch_size': 137}]
function_evaluation time 0.417103 value -0.937391 suggestion {'beta_1': 0.8625867915762648, 'epsilon': 4.857386829709421e-07, 'alpha': 1.1996059006057007, 'learning_rate_init': 0.04328021986421387, 'tol': 0.029483681274059027, 'validation_fraction': 0.5769466693936492, 'hidden_layer_sizes': 131, 'beta_2': 0.9337182125274078, 'batch_size': 137}
observation time 0.001979, current best -0.937391 at iter 13
suggestion time taken 0.006696 iter 14 next_points [{'beta_1': 0.8625867915762648, 'epsilon': 4.857386829709421e-07, 'alpha': 1.1996059006057007, 'learning_rate_init': 0.04328021986421387, 'tol': 0.029483681274059027, 'validation_fraction': 0.5769466693936492, 'hidden_layer_sizes': 131, 'beta_2': 0.9337182125274078, 'batch_size': 149}]
function_evaluation time 0.480293 value -0.931831 suggestion {'beta_1': 0.8625867915762648, 'epsilon': 4.857386829709421e-07, 'alpha': 1.1996059006057007, 'learning_rate_init': 0.04328021986421387, 'tol': 0.029483681274059027, 'validation_fraction': 0.5769466693936492, 'hidden_layer_sizes': 131, 'beta_2': 0.9337182125274078, 'batch_size': 149}
observation time 0.002058, current best -0.937391 at iter 14
saving meta data: {'args': {'--uuid': 'f94333dc8be25c85b4160f41e06f735b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'opentuner', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

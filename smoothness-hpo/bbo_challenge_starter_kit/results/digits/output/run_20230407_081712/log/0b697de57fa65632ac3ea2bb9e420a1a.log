running: {'--uuid': '0b697de57fa65632ac3ea2bb9e420a1a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 0b697de57fa65632ac3ea2bb9e420a1a -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study hyperopt MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002129 iter 0 next_points [{'alpha': 0.006612093028675671, 'batch_size': 230, 'beta_1': 0.5014263734058186, 'beta_2': 0.9075539845174185, 'epsilon': 1.5016760327345059e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.02708524414721928, 'tol': 6.367919444519036e-05, 'validation_fraction': 0.39681021935230393}]
function_evaluation time 0.824011 value 0.156921 suggestion {'alpha': 0.006612093028675671, 'batch_size': 230, 'beta_1': 0.5014263734058186, 'beta_2': 0.9075539845174185, 'epsilon': 1.5016760327345059e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.02708524414721928, 'tol': 6.367919444519036e-05, 'validation_fraction': 0.39681021935230393}
observation time 0.000061, current best 0.156921 at iter 0
suggestion time taken 0.002105 iter 1 next_points [{'alpha': 0.00020250960913168712, 'batch_size': 232, 'beta_1': 0.6876953066771774, 'beta_2': 0.9571292761245708, 'epsilon': 2.838978335176827e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.009163282209012016, 'tol': 0.0006775908291795124, 'validation_fraction': 0.10569991515795835}]
function_evaluation time 0.727652 value 0.127884 suggestion {'alpha': 0.00020250960913168712, 'batch_size': 232, 'beta_1': 0.6876953066771774, 'beta_2': 0.9571292761245708, 'epsilon': 2.838978335176827e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.009163282209012016, 'tol': 0.0006775908291795124, 'validation_fraction': 0.10569991515795835}
observation time 0.000060, current best 0.127884 at iter 1
suggestion time taken 0.002096 iter 2 next_points [{'alpha': 0.00015334277765995493, 'batch_size': 69, 'beta_1': 0.5898434107747229, 'beta_2': 0.9056615284250302, 'epsilon': 4.991097026276365e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 3.1096092522066745e-05, 'tol': 0.03827413608094069, 'validation_fraction': 0.2513452842478007}]
function_evaluation time 0.448606 value 7.279463 suggestion {'alpha': 0.00015334277765995493, 'batch_size': 69, 'beta_1': 0.5898434107747229, 'beta_2': 0.9056615284250302, 'epsilon': 4.991097026276365e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 3.1096092522066745e-05, 'tol': 0.03827413608094069, 'validation_fraction': 0.2513452842478007}
observation time 0.000056, current best 0.127884 at iter 2
suggestion time taken 0.002060 iter 3 next_points [{'alpha': 0.07917917372009299, 'batch_size': 181, 'beta_1': 0.6158892585150332, 'beta_2': 0.9820703060171169, 'epsilon': 2.95621241613853e-07, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.007447447244940693, 'tol': 0.04702712096212548, 'validation_fraction': 0.10118013984948197}]
function_evaluation time 0.510711 value 0.104597 suggestion {'alpha': 0.07917917372009299, 'batch_size': 181, 'beta_1': 0.6158892585150332, 'beta_2': 0.9820703060171169, 'epsilon': 2.95621241613853e-07, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.007447447244940693, 'tol': 0.04702712096212548, 'validation_fraction': 0.10118013984948197}
observation time 0.000061, current best 0.104597 at iter 3
suggestion time taken 0.002303 iter 4 next_points [{'alpha': 0.4447793244535587, 'batch_size': 168, 'beta_1': 0.5462376438381792, 'beta_2': 0.9924871441061156, 'epsilon': 2.0868018358227278e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0013921665242715895, 'tol': 0.0018731914348670763, 'validation_fraction': 0.2227876209773468}]
function_evaluation time 1.341928 value 0.132866 suggestion {'alpha': 0.4447793244535587, 'batch_size': 168, 'beta_1': 0.5462376438381792, 'beta_2': 0.9924871441061156, 'epsilon': 2.0868018358227278e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0013921665242715895, 'tol': 0.0018731914348670763, 'validation_fraction': 0.2227876209773468}
observation time 0.000066, current best 0.104597 at iter 4
suggestion time taken 0.002090 iter 5 next_points [{'alpha': 0.005144402025023595, 'batch_size': 33, 'beta_1': 0.6760353030165048, 'beta_2': 0.9829962094106295, 'epsilon': 2.6931424815674965e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.00023954850991394613, 'tol': 0.0005736952703242914, 'validation_fraction': 0.4680444863029723}]
function_evaluation time 4.041223 value 0.124881 suggestion {'alpha': 0.005144402025023595, 'batch_size': 33, 'beta_1': 0.6760353030165048, 'beta_2': 0.9829962094106295, 'epsilon': 2.6931424815674965e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.00023954850991394613, 'tol': 0.0005736952703242914, 'validation_fraction': 0.4680444863029723}
observation time 0.000063, current best 0.104597 at iter 5
suggestion time taken 0.002089 iter 6 next_points [{'alpha': 0.0009146948712248744, 'batch_size': 12, 'beta_1': 0.5556043128216737, 'beta_2': 0.9278846697801519, 'epsilon': 1.8916613216831354e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.000979572303284302, 'tol': 0.052395422575623206, 'validation_fraction': 0.11008480267450456}]
function_evaluation time 1.568072 value 0.124116 suggestion {'alpha': 0.0009146948712248744, 'batch_size': 12, 'beta_1': 0.5556043128216737, 'beta_2': 0.9278846697801519, 'epsilon': 1.8916613216831354e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.000979572303284302, 'tol': 0.052395422575623206, 'validation_fraction': 0.11008480267450456}
observation time 0.000062, current best 0.104597 at iter 6
suggestion time taken 0.002138 iter 7 next_points [{'alpha': 0.3215453868197326, 'batch_size': 105, 'beta_1': 0.9755125894061168, 'beta_2': 0.9493038183722301, 'epsilon': 6.283361432251226e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.00016333409591348853, 'tol': 0.013672658954488163, 'validation_fraction': 0.253106921781477}]
function_evaluation time 1.347782 value 0.214632 suggestion {'alpha': 0.3215453868197326, 'batch_size': 105, 'beta_1': 0.9755125894061168, 'beta_2': 0.9493038183722301, 'epsilon': 6.283361432251226e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.00016333409591348853, 'tol': 0.013672658954488163, 'validation_fraction': 0.253106921781477}
observation time 0.000060, current best 0.104597 at iter 7
suggestion time taken 0.002285 iter 8 next_points [{'alpha': 0.001091324036931499, 'batch_size': 15, 'beta_1': 0.5961509523197821, 'beta_2': 0.9463078859067804, 'epsilon': 9.57558937696536e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.004552496645445254, 'tol': 0.0008491896036347074, 'validation_fraction': 0.3904809856886937}]
function_evaluation time 3.232967 value 0.161852 suggestion {'alpha': 0.001091324036931499, 'batch_size': 15, 'beta_1': 0.5961509523197821, 'beta_2': 0.9463078859067804, 'epsilon': 9.57558937696536e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.004552496645445254, 'tol': 0.0008491896036347074, 'validation_fraction': 0.3904809856886937}
observation time 0.000062, current best 0.104597 at iter 8
suggestion time taken 0.002128 iter 9 next_points [{'alpha': 0.008397082562025846, 'batch_size': 140, 'beta_1': 0.7558087475678368, 'beta_2': 0.9068602679309236, 'epsilon': 5.309505566284667e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 5.151814717210136e-05, 'tol': 0.05120427359953161, 'validation_fraction': 0.19334483084966408}]
function_evaluation time 0.482555 value 3.570755 suggestion {'alpha': 0.008397082562025846, 'batch_size': 140, 'beta_1': 0.7558087475678368, 'beta_2': 0.9068602679309236, 'epsilon': 5.309505566284667e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 5.151814717210136e-05, 'tol': 0.05120427359953161, 'validation_fraction': 0.19334483084966408}
observation time 0.000068, current best 0.104597 at iter 9
suggestion time taken 0.002109 iter 10 next_points [{'alpha': 4.8513385473454935e-05, 'batch_size': 219, 'beta_1': 0.6276895386254053, 'beta_2': 0.9068854543880052, 'epsilon': 1.2789804366281036e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0050486918905516135, 'tol': 0.0015464549248866417, 'validation_fraction': 0.295078732035332}]
function_evaluation time 1.049273 value 0.110291 suggestion {'alpha': 4.8513385473454935e-05, 'batch_size': 219, 'beta_1': 0.6276895386254053, 'beta_2': 0.9068854543880052, 'epsilon': 1.2789804366281036e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0050486918905516135, 'tol': 0.0015464549248866417, 'validation_fraction': 0.295078732035332}
observation time 0.000064, current best 0.104597 at iter 10
suggestion time taken 0.002116 iter 11 next_points [{'alpha': 8.600134090635276, 'batch_size': 117, 'beta_1': 0.5665853853696847, 'beta_2': 0.9221988604085299, 'epsilon': 5.885237996266732e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.0004152508914974648, 'tol': 0.0007287407139906036, 'validation_fraction': 0.7952680657964453}]
function_evaluation time 2.212096 value 0.822515 suggestion {'alpha': 8.600134090635276, 'batch_size': 117, 'beta_1': 0.5665853853696847, 'beta_2': 0.9221988604085299, 'epsilon': 5.885237996266732e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.0004152508914974648, 'tol': 0.0007287407139906036, 'validation_fraction': 0.7952680657964453}
observation time 0.000065, current best 0.104597 at iter 11
suggestion time taken 0.002105 iter 12 next_points [{'alpha': 9.910852157320926, 'batch_size': 75, 'beta_1': 0.5492884310740254, 'beta_2': 0.9888029527918911, 'epsilon': 3.7276062021358545e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0011197647804829839, 'tol': 0.004712431481231606, 'validation_fraction': 0.10576462425465001}]
function_evaluation time 0.983106 value 0.224846 suggestion {'alpha': 9.910852157320926, 'batch_size': 75, 'beta_1': 0.5492884310740254, 'beta_2': 0.9888029527918911, 'epsilon': 3.7276062021358545e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0011197647804829839, 'tol': 0.004712431481231606, 'validation_fraction': 0.10576462425465001}
observation time 0.000063, current best 0.104597 at iter 12
suggestion time taken 0.002120 iter 13 next_points [{'alpha': 0.009872705077343103, 'batch_size': 91, 'beta_1': 0.7249831833756946, 'beta_2': 0.9700361015253659, 'epsilon': 6.476175115836333e-07, 'hidden_layer_sizes': 153, 'learning_rate_init': 1.2258872290172153e-05, 'tol': 0.0008183962380172255, 'validation_fraction': 0.3913295531719669}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 5.029238 value 3.952491 suggestion {'alpha': 0.009872705077343103, 'batch_size': 91, 'beta_1': 0.7249831833756946, 'beta_2': 0.9700361015253659, 'epsilon': 6.476175115836333e-07, 'hidden_layer_sizes': 153, 'learning_rate_init': 1.2258872290172153e-05, 'tol': 0.0008183962380172255, 'validation_fraction': 0.3913295531719669}
observation time 0.000064, current best 0.104597 at iter 13
suggestion time taken 0.002107 iter 14 next_points [{'alpha': 5.388312861172668, 'batch_size': 106, 'beta_1': 0.7241076559445004, 'beta_2': 0.9728223005572774, 'epsilon': 9.728059205214844e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.08024898353730832, 'tol': 0.0007726362930101101, 'validation_fraction': 0.27250553427567575}]
function_evaluation time 0.679403 value 1.661388 suggestion {'alpha': 5.388312861172668, 'batch_size': 106, 'beta_1': 0.7241076559445004, 'beta_2': 0.9728223005572774, 'epsilon': 9.728059205214844e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.08024898353730832, 'tol': 0.0007726362930101101, 'validation_fraction': 0.27250553427567575}
observation time 0.000065, current best 0.104597 at iter 14
saving meta data: {'args': {'--uuid': '0b697de57fa65632ac3ea2bb9e420a1a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': 'a35d3974f55c5753a4aaecedb08efa3a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u a35d3974f55c5753a4aaecedb08efa3a -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002426 iter 0 next_points [{'alpha': 1.422627603609403, 'batch_size': 235, 'beta_1': 0.9689184462240387, 'beta_2': 0.9910460626720359, 'epsilon': 7.350109340908727e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 7.692811969875558e-05, 'tol': 0.03275113686523986, 'validation_fraction': 0.6656589550414629}]
function_evaluation time 0.211175 value -0.130766 suggestion {'alpha': 1.422627603609403, 'batch_size': 235, 'beta_1': 0.9689184462240387, 'beta_2': 0.9910460626720359, 'epsilon': 7.350109340908727e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 7.692811969875558e-05, 'tol': 0.03275113686523986, 'validation_fraction': 0.6656589550414629}
observation time 0.001411, current best -0.130766 at iter 0
suggestion time taken 0.001774 iter 1 next_points [{'alpha': 0.0035505613868413236, 'batch_size': 50, 'beta_1': 0.7096902721152117, 'beta_2': 0.9999948660400849, 'epsilon': 1.1341721627721684e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.03944524591383359, 'tol': 4.890723146449504e-05, 'validation_fraction': 0.7496543061350249}]
function_evaluation time 1.016636 value -0.919280 suggestion {'alpha': 0.0035505613868413236, 'batch_size': 50, 'beta_1': 0.7096902721152117, 'beta_2': 0.9999948660400849, 'epsilon': 1.1341721627721684e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.03944524591383359, 'tol': 4.890723146449504e-05, 'validation_fraction': 0.7496543061350249}
observation time 0.001376, current best -0.919280 at iter 1
suggestion time taken 0.001755 iter 2 next_points [{'alpha': 0.0012413194329479996, 'batch_size': 114, 'beta_1': 0.7526959972642876, 'beta_2': 0.9999982594419046, 'epsilon': 1.8695080011553813e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 2.6296503143036376e-05, 'tol': 0.00040795018365258296, 'validation_fraction': 0.41076441100281974}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.013205 value -0.370112 suggestion {'alpha': 0.0012413194329479996, 'batch_size': 114, 'beta_1': 0.7526959972642876, 'beta_2': 0.9999982594419046, 'epsilon': 1.8695080011553813e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 2.6296503143036376e-05, 'tol': 0.00040795018365258296, 'validation_fraction': 0.41076441100281974}
observation time 0.001358, current best -0.919280 at iter 2
suggestion time taken 0.001863 iter 3 next_points [{'alpha': 2.7550459033674982e-05, 'batch_size': 183, 'beta_1': 0.8211456817060769, 'beta_2': 0.9969309053453463, 'epsilon': 4.4682541568555573e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 1.5293253599953097e-05, 'tol': 0.0002677160973001609, 'validation_fraction': 0.7372162791710892}]
function_evaluation time 0.842013 value -0.121806 suggestion {'alpha': 2.7550459033674982e-05, 'batch_size': 183, 'beta_1': 0.8211456817060769, 'beta_2': 0.9969309053453463, 'epsilon': 4.4682541568555573e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 1.5293253599953097e-05, 'tol': 0.0002677160973001609, 'validation_fraction': 0.7372162791710892}
observation time 0.001357, current best -0.919280 at iter 3
suggestion time taken 0.001708 iter 4 next_points [{'alpha': 0.0027551501387538266, 'batch_size': 28, 'beta_1': 0.9662695355373507, 'beta_2': 0.9995427633638776, 'epsilon': 3.130620340197726e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 3.2215944367130905e-05, 'tol': 0.006502667518587828, 'validation_fraction': 0.824393436122356}]
function_evaluation time 0.368019 value -0.132218 suggestion {'alpha': 0.0027551501387538266, 'batch_size': 28, 'beta_1': 0.9662695355373507, 'beta_2': 0.9995427633638776, 'epsilon': 3.130620340197726e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 3.2215944367130905e-05, 'tol': 0.006502667518587828, 'validation_fraction': 0.824393436122356}
observation time 0.001390, current best -0.919280 at iter 4
suggestion time taken 0.001732 iter 5 next_points [{'alpha': 0.0002579738943642521, 'batch_size': 191, 'beta_1': 0.9375374700018516, 'beta_2': 0.999997359909849, 'epsilon': 3.262689861156995e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.004349080540512948, 'tol': 0.013903660848394835, 'validation_fraction': 0.43301399822711345}]
function_evaluation time 0.624064 value -0.952003 suggestion {'alpha': 0.0002579738943642521, 'batch_size': 191, 'beta_1': 0.9375374700018516, 'beta_2': 0.999997359909849, 'epsilon': 3.262689861156995e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.004349080540512948, 'tol': 0.013903660848394835, 'validation_fraction': 0.43301399822711345}
observation time 0.001327, current best -0.952003 at iter 5
suggestion time taken 0.001755 iter 6 next_points [{'alpha': 0.8529255939142881, 'batch_size': 45, 'beta_1': 0.9142646343195651, 'beta_2': 0.9999708568341825, 'epsilon': 1.7747081047455976e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.008582870726063027, 'tol': 0.03805615828246384, 'validation_fraction': 0.13088063711365397}]
function_evaluation time 0.464245 value -0.958955 suggestion {'alpha': 0.8529255939142881, 'batch_size': 45, 'beta_1': 0.9142646343195651, 'beta_2': 0.9999708568341825, 'epsilon': 1.7747081047455976e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.008582870726063027, 'tol': 0.03805615828246384, 'validation_fraction': 0.13088063711365397}
observation time 0.001564, current best -0.958955 at iter 6
suggestion time taken 0.001827 iter 7 next_points [{'alpha': 0.00017678591001858734, 'batch_size': 166, 'beta_1': 0.8603987983068817, 'beta_2': 0.9998258019688164, 'epsilon': 1.036273958866186e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.002308657798136908, 'tol': 3.725360652774602e-05, 'validation_fraction': 0.5841884770317074}]
function_evaluation time 1.213812 value -0.940858 suggestion {'alpha': 0.00017678591001858734, 'batch_size': 166, 'beta_1': 0.8603987983068817, 'beta_2': 0.9998258019688164, 'epsilon': 1.036273958866186e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.002308657798136908, 'tol': 3.725360652774602e-05, 'validation_fraction': 0.5841884770317074}
observation time 0.001363, current best -0.958955 at iter 7
suggestion time taken 0.001736 iter 8 next_points [{'alpha': 0.032159087950735986, 'batch_size': 95, 'beta_1': 0.66368562315611, 'beta_2': 0.9995624060755703, 'epsilon': 4.653748503814802e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.021359742284583275, 'tol': 8.470956927826897e-05, 'validation_fraction': 0.8737186701720023}]
function_evaluation time 0.653105 value -0.889366 suggestion {'alpha': 0.032159087950735986, 'batch_size': 95, 'beta_1': 0.66368562315611, 'beta_2': 0.9995624060755703, 'epsilon': 4.653748503814802e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.021359742284583275, 'tol': 8.470956927826897e-05, 'validation_fraction': 0.8737186701720023}
observation time 0.001365, current best -0.958955 at iter 8
suggestion time taken 0.001677 iter 9 next_points [{'alpha': 0.024182722204325113, 'batch_size': 75, 'beta_1': 0.7740878543612218, 'beta_2': 0.9740057674207806, 'epsilon': 4.132352255686244e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.0010395228878381005, 'tol': 0.06930697009746695, 'validation_fraction': 0.2982375134102526}]
function_evaluation time 0.678593 value -0.953368 suggestion {'alpha': 0.024182722204325113, 'batch_size': 75, 'beta_1': 0.7740878543612218, 'beta_2': 0.9740057674207806, 'epsilon': 4.132352255686244e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.0010395228878381005, 'tol': 0.06930697009746695, 'validation_fraction': 0.2982375134102526}
observation time 0.001313, current best -0.958955 at iter 9
suggestion time taken 0.001757 iter 10 next_points [{'alpha': 0.0004895836959862011, 'batch_size': 219, 'beta_1': 0.5555223064291521, 'beta_2': 0.9976270159506747, 'epsilon': 1.910473572214545e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.000266872420590252, 'tol': 0.021260524593409966, 'validation_fraction': 0.20826685824157562}]
function_evaluation time 0.907940 value -0.837831 suggestion {'alpha': 0.0004895836959862011, 'batch_size': 219, 'beta_1': 0.5555223064291521, 'beta_2': 0.9976270159506747, 'epsilon': 1.910473572214545e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.000266872420590252, 'tol': 0.021260524593409966, 'validation_fraction': 0.20826685824157562}
observation time 0.001376, current best -0.958955 at iter 10
suggestion time taken 0.001699 iter 11 next_points [{'alpha': 0.21109374209144124, 'batch_size': 64, 'beta_1': 0.9227079912980716, 'beta_2': 0.9529215032103946, 'epsilon': 5.388054853772509e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.0006205002852330625, 'tol': 0.0015810677683533345, 'validation_fraction': 0.33200627124566295}]
function_evaluation time 2.174893 value -0.966601 suggestion {'alpha': 0.21109374209144124, 'batch_size': 64, 'beta_1': 0.9227079912980716, 'beta_2': 0.9529215032103946, 'epsilon': 5.388054853772509e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.0006205002852330625, 'tol': 0.0015810677683533345, 'validation_fraction': 0.33200627124566295}
observation time 0.001384, current best -0.966601 at iter 11
suggestion time taken 0.001755 iter 12 next_points [{'alpha': 0.2638897090052771, 'batch_size': 136, 'beta_1': 0.894958257001881, 'beta_2': 0.9989622393245483, 'epsilon': 2.1567946970035566e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.0003363948242536148, 'tol': 0.003405817456409274, 'validation_fraction': 0.17662563701158476}]
function_evaluation time 2.121809 value -0.931107 suggestion {'alpha': 0.2638897090052771, 'batch_size': 136, 'beta_1': 0.894958257001881, 'beta_2': 0.9989622393245483, 'epsilon': 2.1567946970035566e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.0003363948242536148, 'tol': 0.003405817456409274, 'validation_fraction': 0.17662563701158476}
observation time 0.001329, current best -0.966601 at iter 12
suggestion time taken 0.001749 iter 13 next_points [{'alpha': 5.767024103991404, 'batch_size': 20, 'beta_1': 0.98733532018253, 'beta_2': 0.9999927737550719, 'epsilon': 1.4426031658652883e-09, 'hidden_layer_sizes': 183, 'learning_rate_init': 4.943735142160658e-05, 'tol': 0.00291131232415301, 'validation_fraction': 0.8789868601936672}]
function_evaluation time 2.837966 value -0.789842 suggestion {'alpha': 5.767024103991404, 'batch_size': 20, 'beta_1': 0.98733532018253, 'beta_2': 0.9999927737550719, 'epsilon': 1.4426031658652883e-09, 'hidden_layer_sizes': 183, 'learning_rate_init': 4.943735142160658e-05, 'tol': 0.00291131232415301, 'validation_fraction': 0.8789868601936672}
observation time 0.001327, current best -0.966601 at iter 13
suggestion time taken 0.001748 iter 14 next_points [{'alpha': 0.009654685773000932, 'batch_size': 137, 'beta_1': 0.949646802769957, 'beta_2': 0.9210252579412193, 'epsilon': 7.057745050302049e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0016575068704060684, 'tol': 0.00017741328244738462, 'validation_fraction': 0.23218542309255116}]
function_evaluation time 1.423822 value -0.963115 suggestion {'alpha': 0.009654685773000932, 'batch_size': 137, 'beta_1': 0.949646802769957, 'beta_2': 0.9210252579412193, 'epsilon': 7.057745050302049e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0016575068704060684, 'tol': 0.00017741328244738462, 'validation_fraction': 0.23218542309255116}
observation time 0.001355, current best -0.966601 at iter 14
saving meta data: {'args': {'--uuid': 'a35d3974f55c5753a4aaecedb08efa3a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': 'd16bae123a495ccdbcfaed95d91ae200', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u d16bae123a495ccdbcfaed95d91ae200 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study turbo MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002106 iter 0 next_points [{'alpha': 1.0830059693004068, 'batch_size': 96, 'beta_1': 0.675096038153675, 'beta_2': 0.9997166649914451, 'epsilon': 3.794835098010047e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.001664444704939426, 'tol': 0.00011573666820698717, 'validation_fraction': 0.8735961245490539}]
function_evaluation time 1.857169 value 0.411301 suggestion {'alpha': 1.0830059693004068, 'batch_size': 96, 'beta_1': 0.675096038153675, 'beta_2': 0.9997166649914451, 'epsilon': 3.794835098010047e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.001664444704939426, 'tol': 0.00011573666820698717, 'validation_fraction': 0.8735961245490539}
observation time 0.001375, current best 0.411301 at iter 0
suggestion time taken 0.001929 iter 1 next_points [{'alpha': 0.00011073977857981799, 'batch_size': 160, 'beta_1': 0.9821464478500059, 'beta_2': 0.9604130999108161, 'epsilon': 6.020008142352166e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.0001553850412800563, 'tol': 0.001985645872200385, 'validation_fraction': 0.6096635689734305}]
function_evaluation time 2.234809 value 0.223934 suggestion {'alpha': 0.00011073977857981799, 'batch_size': 160, 'beta_1': 0.9821464478500059, 'beta_2': 0.9604130999108161, 'epsilon': 6.020008142352166e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.0001553850412800563, 'tol': 0.001985645872200385, 'validation_fraction': 0.6096635689734305}
observation time 0.001387, current best 0.223934 at iter 1
suggestion time taken 0.001792 iter 2 next_points [{'alpha': 0.006728187344034672, 'batch_size': 140, 'beta_1': 0.9846230003218384, 'beta_2': 0.9999913987790884, 'epsilon': 2.358526833586768e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.00023275449726030688, 'tol': 0.0002901227048988287, 'validation_fraction': 0.37588444427617757}]
function_evaluation time 2.485823 value 0.298096 suggestion {'alpha': 0.006728187344034672, 'batch_size': 140, 'beta_1': 0.9846230003218384, 'beta_2': 0.9999913987790884, 'epsilon': 2.358526833586768e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.00023275449726030688, 'tol': 0.0002901227048988287, 'validation_fraction': 0.37588444427617757}
observation time 0.001420, current best 0.223934 at iter 2
suggestion time taken 0.001990 iter 3 next_points [{'alpha': 0.3726997796767206, 'batch_size': 102, 'beta_1': 0.5008376841196742, 'beta_2': 0.998615258479163, 'epsilon': 1.5711052479496433e-09, 'hidden_layer_sizes': 53, 'learning_rate_init': 1.7452054612853876e-05, 'tol': 6.893515748237083e-05, 'validation_fraction': 0.11578410116303567}]
function_evaluation time 0.608313 value 8.812781 suggestion {'alpha': 0.3726997796767206, 'batch_size': 102, 'beta_1': 0.5008376841196742, 'beta_2': 0.998615258479163, 'epsilon': 1.5711052479496433e-09, 'hidden_layer_sizes': 53, 'learning_rate_init': 1.7452054612853876e-05, 'tol': 6.893515748237083e-05, 'validation_fraction': 0.11578410116303567}
observation time 0.001358, current best 0.223934 at iter 3
suggestion time taken 0.001771 iter 4 next_points [{'alpha': 3.214385781293853, 'batch_size': 162, 'beta_1': 0.9880691407940827, 'beta_2': 0.9992329591804308, 'epsilon': 5.191557529258625e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.03473281821213179, 'tol': 0.000977797554224649, 'validation_fraction': 0.25242760748100335}]
function_evaluation time 0.838017 value 0.208302 suggestion {'alpha': 3.214385781293853, 'batch_size': 162, 'beta_1': 0.9880691407940827, 'beta_2': 0.9992329591804308, 'epsilon': 5.191557529258625e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.03473281821213179, 'tol': 0.000977797554224649, 'validation_fraction': 0.25242760748100335}
observation time 0.001356, current best 0.208302 at iter 4
suggestion time taken 0.001719 iter 5 next_points [{'alpha': 0.0072834808212577035, 'batch_size': 42, 'beta_1': 0.911050169008344, 'beta_2': 0.999980043785467, 'epsilon': 1.3336941057756804e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.001219532345563189, 'tol': 0.00033338115454399105, 'validation_fraction': 0.1770284968689906}]
function_evaluation time 2.088798 value 0.124363 suggestion {'alpha': 0.0072834808212577035, 'batch_size': 42, 'beta_1': 0.911050169008344, 'beta_2': 0.999980043785467, 'epsilon': 1.3336941057756804e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.001219532345563189, 'tol': 0.00033338115454399105, 'validation_fraction': 0.1770284968689906}
observation time 0.001343, current best 0.124363 at iter 5
suggestion time taken 0.001710 iter 6 next_points [{'alpha': 0.07031175840143299, 'batch_size': 201, 'beta_1': 0.9372544556554995, 'beta_2': 0.9999954810310725, 'epsilon': 9.538752736322635e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.016020740952003124, 'tol': 0.01654266429604941, 'validation_fraction': 0.7051154261323246}]
function_evaluation time 0.387148 value 0.277540 suggestion {'alpha': 0.07031175840143299, 'batch_size': 201, 'beta_1': 0.9372544556554995, 'beta_2': 0.9999954810310725, 'epsilon': 9.538752736322635e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.016020740952003124, 'tol': 0.01654266429604941, 'validation_fraction': 0.7051154261323246}
observation time 0.001620, current best 0.124363 at iter 6
suggestion time taken 0.001747 iter 7 next_points [{'alpha': 0.024817163665430023, 'batch_size': 246, 'beta_1': 0.8595768045169047, 'beta_2': 0.9997822888771896, 'epsilon': 4.331981606305852e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0001020796196223845, 'tol': 0.0027240032402639086, 'validation_fraction': 0.32833347057711476}]
function_evaluation time 2.272900 value 2.234773 suggestion {'alpha': 0.024817163665430023, 'batch_size': 246, 'beta_1': 0.8595768045169047, 'beta_2': 0.9997822888771896, 'epsilon': 4.331981606305852e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0001020796196223845, 'tol': 0.0027240032402639086, 'validation_fraction': 0.32833347057711476}
observation time 0.001321, current best 0.124363 at iter 7
suggestion time taken 0.001722 iter 8 next_points [{'alpha': 3.842422613064485e-05, 'batch_size': 130, 'beta_1': 0.9542692500690976, 'beta_2': 0.9999984592016464, 'epsilon': 4.7267595846594955e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 1.1293170627019206e-05, 'tol': 8.779286377504706e-05, 'validation_fraction': 0.4938870577601878}]
function_evaluation time 0.767537 value 10.564527 suggestion {'alpha': 3.842422613064485e-05, 'batch_size': 130, 'beta_1': 0.9542692500690976, 'beta_2': 0.9999984592016464, 'epsilon': 4.7267595846594955e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 1.1293170627019206e-05, 'tol': 8.779286377504706e-05, 'validation_fraction': 0.4938870577601878}
observation time 0.001345, current best 0.124363 at iter 8
suggestion time taken 0.001954 iter 9 next_points [{'alpha': 4.8122095090315855e-05, 'batch_size': 230, 'beta_1': 0.9672054209431201, 'beta_2': 0.9968124701358623, 'epsilon': 1.0890754712440844e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.01029622944177285, 'tol': 1.5992604198039946e-05, 'validation_fraction': 0.8863444047244893}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.445040 value 0.655637 suggestion {'alpha': 4.8122095090315855e-05, 'batch_size': 230, 'beta_1': 0.9672054209431201, 'beta_2': 0.9968124701358623, 'epsilon': 1.0890754712440844e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.01029622944177285, 'tol': 1.5992604198039946e-05, 'validation_fraction': 0.8863444047244893}
observation time 0.001343, current best 0.124363 at iter 9
suggestion time taken 0.001699 iter 10 next_points [{'alpha': 0.0022443655934008357, 'batch_size': 218, 'beta_1': 0.9790079428965647, 'beta_2': 0.9999977495381813, 'epsilon': 2.648399398433787e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.04104793559899635, 'tol': 0.005498867595792487, 'validation_fraction': 0.8478730189377935}]
function_evaluation time 0.419880 value 1.278510 suggestion {'alpha': 0.0022443655934008357, 'batch_size': 218, 'beta_1': 0.9790079428965647, 'beta_2': 0.9999977495381813, 'epsilon': 2.648399398433787e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.04104793559899635, 'tol': 0.005498867595792487, 'validation_fraction': 0.8478730189377935}
observation time 0.001375, current best 0.124363 at iter 10
suggestion time taken 0.001701 iter 11 next_points [{'alpha': 0.0005637230401580915, 'batch_size': 26, 'beta_1': 0.8180742579332264, 'beta_2': 0.993135712575411, 'epsilon': 2.582428171176877e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.06166631572448681, 'tol': 0.08006272038806526, 'validation_fraction': 0.5375457629424842}]
function_evaluation time 0.897263 value 0.793902 suggestion {'alpha': 0.0005637230401580915, 'batch_size': 26, 'beta_1': 0.8180742579332264, 'beta_2': 0.993135712575411, 'epsilon': 2.582428171176877e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.06166631572448681, 'tol': 0.08006272038806526, 'validation_fraction': 0.5375457629424842}
observation time 0.001354, current best 0.124363 at iter 11
suggestion time taken 0.001701 iter 12 next_points [{'alpha': 8.84868552525511, 'batch_size': 117, 'beta_1': 0.8032319571892942, 'beta_2': 0.9999338868089774, 'epsilon': 1.7134952564031004e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.0006016599711026143, 'tol': 3.407725856371912e-05, 'validation_fraction': 0.8089868268200743}]
function_evaluation time 2.186686 value 0.346899 suggestion {'alpha': 8.84868552525511, 'batch_size': 117, 'beta_1': 0.8032319571892942, 'beta_2': 0.9999338868089774, 'epsilon': 1.7134952564031004e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.0006016599711026143, 'tol': 3.407725856371912e-05, 'validation_fraction': 0.8089868268200743}
observation time 0.001321, current best 0.124363 at iter 12
suggestion time taken 0.001994 iter 13 next_points [{'alpha': 0.0002536850542257019, 'batch_size': 54, 'beta_1': 0.9282383654228652, 'beta_2': 0.9999726013884885, 'epsilon': 6.410622608611979e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.00036935411616239607, 'tol': 0.014190634081178318, 'validation_fraction': 0.7757533993616772}]
function_evaluation time 0.645588 value 0.503343 suggestion {'alpha': 0.0002536850542257019, 'batch_size': 54, 'beta_1': 0.9282383654228652, 'beta_2': 0.9999726013884885, 'epsilon': 6.410622608611979e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.00036935411616239607, 'tol': 0.014190634081178318, 'validation_fraction': 0.7757533993616772}
observation time 0.001287, current best 0.124363 at iter 13
suggestion time taken 0.001705 iter 14 next_points [{'alpha': 0.0009319556206376225, 'batch_size': 83, 'beta_1': 0.8762866215019182, 'beta_2': 0.9784759272632687, 'epsilon': 1.0638105804952096e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.004108667644544165, 'tol': 0.005175420601641308, 'validation_fraction': 0.1923637760762306}]
function_evaluation time 1.035874 value 0.110617 suggestion {'alpha': 0.0009319556206376225, 'batch_size': 83, 'beta_1': 0.8762866215019182, 'beta_2': 0.9784759272632687, 'epsilon': 1.0638105804952096e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.004108667644544165, 'tol': 0.005175420601641308, 'validation_fraction': 0.1923637760762306}
observation time 0.001278, current best 0.110617 at iter 14
saving meta data: {'args': {'--uuid': 'd16bae123a495ccdbcfaed95d91ae200', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

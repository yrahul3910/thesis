running: {'--uuid': 'cb9617aea12f5c559658286440d9dd9e', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u cb9617aea12f5c559658286440d9dd9e -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002241 iter 0 next_points [{'alpha': 1.2767966189599422, 'batch_size': 200, 'beta_1': 0.9706884099270569, 'beta_2': 0.9983413975563866, 'epsilon': 4.1908955357558386e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.00042062512941167836, 'tol': 0.0014954237162675581, 'validation_fraction': 0.7461437694122357}]
function_evaluation time 1.378069 value -0.894229 suggestion {'alpha': 1.2767966189599422, 'batch_size': 200, 'beta_1': 0.9706884099270569, 'beta_2': 0.9983413975563866, 'epsilon': 4.1908955357558386e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.00042062512941167836, 'tol': 0.0014954237162675581, 'validation_fraction': 0.7461437694122357}
observation time 0.001422, current best -0.894229 at iter 0
suggestion time taken 0.001764 iter 1 next_points [{'alpha': 0.002299090119416756, 'batch_size': 61, 'beta_1': 0.751624441308095, 'beta_2': 0.9999971323180306, 'epsilon': 3.4497995698959225e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.07297165516656512, 'tol': 0.0008456388928683668, 'validation_fraction': 0.8651224346447681}]
function_evaluation time 0.688870 value -0.701316 suggestion {'alpha': 0.002299090119416756, 'batch_size': 61, 'beta_1': 0.751624441308095, 'beta_2': 0.9999971323180306, 'epsilon': 3.4497995698959225e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.07297165516656512, 'tol': 0.0008456388928683668, 'validation_fraction': 0.8651224346447681}
observation time 0.001400, current best -0.894229 at iter 1
suggestion time taken 0.001780 iter 2 next_points [{'alpha': 0.013288867050505747, 'batch_size': 119, 'beta_1': 0.9875849425792191, 'beta_2': 0.9200812051559875, 'epsilon': 9.043017641503541e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 5.372978237986948e-05, 'tol': 8.793476867045407e-05, 'validation_fraction': 0.10176359813944094}]
function_evaluation time 1.616165 value -0.566991 suggestion {'alpha': 0.013288867050505747, 'batch_size': 119, 'beta_1': 0.9875849425792191, 'beta_2': 0.9200812051559875, 'epsilon': 9.043017641503541e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 5.372978237986948e-05, 'tol': 8.793476867045407e-05, 'validation_fraction': 0.10176359813944094}
observation time 0.001392, current best -0.894229 at iter 2
suggestion time taken 0.002040 iter 3 next_points [{'alpha': 0.00029473577710278286, 'batch_size': 90, 'beta_1': 0.9827173016100064, 'beta_2': 0.9929819976786727, 'epsilon': 4.393659862815297e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.030581645103892927, 'tol': 0.00024736193560420764, 'validation_fraction': 0.7913108921595831}]
function_evaluation time 0.748041 value -0.881722 suggestion {'alpha': 0.00029473577710278286, 'batch_size': 90, 'beta_1': 0.9827173016100064, 'beta_2': 0.9929819976786727, 'epsilon': 4.393659862815297e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.030581645103892927, 'tol': 0.00024736193560420764, 'validation_fraction': 0.7913108921595831}
observation time 0.001358, current best -0.894229 at iter 3
suggestion time taken 0.001749 iter 4 next_points [{'alpha': 0.2385446801527293, 'batch_size': 190, 'beta_1': 0.6046781144050888, 'beta_2': 0.9844666903749465, 'epsilon': 3.103231707368137e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 7.649264333666817e-05, 'tol': 0.0001778226576011997, 'validation_fraction': 0.826441609429765}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.681705 value -0.619587 suggestion {'alpha': 0.2385446801527293, 'batch_size': 190, 'beta_1': 0.6046781144050888, 'beta_2': 0.9844666903749465, 'epsilon': 3.103231707368137e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 7.649264333666817e-05, 'tol': 0.0001778226576011997, 'validation_fraction': 0.826441609429765}
observation time 0.001368, current best -0.894229 at iter 4
suggestion time taken 0.001969 iter 5 next_points [{'alpha': 0.03126172224913555, 'batch_size': 181, 'beta_1': 0.9558902331729716, 'beta_2': 0.9999142931723252, 'epsilon': 1.7947320667030665e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.0006558841850272996, 'tol': 0.008080039984936123, 'validation_fraction': 0.28846421526111815}]
function_evaluation time 0.825848 value -0.910934 suggestion {'alpha': 0.03126172224913555, 'batch_size': 181, 'beta_1': 0.9558902331729716, 'beta_2': 0.9999142931723252, 'epsilon': 1.7947320667030665e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.0006558841850272996, 'tol': 0.008080039984936123, 'validation_fraction': 0.28846421526111815}
observation time 0.001410, current best -0.910934 at iter 5
suggestion time taken 0.001748 iter 6 next_points [{'alpha': 0.00040557878992201937, 'batch_size': 55, 'beta_1': 0.788901373200462, 'beta_2': 0.9999915097490846, 'epsilon': 8.223268024015728e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0002619781487173875, 'tol': 0.0007421807905285348, 'validation_fraction': 0.7011053559711589}]
function_evaluation time 3.220191 value -0.890762 suggestion {'alpha': 0.00040557878992201937, 'batch_size': 55, 'beta_1': 0.788901373200462, 'beta_2': 0.9999915097490846, 'epsilon': 8.223268024015728e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0002619781487173875, 'tol': 0.0007421807905285348, 'validation_fraction': 0.7011053559711589}
observation time 0.001394, current best -0.910934 at iter 6
suggestion time taken 0.001770 iter 7 next_points [{'alpha': 0.000171756472712105, 'batch_size': 25, 'beta_1': 0.8384945175118664, 'beta_2': 0.9997821978482632, 'epsilon': 9.538440431184597e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 3.512839617437648e-05, 'tol': 1.2957998548054206e-05, 'validation_fraction': 0.8830711208557744}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 4.325065 value -0.650259 suggestion {'alpha': 0.000171756472712105, 'batch_size': 25, 'beta_1': 0.8384945175118664, 'beta_2': 0.9997821978482632, 'epsilon': 9.538440431184597e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 3.512839617437648e-05, 'tol': 1.2957998548054206e-05, 'validation_fraction': 0.8830711208557744}
observation time 0.001317, current best -0.910934 at iter 7
suggestion time taken 0.001764 iter 8 next_points [{'alpha': 4.042616843200014, 'batch_size': 151, 'beta_1': 0.9198531200619258, 'beta_2': 0.9964335893581814, 'epsilon': 2.463012171812551e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.02011346285533952, 'tol': 0.011445405434289888, 'validation_fraction': 0.3705507369724388}]
function_evaluation time 0.523579 value -0.958938 suggestion {'alpha': 4.042616843200014, 'batch_size': 151, 'beta_1': 0.9198531200619258, 'beta_2': 0.9964335893581814, 'epsilon': 2.463012171812551e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.02011346285533952, 'tol': 0.011445405434289888, 'validation_fraction': 0.3705507369724388}
observation time 0.001379, current best -0.958938 at iter 8
suggestion time taken 0.002025 iter 9 next_points [{'alpha': 1.2747359196322282e-05, 'batch_size': 102, 'beta_1': 0.8972043304623394, 'beta_2': 0.966276126556862, 'epsilon': 7.863352258020616e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 1.3977470334697431e-05, 'tol': 0.002323666658443554, 'validation_fraction': 0.26012077538198625}]
function_evaluation time 2.822655 value -0.380570 suggestion {'alpha': 1.2747359196322282e-05, 'batch_size': 102, 'beta_1': 0.8972043304623394, 'beta_2': 0.966276126556862, 'epsilon': 7.863352258020616e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 1.3977470334697431e-05, 'tol': 0.002323666658443554, 'validation_fraction': 0.26012077538198625}
observation time 0.001319, current best -0.958938 at iter 9
suggestion time taken 0.001757 iter 10 next_points [{'alpha': 6.715176521352863e-05, 'batch_size': 228, 'beta_1': 0.9455689392594138, 'beta_2': 0.9999787833580678, 'epsilon': 1.2472341944747736e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.003539989584019416, 'tol': 0.039823962107612035, 'validation_fraction': 0.14846140748304235}]
function_evaluation time 0.505613 value -0.951999 suggestion {'alpha': 6.715176521352863e-05, 'batch_size': 228, 'beta_1': 0.9455689392594138, 'beta_2': 0.9999787833580678, 'epsilon': 1.2472341944747736e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.003539989584019416, 'tol': 0.039823962107612035, 'validation_fraction': 0.14846140748304235}
observation time 0.001365, current best -0.958938 at iter 10
suggestion time taken 0.001744 iter 11 next_points [{'alpha': 6.430438637625826, 'batch_size': 44, 'beta_1': 0.5219669205921713, 'beta_2': 0.9997194205352083, 'epsilon': 5.714327674923357e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.006624211115631584, 'tol': 4.977780441417127e-05, 'validation_fraction': 0.6730979971330345}]
function_evaluation time 0.722929 value -0.945724 suggestion {'alpha': 6.430438637625826, 'batch_size': 44, 'beta_1': 0.5219669205921713, 'beta_2': 0.9997194205352083, 'epsilon': 5.714327674923357e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.006624211115631584, 'tol': 4.977780441417127e-05, 'validation_fraction': 0.6730979971330345}
observation time 0.001384, current best -0.958938 at iter 11
suggestion time taken 0.001703 iter 12 next_points [{'alpha': 0.5230598402167921, 'batch_size': 147, 'beta_1': 0.9626851448146095, 'beta_2': 0.9999476764167634, 'epsilon': 2.994158509810011e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.0015633175491095686, 'tol': 0.0003567201861224893, 'validation_fraction': 0.5506003023577521}]
function_evaluation time 1.073872 value -0.944328 suggestion {'alpha': 0.5230598402167921, 'batch_size': 147, 'beta_1': 0.9626851448146095, 'beta_2': 0.9999476764167634, 'epsilon': 2.994158509810011e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.0015633175491095686, 'tol': 0.0003567201861224893, 'validation_fraction': 0.5506003023577521}
observation time 0.001348, current best -0.958938 at iter 12
suggestion time taken 0.001734 iter 13 next_points [{'alpha': 0.01457573125036863, 'batch_size': 222, 'beta_1': 0.9094749204479682, 'beta_2': 0.9999982407360234, 'epsilon': 1.662592092365594e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0519810942547395, 'tol': 0.004059448721484731, 'validation_fraction': 0.4178352395515223}]
function_evaluation time 0.768772 value -0.763424 suggestion {'alpha': 0.01457573125036863, 'batch_size': 222, 'beta_1': 0.9094749204479682, 'beta_2': 0.9999982407360234, 'epsilon': 1.662592092365594e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0519810942547395, 'tol': 0.004059448721484731, 'validation_fraction': 0.4178352395515223}
observation time 0.001369, current best -0.958938 at iter 13
suggestion time taken 0.001727 iter 14 next_points [{'alpha': 0.0008663386516285537, 'batch_size': 129, 'beta_1': 0.6491060524673107, 'beta_2': 0.9999774100805461, 'epsilon': 2.1251915225691144e-07, 'hidden_layer_sizes': 111, 'learning_rate_init': 2.0459764909072166e-05, 'tol': 3.4091130320403336e-05, 'validation_fraction': 0.6043490293598188}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.642018 value -0.184533 suggestion {'alpha': 0.0008663386516285537, 'batch_size': 129, 'beta_1': 0.6491060524673107, 'beta_2': 0.9999774100805461, 'epsilon': 2.1251915225691144e-07, 'hidden_layer_sizes': 111, 'learning_rate_init': 2.0459764909072166e-05, 'tol': 3.4091130320403336e-05, 'validation_fraction': 0.6043490293598188}
observation time 0.001321, current best -0.958938 at iter 14
saving meta data: {'args': {'--uuid': 'cb9617aea12f5c559658286440d9dd9e', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

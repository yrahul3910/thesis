running: {'--uuid': 'e8450a3da7505571b834829f94758596', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u e8450a3da7505571b834829f94758596 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002312 iter 0 next_points [{'alpha': 0.7272004669792115, 'batch_size': 227, 'beta_1': 0.939125654039461, 'beta_2': 0.9380274501135422, 'epsilon': 1.145347405174154e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 1.3124575627519913e-05, 'tol': 0.03435029954722182, 'validation_fraction': 0.5765203810296813}]
function_evaluation time 0.254485 value -0.119026 suggestion {'alpha': 0.7272004669792115, 'batch_size': 227, 'beta_1': 0.939125654039461, 'beta_2': 0.9380274501135422, 'epsilon': 1.145347405174154e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 1.3124575627519913e-05, 'tol': 0.03435029954722182, 'validation_fraction': 0.5765203810296813}
observation time 0.000065, current best -0.119026 at iter 0
suggestion time taken 0.002096 iter 1 next_points [{'alpha': 5.728028467923364e-05, 'batch_size': 167, 'beta_1': 0.7132851538277261, 'beta_2': 0.956539314170525, 'epsilon': 6.23630744620962e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 2.1124160929522942e-05, 'tol': 0.0015145654771523207, 'validation_fraction': 0.11278470301829614}]
function_evaluation time 2.828049 value -0.410325 suggestion {'alpha': 5.728028467923364e-05, 'batch_size': 167, 'beta_1': 0.7132851538277261, 'beta_2': 0.956539314170525, 'epsilon': 6.23630744620962e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 2.1124160929522942e-05, 'tol': 0.0015145654771523207, 'validation_fraction': 0.11278470301829614}
observation time 0.000056, current best -0.410325 at iter 1
suggestion time taken 0.002047 iter 2 next_points [{'alpha': 1.2238943258809214e-05, 'batch_size': 49, 'beta_1': 0.6318730236896506, 'beta_2': 0.9341646445729744, 'epsilon': 1.1414766479046287e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.0005660308244320924, 'tol': 0.0013617159647055313, 'validation_fraction': 0.7173326003237747}]
function_evaluation time 1.507796 value -0.940166 suggestion {'alpha': 1.2238943258809214e-05, 'batch_size': 49, 'beta_1': 0.6318730236896506, 'beta_2': 0.9341646445729744, 'epsilon': 1.1414766479046287e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.0005660308244320924, 'tol': 0.0013617159647055313, 'validation_fraction': 0.7173326003237747}
observation time 0.000073, current best -0.940166 at iter 2
suggestion time taken 0.002153 iter 3 next_points [{'alpha': 1.223349381180521, 'batch_size': 125, 'beta_1': 0.6843850001269152, 'beta_2': 0.9004705361784076, 'epsilon': 1.744617753391373e-08, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.0002509765682997505, 'tol': 0.002057024998373561, 'validation_fraction': 0.6620392304168674}]
function_evaluation time 1.996309 value -0.927633 suggestion {'alpha': 1.223349381180521, 'batch_size': 125, 'beta_1': 0.6843850001269152, 'beta_2': 0.9004705361784076, 'epsilon': 1.744617753391373e-08, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.0002509765682997505, 'tol': 0.002057024998373561, 'validation_fraction': 0.6620392304168674}
observation time 0.000071, current best -0.940166 at iter 3
suggestion time taken 0.002122 iter 4 next_points [{'alpha': 0.0007199432990650611, 'batch_size': 98, 'beta_1': 0.50600304333007, 'beta_2': 0.900132859270879, 'epsilon': 1.0364356893550243e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.000987413022951663, 'tol': 0.0015395394025167842, 'validation_fraction': 0.25211999394971807}]
function_evaluation time 1.221491 value -0.962435 suggestion {'alpha': 0.0007199432990650611, 'batch_size': 98, 'beta_1': 0.50600304333007, 'beta_2': 0.900132859270879, 'epsilon': 1.0364356893550243e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.000987413022951663, 'tol': 0.0015395394025167842, 'validation_fraction': 0.25211999394971807}
observation time 0.000072, current best -0.962435 at iter 4
suggestion time taken 0.002116 iter 5 next_points [{'alpha': 0.0002875813867713322, 'batch_size': 207, 'beta_1': 0.7489691834329392, 'beta_2': 0.9486107691843388, 'epsilon': 1.562467907757493e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.00618163008635328, 'tol': 6.805841188557238e-05, 'validation_fraction': 0.2661940902128698}]
function_evaluation time 1.013459 value -0.960354 suggestion {'alpha': 0.0002875813867713322, 'batch_size': 207, 'beta_1': 0.7489691834329392, 'beta_2': 0.9486107691843388, 'epsilon': 1.562467907757493e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.00618163008635328, 'tol': 6.805841188557238e-05, 'validation_fraction': 0.2661940902128698}
observation time 0.000060, current best -0.962435 at iter 5
suggestion time taken 0.002103 iter 6 next_points [{'alpha': 0.048329424850401155, 'batch_size': 78, 'beta_1': 0.8013699106447194, 'beta_2': 0.9353897275069221, 'epsilon': 7.62730958241798e-08, 'hidden_layer_sizes': 178, 'learning_rate_init': 5.559992029221139e-05, 'tol': 0.0015138007167715118, 'validation_fraction': 0.12684223811745357}]
function_evaluation time 4.234657 value -0.942255 suggestion {'alpha': 0.048329424850401155, 'batch_size': 78, 'beta_1': 0.8013699106447194, 'beta_2': 0.9353897275069221, 'epsilon': 7.62730958241798e-08, 'hidden_layer_sizes': 178, 'learning_rate_init': 5.559992029221139e-05, 'tol': 0.0015138007167715118, 'validation_fraction': 0.12684223811745357}
observation time 0.000073, current best -0.962435 at iter 6
suggestion time taken 0.002336 iter 7 next_points [{'alpha': 0.6180646663867644, 'batch_size': 232, 'beta_1': 0.5510394172864813, 'beta_2': 0.9049333764418026, 'epsilon': 1.9885289421439667e-09, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0005849848145349902, 'tol': 0.0017945287046768528, 'validation_fraction': 0.7389272762255064}]
function_evaluation time 1.384350 value -0.931110 suggestion {'alpha': 0.6180646663867644, 'batch_size': 232, 'beta_1': 0.5510394172864813, 'beta_2': 0.9049333764418026, 'epsilon': 1.9885289421439667e-09, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0005849848145349902, 'tol': 0.0017945287046768528, 'validation_fraction': 0.7389272762255064}
observation time 0.000057, current best -0.962435 at iter 7
suggestion time taken 0.002098 iter 8 next_points [{'alpha': 0.0005747813586402981, 'batch_size': 55, 'beta_1': 0.8689407812533051, 'beta_2': 0.9050603146764992, 'epsilon': 3.3215085456629753e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.0001809418941050096, 'tol': 0.012168975469808945, 'validation_fraction': 0.24818480410511742}]
function_evaluation time 1.480557 value -0.945020 suggestion {'alpha': 0.0005747813586402981, 'batch_size': 55, 'beta_1': 0.8689407812533051, 'beta_2': 0.9050603146764992, 'epsilon': 3.3215085456629753e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.0001809418941050096, 'tol': 0.012168975469808945, 'validation_fraction': 0.24818480410511742}
observation time 0.000070, current best -0.962435 at iter 8
suggestion time taken 0.002114 iter 9 next_points [{'alpha': 0.04535041176598294, 'batch_size': 94, 'beta_1': 0.7376808992135715, 'beta_2': 0.9709245277899976, 'epsilon': 3.9852580798011627e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 2.496003762567015e-05, 'tol': 0.00040891850215611474, 'validation_fraction': 0.6136445630104937}]
function_evaluation time 3.878899 value -0.729784 suggestion {'alpha': 0.04535041176598294, 'batch_size': 94, 'beta_1': 0.7376808992135715, 'beta_2': 0.9709245277899976, 'epsilon': 3.9852580798011627e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 2.496003762567015e-05, 'tol': 0.00040891850215611474, 'validation_fraction': 0.6136445630104937}
observation time 0.000059, current best -0.962435 at iter 9
suggestion time taken 0.002067 iter 10 next_points [{'alpha': 8.441922548646044, 'batch_size': 18, 'beta_1': 0.7048649649396129, 'beta_2': 0.9728546033194737, 'epsilon': 4.190364542457736e-08, 'hidden_layer_sizes': 149, 'learning_rate_init': 5.8999061803437384e-05, 'tol': 0.003929563861961678, 'validation_fraction': 0.14602243485287347}]
function_evaluation time 5.843804 value -0.944340 suggestion {'alpha': 8.441922548646044, 'batch_size': 18, 'beta_1': 0.7048649649396129, 'beta_2': 0.9728546033194737, 'epsilon': 4.190364542457736e-08, 'hidden_layer_sizes': 149, 'learning_rate_init': 5.8999061803437384e-05, 'tol': 0.003929563861961678, 'validation_fraction': 0.14602243485287347}
observation time 0.000062, current best -0.962435 at iter 10
suggestion time taken 0.002311 iter 11 next_points [{'alpha': 0.001835231276290996, 'batch_size': 184, 'beta_1': 0.5925343819566397, 'beta_2': 0.9261211863084293, 'epsilon': 5.874025363396161e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.0010061394072987653, 'tol': 0.00045192619808187, 'validation_fraction': 0.16744975694798042}]
function_evaluation time 1.151711 value -0.963115 suggestion {'alpha': 0.001835231276290996, 'batch_size': 184, 'beta_1': 0.5925343819566397, 'beta_2': 0.9261211863084293, 'epsilon': 5.874025363396161e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.0010061394072987653, 'tol': 0.00045192619808187, 'validation_fraction': 0.16744975694798042}
observation time 0.000059, current best -0.963115 at iter 11
suggestion time taken 0.002094 iter 12 next_points [{'alpha': 0.11606712889006474, 'batch_size': 213, 'beta_1': 0.5408577842927088, 'beta_2': 0.9255179935238461, 'epsilon': 8.255035311230618e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0001544279632109459, 'tol': 0.0067679848188940215, 'validation_fraction': 0.6968037524958024}]
function_evaluation time 1.023711 value -0.520603 suggestion {'alpha': 0.11606712889006474, 'batch_size': 213, 'beta_1': 0.5408577842927088, 'beta_2': 0.9255179935238461, 'epsilon': 8.255035311230618e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0001544279632109459, 'tol': 0.0067679848188940215, 'validation_fraction': 0.6968037524958024}
observation time 0.000072, current best -0.963115 at iter 12
suggestion time taken 0.002075 iter 13 next_points [{'alpha': 0.002155391785237333, 'batch_size': 173, 'beta_1': 0.93126737402313, 'beta_2': 0.9092187594480166, 'epsilon': 1.049991014652503e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.09248059066034439, 'tol': 6.453188022332759e-05, 'validation_fraction': 0.271510387494933}]
function_evaluation time 1.283336 value -0.796600 suggestion {'alpha': 0.002155391785237333, 'batch_size': 173, 'beta_1': 0.93126737402313, 'beta_2': 0.9092187594480166, 'epsilon': 1.049991014652503e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.09248059066034439, 'tol': 6.453188022332759e-05, 'validation_fraction': 0.271510387494933}
observation time 0.000059, current best -0.963115 at iter 13
suggestion time taken 0.002067 iter 14 next_points [{'alpha': 0.00019725355599816693, 'batch_size': 213, 'beta_1': 0.862373984423718, 'beta_2': 0.9432407821043962, 'epsilon': 2.7335604340352278e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0016147311861800082, 'tol': 0.00022807016979543637, 'validation_fraction': 0.10584357164287801}]
function_evaluation time 1.175161 value -0.962440 suggestion {'alpha': 0.00019725355599816693, 'batch_size': 213, 'beta_1': 0.862373984423718, 'beta_2': 0.9432407821043962, 'epsilon': 2.7335604340352278e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0016147311861800082, 'tol': 0.00022807016979543637, 'validation_fraction': 0.10584357164287801}
observation time 0.000059, current best -0.963115 at iter 14
saving meta data: {'args': {'--uuid': 'e8450a3da7505571b834829f94758596', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': 'ee1435eba017571b85725896df37d937', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u ee1435eba017571b85725896df37d937 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230407_081712
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study turbo MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002587 iter 0 next_points [{'alpha': 6.956060700319539e-05, 'batch_size': 17, 'beta_1': 0.608544017116422, 'beta_2': 0.9999085873603213, 'epsilon': 2.1578044295401085e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.003645225719871585, 'tol': 0.00016582622397602438, 'validation_fraction': 0.532912315257096}]
function_evaluation time 1.863853 value 0.168393 suggestion {'alpha': 6.956060700319539e-05, 'batch_size': 17, 'beta_1': 0.608544017116422, 'beta_2': 0.9999085873603213, 'epsilon': 2.1578044295401085e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.003645225719871585, 'tol': 0.00016582622397602438, 'validation_fraction': 0.532912315257096}
observation time 0.001434, current best 0.168393 at iter 0
suggestion time taken 0.001779 iter 1 next_points [{'alpha': 0.012374181819369525, 'batch_size': 198, 'beta_1': 0.9622652293645457, 'beta_2': 0.999998392412067, 'epsilon': 4.0557064223077995e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.00013193838409856798, 'tol': 0.0014177264389628943, 'validation_fraction': 0.7992724529904328}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.766470 value 5.588375 suggestion {'alpha': 0.012374181819369525, 'batch_size': 198, 'beta_1': 0.9622652293645457, 'beta_2': 0.999998392412067, 'epsilon': 4.0557064223077995e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.00013193838409856798, 'tol': 0.0014177264389628943, 'validation_fraction': 0.7992724529904328}
observation time 0.001387, current best 0.168393 at iter 1
suggestion time taken 0.002295 iter 2 next_points [{'alpha': 1.1004006897630135e-05, 'batch_size': 73, 'beta_1': 0.9821761558444628, 'beta_2': 0.9985872261005381, 'epsilon': 4.137172636011908e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 3.830524156390473e-05, 'tol': 0.022548844887001866, 'validation_fraction': 0.517501112945684}]
function_evaluation time 0.306761 value 9.083685 suggestion {'alpha': 1.1004006897630135e-05, 'batch_size': 73, 'beta_1': 0.9821761558444628, 'beta_2': 0.9985872261005381, 'epsilon': 4.137172636011908e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 3.830524156390473e-05, 'tol': 0.022548844887001866, 'validation_fraction': 0.517501112945684}
observation time 0.001427, current best 0.168393 at iter 2
suggestion time taken 0.001782 iter 3 next_points [{'alpha': 2.3694037640647286e-05, 'batch_size': 132, 'beta_1': 0.9890682177495551, 'beta_2': 0.9999970483844794, 'epsilon': 6.41464660171394e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0003437636699628435, 'tol': 0.0915136686119524, 'validation_fraction': 0.2757889733575329}]
function_evaluation time 0.561800 value 0.845803 suggestion {'alpha': 2.3694037640647286e-05, 'batch_size': 132, 'beta_1': 0.9890682177495551, 'beta_2': 0.9999970483844794, 'epsilon': 6.41464660171394e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0003437636699628435, 'tol': 0.0915136686119524, 'validation_fraction': 0.2757889733575329}
observation time 0.001418, current best 0.168393 at iter 3
suggestion time taken 0.001776 iter 4 next_points [{'alpha': 5.900868492598047, 'batch_size': 79, 'beta_1': 0.986217704162286, 'beta_2': 0.9973094409408989, 'epsilon': 9.430337187998574e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0026236140576999523, 'tol': 0.00026130142084181194, 'validation_fraction': 0.41783544480027823}]
function_evaluation time 1.631519 value 0.180880 suggestion {'alpha': 5.900868492598047, 'batch_size': 79, 'beta_1': 0.986217704162286, 'beta_2': 0.9973094409408989, 'epsilon': 9.430337187998574e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0026236140576999523, 'tol': 0.00026130142084181194, 'validation_fraction': 0.41783544480027823}
observation time 0.001446, current best 0.168393 at iter 4
suggestion time taken 0.002056 iter 5 next_points [{'alpha': 0.1515813600093725, 'batch_size': 26, 'beta_1': 0.5367450283189266, 'beta_2': 0.9491938021168488, 'epsilon': 9.791104761775739e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.00019767620521881772, 'tol': 0.0003355376775352014, 'validation_fraction': 0.8520909121335799}]
function_evaluation time 3.200276 value 0.269956 suggestion {'alpha': 0.1515813600093725, 'batch_size': 26, 'beta_1': 0.5367450283189266, 'beta_2': 0.9491938021168488, 'epsilon': 9.791104761775739e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.00019767620521881772, 'tol': 0.0003355376775352014, 'validation_fraction': 0.8520909121335799}
observation time 0.001486, current best 0.168393 at iter 5
suggestion time taken 0.001748 iter 6 next_points [{'alpha': 0.00035650555441386433, 'batch_size': 228, 'beta_1': 0.9497025320075952, 'beta_2': 0.9994313941953241, 'epsilon': 1.7509428796384228e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 1.9413366977475557e-05, 'tol': 3.973201702507531e-05, 'validation_fraction': 0.8820494656422113}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.201133 value 9.652219 suggestion {'alpha': 0.00035650555441386433, 'batch_size': 228, 'beta_1': 0.9497025320075952, 'beta_2': 0.9994313941953241, 'epsilon': 1.7509428796384228e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 1.9413366977475557e-05, 'tol': 3.973201702507531e-05, 'validation_fraction': 0.8820494656422113}
observation time 0.001677, current best 0.168393 at iter 6
suggestion time taken 0.001821 iter 7 next_points [{'alpha': 3.0135405504027006, 'batch_size': 90, 'beta_1': 0.8789446548707963, 'beta_2': 0.9969356959621839, 'epsilon': 6.519872141244375e-09, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.019870325400873405, 'tol': 0.006182706877318989, 'validation_fraction': 0.1575304748217613}]
function_evaluation time 0.783683 value 0.129118 suggestion {'alpha': 3.0135405504027006, 'batch_size': 90, 'beta_1': 0.8789446548707963, 'beta_2': 0.9969356959621839, 'epsilon': 6.519872141244375e-09, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.019870325400873405, 'tol': 0.006182706877318989, 'validation_fraction': 0.1575304748217613}
observation time 0.001408, current best 0.129118 at iter 7
suggestion time taken 0.001818 iter 8 next_points [{'alpha': 1.0066218925359371, 'batch_size': 100, 'beta_1': 0.6922334447085831, 'beta_2': 0.999995796889806, 'epsilon': 2.7240670385266053e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 5.02014922187068e-05, 'tol': 0.010759352711106535, 'validation_fraction': 0.143557919107977}]
function_evaluation time 2.845333 value 0.445337 suggestion {'alpha': 1.0066218925359371, 'batch_size': 100, 'beta_1': 0.6922334447085831, 'beta_2': 0.999995796889806, 'epsilon': 2.7240670385266053e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 5.02014922187068e-05, 'tol': 0.010759352711106535, 'validation_fraction': 0.143557919107977}
observation time 0.001422, current best 0.129118 at iter 8
suggestion time taken 0.001774 iter 9 next_points [{'alpha': 0.006456714363906046, 'batch_size': 164, 'beta_1': 0.8576637408016664, 'beta_2': 0.9998070421469228, 'epsilon': 4.7859759174271324e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.0009087419778653831, 'tol': 1.6481152115506494e-05, 'validation_fraction': 0.1926756155752949}]
function_evaluation time 1.490980 value 0.135562 suggestion {'alpha': 0.006456714363906046, 'batch_size': 164, 'beta_1': 0.8576637408016664, 'beta_2': 0.9998070421469228, 'epsilon': 4.7859759174271324e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.0009087419778653831, 'tol': 1.6481152115506494e-05, 'validation_fraction': 0.1926756155752949}
observation time 0.001371, current best 0.129118 at iter 9
suggestion time taken 0.001807 iter 10 next_points [{'alpha': 1.6332557637201544, 'batch_size': 150, 'beta_1': 0.6659119834048037, 'beta_2': 0.9999438384360013, 'epsilon': 2.440874610812426e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.005474429275012587, 'tol': 1.4433495659916388e-05, 'validation_fraction': 0.8391670188029049}]
function_evaluation time 0.844629 value 0.290204 suggestion {'alpha': 1.6332557637201544, 'batch_size': 150, 'beta_1': 0.6659119834048037, 'beta_2': 0.9999438384360013, 'epsilon': 2.440874610812426e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.005474429275012587, 'tol': 1.4433495659916388e-05, 'validation_fraction': 0.8391670188029049}
observation time 0.001380, current best 0.129118 at iter 10
suggestion time taken 0.001809 iter 11 next_points [{'alpha': 0.0011767613835319656, 'batch_size': 177, 'beta_1': 0.9201836740056104, 'beta_2': 0.999967838423924, 'epsilon': 2.0491195000511484e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.000111156296466898, 'tol': 0.002412240198441808, 'validation_fraction': 0.6200894799191412}]
function_evaluation time 2.633157 value 2.644838 suggestion {'alpha': 0.0011767613835319656, 'batch_size': 177, 'beta_1': 0.9201836740056104, 'beta_2': 0.999967838423924, 'epsilon': 2.0491195000511484e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.000111156296466898, 'tol': 0.002412240198441808, 'validation_fraction': 0.6200894799191412}
observation time 0.001410, current best 0.129118 at iter 11
suggestion time taken 0.001772 iter 12 next_points [{'alpha': 9.419026644543848e-05, 'batch_size': 141, 'beta_1': 0.8424139149776846, 'beta_2': 0.9996838182222514, 'epsilon': 4.726042391917233e-09, 'hidden_layer_sizes': 183, 'learning_rate_init': 1.1370837804896825e-05, 'tol': 0.0012006295202828322, 'validation_fraction': 0.4104387161497987}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.552655 value 4.821127 suggestion {'alpha': 9.419026644543848e-05, 'batch_size': 141, 'beta_1': 0.8424139149776846, 'beta_2': 0.9996838182222514, 'epsilon': 4.726042391917233e-09, 'hidden_layer_sizes': 183, 'learning_rate_init': 1.1370837804896825e-05, 'tol': 0.0012006295202828322, 'validation_fraction': 0.4104387161497987}
observation time 0.001405, current best 0.129118 at iter 12
suggestion time taken 0.001682 iter 13 next_points [{'alpha': 0.0027083657562088337, 'batch_size': 238, 'beta_1': 0.9412537283106772, 'beta_2': 0.9999866246542848, 'epsilon': 1.181072344169149e-07, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.0018150899741111873, 'tol': 0.05395255748488122, 'validation_fraction': 0.6744930822536616}]
function_evaluation time 0.366202 value 0.357912 suggestion {'alpha': 0.0027083657562088337, 'batch_size': 238, 'beta_1': 0.9412537283106772, 'beta_2': 0.9999866246542848, 'epsilon': 1.181072344169149e-07, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.0018150899741111873, 'tol': 0.05395255748488122, 'validation_fraction': 0.6744930822536616}
observation time 0.001426, current best 0.129118 at iter 13
suggestion time taken 0.001712 iter 14 next_points [{'alpha': 0.2969969273022322, 'batch_size': 47, 'beta_1': 0.9759193692986134, 'beta_2': 0.999991203075316, 'epsilon': 1.5517772832586675e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.0871173227343418, 'tol': 0.004563632621652881, 'validation_fraction': 0.3310149681117943}]
function_evaluation time 1.669831 value 0.645550 suggestion {'alpha': 0.2969969273022322, 'batch_size': 47, 'beta_1': 0.9759193692986134, 'beta_2': 0.999991203075316, 'epsilon': 1.5517772832586675e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.0871173227343418, 'tol': 0.004563632621652881, 'validation_fraction': 0.3310149681117943}
observation time 0.001372, current best 0.129118 at iter 14
saving meta data: {'args': {'--uuid': 'ee1435eba017571b85725896df37d937', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230407_081712', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

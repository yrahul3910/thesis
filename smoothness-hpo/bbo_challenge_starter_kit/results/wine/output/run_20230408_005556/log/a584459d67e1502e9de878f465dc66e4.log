running: {'--uuid': 'a584459d67e1502e9de878f465dc66e4', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_005556', '--opt': 'turbo', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d wine -o turbo -u a584459d67e1502e9de878f465dc66e4 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230408_005556
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [16.063962273407764, 23.274250254613083, 19.80193088400322, 3.463918210725012, 15.210579700922176])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_wine_nll betwen [15.51998549 22.35390307 19.16402613  3.37792524 14.64310022] and [16.06396227 23.27425025 19.80193088  3.46391821 15.2105797 ]
  warnings.warn(

Signature errors:
                          0         1         2         3         4       max
MLP-adam_wine_nll  0.543977  0.920347  0.637905  0.085993  0.567479  0.920347
max                0.543977  0.920347  0.637905  0.085993  0.567479  0.920347
starting sklearn study turbo MLP-adam wine nll 15 1
with data root: None
suggestion time taken 0.002191 iter 0 next_points [{'alpha': 0.0019506999672676759, 'batch_size': 16, 'beta_1': 0.8351215450768227, 'beta_2': 0.9999702550761148, 'epsilon': 2.355572140555387e-08, 'hidden_layer_sizes': 144, 'learning_rate_init': 6.141062533915979e-05, 'tol': 3.116412038849103e-05, 'validation_fraction': 0.4228771954189365}]
function_evaluation time 0.109679 value 14.578365 suggestion {'alpha': 0.0019506999672676759, 'batch_size': 16, 'beta_1': 0.8351215450768227, 'beta_2': 0.9999702550761148, 'epsilon': 2.355572140555387e-08, 'hidden_layer_sizes': 144, 'learning_rate_init': 6.141062533915979e-05, 'tol': 3.116412038849103e-05, 'validation_fraction': 0.4228771954189365}
observation time 0.001497, current best 14.578365 at iter 0
suggestion time taken 0.001968 iter 1 next_points [{'alpha': 0.04244044068309929, 'batch_size': 49, 'beta_1': 0.7492244351683928, 'beta_2': 0.9495380985149328, 'epsilon': 1.3236569597357705e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.027763435276933736, 'tol': 0.004636960347528248, 'validation_fraction': 0.17242287294215672}]
function_evaluation time 0.111968 value 3.645168 suggestion {'alpha': 0.04244044068309929, 'batch_size': 49, 'beta_1': 0.7492244351683928, 'beta_2': 0.9495380985149328, 'epsilon': 1.3236569597357705e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.027763435276933736, 'tol': 0.004636960347528248, 'validation_fraction': 0.17242287294215672}
observation time 0.001458, current best 3.645168 at iter 1
suggestion time taken 0.001791 iter 2 next_points [{'alpha': 0.00026613434735068794, 'batch_size': 74, 'beta_1': 0.5193643250982772, 'beta_2': 0.9998047153870152, 'epsilon': 4.063404596776041e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 1.3420637475679728e-05, 'tol': 0.012085680700216832, 'validation_fraction': 0.37633363912621204}]
function_evaluation time 0.054494 value 22.506069 suggestion {'alpha': 0.00026613434735068794, 'batch_size': 74, 'beta_1': 0.5193643250982772, 'beta_2': 0.9998047153870152, 'epsilon': 4.063404596776041e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 1.3420637475679728e-05, 'tol': 0.012085680700216832, 'validation_fraction': 0.37633363912621204}
observation time 0.001395, current best 3.645168 at iter 2
suggestion time taken 0.001755 iter 3 next_points [{'alpha': 5.262906032589694, 'batch_size': 30, 'beta_1': 0.9064487845719211, 'beta_2': 0.9907015072285105, 'epsilon': 6.99468624604197e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.0010779235378923654, 'tol': 9.279177201793976e-05, 'validation_fraction': 0.7264758630329768}]
function_evaluation time 0.062255 value 16.026067 suggestion {'alpha': 5.262906032589694, 'batch_size': 30, 'beta_1': 0.9064487845719211, 'beta_2': 0.9907015072285105, 'epsilon': 6.99468624604197e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.0010779235378923654, 'tol': 9.279177201793976e-05, 'validation_fraction': 0.7264758630329768}
observation time 0.001651, current best 3.645168 at iter 3
suggestion time taken 0.001779 iter 4 next_points [{'alpha': 0.26251605619703217, 'batch_size': 41, 'beta_1': 0.7045242812090482, 'beta_2': 0.9992553087449771, 'epsilon': 3.2611980501114197e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0003274775405286573, 'tol': 0.005929155835216556, 'validation_fraction': 0.528654125161216}]
function_evaluation time 0.121838 value 12.298531 suggestion {'alpha': 0.26251605619703217, 'batch_size': 41, 'beta_1': 0.7045242812090482, 'beta_2': 0.9992553087449771, 'epsilon': 3.2611980501114197e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0003274775405286573, 'tol': 0.005929155835216556, 'validation_fraction': 0.528654125161216}
observation time 0.001442, current best 3.645168 at iter 4
suggestion time taken 0.001791 iter 5 next_points [{'alpha': 5.969549370319816e-05, 'batch_size': 69, 'beta_1': 0.8903985042563921, 'beta_2': 0.9999971654868027, 'epsilon': 5.130238618848962e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.00014887053848380475, 'tol': 0.06427384611584064, 'validation_fraction': 0.14859921533128012}]
function_evaluation time 0.065088 value 19.912086 suggestion {'alpha': 5.969549370319816e-05, 'batch_size': 69, 'beta_1': 0.8903985042563921, 'beta_2': 0.9999971654868027, 'epsilon': 5.130238618848962e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.00014887053848380475, 'tol': 0.06427384611584064, 'validation_fraction': 0.14859921533128012}
observation time 0.001396, current best 3.645168 at iter 5
suggestion time taken 0.001759 iter 6 next_points [{'alpha': 0.0074372412702142995, 'batch_size': 181, 'beta_1': 0.9784590969202759, 'beta_2': 0.9999334782083678, 'epsilon': 9.935026062125469e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.002301940321912027, 'tol': 0.05895595290462158, 'validation_fraction': 0.26052470947136125}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.071796 value 7.573231 suggestion {'alpha': 0.0074372412702142995, 'batch_size': 181, 'beta_1': 0.9784590969202759, 'beta_2': 0.9999334782083678, 'epsilon': 9.935026062125469e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.002301940321912027, 'tol': 0.05895595290462158, 'validation_fraction': 0.26052470947136125}
observation time 0.001349, current best 3.645168 at iter 6
suggestion time taken 0.001710 iter 7 next_points [{'alpha': 1.149798026409905e-05, 'batch_size': 240, 'beta_1': 0.9396699755530616, 'beta_2': 0.9726945397223906, 'epsilon': 5.28027571084967e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.004726759939249087, 'tol': 0.0011527737253020827, 'validation_fraction': 0.5343626859140523}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.119026 value 5.186076 suggestion {'alpha': 1.149798026409905e-05, 'batch_size': 240, 'beta_1': 0.9396699755530616, 'beta_2': 0.9726945397223906, 'epsilon': 5.28027571084967e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.004726759939249087, 'tol': 0.0011527737253020827, 'validation_fraction': 0.5343626859140523}
observation time 0.001373, current best 3.645168 at iter 7
suggestion time taken 0.001754 iter 8 next_points [{'alpha': 8.867703036869309e-05, 'batch_size': 100, 'beta_1': 0.6552708796446799, 'beta_2': 0.9971043978292846, 'epsilon': 1.8466346486465566e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0547906719066198, 'tol': 0.0001390378800949429, 'validation_fraction': 0.29900072925275456}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.116539 value 1.246094 suggestion {'alpha': 8.867703036869309e-05, 'batch_size': 100, 'beta_1': 0.6552708796446799, 'beta_2': 0.9971043978292846, 'epsilon': 1.8466346486465566e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0547906719066198, 'tol': 0.0001390378800949429, 'validation_fraction': 0.29900072925275456}
observation time 0.001407, current best 1.246094 at iter 8
suggestion time taken 0.001715 iter 9 next_points [{'alpha': 0.08250288528117478, 'batch_size': 89, 'beta_1': 0.9491628759414464, 'beta_2': 0.998398486562971, 'epsilon': 9.034696750682e-08, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00023131707538188932, 'tol': 6.863655024296924e-05, 'validation_fraction': 0.8369821945040885}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.069061 value 12.352018 suggestion {'alpha': 0.08250288528117478, 'batch_size': 89, 'beta_1': 0.9491628759414464, 'beta_2': 0.998398486562971, 'epsilon': 9.034696750682e-08, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00023131707538188932, 'tol': 6.863655024296924e-05, 'validation_fraction': 0.8369821945040885}
observation time 0.001391, current best 1.246094 at iter 9
suggestion time taken 0.001688 iter 10 next_points [{'alpha': 0.005459522445045948, 'batch_size': 124, 'beta_1': 0.9332359370815944, 'beta_2': 0.9999987737874346, 'epsilon': 1.4215778179795143e-07, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.020835536462271088, 'tol': 0.0026826975213206155, 'validation_fraction': 0.11268375514043277}]
function_evaluation time 0.066702 value 17.263277 suggestion {'alpha': 0.005459522445045948, 'batch_size': 124, 'beta_1': 0.9332359370815944, 'beta_2': 0.9999987737874346, 'epsilon': 1.4215778179795143e-07, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.020835536462271088, 'tol': 0.0026826975213206155, 'validation_fraction': 0.11268375514043277}
observation time 0.001393, current best 1.246094 at iter 10
suggestion time taken 0.001668 iter 11 next_points [{'alpha': 3.1499077819544103, 'batch_size': 195, 'beta_1': 0.9592944918499682, 'beta_2': 0.9989084059619399, 'epsilon': 1.5171888307566159e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 1.898495330193077e-05, 'tol': 2.298124297912532e-05, 'validation_fraction': 0.7653911376402888}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.044033 value 22.504775 suggestion {'alpha': 3.1499077819544103, 'batch_size': 195, 'beta_1': 0.9592944918499682, 'beta_2': 0.9989084059619399, 'epsilon': 1.5171888307566159e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 1.898495330193077e-05, 'tol': 2.298124297912532e-05, 'validation_fraction': 0.7653911376402888}
observation time 0.001364, current best 1.246094 at iter 11
suggestion time taken 0.001733 iter 12 next_points [{'alpha': 0.02893311294398531, 'batch_size': 235, 'beta_1': 0.8481189850731118, 'beta_2': 0.9999164026530707, 'epsilon': 1.5098855686039018e-08, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.08736235220640048, 'tol': 0.0003723653599054591, 'validation_fraction': 0.8981320427471717}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.075358 value 10.236797 suggestion {'alpha': 0.02893311294398531, 'batch_size': 235, 'beta_1': 0.8481189850731118, 'beta_2': 0.9999164026530707, 'epsilon': 1.5098855686039018e-08, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.08736235220640048, 'tol': 0.0003723653599054591, 'validation_fraction': 0.8981320427471717}
observation time 0.001368, current best 1.246094 at iter 12
suggestion time taken 0.001685 iter 13 next_points [{'alpha': 1.662283517902867, 'batch_size': 111, 'beta_1': 0.6172554694216681, 'beta_2': 0.9835044689036693, 'epsilon': 4.3385180029441534e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 9.282187473612817e-05, 'tol': 0.022024596963396318, 'validation_fraction': 0.8614942004942255}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.046656 value 21.534473 suggestion {'alpha': 1.662283517902867, 'batch_size': 111, 'beta_1': 0.6172554694216681, 'beta_2': 0.9835044689036693, 'epsilon': 4.3385180029441534e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 9.282187473612817e-05, 'tol': 0.022024596963396318, 'validation_fraction': 0.8614942004942255}
observation time 0.001402, current best 1.246094 at iter 13
suggestion time taken 0.001688 iter 14 next_points [{'alpha': 0.0006477669965988424, 'batch_size': 146, 'beta_1': 0.7816310933107924, 'beta_2': 0.9996611373581191, 'epsilon': 2.274553745529992e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 4.243195770616249e-05, 'tol': 0.0002020365446795259, 'validation_fraction': 0.6139109671875558}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.056361 value 22.482790 suggestion {'alpha': 0.0006477669965988424, 'batch_size': 146, 'beta_1': 0.7816310933107924, 'beta_2': 0.9996611373581191, 'epsilon': 2.274553745529992e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 4.243195770616249e-05, 'tol': 0.0002020365446795259, 'validation_fraction': 0.6139109671875558}
observation time 0.001412, current best 1.246094 at iter 14
saving meta data: {'args': {'--uuid': 'a584459d67e1502e9de878f465dc66e4', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_005556', '--opt': 'turbo', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [16.063962273407764, 23.274250254613083, 19.80193088400322, 3.463918210725012, 15.210579700922176])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '20c97dae83385d958baa76a98cb0a444', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_005556', '--opt': 'opentuner', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d wine -o opentuner -u 20c97dae83385d958baa76a98cb0a444 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230408_005556
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])
Signature errors:
                     0    1    2    3    4  max
MLP-adam_wine_acc  0.0  0.0  0.0  0.0  0.0  0.0
max                0.0  0.0  0.0  0.0  0.0  0.0
starting sklearn study opentuner MLP-adam wine acc 15 1
with data root: None
suggestion time taken 0.029961 iter 0 next_points [{'hidden_layer_sizes': 86, 'alpha': 6.971680953413161, 'batch_size': 161, 'learning_rate_init': 0.04905653951534877, 'tol': 0.08804895932194705, 'validation_fraction': 0.44593690819728904, 'beta_1': 0.8900041370684058, 'beta_2': 0.9876806045518721, 'epsilon': 3.218415037306477e-08}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.069267 value -0.600000 suggestion {'hidden_layer_sizes': 86, 'alpha': 6.971680953413161, 'batch_size': 161, 'learning_rate_init': 0.04905653951534877, 'tol': 0.08804895932194705, 'validation_fraction': 0.44593690819728904, 'beta_1': 0.8900041370684058, 'beta_2': 0.9876806045518721, 'epsilon': 3.218415037306477e-08}
observation time 0.004553, current best -0.600000 at iter 0
suggestion time taken 0.007982 iter 1 next_points [{'hidden_layer_sizes': 86, 'alpha': 5.021565143117401, 'batch_size': 186, 'learning_rate_init': 0.06157464415549357, 'tol': 0.08804895932194705, 'validation_fraction': 0.44593690819728904, 'beta_1': 0.8900041370684058, 'beta_2': 0.9876806045518721, 'epsilon': 3.218415037306477e-08}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.060676 value -0.526601 suggestion {'hidden_layer_sizes': 86, 'alpha': 5.021565143117401, 'batch_size': 186, 'learning_rate_init': 0.06157464415549357, 'tol': 0.08804895932194705, 'validation_fraction': 0.44593690819728904, 'beta_1': 0.8900041370684058, 'beta_2': 0.9876806045518721, 'epsilon': 3.218415037306477e-08}
observation time 0.001934, current best -0.600000 at iter 1
suggestion time taken 0.047437 iter 2 next_points [{'batch_size': 88, 'tol': 0.022772496046723645, 'alpha': 0.7059779625345218, 'hidden_layer_sizes': 53, 'epsilon': 5.451700876573918e-07, 'beta_2': 0.9125664998552511, 'validation_fraction': 0.18336694708554663, 'learning_rate_init': 0.04899808464813276, 'beta_1': 0.6270471733209495}]
function_evaluation time 0.102225 value -0.732020 suggestion {'batch_size': 88, 'tol': 0.022772496046723645, 'alpha': 0.7059779625345218, 'hidden_layer_sizes': 53, 'epsilon': 5.451700876573918e-07, 'beta_2': 0.9125664998552511, 'validation_fraction': 0.18336694708554663, 'learning_rate_init': 0.04899808464813276, 'beta_1': 0.6270471733209495}
observation time 0.002201, current best -0.732020 at iter 2
suggestion time taken 0.007195 iter 3 next_points [{'batch_size': 88, 'tol': 0.022772496046723645, 'alpha': 0.7059779625345218, 'hidden_layer_sizes': 53, 'epsilon': 9.312887333806353e-07, 'beta_2': 0.9125664998552511, 'validation_fraction': 0.18336694708554663, 'learning_rate_init': 0.04899808464813276, 'beta_1': 0.6270471733209495}]
function_evaluation time 0.110667 value -0.738177 suggestion {'batch_size': 88, 'tol': 0.022772496046723645, 'alpha': 0.7059779625345218, 'hidden_layer_sizes': 53, 'epsilon': 9.312887333806353e-07, 'beta_2': 0.9125664998552511, 'validation_fraction': 0.18336694708554663, 'learning_rate_init': 0.04899808464813276, 'beta_1': 0.6270471733209495}
observation time 0.001983, current best -0.738177 at iter 3
suggestion time taken 0.005947 iter 4 next_points [{'hidden_layer_sizes': 80, 'alpha': 4.435131251108677, 'batch_size': 42, 'learning_rate_init': 0.08328424673811712, 'tol': 0.030570986050237826, 'validation_fraction': 0.5715032862042283, 'beta_1': 0.9033514958175469, 'beta_2': 0.9318179003200054, 'epsilon': 3.8598609544745934e-07}]
function_evaluation time 0.083693 value -0.626847 suggestion {'hidden_layer_sizes': 80, 'alpha': 4.435131251108677, 'batch_size': 42, 'learning_rate_init': 0.08328424673811712, 'tol': 0.030570986050237826, 'validation_fraction': 0.5715032862042283, 'beta_1': 0.9033514958175469, 'beta_2': 0.9318179003200054, 'epsilon': 3.8598609544745934e-07}
observation time 0.002156, current best -0.738177 at iter 4
suggestion time taken 0.006912 iter 5 next_points [{'batch_size': 88, 'tol': 0.022772496046723645, 'alpha': 0.7059779625345218, 'hidden_layer_sizes': 64, 'epsilon': 9.312887333806353e-07, 'beta_2': 0.9125664998552511, 'validation_fraction': 0.18336694708554663, 'learning_rate_init': 0.04899808464813276, 'beta_1': 0.6486160444238982}]
function_evaluation time 0.111516 value -0.669704 suggestion {'batch_size': 88, 'tol': 0.022772496046723645, 'alpha': 0.7059779625345218, 'hidden_layer_sizes': 64, 'epsilon': 9.312887333806353e-07, 'beta_2': 0.9125664998552511, 'validation_fraction': 0.18336694708554663, 'learning_rate_init': 0.04899808464813276, 'beta_1': 0.6486160444238982}
observation time 0.002271, current best -0.738177 at iter 5
suggestion time taken 0.005240 iter 6 next_points [{'batch_size': 181, 'tol': 0.012921093862403966, 'alpha': 0.7300424612734863, 'hidden_layer_sizes': 120, 'epsilon': 1.9744467830204348e-07, 'beta_2': 0.9798030746243003, 'validation_fraction': 0.7777813234848842, 'learning_rate_init': 0.09207834629136118, 'beta_1': 0.6052125174397857}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.090854 value -0.626601 suggestion {'batch_size': 181, 'tol': 0.012921093862403966, 'alpha': 0.7300424612734863, 'hidden_layer_sizes': 120, 'epsilon': 1.9744467830204348e-07, 'beta_2': 0.9798030746243003, 'validation_fraction': 0.7777813234848842, 'learning_rate_init': 0.09207834629136118, 'beta_1': 0.6052125174397857}
observation time 0.001889, current best -0.738177 at iter 6
suggestion time taken 0.006739 iter 7 next_points [{'batch_size': 88, 'tol': 0.022772496046723645, 'alpha': 0.7059779625345218, 'hidden_layer_sizes': 53, 'epsilon': 9.312887333806353e-07, 'beta_2': 0.9125664998552511, 'validation_fraction': 0.3308324385949056, 'learning_rate_init': 0.04899808464813276, 'beta_1': 0.6270471733209495}]
function_evaluation time 0.091544 value -0.621429 suggestion {'batch_size': 88, 'tol': 0.022772496046723645, 'alpha': 0.7059779625345218, 'hidden_layer_sizes': 53, 'epsilon': 9.312887333806353e-07, 'beta_2': 0.9125664998552511, 'validation_fraction': 0.3308324385949056, 'learning_rate_init': 0.04899808464813276, 'beta_1': 0.6270471733209495}
observation time 0.001886, current best -0.738177 at iter 7
suggestion time taken 0.006181 iter 8 next_points [{'hidden_layer_sizes': 168, 'alpha': 5.874729202213626, 'batch_size': 37, 'learning_rate_init': 0.09590408953384959, 'tol': 0.05669633782982902, 'validation_fraction': 0.18208186908933266, 'beta_1': 0.8315877815556566, 'beta_2': 0.9528668841402931, 'epsilon': 7.201375583914805e-07}]
function_evaluation time 0.093786 value -0.550739 suggestion {'hidden_layer_sizes': 168, 'alpha': 5.874729202213626, 'batch_size': 37, 'learning_rate_init': 0.09590408953384959, 'tol': 0.05669633782982902, 'validation_fraction': 0.18208186908933266, 'beta_1': 0.8315877815556566, 'beta_2': 0.9528668841402931, 'epsilon': 7.201375583914805e-07}
observation time 0.001864, current best -0.738177 at iter 8
suggestion time taken 0.005103 iter 9 next_points [{'batch_size': 200, 'tol': 0.018145153234299705, 'alpha': 0.5107371538780731, 'hidden_layer_sizes': 154, 'epsilon': 9.261886368133455e-07, 'beta_2': 0.9060879760296352, 'validation_fraction': 0.3615754654733391, 'learning_rate_init': 0.08954944628855481, 'beta_1': 0.8068743074652129}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.079726 value -0.606650 suggestion {'batch_size': 200, 'tol': 0.018145153234299705, 'alpha': 0.5107371538780731, 'hidden_layer_sizes': 154, 'epsilon': 9.261886368133455e-07, 'beta_2': 0.9060879760296352, 'validation_fraction': 0.3615754654733391, 'learning_rate_init': 0.08954944628855481, 'beta_1': 0.8068743074652129}
observation time 0.001880, current best -0.738177 at iter 9
suggestion time taken 0.006672 iter 10 next_points [{'batch_size': 187, 'tol': 0.022772496046723645, 'alpha': 0.7059779625345218, 'hidden_layer_sizes': 53, 'epsilon': 9.312887333806353e-07, 'beta_2': 0.9125664998552511, 'validation_fraction': 0.18336694708554663, 'learning_rate_init': 0.04899808464813276, 'beta_1': 0.6270471733209495}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.068902 value -0.593842 suggestion {'batch_size': 187, 'tol': 0.022772496046723645, 'alpha': 0.7059779625345218, 'hidden_layer_sizes': 53, 'epsilon': 9.312887333806353e-07, 'beta_2': 0.9125664998552511, 'validation_fraction': 0.18336694708554663, 'learning_rate_init': 0.04899808464813276, 'beta_1': 0.6270471733209495}
observation time 0.002008, current best -0.738177 at iter 10
suggestion time taken 0.005138 iter 11 next_points [{'batch_size': 69, 'tol': 0.08860430585324346, 'alpha': 5.979747458314725, 'hidden_layer_sizes': 111, 'epsilon': 7.247926367142932e-07, 'beta_2': 0.9756311395983827, 'validation_fraction': 0.44788079898140454, 'learning_rate_init': 0.014170161915895308, 'beta_1': 0.5781732647791613}]
function_evaluation time 0.074290 value -0.590887 suggestion {'batch_size': 69, 'tol': 0.08860430585324346, 'alpha': 5.979747458314725, 'hidden_layer_sizes': 111, 'epsilon': 7.247926367142932e-07, 'beta_2': 0.9756311395983827, 'validation_fraction': 0.44788079898140454, 'learning_rate_init': 0.014170161915895308, 'beta_1': 0.5781732647791613}
observation time 0.002142, current best -0.738177 at iter 11
suggestion time taken 0.006060 iter 12 next_points [{'hidden_layer_sizes': 135, 'alpha': 2.4964139309119795, 'batch_size': 37, 'learning_rate_init': 0.08965850335632723, 'tol': 0.0832809595942711, 'validation_fraction': 0.10181239708772499, 'beta_1': 0.6145392234057072, 'beta_2': 0.9158546711195563, 'epsilon': 6.326058482891407e-07}]
function_evaluation time 0.089497 value -0.569704 suggestion {'hidden_layer_sizes': 135, 'alpha': 2.4964139309119795, 'batch_size': 37, 'learning_rate_init': 0.08965850335632723, 'tol': 0.0832809595942711, 'validation_fraction': 0.10181239708772499, 'beta_1': 0.6145392234057072, 'beta_2': 0.9158546711195563, 'epsilon': 6.326058482891407e-07}
observation time 0.001953, current best -0.738177 at iter 12
suggestion time taken 0.007024 iter 13 next_points [{'batch_size': 88, 'tol': 0.022772496046723645, 'alpha': 0.7059779625345218, 'hidden_layer_sizes': 180, 'epsilon': 9.312887333806353e-07, 'beta_2': 0.9587516654446454, 'validation_fraction': 0.18336694708554663, 'learning_rate_init': 0.08912028017636013, 'beta_1': 0.6270471733209495}]
function_evaluation time 0.080624 value -0.473645 suggestion {'batch_size': 88, 'tol': 0.022772496046723645, 'alpha': 0.7059779625345218, 'hidden_layer_sizes': 180, 'epsilon': 9.312887333806353e-07, 'beta_2': 0.9587516654446454, 'validation_fraction': 0.18336694708554663, 'learning_rate_init': 0.08912028017636013, 'beta_1': 0.6270471733209495}
observation time 0.001692, current best -0.738177 at iter 13
suggestion time taken 0.005761 iter 14 next_points [{'hidden_layer_sizes': 162, 'alpha': 0.11665182534392875, 'batch_size': 208, 'learning_rate_init': 0.02269294899826828, 'tol': 0.001717564438005571, 'validation_fraction': 0.5410452049047292, 'beta_1': 0.8302484367712617, 'beta_2': 0.9369414395580584, 'epsilon': 3.735229739451518e-08}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.109718 value -0.726108 suggestion {'hidden_layer_sizes': 162, 'alpha': 0.11665182534392875, 'batch_size': 208, 'learning_rate_init': 0.02269294899826828, 'tol': 0.001717564438005571, 'validation_fraction': 0.5410452049047292, 'beta_1': 0.8302484367712617, 'beta_2': 0.9369414395580584, 'epsilon': 3.735229739451518e-08}
observation time 0.002014, current best -0.738177 at iter 14
saving meta data: {'args': {'--uuid': '20c97dae83385d958baa76a98cb0a444', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_005556', '--opt': 'opentuner', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])}
saving results
saving timing
saving suggest log
done

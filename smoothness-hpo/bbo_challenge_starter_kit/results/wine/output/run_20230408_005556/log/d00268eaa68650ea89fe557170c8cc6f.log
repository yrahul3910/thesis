running: {'--uuid': 'd00268eaa68650ea89fe557170c8cc6f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_005556', '--opt': 'hyperopt', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d wine -o hyperopt -u d00268eaa68650ea89fe557170c8cc6f -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230408_005556
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])
Signature errors:
                     0    1    2    3    4  max
MLP-adam_wine_acc  0.0  0.0  0.0  0.0  0.0  0.0
max                0.0  0.0  0.0  0.0  0.0  0.0
starting sklearn study hyperopt MLP-adam wine acc 15 1
with data root: None
suggestion time taken 0.002315 iter 0 next_points [{'alpha': 0.4229280636485821, 'batch_size': 214, 'beta_1': 0.5979644795247572, 'beta_2': 0.9956749579014061, 'epsilon': 3.168636622105564e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.04890007861032488, 'tol': 0.00013550949944020365, 'validation_fraction': 0.21969883252260325}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.117662 value -0.677094 suggestion {'alpha': 0.4229280636485821, 'batch_size': 214, 'beta_1': 0.5979644795247572, 'beta_2': 0.9956749579014061, 'epsilon': 3.168636622105564e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.04890007861032488, 'tol': 0.00013550949944020365, 'validation_fraction': 0.21969883252260325}
observation time 0.000068, current best -0.677094 at iter 0
suggestion time taken 0.002186 iter 1 next_points [{'alpha': 2.289782446623564, 'batch_size': 166, 'beta_1': 0.6894092706870177, 'beta_2': 0.927461043929467, 'epsilon': 3.427540628500899e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.0010943981829207717, 'tol': 0.00288112229456552, 'validation_fraction': 0.49002303651315954}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.105709 value -0.528818 suggestion {'alpha': 2.289782446623564, 'batch_size': 166, 'beta_1': 0.6894092706870177, 'beta_2': 0.927461043929467, 'epsilon': 3.427540628500899e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.0010943981829207717, 'tol': 0.00288112229456552, 'validation_fraction': 0.49002303651315954}
observation time 0.000071, current best -0.677094 at iter 1
suggestion time taken 0.002320 iter 2 next_points [{'alpha': 0.00163777385773883, 'batch_size': 154, 'beta_1': 0.8413978644721322, 'beta_2': 0.9994931376796864, 'epsilon': 1.905426093685713e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.003953864556692933, 'tol': 0.001804173879777149, 'validation_fraction': 0.21986236221255587}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.094694 value -0.646798 suggestion {'alpha': 0.00163777385773883, 'batch_size': 154, 'beta_1': 0.8413978644721322, 'beta_2': 0.9994931376796864, 'epsilon': 1.905426093685713e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.003953864556692933, 'tol': 0.001804173879777149, 'validation_fraction': 0.21986236221255587}
observation time 0.000072, current best -0.677094 at iter 2
suggestion time taken 0.002157 iter 3 next_points [{'alpha': 0.0009474055670676379, 'batch_size': 191, 'beta_1': 0.5592228662701142, 'beta_2': 0.9207940348950628, 'epsilon': 1.0858991679584364e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.00034800361002567624, 'tol': 0.0005076030377292467, 'validation_fraction': 0.4452680618246355}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.055666 value -0.366256 suggestion {'alpha': 0.0009474055670676379, 'batch_size': 191, 'beta_1': 0.5592228662701142, 'beta_2': 0.9207940348950628, 'epsilon': 1.0858991679584364e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.00034800361002567624, 'tol': 0.0005076030377292467, 'validation_fraction': 0.4452680618246355}
observation time 0.000072, current best -0.677094 at iter 3
suggestion time taken 0.002144 iter 4 next_points [{'alpha': 0.05702475825402313, 'batch_size': 102, 'beta_1': 0.8075606849886916, 'beta_2': 0.9296897563534199, 'epsilon': 1.6803192865701673e-09, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.0006675183528741091, 'tol': 0.008930005808985685, 'validation_fraction': 0.7570389347757489}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.099102 value -0.598768 suggestion {'alpha': 0.05702475825402313, 'batch_size': 102, 'beta_1': 0.8075606849886916, 'beta_2': 0.9296897563534199, 'epsilon': 1.6803192865701673e-09, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.0006675183528741091, 'tol': 0.008930005808985685, 'validation_fraction': 0.7570389347757489}
observation time 0.000069, current best -0.677094 at iter 4
suggestion time taken 0.002156 iter 5 next_points [{'alpha': 0.00015344848611428396, 'batch_size': 180, 'beta_1': 0.5376293728436736, 'beta_2': 0.9368757764424488, 'epsilon': 2.4265062724029025e-09, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.05538531859225705, 'tol': 0.09135297919038372, 'validation_fraction': 0.39377288282967}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.087860 value -0.697044 suggestion {'alpha': 0.00015344848611428396, 'batch_size': 180, 'beta_1': 0.5376293728436736, 'beta_2': 0.9368757764424488, 'epsilon': 2.4265062724029025e-09, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.05538531859225705, 'tol': 0.09135297919038372, 'validation_fraction': 0.39377288282967}
observation time 0.000072, current best -0.697044 at iter 5
suggestion time taken 0.002144 iter 6 next_points [{'alpha': 3.712685097920242e-05, 'batch_size': 43, 'beta_1': 0.5279070782134102, 'beta_2': 0.9011091840417136, 'epsilon': 2.193838089492603e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.00023407100474533978, 'tol': 0.0002765666476423594, 'validation_fraction': 0.6869824901291415}]
function_evaluation time 0.059851 value -0.395567 suggestion {'alpha': 3.712685097920242e-05, 'batch_size': 43, 'beta_1': 0.5279070782134102, 'beta_2': 0.9011091840417136, 'epsilon': 2.193838089492603e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.00023407100474533978, 'tol': 0.0002765666476423594, 'validation_fraction': 0.6869824901291415}
observation time 0.000070, current best -0.697044 at iter 6
suggestion time taken 0.002168 iter 7 next_points [{'alpha': 0.674759115313698, 'batch_size': 46, 'beta_1': 0.9107978234751707, 'beta_2': 0.9033208227541085, 'epsilon': 1.3677674295215776e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.012803939294185619, 'tol': 0.054243291102251685, 'validation_fraction': 0.31316501765259386}]
function_evaluation time 0.095750 value -0.775616 suggestion {'alpha': 0.674759115313698, 'batch_size': 46, 'beta_1': 0.9107978234751707, 'beta_2': 0.9033208227541085, 'epsilon': 1.3677674295215776e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.012803939294185619, 'tol': 0.054243291102251685, 'validation_fraction': 0.31316501765259386}
observation time 0.000074, current best -0.775616 at iter 7
suggestion time taken 0.002158 iter 8 next_points [{'alpha': 2.4189302786307247, 'batch_size': 212, 'beta_1': 0.6512816001409093, 'beta_2': 0.9093014529832547, 'epsilon': 1.524853541646163e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 7.74358976574534e-05, 'tol': 0.004800439954889575, 'validation_fraction': 0.2710697990995138}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.052285 value -0.330788 suggestion {'alpha': 2.4189302786307247, 'batch_size': 212, 'beta_1': 0.6512816001409093, 'beta_2': 0.9093014529832547, 'epsilon': 1.524853541646163e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 7.74358976574534e-05, 'tol': 0.004800439954889575, 'validation_fraction': 0.2710697990995138}
observation time 0.000070, current best -0.775616 at iter 8
suggestion time taken 0.002174 iter 9 next_points [{'alpha': 2.3398737024262313, 'batch_size': 207, 'beta_1': 0.7221706835698662, 'beta_2': 0.9973253167315751, 'epsilon': 4.072276161905408e-08, 'hidden_layer_sizes': 166, 'learning_rate_init': 1.0409979338919852e-05, 'tol': 0.002544277649716049, 'validation_fraction': 0.6737836007017114}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.048344 value -0.337931 suggestion {'alpha': 2.3398737024262313, 'batch_size': 207, 'beta_1': 0.7221706835698662, 'beta_2': 0.9973253167315751, 'epsilon': 4.072276161905408e-08, 'hidden_layer_sizes': 166, 'learning_rate_init': 1.0409979338919852e-05, 'tol': 0.002544277649716049, 'validation_fraction': 0.6737836007017114}
observation time 0.000072, current best -0.775616 at iter 9
suggestion time taken 0.002404 iter 10 next_points [{'alpha': 0.00011469617838988202, 'batch_size': 110, 'beta_1': 0.5198712951661258, 'beta_2': 0.9566678892457071, 'epsilon': 8.225459360921205e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.00012986415812817883, 'tol': 0.0019055688889068518, 'validation_fraction': 0.4043977097987518}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.052103 value -0.409852 suggestion {'alpha': 0.00011469617838988202, 'batch_size': 110, 'beta_1': 0.5198712951661258, 'beta_2': 0.9566678892457071, 'epsilon': 8.225459360921205e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.00012986415812817883, 'tol': 0.0019055688889068518, 'validation_fraction': 0.4043977097987518}
observation time 0.000076, current best -0.775616 at iter 10
suggestion time taken 0.002128 iter 11 next_points [{'alpha': 0.15133113332196052, 'batch_size': 124, 'beta_1': 0.949548839476901, 'beta_2': 0.9811490008606147, 'epsilon': 5.5663306638765e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0750748096928256, 'tol': 0.02106512847246053, 'validation_fraction': 0.4634071884226387}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.070665 value -0.479803 suggestion {'alpha': 0.15133113332196052, 'batch_size': 124, 'beta_1': 0.949548839476901, 'beta_2': 0.9811490008606147, 'epsilon': 5.5663306638765e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0750748096928256, 'tol': 0.02106512847246053, 'validation_fraction': 0.4634071884226387}
observation time 0.000073, current best -0.775616 at iter 11
suggestion time taken 0.002205 iter 12 next_points [{'alpha': 0.18830373912832246, 'batch_size': 28, 'beta_1': 0.7664291706025411, 'beta_2': 0.9657645271318656, 'epsilon': 4.0112688003500545e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 6.27658744355762e-05, 'tol': 0.00010598868910301521, 'validation_fraction': 0.6895960186439188}]
function_evaluation time 0.071392 value -0.379557 suggestion {'alpha': 0.18830373912832246, 'batch_size': 28, 'beta_1': 0.7664291706025411, 'beta_2': 0.9657645271318656, 'epsilon': 4.0112688003500545e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 6.27658744355762e-05, 'tol': 0.00010598868910301521, 'validation_fraction': 0.6895960186439188}
observation time 0.000074, current best -0.775616 at iter 12
suggestion time taken 0.002156 iter 13 next_points [{'alpha': 0.0007378752986226863, 'batch_size': 106, 'beta_1': 0.671783309775283, 'beta_2': 0.9670589516762159, 'epsilon': 4.354987957680757e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.003961243694174228, 'tol': 0.002979840934751703, 'validation_fraction': 0.1109318111212266}]
function_evaluation time 0.090002 value -0.521182 suggestion {'alpha': 0.0007378752986226863, 'batch_size': 106, 'beta_1': 0.671783309775283, 'beta_2': 0.9670589516762159, 'epsilon': 4.354987957680757e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.003961243694174228, 'tol': 0.002979840934751703, 'validation_fraction': 0.1109318111212266}
observation time 0.000073, current best -0.775616 at iter 13
suggestion time taken 0.002468 iter 14 next_points [{'alpha': 9.48065045592415, 'batch_size': 168, 'beta_1': 0.526714784201208, 'beta_2': 0.9644976746000443, 'epsilon': 6.351826949569168e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 6.7196097089951e-05, 'tol': 2.4643718591799235e-05, 'validation_fraction': 0.10927509964544942}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.044513 value -0.316995 suggestion {'alpha': 9.48065045592415, 'batch_size': 168, 'beta_1': 0.526714784201208, 'beta_2': 0.9644976746000443, 'epsilon': 6.351826949569168e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 6.7196097089951e-05, 'tol': 2.4643718591799235e-05, 'validation_fraction': 0.10927509964544942}
observation time 0.000073, current best -0.775616 at iter 14
saving meta data: {'args': {'--uuid': 'd00268eaa68650ea89fe557170c8cc6f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230408_005556', '--opt': 'hyperopt', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])}
saving results
saving timing
saving suggest log
done

2023-03-25 22:49:16.845877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
2023-03-25 22:49:20.104232: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-25 22:49:20.106850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-03-25 22:49:20.614861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:81:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.65GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2023-03-25 22:49:20.614886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 22:49:20.621049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 22:49:20.621104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-25 22:49:20.624653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-25 22:49:20.633486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-25 22:49:20.646351: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2023-03-25 22:49:20.648267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-25 22:49:20.648764: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-25 22:49:20.649291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-03-25 22:49:20.649658: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-25 22:49:20.651047: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-25 22:49:20.651226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:81:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.65GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2023-03-25 22:49:20.651244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 22:49:20.651255: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 22:49:20.651263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-25 22:49:20.651271: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-25 22:49:20.651278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-25 22:49:20.651286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2023-03-25 22:49:20.651293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-25 22:49:20.651300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-25 22:49:20.651516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-03-25 22:49:20.651675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 22:49:21.194711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-03-25 22:49:21.194754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2023-03-25 22:49:21.194762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2023-03-25 22:49:21.195746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7281 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:81:00.0, compute capability: 7.5)
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
2023-03-25 22:49:21.343802: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-03-25 22:49:21.357110: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2994325000 Hz
Epoch 1/500
2023-03-25 22:49:21.630092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 22:49:22.056209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
 1/23 [>.............................] - ETA: 15s - loss: 0.051323/23 [==============================] - 1s 2ms/step - loss: 0.0484
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038823/23 [==============================] - 0s 1ms/step - loss: 0.0359
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026823/23 [==============================] - 0s 1ms/step - loss: 0.0236
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015523/23 [==============================] - 0s 1ms/step - loss: 0.0134
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009123/23 [==============================] - 0s 1ms/step - loss: 0.0082
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006223/23 [==============================] - 0s 1ms/step - loss: 0.0068
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007023/23 [==============================] - 0s 1ms/step - loss: 0.0068
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006323/23 [==============================] - 0s 1ms/step - loss: 0.0063
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004923/23 [==============================] - 0s 1ms/step - loss: 0.0058
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006523/23 [==============================] - 0s 1ms/step - loss: 0.0055
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003523/23 [==============================] - 0s 1ms/step - loss: 0.0042
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004523/23 [==============================] - 0s 1ms/step - loss: 0.0040
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004023/23 [==============================] - 0s 1ms/step - loss: 0.0033
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003223/23 [==============================] - 0s 1ms/step - loss: 0.0028
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002423/23 [==============================] - 0s 1ms/step - loss: 0.0025
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002223/23 [==============================] - 0s 1ms/step - loss: 0.0023
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003423/23 [==============================] - 0s 1ms/step - loss: 0.0023
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002323/23 [==============================] - 0s 1ms/step - loss: 0.0021
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002223/23 [==============================] - 0s 1ms/step - loss: 0.0021
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001823/23 [==============================] - 0s 1ms/step - loss: 0.0020
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002423/23 [==============================] - 0s 1ms/step - loss: 0.0020
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001823/23 [==============================] - 0s 1ms/step - loss: 0.0019
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001923/23 [==============================] - 0s 1ms/step - loss: 0.0019
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001923/23 [==============================] - 0s 1ms/step - loss: 0.0020
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001723/23 [==============================] - 0s 1ms/step - loss: 0.0018
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 4s - loss: 0.052723/23 [==============================] - 0s 1ms/step - loss: 0.0526
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.049023/23 [==============================] - 0s 1ms/step - loss: 0.0472
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040623/23 [==============================] - 0s 1ms/step - loss: 0.0381
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029723/23 [==============================] - 0s 1ms/step - loss: 0.0262
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016823/23 [==============================] - 0s 1ms/step - loss: 0.0141
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007523/23 [==============================] - 0s 1ms/step - loss: 0.0082
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006323/23 [==============================] - 0s 1ms/step - loss: 0.0074
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006723/23 [==============================] - 0s 1ms/step - loss: 0.0071
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006823/23 [==============================] - 0s 1ms/step - loss: 0.0065
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006423/23 [==============================] - 0s 1ms/step - loss: 0.0060
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.005823/23 [==============================] - 0s 1ms/step - loss: 0.0053
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.005323/23 [==============================] - 0s 1ms/step - loss: 0.0050
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004223/23 [==============================] - 0s 1ms/step - loss: 0.0046
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004123/23 [==============================] - 0s 1ms/step - loss: 0.0042
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004323/23 [==============================] - 0s 1ms/step - loss: 0.0043
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004123/23 [==============================] - 0s 1ms/step - loss: 0.0041
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004823/23 [==============================] - 0s 1ms/step - loss: 0.0041
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004123/23 [==============================] - 0s 1ms/step - loss: 0.0040
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003523/23 [==============================] - 0s 1ms/step - loss: 0.0039
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.005023/23 [==============================] - 0s 1ms/step - loss: 0.0039
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.005223/23 [==============================] - 0s 2ms/step - loss: 0.0039
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003823/23 [==============================] - 0s 1ms/step - loss: 0.0035
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003123/23 [==============================] - 0s 1ms/step - loss: 0.0036
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002323/23 [==============================] - 0s 1ms/step - loss: 0.0031
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002423/23 [==============================] - 0s 2ms/step - loss: 0.0031
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002923/23 [==============================] - 0s 2ms/step - loss: 0.0034
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001923/23 [==============================] - 0s 2ms/step - loss: 0.0028
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002523/23 [==============================] - 0s 2ms/step - loss: 0.0027
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003423/23 [==============================] - 0s 2ms/step - loss: 0.0027
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001723/23 [==============================] - 0s 2ms/step - loss: 0.0025
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002323/23 [==============================] - 0s 2ms/step - loss: 0.0024
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002323/23 [==============================] - 0s 2ms/step - loss: 0.0024
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002023/23 [==============================] - 0s 1ms/step - loss: 0.0021
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002223/23 [==============================] - 0s 1ms/step - loss: 0.0021
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002123/23 [==============================] - 0s 2ms/step - loss: 0.0021
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002223/23 [==============================] - 0s 2ms/step - loss: 0.0020
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001923/23 [==============================] - 0s 2ms/step - loss: 0.0019
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002423/23 [==============================] - 0s 2ms/step - loss: 0.0017
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001323/23 [==============================] - 0s 2ms/step - loss: 0.0016
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001623/23 [==============================] - 0s 2ms/step - loss: 0.0016
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 4s - loss: 0.103323/23 [==============================] - 0s 1ms/step - loss: 0.1021
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.088323/23 [==============================] - 0s 1ms/step - loss: 0.0920
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.080023/23 [==============================] - 0s 1ms/step - loss: 0.0817
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.076723/23 [==============================] - 0s 1ms/step - loss: 0.0739
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.070523/23 [==============================] - 0s 1ms/step - loss: 0.0676
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.059123/23 [==============================] - 0s 2ms/step - loss: 0.0586
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.049623/23 [==============================] - 0s 2ms/step - loss: 0.0475
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.043423/23 [==============================] - 0s 2ms/step - loss: 0.0407
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039323/23 [==============================] - 0s 1ms/step - loss: 0.0376
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.037023/23 [==============================] - 0s 1ms/step - loss: 0.0347
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029023/23 [==============================] - 0s 2ms/step - loss: 0.0320
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030523/23 [==============================] - 0s 1ms/step - loss: 0.0306
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030723/23 [==============================] - 0s 1ms/step - loss: 0.0299
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027623/23 [==============================] - 0s 1ms/step - loss: 0.0280
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026323/23 [==============================] - 0s 2ms/step - loss: 0.0264
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.023923/23 [==============================] - 0s 2ms/step - loss: 0.0251
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022523/23 [==============================] - 0s 2ms/step - loss: 0.0241
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020423/23 [==============================] - 0s 2ms/step - loss: 0.0224
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019123/23 [==============================] - 0s 2ms/step - loss: 0.0205
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020223/23 [==============================] - 0s 2ms/step - loss: 0.0197
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018323/23 [==============================] - 0s 2ms/step - loss: 0.0188
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017523/23 [==============================] - 0s 2ms/step - loss: 0.0186
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017623/23 [==============================] - 0s 2ms/step - loss: 0.0179
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016523/23 [==============================] - 0s 2ms/step - loss: 0.0174
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.013923/23 [==============================] - 0s 2ms/step - loss: 0.0168
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016223/23 [==============================] - 0s 2ms/step - loss: 0.0166
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016123/23 [==============================] - 0s 2ms/step - loss: 0.0166
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017223/23 [==============================] - 0s 2ms/step - loss: 0.0168
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015523/23 [==============================] - 0s 2ms/step - loss: 0.0163
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014823/23 [==============================] - 0s 2ms/step - loss: 0.0164
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019823/23 [==============================] - 0s 2ms/step - loss: 0.0166
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015223/23 [==============================] - 0s 2ms/step - loss: 0.0162
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015223/23 [==============================] - 0s 2ms/step - loss: 0.0162
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016823/23 [==============================] - 0s 2ms/step - loss: 0.0163
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016423/23 [==============================] - 0s 2ms/step - loss: 0.0162
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016823/23 [==============================] - 0s 2ms/step - loss: 0.0162
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014123/23 [==============================] - 0s 2ms/step - loss: 0.0154
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015623/23 [==============================] - 0s 2ms/step - loss: 0.0158
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017023/23 [==============================] - 0s 2ms/step - loss: 0.0158
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016923/23 [==============================] - 0s 2ms/step - loss: 0.0159
Epoch 41/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016923/23 [==============================] - 0s 2ms/step - loss: 0.0158
Epoch 42/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017323/23 [==============================] - 0s 2ms/step - loss: 0.0157
Epoch 43/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016023/23 [==============================] - 0s 2ms/step - loss: 0.0157
Epoch 44/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014223/23 [==============================] - 0s 2ms/step - loss: 0.0151
Epoch 45/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016023/23 [==============================] - 0s 2ms/step - loss: 0.0155
Epoch 46/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014823/23 [==============================] - 0s 2ms/step - loss: 0.0156
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running smooth
[get_model] Finished running smooth
Beta: -134471624.91689205  | Score: 0.0
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 4s - loss: 0.105823/23 [==============================] - 0s 1ms/step - loss: 0.1082
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.109723/23 [==============================] - 0s 1ms/step - loss: 0.1025
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.091923/23 [==============================] - 0s 1ms/step - loss: 0.0954
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.097923/23 [==============================] - 0s 1ms/step - loss: 0.0922
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.081923/23 [==============================] - 0s 1ms/step - loss: 0.0860
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.085623/23 [==============================] - 0s 2ms/step - loss: 0.0855
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.086523/23 [==============================] - 0s 1ms/step - loss: 0.0859
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.084123/23 [==============================] - 0s 1ms/step - loss: 0.0834
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.081423/23 [==============================] - 0s 1ms/step - loss: 0.0842
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.082123/23 [==============================] - 0s 1ms/step - loss: 0.0807
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.067923/23 [==============================] - 0s 1ms/step - loss: 0.0609
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.050823/23 [==============================] - 0s 1ms/step - loss: 0.0512
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.051623/23 [==============================] - 0s 1ms/step - loss: 0.0481
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.047523/23 [==============================] - 0s 1ms/step - loss: 0.0451
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044823/23 [==============================] - 0s 1ms/step - loss: 0.0433
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.043523/23 [==============================] - 0s 1ms/step - loss: 0.0432
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041823/23 [==============================] - 0s 1ms/step - loss: 0.0411
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041823/23 [==============================] - 0s 1ms/step - loss: 0.0403
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040023/23 [==============================] - 0s 1ms/step - loss: 0.0401
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038023/23 [==============================] - 0s 1ms/step - loss: 0.0385
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038323/23 [==============================] - 0s 1ms/step - loss: 0.0373
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038823/23 [==============================] - 0s 1ms/step - loss: 0.0366
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030823/23 [==============================] - 0s 1ms/step - loss: 0.0337
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034223/23 [==============================] - 0s 1ms/step - loss: 0.0326
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030523/23 [==============================] - 0s 1ms/step - loss: 0.0292
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027323/23 [==============================] - 0s 1ms/step - loss: 0.0272
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.032523/23 [==============================] - 0s 1ms/step - loss: 0.0271
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027423/23 [==============================] - 0s 1ms/step - loss: 0.0255
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026523/23 [==============================] - 0s 1ms/step - loss: 0.0245
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024823/23 [==============================] - 0s 1ms/step - loss: 0.0244
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027723/23 [==============================] - 0s 2ms/step - loss: 0.0247
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.023323/23 [==============================] - 0s 1ms/step - loss: 0.0239
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022323/23 [==============================] - 0s 2ms/step - loss: 0.0234
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.023923/23 [==============================] - 0s 2ms/step - loss: 0.0234
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025923/23 [==============================] - 0s 2ms/step - loss: 0.0234
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022423/23 [==============================] - 0s 2ms/step - loss: 0.0229
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026223/23 [==============================] - 0s 2ms/step - loss: 0.0232
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019823/23 [==============================] - 0s 2ms/step - loss: 0.0225
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.023523/23 [==============================] - 0s 2ms/step - loss: 0.0230
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019923/23 [==============================] - 0s 2ms/step - loss: 0.0219
Epoch 41/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022023/23 [==============================] - 0s 1ms/step - loss: 0.0225
Epoch 42/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022623/23 [==============================] - 0s 1ms/step - loss: 0.0223
Epoch 43/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022123/23 [==============================] - 0s 2ms/step - loss: 0.0222
Epoch 44/500
 1/23 [>.............................] - ETA: 0s - loss: 0.023923/23 [==============================] - 0s 1ms/step - loss: 0.0223
Epoch 45/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022223/23 [==============================] - 0s 2ms/step - loss: 0.0224
Epoch 46/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025723/23 [==============================] - 0s 1ms/step - loss: 0.0229
Epoch 47/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022723/23 [==============================] - 0s 1ms/step - loss: 0.0224
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
Beta: -73362763699.45815  | Score: 0.0
[get_model] Running smooth
[get_model] Finished running smooth
Beta: -489352944634.47253  | Score: 0.0
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_9 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 4s - loss: 0.052823/23 [==============================] - 0s 2ms/step - loss: 0.0524
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.051323/23 [==============================] - 0s 1ms/step - loss: 0.0509
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.050623/23 [==============================] - 0s 1ms/step - loss: 0.0500
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.049823/23 [==============================] - 0s 1ms/step - loss: 0.0495
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.050023/23 [==============================] - 0s 1ms/step - loss: 0.0487
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.048823/23 [==============================] - 0s 2ms/step - loss: 0.0481
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046223/23 [==============================] - 0s 2ms/step - loss: 0.0471
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.047823/23 [==============================] - 0s 2ms/step - loss: 0.0463
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045023/23 [==============================] - 0s 2ms/step - loss: 0.0454
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046623/23 [==============================] - 0s 1ms/step - loss: 0.0454
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044723/23 [==============================] - 0s 2ms/step - loss: 0.0454
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045623/23 [==============================] - 0s 2ms/step - loss: 0.0454
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045623/23 [==============================] - 0s 2ms/step - loss: 0.0453
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045823/23 [==============================] - 0s 2ms/step - loss: 0.0454
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046623/23 [==============================] - 0s 2ms/step - loss: 0.0452
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.043323/23 [==============================] - 0s 1ms/step - loss: 0.0451
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045923/23 [==============================] - 0s 1ms/step - loss: 0.0451
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044523/23 [==============================] - 0s 2ms/step - loss: 0.0449
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044523/23 [==============================] - 0s 2ms/step - loss: 0.0450
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
Beta: -2828625746954.3755  | Score: 0.6492602262837249
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_11 (InputLayer)        [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 4s - loss: 0.051323/23 [==============================] - 0s 2ms/step - loss: 0.0482
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039123/23 [==============================] - 0s 2ms/step - loss: 0.0359
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025923/23 [==============================] - 0s 2ms/step - loss: 0.0233
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016823/23 [==============================] - 0s 2ms/step - loss: 0.0140
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.010223/23 [==============================] - 0s 2ms/step - loss: 0.0107
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.011423/23 [==============================] - 0s 2ms/step - loss: 0.0109
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.012023/23 [==============================] - 0s 2ms/step - loss: 0.0113
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.010723/23 [==============================] - 0s 2ms/step - loss: 0.0103
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.011023/23 [==============================] - 0s 2ms/step - loss: 0.0104
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.010123/23 [==============================] - 0s 2ms/step - loss: 0.0101
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009723/23 [==============================] - 0s 2ms/step - loss: 0.0096
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.010123/23 [==============================] - 0s 1ms/step - loss: 0.0099
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007723/23 [==============================] - 0s 2ms/step - loss: 0.0086
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007023/23 [==============================] - 0s 2ms/step - loss: 0.0069
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006023/23 [==============================] - 0s 1ms/step - loss: 0.0058
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.005323/23 [==============================] - 0s 1ms/step - loss: 0.0053
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004623/23 [==============================] - 0s 2ms/step - loss: 0.0048
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004123/23 [==============================] - 0s 2ms/step - loss: 0.0044
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003423/23 [==============================] - 0s 2ms/step - loss: 0.0043
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003823/23 [==============================] - 0s 2ms/step - loss: 0.0041
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004323/23 [==============================] - 0s 2ms/step - loss: 0.0040
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003623/23 [==============================] - 0s 1ms/step - loss: 0.0039
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003023/23 [==============================] - 0s 2ms/step - loss: 0.0037
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003223/23 [==============================] - 0s 2ms/step - loss: 0.0038
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003723/23 [==============================] - 0s 2ms/step - loss: 0.0037
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003523/23 [==============================] - 0s 2ms/step - loss: 0.0036
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003823/23 [==============================] - 0s 2ms/step - loss: 0.0036
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003823/23 [==============================] - 0s 2ms/step - loss: 0.0035
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003423/23 [==============================] - 0s 1ms/step - loss: 0.0035
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002823/23 [==============================] - 0s 1ms/step - loss: 0.0034
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003123/23 [==============================] - 0s 1ms/step - loss: 0.0033
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
Beta: -6708899776054.348  | Score: 0.0
Accuracy: 0.6492602262837249
Time: 12.294971942901611

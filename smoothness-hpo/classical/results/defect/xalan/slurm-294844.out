2023-03-25 22:49:25.419884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
2023-03-25 22:49:31.795383: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-25 22:49:31.860434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-03-25 22:49:32.620351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.65GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2023-03-25 22:49:32.620403: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 22:49:32.760853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 22:49:32.760927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-25 22:49:32.818419: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-25 22:49:32.852043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-25 22:49:32.963270: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-03-25 22:49:33.012867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-25 22:49:33.022416: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-25 22:49:33.032419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-03-25 22:49:33.032866: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-25 22:49:33.034705: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-25 22:49:33.034943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.65GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2023-03-25 22:49:33.034963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 22:49:33.034976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 22:49:33.034987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-25 22:49:33.034998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-25 22:49:33.035009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-25 22:49:33.035019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-03-25 22:49:33.035029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-25 22:49:33.035039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-25 22:49:33.035370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-03-25 22:49:33.039177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 22:49:35.971443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-03-25 22:49:35.971868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2023-03-25 22:49:35.971877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2023-03-25 22:49:35.978874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7281 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:41:00.0, compute capability: 7.5)
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
2023-03-25 22:49:36.444421: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-03-25 22:49:36.479393: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2994580000 Hz
Epoch 1/500
2023-03-25 22:49:37.035931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 22:49:39.675491: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
 1/23 [>.............................] - ETA: 1:13 - loss: 0.050823/23 [==============================] - ETA: 0s - loss: 0.0487  23/23 [==============================] - 3s 2ms/step - loss: 0.0486
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040223/23 [==============================] - 0s 2ms/step - loss: 0.0381
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029623/23 [==============================] - 0s 2ms/step - loss: 0.0275
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019223/23 [==============================] - 0s 2ms/step - loss: 0.0174
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.013523/23 [==============================] - 0s 2ms/step - loss: 0.0114
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.012923/23 [==============================] - 0s 2ms/step - loss: 0.0101
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.011323/23 [==============================] - 0s 2ms/step - loss: 0.0093
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007823/23 [==============================] - 0s 2ms/step - loss: 0.0085
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007823/23 [==============================] - 0s 2ms/step - loss: 0.0083
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007323/23 [==============================] - 0s 2ms/step - loss: 0.0077
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007523/23 [==============================] - 0s 2ms/step - loss: 0.0077
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007423/23 [==============================] - 0s 2ms/step - loss: 0.0076
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009523/23 [==============================] - 0s 2ms/step - loss: 0.0078
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007523/23 [==============================] - 0s 2ms/step - loss: 0.0077
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006523/23 [==============================] - 0s 2ms/step - loss: 0.0075
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.008023/23 [==============================] - 0s 2ms/step - loss: 0.0077
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007323/23 [==============================] - 0s 2ms/step - loss: 0.0075
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006323/23 [==============================] - 0s 2ms/step - loss: 0.0073
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007623/23 [==============================] - 0s 2ms/step - loss: 0.0073
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.005823/23 [==============================] - 0s 2ms/step - loss: 0.0070
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007923/23 [==============================] - 0s 2ms/step - loss: 0.0075
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007923/23 [==============================] - 0s 2ms/step - loss: 0.0073
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.005423/23 [==============================] - 0s 2ms/step - loss: 0.0071
[get_model] Fit autoencoder
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 6s - loss: 0.052823/23 [==============================] - 0s 2ms/step - loss: 0.0526
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.049723/23 [==============================] - 0s 2ms/step - loss: 0.0488
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.043823/23 [==============================] - 0s 2ms/step - loss: 0.0417
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.035723/23 [==============================] - 0s 2ms/step - loss: 0.0333
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025323/23 [==============================] - 0s 2ms/step - loss: 0.0224
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.013423/23 [==============================] - 0s 2ms/step - loss: 0.0112
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009623/23 [==============================] - 0s 2ms/step - loss: 0.0094
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.010123/23 [==============================] - 0s 2ms/step - loss: 0.0093
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.008423/23 [==============================] - 0s 2ms/step - loss: 0.0089
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009523/23 [==============================] - 0s 2ms/step - loss: 0.0088
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009823/23 [==============================] - 0s 2ms/step - loss: 0.0085
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.008223/23 [==============================] - 0s 2ms/step - loss: 0.0081
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007423/23 [==============================] - 0s 2ms/step - loss: 0.0073
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006623/23 [==============================] - 0s 2ms/step - loss: 0.0068
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006923/23 [==============================] - 0s 2ms/step - loss: 0.0063
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.005623/23 [==============================] - 0s 2ms/step - loss: 0.0058
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.005423/23 [==============================] - 0s 2ms/step - loss: 0.0052
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004923/23 [==============================] - 0s 2ms/step - loss: 0.0047
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004323/23 [==============================] - 0s 2ms/step - loss: 0.0045
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004423/23 [==============================] - 0s 2ms/step - loss: 0.0042
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004623/23 [==============================] - 0s 2ms/step - loss: 0.0041
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003823/23 [==============================] - 0s 2ms/step - loss: 0.0040
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004523/23 [==============================] - 0s 2ms/step - loss: 0.0041
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004823/23 [==============================] - 0s 2ms/step - loss: 0.0040
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.005023/23 [==============================] - 0s 2ms/step - loss: 0.0040
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004523/23 [==============================] - 0s 2ms/step - loss: 0.0040
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004323/23 [==============================] - 0s 2ms/step - loss: 0.0039
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004023/23 [==============================] - 0s 2ms/step - loss: 0.0038
[get_model] Fit autoencoder
Beta: 0  | Score: 0.682526661197703
[get_model] Running smooth
[get_model] Finished running smooth
Beta: -82597945.59028146  | Score: 0.0
[get_model] Running smooth
[get_model] Finished running smooth
Beta: -489352944634.47253  | Score: 0.0
[get_model] Running smooth
[get_model] Finished running smooth
Beta: -1044294233546.4435  | Score: 0.0
[get_model] Running wfo
[get_model] Finished running wfo
Beta: -99535879874243.36  | Score: 0.5362853628536286
Accuracy: 0.682526661197703
Time: 11.862187623977661

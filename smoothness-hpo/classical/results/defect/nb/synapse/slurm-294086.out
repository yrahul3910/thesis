2023-03-22 21:16:26.301274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
2023-03-22 21:16:42.984631: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-22 21:16:43.042694: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-03-22 21:16:43.974561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:af:00.0 name: Quadro P4000 computeCapability: 6.1
coreClock: 1.48GHz coreCount: 14 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 226.62GiB/s
2023-03-22 21:16:43.974637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-22 21:16:44.095237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-22 21:16:44.095427: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-22 21:16:44.147142: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-22 21:16:44.179241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-22 21:16:44.281174: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-03-22 21:16:44.332790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-22 21:16:44.346552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-22 21:16:44.365926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-03-22 21:16:44.366961: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-22 21:16:44.368324: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-22 21:16:44.368688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:af:00.0 name: Quadro P4000 computeCapability: 6.1
coreClock: 1.48GHz coreCount: 14 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 226.62GiB/s
2023-03-22 21:16:44.368729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-22 21:16:44.368754: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-22 21:16:44.368774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-22 21:16:44.368793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-22 21:16:44.368811: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-22 21:16:44.368829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-03-22 21:16:44.368847: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-22 21:16:44.368865: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-22 21:16:44.369248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-03-22 21:16:44.379105: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-22 21:16:47.196689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-03-22 21:16:47.196752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2023-03-22 21:16:47.196765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2023-03-22 21:16:47.208192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7450 MB memory) -> physical GPU (device: 0, name: Quadro P4000, pci bus id: 0000:af:00.0, compute capability: 6.1)
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
2023-03-22 21:16:47.904430: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-03-22 21:16:47.961730: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
Epoch 1/500
2023-03-22 21:16:48.765132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-22 21:16:51.006240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
1/6 [====>.........................] - ETA: 15s - loss: 0.05396/6 [==============================] - 3s 4ms/step - loss: 0.0531
Epoch 2/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05136/6 [==============================] - 0s 3ms/step - loss: 0.0502
Epoch 3/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04766/6 [==============================] - 0s 3ms/step - loss: 0.0467
Epoch 4/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04426/6 [==============================] - 0s 3ms/step - loss: 0.0433
Epoch 5/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04036/6 [==============================] - 0s 3ms/step - loss: 0.0397
Epoch 6/500
1/6 [====>.........................] - ETA: 0s - loss: 0.03746/6 [==============================] - 0s 3ms/step - loss: 0.0361
Epoch 7/500
1/6 [====>.........................] - ETA: 0s - loss: 0.03326/6 [==============================] - 0s 3ms/step - loss: 0.0321
Epoch 8/500
1/6 [====>.........................] - ETA: 0s - loss: 0.02936/6 [==============================] - 0s 3ms/step - loss: 0.0285
Epoch 9/500
1/6 [====>.........................] - ETA: 0s - loss: 0.02506/6 [==============================] - 0s 3ms/step - loss: 0.0250
Epoch 10/500
1/6 [====>.........................] - ETA: 0s - loss: 0.02256/6 [==============================] - 0s 3ms/step - loss: 0.0219
Epoch 11/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01866/6 [==============================] - 0s 3ms/step - loss: 0.0187
Epoch 12/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01656/6 [==============================] - 0s 3ms/step - loss: 0.0160
Epoch 13/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01406/6 [==============================] - 0s 3ms/step - loss: 0.0135
Epoch 14/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01316/6 [==============================] - 0s 3ms/step - loss: 0.0118
Epoch 15/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01126/6 [==============================] - 0s 3ms/step - loss: 0.0102
Epoch 16/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01006/6 [==============================] - 0s 3ms/step - loss: 0.0090
Epoch 17/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00796/6 [==============================] - 0s 3ms/step - loss: 0.0080
Epoch 18/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00646/6 [==============================] - 0s 3ms/step - loss: 0.0073
Epoch 19/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00496/6 [==============================] - 0s 3ms/step - loss: 0.0066
Epoch 20/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00626/6 [==============================] - 0s 3ms/step - loss: 0.0068
Epoch 21/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00576/6 [==============================] - 0s 3ms/step - loss: 0.0066
Epoch 22/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00686/6 [==============================] - 0s 3ms/step - loss: 0.0067
Epoch 23/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00706/6 [==============================] - 0s 3ms/step - loss: 0.0064
Epoch 24/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00576/6 [==============================] - 0s 3ms/step - loss: 0.0060
Epoch 25/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00546/6 [==============================] - 0s 3ms/step - loss: 0.0061
Epoch 26/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00606/6 [==============================] - 0s 3ms/step - loss: 0.0060
Epoch 27/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00686/6 [==============================] - 0s 3ms/step - loss: 0.0062
Epoch 28/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00596/6 [==============================] - 0s 3ms/step - loss: 0.0059
Epoch 29/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00496/6 [==============================] - 0s 3ms/step - loss: 0.0059
Epoch 30/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00576/6 [==============================] - 0s 3ms/step - loss: 0.0058
Epoch 31/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00736/6 [==============================] - 0s 3ms/step - loss: 0.0064
Epoch 32/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00516/6 [==============================] - 0s 3ms/step - loss: 0.0057
Epoch 33/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00666/6 [==============================] - 0s 3ms/step - loss: 0.0060
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
1/6 [====>.........................] - ETA: 1s - loss: 0.05386/6 [==============================] - 0s 3ms/step - loss: 0.0533
Epoch 2/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05346/6 [==============================] - 0s 3ms/step - loss: 0.0530
Epoch 3/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05336/6 [==============================] - 0s 3ms/step - loss: 0.0529
Epoch 4/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05286/6 [==============================] - 0s 3ms/step - loss: 0.0526
Epoch 5/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05296/6 [==============================] - 0s 3ms/step - loss: 0.0526
Epoch 6/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05286/6 [==============================] - 0s 3ms/step - loss: 0.0524
Epoch 7/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05306/6 [==============================] - 0s 3ms/step - loss: 0.0523
Epoch 8/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05166/6 [==============================] - 0s 3ms/step - loss: 0.0516
Epoch 9/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05216/6 [==============================] - 0s 3ms/step - loss: 0.0516
Epoch 10/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05196/6 [==============================] - 0s 4ms/step - loss: 0.0513
Epoch 11/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05076/6 [==============================] - 0s 3ms/step - loss: 0.0507
Epoch 12/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05096/6 [==============================] - 0s 4ms/step - loss: 0.0505
Epoch 13/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04926/6 [==============================] - 0s 4ms/step - loss: 0.0498
Epoch 14/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05046/6 [==============================] - 0s 4ms/step - loss: 0.0499
Epoch 15/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05016/6 [==============================] - 0s 4ms/step - loss: 0.0499
Epoch 16/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05006/6 [==============================] - 0s 4ms/step - loss: 0.0497
Epoch 17/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04996/6 [==============================] - 0s 4ms/step - loss: 0.0497
Epoch 18/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04896/6 [==============================] - 0s 4ms/step - loss: 0.0492
Epoch 19/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04836/6 [==============================] - 0s 4ms/step - loss: 0.0492
Epoch 20/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04956/6 [==============================] - 0s 4ms/step - loss: 0.0494
Epoch 21/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04846/6 [==============================] - 0s 3ms/step - loss: 0.0490
Epoch 22/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04956/6 [==============================] - 0s 3ms/step - loss: 0.0493
Epoch 23/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04926/6 [==============================] - 0s 4ms/step - loss: 0.0493
Epoch 24/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04966/6 [==============================] - 0s 3ms/step - loss: 0.0492
Epoch 25/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04846/6 [==============================] - 0s 4ms/step - loss: 0.0491
Epoch 26/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04976/6 [==============================] - 0s 4ms/step - loss: 0.0491
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
1/6 [====>.........................] - ETA: 1s - loss: 0.05296/6 [==============================] - 0s 3ms/step - loss: 0.0529
Epoch 2/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05196/6 [==============================] - 0s 3ms/step - loss: 0.0521
Epoch 3/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05186/6 [==============================] - 0s 3ms/step - loss: 0.0517
Epoch 4/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05126/6 [==============================] - 0s 3ms/step - loss: 0.0511
Epoch 5/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05046/6 [==============================] - 0s 4ms/step - loss: 0.0506
Epoch 6/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05096/6 [==============================] - 0s 3ms/step - loss: 0.0505
Epoch 7/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04976/6 [==============================] - 0s 3ms/step - loss: 0.0499
Epoch 8/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04946/6 [==============================] - 0s 4ms/step - loss: 0.0495
Epoch 9/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04956/6 [==============================] - 0s 3ms/step - loss: 0.0492
Epoch 10/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04906/6 [==============================] - 0s 3ms/step - loss: 0.0490
Epoch 11/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04996/6 [==============================] - 0s 5ms/step - loss: 0.0490
Epoch 12/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04906/6 [==============================] - 0s 4ms/step - loss: 0.0483
Epoch 13/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04946/6 [==============================] - 0s 3ms/step - loss: 0.0485
Epoch 14/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04836/6 [==============================] - 0s 3ms/step - loss: 0.0482
Epoch 15/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04726/6 [==============================] - 0s 3ms/step - loss: 0.0478
Epoch 16/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04796/6 [==============================] - 0s 4ms/step - loss: 0.0477
Epoch 17/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04716/6 [==============================] - 0s 4ms/step - loss: 0.0476
Epoch 18/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04746/6 [==============================] - 0s 4ms/step - loss: 0.0477
Epoch 19/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04626/6 [==============================] - 0s 3ms/step - loss: 0.0472
Epoch 20/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04686/6 [==============================] - 0s 4ms/step - loss: 0.0470
Epoch 21/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04826/6 [==============================] - 0s 3ms/step - loss: 0.0477
Epoch 22/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04886/6 [==============================] - 0s 3ms/step - loss: 0.0476
Epoch 23/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04876/6 [==============================] - 0s 4ms/step - loss: 0.0477
Epoch 24/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04696/6 [==============================] - 0s 3ms/step - loss: 0.0471
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
Beta: 0  | Score: 0.024390243902439022
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
1/6 [====>.........................] - ETA: 1s - loss: 0.05086/6 [==============================] - 0s 3ms/step - loss: 0.0499
Epoch 2/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04716/6 [==============================] - 0s 3ms/step - loss: 0.0461
Epoch 3/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04306/6 [==============================] - 0s 4ms/step - loss: 0.0423
Epoch 4/500
1/6 [====>.........................] - ETA: 0s - loss: 0.03966/6 [==============================] - 0s 3ms/step - loss: 0.0386
Epoch 5/500
1/6 [====>.........................] - ETA: 0s - loss: 0.03546/6 [==============================] - 0s 3ms/step - loss: 0.0345
Epoch 6/500
1/6 [====>.........................] - ETA: 0s - loss: 0.03086/6 [==============================] - 0s 4ms/step - loss: 0.0305
Epoch 7/500
1/6 [====>.........................] - ETA: 0s - loss: 0.02796/6 [==============================] - 0s 4ms/step - loss: 0.0269
Epoch 8/500
1/6 [====>.........................] - ETA: 0s - loss: 0.02476/6 [==============================] - 0s 4ms/step - loss: 0.0233
Epoch 9/500
1/6 [====>.........................] - ETA: 0s - loss: 0.02036/6 [==============================] - 0s 3ms/step - loss: 0.0198
Epoch 10/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01786/6 [==============================] - 0s 3ms/step - loss: 0.0166
Epoch 11/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01326/6 [==============================] - 0s 3ms/step - loss: 0.0131
Epoch 12/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01126/6 [==============================] - 0s 3ms/step - loss: 0.0106
Epoch 13/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00966/6 [==============================] - 0s 4ms/step - loss: 0.0087
Epoch 14/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00826/6 [==============================] - 0s 4ms/step - loss: 0.0072
Epoch 15/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00606/6 [==============================] - 0s 4ms/step - loss: 0.0063
Epoch 16/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00506/6 [==============================] - 0s 4ms/step - loss: 0.0057
Epoch 17/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00566/6 [==============================] - 0s 3ms/step - loss: 0.0058
Epoch 18/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00506/6 [==============================] - 0s 3ms/step - loss: 0.0054
Epoch 19/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00456/6 [==============================] - 0s 3ms/step - loss: 0.0051
Epoch 20/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00506/6 [==============================] - 0s 4ms/step - loss: 0.0056
Epoch 21/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00706/6 [==============================] - 0s 3ms/step - loss: 0.0056
Epoch 22/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00516/6 [==============================] - 0s 3ms/step - loss: 0.0052
Epoch 23/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00486/6 [==============================] - 0s 3ms/step - loss: 0.0049
Epoch 24/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00366/6 [==============================] - 0s 4ms/step - loss: 0.0046
Epoch 25/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00436/6 [==============================] - 0s 3ms/step - loss: 0.0046
Epoch 26/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00586/6 [==============================] - 0s 3ms/step - loss: 0.0052
Epoch 27/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00446/6 [==============================] - 0s 3ms/step - loss: 0.0045
Epoch 28/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00466/6 [==============================] - 0s 3ms/step - loss: 0.0048
Epoch 29/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00416/6 [==============================] - 0s 3ms/step - loss: 0.0048
Epoch 30/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00426/6 [==============================] - 0s 3ms/step - loss: 0.0046
Epoch 31/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00356/6 [==============================] - 0s 4ms/step - loss: 0.0045
Epoch 32/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00506/6 [==============================] - 0s 4ms/step - loss: 0.0046
Epoch 33/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00436/6 [==============================] - 0s 4ms/step - loss: 0.0046
Epoch 34/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00496/6 [==============================] - 0s 4ms/step - loss: 0.0046
Epoch 35/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00396/6 [==============================] - 0s 4ms/step - loss: 0.0043
Epoch 36/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00546/6 [==============================] - 0s 4ms/step - loss: 0.0047
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
Beta: 0  | Score: 0.23404255319148934
Beta: -693455979.346717  | Score: 0.5029940119760479
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running wfo
[get_model] Finished running wfo
Beta: -2813371850166.219  | Score: 0.0
Beta: -3159951820148.6455  | Score: 0.509090909090909
Accuracy: 0.509090909090909
Time: 13.471140384674072

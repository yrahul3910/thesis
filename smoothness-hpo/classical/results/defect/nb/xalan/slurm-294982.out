2023-03-26 19:17:22.411180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
2023-03-26 19:17:26.732774: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-26 19:17:26.737478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-03-26 19:17:31.300069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6
coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.54GiB deviceMemoryBandwidth: 715.34GiB/s
2023-03-26 19:17:31.300667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6
coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.54GiB deviceMemoryBandwidth: 715.34GiB/s
2023-03-26 19:17:31.300887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:81:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6
coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.54GiB deviceMemoryBandwidth: 715.34GiB/s
2023-03-26 19:17:31.301101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:c1:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6
coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.54GiB deviceMemoryBandwidth: 715.34GiB/s
2023-03-26 19:17:31.301121: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-26 19:17:31.312758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-26 19:17:31.312812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-26 19:17:31.319829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-26 19:17:31.322364: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-26 19:17:31.332766: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2023-03-26 19:17:31.335467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-26 19:17:31.336459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-26 19:17:31.339349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2023-03-26 19:17:31.339771: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-26 19:17:31.343182: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-26 19:17:31.567413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6
coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.54GiB deviceMemoryBandwidth: 715.34GiB/s
2023-03-26 19:17:31.567629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6
coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.54GiB deviceMemoryBandwidth: 715.34GiB/s
2023-03-26 19:17:31.567820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:81:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6
coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.54GiB deviceMemoryBandwidth: 715.34GiB/s
2023-03-26 19:17:31.568008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:c1:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6
coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.54GiB deviceMemoryBandwidth: 715.34GiB/s
2023-03-26 19:17:31.568045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-26 19:17:31.568063: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-26 19:17:31.568072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-26 19:17:31.568080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-26 19:17:31.568089: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-26 19:17:31.568097: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2023-03-26 19:17:31.568105: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-26 19:17:31.568114: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-26 19:17:31.569405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2023-03-26 19:17:31.569732: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-26 19:17:32.771077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-03-26 19:17:32.771118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 
2023-03-26 19:17:32.771133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y Y Y 
2023-03-26 19:17:32.771136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N Y Y 
2023-03-26 19:17:32.771139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   Y Y N Y 
2023-03-26 19:17:32.771141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   Y Y Y N 
2023-03-26 19:17:32.773043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 45377 MB memory) -> physical GPU (device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6)
2023-03-26 19:17:32.774978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 45377 MB memory) -> physical GPU (device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6)
2023-03-26 19:17:32.775602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 45377 MB memory) -> physical GPU (device: 2, name: NVIDIA RTX A6000, pci bus id: 0000:81:00.0, compute capability: 8.6)
2023-03-26 19:17:32.776244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 45377 MB memory) -> physical GPU (device: 3, name: NVIDIA RTX A6000, pci bus id: 0000:c1:00.0, compute capability: 8.6)
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
2023-03-26 19:17:33.211546: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-03-26 19:17:33.226790: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2794825000 Hz
Epoch 1/500
2023-03-26 19:17:33.505827: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-26 19:17:34.245426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-26 19:17:34.255157: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
 1/23 [>.............................] - ETA: 22s - loss: 0.105223/23 [==============================] - 1s 2ms/step - loss: 0.1028
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.092723/23 [==============================] - 0s 2ms/step - loss: 0.0853
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.076423/23 [==============================] - 0s 2ms/step - loss: 0.0747
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.070723/23 [==============================] - 0s 2ms/step - loss: 0.0703
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.072423/23 [==============================] - 0s 2ms/step - loss: 0.0670
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.067423/23 [==============================] - 0s 2ms/step - loss: 0.0641
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.067423/23 [==============================] - 0s 2ms/step - loss: 0.0568
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046423/23 [==============================] - 0s 2ms/step - loss: 0.0485
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039323/23 [==============================] - 0s 2ms/step - loss: 0.0430
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.042223/23 [==============================] - 0s 2ms/step - loss: 0.0414
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040423/23 [==============================] - 0s 2ms/step - loss: 0.0395
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039523/23 [==============================] - 0s 2ms/step - loss: 0.0380
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038423/23 [==============================] - 0s 2ms/step - loss: 0.0371
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.043223/23 [==============================] - 0s 2ms/step - loss: 0.0364
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039223/23 [==============================] - 0s 2ms/step - loss: 0.0352
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034423/23 [==============================] - 0s 2ms/step - loss: 0.0343
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.028723/23 [==============================] - 0s 2ms/step - loss: 0.0326
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.032023/23 [==============================] - 0s 2ms/step - loss: 0.0324
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029923/23 [==============================] - 0s 2ms/step - loss: 0.0324
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030323/23 [==============================] - 0s 2ms/step - loss: 0.0315
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034423/23 [==============================] - 0s 2ms/step - loss: 0.0309
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027823/23 [==============================] - 0s 2ms/step - loss: 0.0298
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029323/23 [==============================] - 0s 2ms/step - loss: 0.0295
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031423/23 [==============================] - 0s 2ms/step - loss: 0.0292
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.028123/23 [==============================] - 0s 2ms/step - loss: 0.0284
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030723/23 [==============================] - 0s 2ms/step - loss: 0.0290
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029723/23 [==============================] - 0s 2ms/step - loss: 0.0270
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019123/23 [==============================] - 0s 2ms/step - loss: 0.0208
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019423/23 [==============================] - 0s 2ms/step - loss: 0.0198
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020623/23 [==============================] - 0s 2ms/step - loss: 0.0200
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020023/23 [==============================] - 0s 2ms/step - loss: 0.0206
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019323/23 [==============================] - 0s 2ms/step - loss: 0.0200
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.023523/23 [==============================] - 0s 2ms/step - loss: 0.0202
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021023/23 [==============================] - 0s 2ms/step - loss: 0.0196
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022423/23 [==============================] - 0s 2ms/step - loss: 0.0199
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018023/23 [==============================] - 0s 2ms/step - loss: 0.0192
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018623/23 [==============================] - 0s 2ms/step - loss: 0.0190
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021423/23 [==============================] - 0s 2ms/step - loss: 0.0192
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017423/23 [==============================] - 0s 2ms/step - loss: 0.0184
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022723/23 [==============================] - 0s 2ms/step - loss: 0.0189
Epoch 41/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018423/23 [==============================] - 0s 2ms/step - loss: 0.0189
Epoch 42/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018423/23 [==============================] - 0s 2ms/step - loss: 0.0186
Epoch 43/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017823/23 [==============================] - 0s 2ms/step - loss: 0.0184
Epoch 44/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017523/23 [==============================] - 0s 2ms/step - loss: 0.0188
Epoch 45/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017223/23 [==============================] - 0s 2ms/step - loss: 0.0177
Epoch 46/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016823/23 [==============================] - 0s 2ms/step - loss: 0.0185
Epoch 47/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019923/23 [==============================] - 0s 2ms/step - loss: 0.0181
Epoch 48/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016823/23 [==============================] - 0s 2ms/step - loss: 0.0172
Epoch 49/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016323/23 [==============================] - 0s 2ms/step - loss: 0.0177
Epoch 50/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014923/23 [==============================] - 0s 2ms/step - loss: 0.0173
Epoch 51/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018423/23 [==============================] - 0s 2ms/step - loss: 0.0172
Epoch 52/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017123/23 [==============================] - 0s 2ms/step - loss: 0.0174
Epoch 53/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017123/23 [==============================] - 0s 2ms/step - loss: 0.0168
Epoch 54/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015823/23 [==============================] - 0s 2ms/step - loss: 0.0167
Epoch 55/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015823/23 [==============================] - 0s 2ms/step - loss: 0.0166
Epoch 56/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014423/23 [==============================] - 0s 2ms/step - loss: 0.0160
Epoch 57/500
 1/23 [>.............................] - ETA: 0s - loss: 0.013923/23 [==============================] - 0s 2ms/step - loss: 0.0161
Epoch 58/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014323/23 [==============================] - 0s 2ms/step - loss: 0.0162
Epoch 59/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017523/23 [==============================] - 0s 2ms/step - loss: 0.0166
Epoch 60/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016523/23 [==============================] - 0s 2ms/step - loss: 0.0159
Epoch 61/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014823/23 [==============================] - 0s 2ms/step - loss: 0.0160
Epoch 62/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014323/23 [==============================] - 0s 2ms/step - loss: 0.0156
Epoch 63/500
 1/23 [>.............................] - ETA: 0s - loss: 0.012423/23 [==============================] - 0s 2ms/step - loss: 0.0152
Epoch 64/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017423/23 [==============================] - 0s 2ms/step - loss: 0.0159
Epoch 65/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016123/23 [==============================] - 0s 2ms/step - loss: 0.0156
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 4s - loss: 0.106723/23 [==============================] - 0s 1ms/step - loss: 0.0976
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.074723/23 [==============================] - 0s 1ms/step - loss: 0.0756
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.069223/23 [==============================] - 0s 1ms/step - loss: 0.0633
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.057523/23 [==============================] - 0s 984us/step - loss: 0.0587
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.059423/23 [==============================] - 0s 999us/step - loss: 0.0586
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.053423/23 [==============================] - 0s 957us/step - loss: 0.0554
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.052323/23 [==============================] - 0s 964us/step - loss: 0.0537
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.054823/23 [==============================] - 0s 982us/step - loss: 0.0524
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044923/23 [==============================] - 0s 982us/step - loss: 0.0489
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.049623/23 [==============================] - 0s 1ms/step - loss: 0.0480
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044423/23 [==============================] - 0s 1ms/step - loss: 0.0460
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.042523/23 [==============================] - 0s 994us/step - loss: 0.0443
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.049423/23 [==============================] - 0s 1ms/step - loss: 0.0444
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040023/23 [==============================] - 0s 1ms/step - loss: 0.0424
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044123/23 [==============================] - 0s 1ms/step - loss: 0.0428
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046223/23 [==============================] - 0s 1ms/step - loss: 0.0434
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040923/23 [==============================] - 0s 1ms/step - loss: 0.0414
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.035023/23 [==============================] - 0s 1ms/step - loss: 0.0408
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.042123/23 [==============================] - 0s 1ms/step - loss: 0.0328
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031123/23 [==============================] - 0s 2ms/step - loss: 0.0289
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.028223/23 [==============================] - 0s 2ms/step - loss: 0.0272
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021823/23 [==============================] - 0s 2ms/step - loss: 0.0251
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025523/23 [==============================] - 0s 2ms/step - loss: 0.0257
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027623/23 [==============================] - 0s 2ms/step - loss: 0.0251
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026723/23 [==============================] - 0s 2ms/step - loss: 0.0245
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027723/23 [==============================] - 0s 2ms/step - loss: 0.0237
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024323/23 [==============================] - 0s 2ms/step - loss: 0.0230
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020123/23 [==============================] - 0s 1ms/step - loss: 0.0227
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022223/23 [==============================] - 0s 1ms/step - loss: 0.0220
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021523/23 [==============================] - 0s 1ms/step - loss: 0.0216
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017323/23 [==============================] - 0s 1ms/step - loss: 0.0215
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019923/23 [==============================] - 0s 1ms/step - loss: 0.0208
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018623/23 [==============================] - 0s 1ms/step - loss: 0.0205
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019123/23 [==============================] - 0s 2ms/step - loss: 0.0210
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.023523/23 [==============================] - 0s 2ms/step - loss: 0.0203
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025323/23 [==============================] - 0s 2ms/step - loss: 0.0209
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019023/23 [==============================] - 0s 2ms/step - loss: 0.0197
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020923/23 [==============================] - 0s 2ms/step - loss: 0.0196
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022423/23 [==============================] - 0s 2ms/step - loss: 0.0202
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017723/23 [==============================] - 0s 2ms/step - loss: 0.0190
Epoch 41/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025023/23 [==============================] - 0s 2ms/step - loss: 0.0198
Epoch 42/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018923/23 [==============================] - 0s 2ms/step - loss: 0.0193
Epoch 43/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022823/23 [==============================] - 0s 2ms/step - loss: 0.0196
Epoch 44/500
 1/23 [>.............................] - ETA: 0s - loss: 0.013923/23 [==============================] - 0s 2ms/step - loss: 0.0177
Epoch 45/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017023/23 [==============================] - 0s 2ms/step - loss: 0.0183
Epoch 46/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017023/23 [==============================] - 0s 2ms/step - loss: 0.0189
Epoch 47/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019823/23 [==============================] - 0s 2ms/step - loss: 0.0189
Epoch 48/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016623/23 [==============================] - 0s 2ms/step - loss: 0.0178
Epoch 49/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018523/23 [==============================] - 0s 2ms/step - loss: 0.0182
Epoch 50/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020923/23 [==============================] - 0s 2ms/step - loss: 0.0184
Epoch 51/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018623/23 [==============================] - 0s 2ms/step - loss: 0.0179
Epoch 52/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015223/23 [==============================] - 0s 2ms/step - loss: 0.0171
Epoch 53/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020723/23 [==============================] - 0s 1ms/step - loss: 0.0184
Epoch 54/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015923/23 [==============================] - 0s 1ms/step - loss: 0.0172
Epoch 55/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015223/23 [==============================] - 0s 1ms/step - loss: 0.0174
Epoch 56/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015623/23 [==============================] - 0s 1ms/step - loss: 0.0169
Epoch 57/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016323/23 [==============================] - 0s 1ms/step - loss: 0.0172
Epoch 58/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018223/23 [==============================] - 0s 1ms/step - loss: 0.0175
Epoch 59/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019023/23 [==============================] - 0s 1ms/step - loss: 0.0174
Epoch 60/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021223/23 [==============================] - 0s 1ms/step - loss: 0.0179
Epoch 61/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020523/23 [==============================] - 0s 2ms/step - loss: 0.0177
[get_model] Fit autoencoder
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 4s - loss: 0.104423/23 [==============================] - 0s 1ms/step - loss: 0.1025
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.087023/23 [==============================] - 0s 1ms/step - loss: 0.0796
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.069123/23 [==============================] - 0s 1ms/step - loss: 0.0637
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.055023/23 [==============================] - 0s 1ms/step - loss: 0.0529
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.049423/23 [==============================] - 0s 1ms/step - loss: 0.0500
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045223/23 [==============================] - 0s 1ms/step - loss: 0.0473
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.047123/23 [==============================] - 0s 1ms/step - loss: 0.0477
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.049623/23 [==============================] - 0s 1ms/step - loss: 0.0467
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046223/23 [==============================] - 0s 2ms/step - loss: 0.0449
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045723/23 [==============================] - 0s 2ms/step - loss: 0.0444
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044723/23 [==============================] - 0s 2ms/step - loss: 0.0427
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040323/23 [==============================] - 0s 2ms/step - loss: 0.0390
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041023/23 [==============================] - 0s 2ms/step - loss: 0.0374
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036523/23 [==============================] - 0s 2ms/step - loss: 0.0346
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031423/23 [==============================] - 0s 2ms/step - loss: 0.0330
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029423/23 [==============================] - 0s 2ms/step - loss: 0.0308
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029223/23 [==============================] - 0s 2ms/step - loss: 0.0308
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.028223/23 [==============================] - 0s 2ms/step - loss: 0.0300
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.023223/23 [==============================] - 0s 2ms/step - loss: 0.0281
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025323/23 [==============================] - 0s 2ms/step - loss: 0.0287
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027423/23 [==============================] - 0s 1ms/step - loss: 0.0287
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029823/23 [==============================] - 0s 2ms/step - loss: 0.0290
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026123/23 [==============================] - 0s 2ms/step - loss: 0.0275
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.032123/23 [==============================] - 0s 2ms/step - loss: 0.0287
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027223/23 [==============================] - 0s 2ms/step - loss: 0.0277
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031223/23 [==============================] - 0s 2ms/step - loss: 0.0277
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026123/23 [==============================] - 0s 2ms/step - loss: 0.0260
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022723/23 [==============================] - 0s 2ms/step - loss: 0.0256
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025423/23 [==============================] - 0s 2ms/step - loss: 0.0253
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027023/23 [==============================] - 0s 2ms/step - loss: 0.0249
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020223/23 [==============================] - 0s 2ms/step - loss: 0.0235
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027023/23 [==============================] - 0s 2ms/step - loss: 0.0237
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021323/23 [==============================] - 0s 2ms/step - loss: 0.0224
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019323/23 [==============================] - 0s 2ms/step - loss: 0.0219
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026623/23 [==============================] - 0s 2ms/step - loss: 0.0228
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018123/23 [==============================] - 0s 2ms/step - loss: 0.0218
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024123/23 [==============================] - 0s 2ms/step - loss: 0.0225
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.023923/23 [==============================] - 0s 2ms/step - loss: 0.0215
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017123/23 [==============================] - 0s 2ms/step - loss: 0.0207
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026223/23 [==============================] - 0s 2ms/step - loss: 0.0223
Epoch 41/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020923/23 [==============================] - 0s 2ms/step - loss: 0.0212
Epoch 42/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020723/23 [==============================] - 0s 2ms/step - loss: 0.0213
Epoch 43/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021323/23 [==============================] - 0s 2ms/step - loss: 0.0211
Epoch 44/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024323/23 [==============================] - 0s 2ms/step - loss: 0.0206
Epoch 45/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019323/23 [==============================] - 0s 2ms/step - loss: 0.0182
Epoch 46/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017623/23 [==============================] - 0s 2ms/step - loss: 0.0172
Epoch 47/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019523/23 [==============================] - 0s 2ms/step - loss: 0.0173
Epoch 48/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018423/23 [==============================] - 0s 2ms/step - loss: 0.0174
Epoch 49/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018223/23 [==============================] - 0s 2ms/step - loss: 0.0172
Epoch 50/500
 1/23 [>.............................] - ETA: 0s - loss: 0.013423/23 [==============================] - 0s 2ms/step - loss: 0.0166
Epoch 51/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020323/23 [==============================] - 0s 2ms/step - loss: 0.0177
Epoch 52/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015923/23 [==============================] - 0s 2ms/step - loss: 0.0172
Epoch 53/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016623/23 [==============================] - 0s 2ms/step - loss: 0.0165
Epoch 54/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014623/23 [==============================] - 0s 2ms/step - loss: 0.0166
Epoch 55/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018523/23 [==============================] - 0s 2ms/step - loss: 0.0172
Epoch 56/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017623/23 [==============================] - 0s 2ms/step - loss: 0.0170
Epoch 57/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015723/23 [==============================] - 0s 2ms/step - loss: 0.0161
Epoch 58/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019623/23 [==============================] - 0s 2ms/step - loss: 0.0171
Epoch 59/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016223/23 [==============================] - 0s 2ms/step - loss: 0.0161
Epoch 60/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014823/23 [==============================] - 0s 2ms/step - loss: 0.0165
Epoch 61/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015923/23 [==============================] - 0s 2ms/step - loss: 0.0167
Epoch 62/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016223/23 [==============================] - 0s 2ms/step - loss: 0.0167
Epoch 63/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015823/23 [==============================] - 0s 2ms/step - loss: 0.0164
Epoch 64/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014023/23 [==============================] - 0s 2ms/step - loss: 0.0167
Epoch 65/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016323/23 [==============================] - 0s 2ms/step - loss: 0.0166
[get_model] Fit autoencoder
Beta: 0  | Score: 0.5919003115264798
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running wfo
[get_model] Finished running wfo
Beta: -52774845.08916696  | Score: 0.0
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 4s - loss: 0.105523/23 [==============================] - 0s 2ms/step - loss: 0.1009
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.084923/23 [==============================] - 0s 2ms/step - loss: 0.0857
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.078423/23 [==============================] - 0s 2ms/step - loss: 0.0760
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.070823/23 [==============================] - 0s 2ms/step - loss: 0.0693
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.064123/23 [==============================] - 0s 2ms/step - loss: 0.0659
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.064123/23 [==============================] - 0s 2ms/step - loss: 0.0641
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.062223/23 [==============================] - 0s 2ms/step - loss: 0.0614
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.059223/23 [==============================] - 0s 2ms/step - loss: 0.0599
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.056323/23 [==============================] - 0s 2ms/step - loss: 0.0573
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.058923/23 [==============================] - 0s 2ms/step - loss: 0.0556
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.058823/23 [==============================] - 0s 2ms/step - loss: 0.0523
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.051823/23 [==============================] - 0s 2ms/step - loss: 0.0492
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046923/23 [==============================] - 0s 2ms/step - loss: 0.0480
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045523/23 [==============================] - 0s 2ms/step - loss: 0.0467
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046723/23 [==============================] - 0s 2ms/step - loss: 0.0454
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045723/23 [==============================] - 0s 2ms/step - loss: 0.0447
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045823/23 [==============================] - 0s 2ms/step - loss: 0.0433
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046023/23 [==============================] - 0s 2ms/step - loss: 0.0424
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.043523/23 [==============================] - 0s 2ms/step - loss: 0.0428
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040723/23 [==============================] - 0s 2ms/step - loss: 0.0421
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036223/23 [==============================] - 0s 2ms/step - loss: 0.0412
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041023/23 [==============================] - 0s 2ms/step - loss: 0.0417
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036523/23 [==============================] - 0s 2ms/step - loss: 0.0412
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045323/23 [==============================] - 0s 2ms/step - loss: 0.0418
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038423/23 [==============================] - 0s 2ms/step - loss: 0.0401
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044823/23 [==============================] - 0s 2ms/step - loss: 0.0407
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040723/23 [==============================] - 0s 2ms/step - loss: 0.0406
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041123/23 [==============================] - 0s 2ms/step - loss: 0.0400
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039423/23 [==============================] - 0s 2ms/step - loss: 0.0394
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039223/23 [==============================] - 0s 2ms/step - loss: 0.0386
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038823/23 [==============================] - 0s 2ms/step - loss: 0.0392
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041323/23 [==============================] - 0s 2ms/step - loss: 0.0391
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036023/23 [==============================] - 0s 2ms/step - loss: 0.0385
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041923/23 [==============================] - 0s 2ms/step - loss: 0.0389
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034523/23 [==============================] - 0s 2ms/step - loss: 0.0375
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038223/23 [==============================] - 0s 2ms/step - loss: 0.0384
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.037423/23 [==============================] - 0s 2ms/step - loss: 0.0379
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.037023/23 [==============================] - 0s 2ms/step - loss: 0.0379
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.035023/23 [==============================] - 0s 2ms/step - loss: 0.0372
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038023/23 [==============================] - 0s 2ms/step - loss: 0.0369
Epoch 41/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034923/23 [==============================] - 0s 2ms/step - loss: 0.0369
Epoch 42/500
 1/23 [>.............................] - ETA: 0s - loss: 0.037723/23 [==============================] - 0s 2ms/step - loss: 0.0374
Epoch 43/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036323/23 [==============================] - 0s 2ms/step - loss: 0.0372
Epoch 44/500
 1/23 [>.............................] - ETA: 0s - loss: 0.037023/23 [==============================] - 0s 2ms/step - loss: 0.0369
Epoch 45/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033423/23 [==============================] - 0s 2ms/step - loss: 0.0359
Epoch 46/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038523/23 [==============================] - 0s 2ms/step - loss: 0.0371
Epoch 47/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034723/23 [==============================] - 0s 2ms/step - loss: 0.0367
Epoch 48/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038223/23 [==============================] - 0s 2ms/step - loss: 0.0373
Epoch 49/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039523/23 [==============================] - 0s 2ms/step - loss: 0.0369
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
Beta: -72520094074.15636  | Score: 0.0
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running wfo
[get_model] Finished running wfo
Beta: -1116458417950.0698  | Score: 0.0
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running wfo
[get_model] Finished running wfo
Beta: -67590937116379.86  | Score: 0.536764705882353
Email sent! Message ID:
010001872036a8a4-dc98c711-9f9e-47a9-88c2-491f3c6bca3a-000000
Accuracy: 0.5919003115264798
Time: 18.98766040802002

2023-03-25 23:02:17.110206: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
2023-03-25 23:02:20.099101: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-25 23:02:20.101663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-03-25 23:02:20.593003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:81:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.65GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2023-03-25 23:02:20.593034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 23:02:20.598403: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 23:02:20.598434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-25 23:02:20.601575: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-25 23:02:20.606490: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-25 23:02:20.611894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2023-03-25 23:02:20.613628: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-25 23:02:20.614106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-25 23:02:20.614640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-03-25 23:02:20.615112: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-25 23:02:20.616490: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-25 23:02:20.616681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:81:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.65GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2023-03-25 23:02:20.616702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 23:02:20.616715: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 23:02:20.616725: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-25 23:02:20.616735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-25 23:02:20.616744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-25 23:02:20.616753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2023-03-25 23:02:20.616762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-25 23:02:20.616771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-25 23:02:20.617034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-03-25 23:02:20.617203: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 23:02:21.157720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-03-25 23:02:21.157763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2023-03-25 23:02:21.157772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2023-03-25 23:02:21.158683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7281 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:81:00.0, compute capability: 7.5)
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
2023-03-25 23:02:21.300886: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-03-25 23:02:21.314143: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2994325000 Hz
Epoch 1/500
2023-03-25 23:02:21.587406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 23:02:21.998792: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
 1/23 [>.............................] - ETA: 15s - loss: 0.100323/23 [==============================] - 1s 2ms/step - loss: 0.1044
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.098723/23 [==============================] - 0s 2ms/step - loss: 0.0954
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.097623/23 [==============================] - 0s 2ms/step - loss: 0.0894
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.082823/23 [==============================] - 0s 2ms/step - loss: 0.0831
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.083423/23 [==============================] - 0s 2ms/step - loss: 0.0824
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.080323/23 [==============================] - 0s 2ms/step - loss: 0.0799
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.075323/23 [==============================] - 0s 2ms/step - loss: 0.0766
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.076223/23 [==============================] - 0s 2ms/step - loss: 0.0747
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.071123/23 [==============================] - 0s 2ms/step - loss: 0.0708
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.063923/23 [==============================] - 0s 2ms/step - loss: 0.0608
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.053723/23 [==============================] - 0s 2ms/step - loss: 0.0529
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.056623/23 [==============================] - 0s 2ms/step - loss: 0.0516
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.050223/23 [==============================] - 0s 2ms/step - loss: 0.0502
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.048523/23 [==============================] - 0s 2ms/step - loss: 0.0499
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.051723/23 [==============================] - 0s 2ms/step - loss: 0.0491
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.050023/23 [==============================] - 0s 2ms/step - loss: 0.0496
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045823/23 [==============================] - 0s 2ms/step - loss: 0.0476
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045623/23 [==============================] - 0s 2ms/step - loss: 0.0469
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045123/23 [==============================] - 0s 2ms/step - loss: 0.0461
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.043823/23 [==============================] - 0s 1ms/step - loss: 0.0454
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046723/23 [==============================] - 0s 1ms/step - loss: 0.0458
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.043423/23 [==============================] - 0s 2ms/step - loss: 0.0444
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.042223/23 [==============================] - 0s 1ms/step - loss: 0.0434
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041823/23 [==============================] - 0s 1ms/step - loss: 0.0432
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039123/23 [==============================] - 0s 1ms/step - loss: 0.0429
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.050623/23 [==============================] - 0s 1ms/step - loss: 0.0439
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040623/23 [==============================] - 0s 1ms/step - loss: 0.0422
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040423/23 [==============================] - 0s 2ms/step - loss: 0.0425
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041823/23 [==============================] - 0s 2ms/step - loss: 0.0423
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.048423/23 [==============================] - 0s 2ms/step - loss: 0.0433
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044523/23 [==============================] - 0s 2ms/step - loss: 0.0427
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045523/23 [==============================] - 0s 1ms/step - loss: 0.0431
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.042823/23 [==============================] - 0s 1ms/step - loss: 0.0414
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041123/23 [==============================] - 0s 2ms/step - loss: 0.0428
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041723/23 [==============================] - 0s 2ms/step - loss: 0.0421
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 4s - loss: 0.052823/23 [==============================] - 0s 2ms/step - loss: 0.0522
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.048823/23 [==============================] - 0s 2ms/step - loss: 0.0470
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038723/23 [==============================] - 0s 2ms/step - loss: 0.0367
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026823/23 [==============================] - 0s 1ms/step - loss: 0.0238
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014123/23 [==============================] - 0s 1ms/step - loss: 0.0127
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007923/23 [==============================] - 0s 2ms/step - loss: 0.0086
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.008923/23 [==============================] - 0s 1ms/step - loss: 0.0081
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.008823/23 [==============================] - 0s 2ms/step - loss: 0.0071
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006323/23 [==============================] - 0s 2ms/step - loss: 0.0054
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004123/23 [==============================] - 0s 2ms/step - loss: 0.0043
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003523/23 [==============================] - 0s 2ms/step - loss: 0.0031
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002823/23 [==============================] - 0s 2ms/step - loss: 0.0026
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002123/23 [==============================] - 0s 1ms/step - loss: 0.0023
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001823/23 [==============================] - 0s 2ms/step - loss: 0.0022
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002423/23 [==============================] - 0s 2ms/step - loss: 0.0021
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001923/23 [==============================] - 0s 2ms/step - loss: 0.0020
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001823/23 [==============================] - 0s 1ms/step - loss: 0.0018
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001423/23 [==============================] - 0s 2ms/step - loss: 0.0017
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002023/23 [==============================] - 0s 2ms/step - loss: 0.0019
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001523/23 [==============================] - 0s 2ms/step - loss: 0.0017
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002023/23 [==============================] - 0s 2ms/step - loss: 0.0018
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001523/23 [==============================] - 0s 2ms/step - loss: 0.0017
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001923/23 [==============================] - 0s 2ms/step - loss: 0.0017
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001623/23 [==============================] - 0s 2ms/step - loss: 0.0016
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001823/23 [==============================] - 0s 2ms/step - loss: 0.0016
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001623/23 [==============================] - 0s 2ms/step - loss: 0.0016
[get_model] Fit autoencoder
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 4s - loss: 0.104423/23 [==============================] - 0s 1ms/step - loss: 0.1069
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.086023/23 [==============================] - 0s 1ms/step - loss: 0.0872
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.077123/23 [==============================] - 0s 1ms/step - loss: 0.0746
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.073223/23 [==============================] - 0s 1ms/step - loss: 0.0675
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.063623/23 [==============================] - 0s 1ms/step - loss: 0.0647
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.069023/23 [==============================] - 0s 1ms/step - loss: 0.0632
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.057223/23 [==============================] - 0s 1ms/step - loss: 0.0603
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.063723/23 [==============================] - 0s 1ms/step - loss: 0.0609
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.061023/23 [==============================] - 0s 1ms/step - loss: 0.0586
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.055323/23 [==============================] - 0s 1ms/step - loss: 0.0555
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.055423/23 [==============================] - 0s 1ms/step - loss: 0.0533
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.052723/23 [==============================] - 0s 1ms/step - loss: 0.0520
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.051423/23 [==============================] - 0s 1ms/step - loss: 0.0503
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046723/23 [==============================] - 0s 1ms/step - loss: 0.0488
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040623/23 [==============================] - 0s 2ms/step - loss: 0.0449
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046023/23 [==============================] - 0s 1ms/step - loss: 0.0445
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040623/23 [==============================] - 0s 1ms/step - loss: 0.0417
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033723/23 [==============================] - 0s 2ms/step - loss: 0.0392
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.035623/23 [==============================] - 0s 2ms/step - loss: 0.0379
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038523/23 [==============================] - 0s 2ms/step - loss: 0.0363
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033523/23 [==============================] - 0s 2ms/step - loss: 0.0355
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027823/23 [==============================] - 0s 1ms/step - loss: 0.0339
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036323/23 [==============================] - 0s 2ms/step - loss: 0.0344
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.035023/23 [==============================] - 0s 1ms/step - loss: 0.0342
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034923/23 [==============================] - 0s 1ms/step - loss: 0.0342
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031923/23 [==============================] - 0s 1ms/step - loss: 0.0329
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033823/23 [==============================] - 0s 1ms/step - loss: 0.0331
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030723/23 [==============================] - 0s 1ms/step - loss: 0.0324
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031523/23 [==============================] - 0s 2ms/step - loss: 0.0319
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.035123/23 [==============================] - 0s 1ms/step - loss: 0.0327
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.035323/23 [==============================] - 0s 1ms/step - loss: 0.0333
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030723/23 [==============================] - 0s 2ms/step - loss: 0.0318
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031123/23 [==============================] - 0s 1ms/step - loss: 0.0322
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.032223/23 [==============================] - 0s 1ms/step - loss: 0.0319
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030823/23 [==============================] - 0s 2ms/step - loss: 0.0313
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033923/23 [==============================] - 0s 2ms/step - loss: 0.0321
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027423/23 [==============================] - 0s 2ms/step - loss: 0.0307
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031623/23 [==============================] - 0s 2ms/step - loss: 0.0320
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.028923/23 [==============================] - 0s 1ms/step - loss: 0.0313
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033423/23 [==============================] - 0s 2ms/step - loss: 0.0323
Epoch 41/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029223/23 [==============================] - 0s 2ms/step - loss: 0.0308
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 4s - loss: 0.103823/23 [==============================] - 0s 2ms/step - loss: 0.1051
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.100123/23 [==============================] - 0s 2ms/step - loss: 0.0948
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.085623/23 [==============================] - 0s 2ms/step - loss: 0.0863
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.080123/23 [==============================] - 0s 2ms/step - loss: 0.0812
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.078923/23 [==============================] - 0s 2ms/step - loss: 0.0794
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.076623/23 [==============================] - 0s 2ms/step - loss: 0.0783
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.080823/23 [==============================] - 0s 2ms/step - loss: 0.0753
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.074623/23 [==============================] - 0s 2ms/step - loss: 0.0749
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.069523/23 [==============================] - 0s 2ms/step - loss: 0.0713
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.064623/23 [==============================] - 0s 2ms/step - loss: 0.0704
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.074823/23 [==============================] - 0s 2ms/step - loss: 0.0717
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.067723/23 [==============================] - 0s 2ms/step - loss: 0.0712
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.070223/23 [==============================] - 0s 2ms/step - loss: 0.0710
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.071323/23 [==============================] - 0s 2ms/step - loss: 0.0688
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.069223/23 [==============================] - 0s 2ms/step - loss: 0.0629
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.057323/23 [==============================] - 0s 2ms/step - loss: 0.0581
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.058923/23 [==============================] - 0s 2ms/step - loss: 0.0550
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.052723/23 [==============================] - 0s 2ms/step - loss: 0.0532
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.048823/23 [==============================] - 0s 2ms/step - loss: 0.0511
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.050523/23 [==============================] - 0s 2ms/step - loss: 0.0496
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.050723/23 [==============================] - 0s 2ms/step - loss: 0.0470
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046323/23 [==============================] - 0s 2ms/step - loss: 0.0451
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041523/23 [==============================] - 0s 2ms/step - loss: 0.0425
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041823/23 [==============================] - 0s 2ms/step - loss: 0.0419
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.048423/23 [==============================] - 0s 2ms/step - loss: 0.0438
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044423/23 [==============================] - 0s 2ms/step - loss: 0.0416
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.042323/23 [==============================] - 0s 2ms/step - loss: 0.0413
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044123/23 [==============================] - 0s 2ms/step - loss: 0.0411
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039023/23 [==============================] - 0s 2ms/step - loss: 0.0403
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041123/23 [==============================] - 0s 2ms/step - loss: 0.0405
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038923/23 [==============================] - 0s 2ms/step - loss: 0.0396
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.042823/23 [==============================] - 0s 2ms/step - loss: 0.0395
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.037823/23 [==============================] - 0s 2ms/step - loss: 0.0372
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040523/23 [==============================] - 0s 2ms/step - loss: 0.0383
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039723/23 [==============================] - 0s 2ms/step - loss: 0.0383
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.035623/23 [==============================] - 0s 2ms/step - loss: 0.0371
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034823/23 [==============================] - 0s 2ms/step - loss: 0.0369
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040623/23 [==============================] - 0s 2ms/step - loss: 0.0370
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039723/23 [==============================] - 0s 2ms/step - loss: 0.0368
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.035823/23 [==============================] - 0s 2ms/step - loss: 0.0367
Epoch 41/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039223/23 [==============================] - 0s 2ms/step - loss: 0.0361
Epoch 42/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038323/23 [==============================] - 0s 2ms/step - loss: 0.0371
Epoch 43/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034723/23 [==============================] - 0s 2ms/step - loss: 0.0362
Epoch 44/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038223/23 [==============================] - 0s 2ms/step - loss: 0.0359
Epoch 45/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036423/23 [==============================] - 0s 2ms/step - loss: 0.0357
Epoch 46/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033423/23 [==============================] - 0s 2ms/step - loss: 0.0364
Epoch 47/500
 1/23 [>.............................] - ETA: 0s - loss: 0.037223/23 [==============================] - 0s 2ms/step - loss: 0.0372
Epoch 48/500
 1/23 [>.............................] - ETA: 0s - loss: 0.035323/23 [==============================] - 0s 2ms/step - loss: 0.0358
Epoch 49/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036223/23 [==============================] - 0s 2ms/step - loss: 0.0354
Epoch 50/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036623/23 [==============================] - 0s 2ms/step - loss: 0.0356
Epoch 51/500
 1/23 [>.............................] - ETA: 0s - loss: 0.043223/23 [==============================] - 0s 2ms/step - loss: 0.0373
Epoch 52/500
 1/23 [>.............................] - ETA: 0s - loss: 0.032023/23 [==============================] - 0s 1ms/step - loss: 0.0352
Epoch 53/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038823/23 [==============================] - 0s 2ms/step - loss: 0.0363
Epoch 54/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036923/23 [==============================] - 0s 1ms/step - loss: 0.0361
Epoch 55/500
 1/23 [>.............................] - ETA: 0s - loss: 0.035623/23 [==============================] - 0s 2ms/step - loss: 0.0357
Epoch 56/500
 1/23 [>.............................] - ETA: 0s - loss: 0.039023/23 [==============================] - 0s 1ms/step - loss: 0.0365
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
Accuracy: 0.6836483155299918
Time: 9.763877868652344

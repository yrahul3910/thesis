2023-03-25 22:56:29.364479: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
2023-03-25 22:56:35.690019: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-25 22:56:35.721773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-03-25 22:56:36.448500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.65GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2023-03-25 22:56:36.448571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 22:56:36.589135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 22:56:36.589229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-25 22:56:36.646760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-25 22:56:36.680161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-25 22:56:36.808032: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-03-25 22:56:36.857491: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-25 22:56:36.867199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-25 22:56:36.877127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-03-25 22:56:36.877672: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-25 22:56:36.879763: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-25 22:56:36.880011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.65GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2023-03-25 22:56:36.880034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 22:56:36.880047: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 22:56:36.880059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-25 22:56:36.880070: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-25 22:56:36.880081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-25 22:56:36.880091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-03-25 22:56:36.880101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-25 22:56:36.880111: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-25 22:56:36.880430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-03-25 22:56:36.883866: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 22:56:39.807739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-03-25 22:56:39.808054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2023-03-25 22:56:39.808064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2023-03-25 22:56:39.815137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7281 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:41:00.0, compute capability: 7.5)
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
2023-03-25 22:56:40.272299: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-03-25 22:56:40.307377: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2994580000 Hz
Epoch 1/500
2023-03-25 22:56:40.855606: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 22:56:43.470186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
 1/23 [>.............................] - ETA: 1:12 - loss: 0.053123/23 [==============================] - 3s 2ms/step - loss: 0.0525
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.051523/23 [==============================] - 0s 2ms/step - loss: 0.0513
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.051023/23 [==============================] - 0s 2ms/step - loss: 0.0508
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.050523/23 [==============================] - 0s 2ms/step - loss: 0.0505
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.050323/23 [==============================] - 0s 2ms/step - loss: 0.0476
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.037023/23 [==============================] - 0s 2ms/step - loss: 0.0331
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019923/23 [==============================] - 0s 2ms/step - loss: 0.0158
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006723/23 [==============================] - 0s 2ms/step - loss: 0.0056
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004323/23 [==============================] - 0s 2ms/step - loss: 0.0042
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003623/23 [==============================] - 0s 2ms/step - loss: 0.0034
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002423/23 [==============================] - 0s 2ms/step - loss: 0.0028
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002923/23 [==============================] - 0s 2ms/step - loss: 0.0027
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003123/23 [==============================] - 0s 2ms/step - loss: 0.0026
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002523/23 [==============================] - 0s 2ms/step - loss: 0.0026
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002923/23 [==============================] - 0s 2ms/step - loss: 0.0025
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002323/23 [==============================] - 0s 2ms/step - loss: 0.0023
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001823/23 [==============================] - 0s 2ms/step - loss: 0.0022
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002123/23 [==============================] - 0s 2ms/step - loss: 0.0022
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001923/23 [==============================] - 0s 2ms/step - loss: 0.0020
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001923/23 [==============================] - 0s 2ms/step - loss: 0.0020
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002723/23 [==============================] - 0s 2ms/step - loss: 0.0020
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 6s - loss: 0.113323/23 [==============================] - 0s 2ms/step - loss: 0.0997
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.082023/23 [==============================] - 0s 2ms/step - loss: 0.0774
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.067323/23 [==============================] - 0s 2ms/step - loss: 0.0649
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.057623/23 [==============================] - 0s 2ms/step - loss: 0.0597
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.062223/23 [==============================] - 0s 2ms/step - loss: 0.0565
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.057323/23 [==============================] - 0s 2ms/step - loss: 0.0548
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.051323/23 [==============================] - 0s 2ms/step - loss: 0.0531
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.052923/23 [==============================] - 0s 2ms/step - loss: 0.0530
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.051323/23 [==============================] - 0s 2ms/step - loss: 0.0511
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045123/23 [==============================] - 0s 2ms/step - loss: 0.0492
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045923/23 [==============================] - 0s 2ms/step - loss: 0.0485
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.051323/23 [==============================] - 0s 2ms/step - loss: 0.0489
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044523/23 [==============================] - 0s 2ms/step - loss: 0.0470
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046323/23 [==============================] - 0s 2ms/step - loss: 0.0461
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045723/23 [==============================] - 0s 2ms/step - loss: 0.0447
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044923/23 [==============================] - 0s 2ms/step - loss: 0.0429
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.042923/23 [==============================] - 0s 2ms/step - loss: 0.0433
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038923/23 [==============================] - 0s 2ms/step - loss: 0.0412
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040623/23 [==============================] - 0s 2ms/step - loss: 0.0409
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.040023/23 [==============================] - 0s 2ms/step - loss: 0.0393
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038223/23 [==============================] - 0s 2ms/step - loss: 0.0388
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.036123/23 [==============================] - 0s 2ms/step - loss: 0.0359
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.035323/23 [==============================] - 0s 2ms/step - loss: 0.0313
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026523/23 [==============================] - 0s 2ms/step - loss: 0.0276
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025323/23 [==============================] - 0s 2ms/step - loss: 0.0259
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.023523/23 [==============================] - 0s 2ms/step - loss: 0.0243
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027323/23 [==============================] - 0s 2ms/step - loss: 0.0254
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024723/23 [==============================] - 0s 2ms/step - loss: 0.0239
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.023023/23 [==============================] - 0s 2ms/step - loss: 0.0241
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019723/23 [==============================] - 0s 2ms/step - loss: 0.0228
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.023223/23 [==============================] - 0s 2ms/step - loss: 0.0225
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019723/23 [==============================] - 0s 2ms/step - loss: 0.0216
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021023/23 [==============================] - 0s 2ms/step - loss: 0.0215
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020223/23 [==============================] - 0s 2ms/step - loss: 0.0213
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021523/23 [==============================] - 0s 2ms/step - loss: 0.0206
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020423/23 [==============================] - 0s 2ms/step - loss: 0.0213
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020123/23 [==============================] - 0s 2ms/step - loss: 0.0207
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019723/23 [==============================] - 0s 2ms/step - loss: 0.0204
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021023/23 [==============================] - 0s 2ms/step - loss: 0.0200
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016923/23 [==============================] - 0s 2ms/step - loss: 0.0195
Epoch 41/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018423/23 [==============================] - 0s 2ms/step - loss: 0.0198
Epoch 42/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021023/23 [==============================] - 0s 2ms/step - loss: 0.0202
Epoch 43/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018623/23 [==============================] - 0s 2ms/step - loss: 0.0198
Epoch 44/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018323/23 [==============================] - 0s 2ms/step - loss: 0.0194
Epoch 45/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016423/23 [==============================] - 0s 2ms/step - loss: 0.0189
Epoch 46/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017323/23 [==============================] - 0s 2ms/step - loss: 0.0189
Epoch 47/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021223/23 [==============================] - 0s 2ms/step - loss: 0.0199
Epoch 48/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018823/23 [==============================] - 0s 2ms/step - loss: 0.0192
Epoch 49/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016823/23 [==============================] - 0s 2ms/step - loss: 0.0189
Epoch 50/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017723/23 [==============================] - 0s 2ms/step - loss: 0.0190
Epoch 51/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018823/23 [==============================] - 0s 2ms/step - loss: 0.0183
Epoch 52/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020023/23 [==============================] - 0s 2ms/step - loss: 0.0185
Epoch 53/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016523/23 [==============================] - 0s 2ms/step - loss: 0.0187
Epoch 54/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017023/23 [==============================] - 0s 2ms/step - loss: 0.0182
Epoch 55/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019823/23 [==============================] - 0s 2ms/step - loss: 0.0188
Epoch 56/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019923/23 [==============================] - 0s 2ms/step - loss: 0.0182
Epoch 57/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017823/23 [==============================] - 0s 2ms/step - loss: 0.0183
Epoch 58/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018423/23 [==============================] - 0s 2ms/step - loss: 0.0187
Epoch 59/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015823/23 [==============================] - 0s 2ms/step - loss: 0.0179
Epoch 60/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019823/23 [==============================] - 0s 2ms/step - loss: 0.0185
Epoch 61/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020123/23 [==============================] - 0s 2ms/step - loss: 0.0188
Epoch 62/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016623/23 [==============================] - 0s 2ms/step - loss: 0.0175
Epoch 63/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019523/23 [==============================] - 0s 2ms/step - loss: 0.0182
Epoch 64/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019323/23 [==============================] - 0s 2ms/step - loss: 0.0182
[get_model] Fit autoencoder
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running smooth
[get_model] Finished running smooth
Beta: 0.01770072292858998  | Score: 0.0
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 5s - loss: 0.113123/23 [==============================] - 0s 2ms/step - loss: 0.1045
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.093423/23 [==============================] - 0s 2ms/step - loss: 0.0921
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.088823/23 [==============================] - 0s 2ms/step - loss: 0.0822
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.076923/23 [==============================] - 0s 2ms/step - loss: 0.0732
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.074623/23 [==============================] - 0s 2ms/step - loss: 0.0709
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.066923/23 [==============================] - 0s 2ms/step - loss: 0.0692
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.065223/23 [==============================] - 0s 2ms/step - loss: 0.0673
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.071323/23 [==============================] - 0s 2ms/step - loss: 0.0686
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.067623/23 [==============================] - 0s 2ms/step - loss: 0.0661
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.072623/23 [==============================] - 0s 2ms/step - loss: 0.0653
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.066523/23 [==============================] - 0s 2ms/step - loss: 0.0647
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.066723/23 [==============================] - 0s 2ms/step - loss: 0.0626
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.059923/23 [==============================] - 0s 2ms/step - loss: 0.0597
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.059423/23 [==============================] - 0s 2ms/step - loss: 0.0573
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.057523/23 [==============================] - 0s 2ms/step - loss: 0.0558
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.050123/23 [==============================] - 0s 2ms/step - loss: 0.0446
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038023/23 [==============================] - 0s 2ms/step - loss: 0.0367
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033923/23 [==============================] - 0s 2ms/step - loss: 0.0350
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033123/23 [==============================] - 0s 2ms/step - loss: 0.0339
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030923/23 [==============================] - 0s 2ms/step - loss: 0.0320
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031823/23 [==============================] - 0s 2ms/step - loss: 0.0313
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.032923/23 [==============================] - 0s 2ms/step - loss: 0.0310
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026123/23 [==============================] - 0s 2ms/step - loss: 0.0292
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026623/23 [==============================] - 0s 2ms/step - loss: 0.0289
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029323/23 [==============================] - 0s 2ms/step - loss: 0.0281
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024323/23 [==============================] - 0s 2ms/step - loss: 0.0272
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030823/23 [==============================] - 0s 2ms/step - loss: 0.0274
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.028623/23 [==============================] - 0s 2ms/step - loss: 0.0273
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029223/23 [==============================] - 0s 2ms/step - loss: 0.0264
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030223/23 [==============================] - 0s 2ms/step - loss: 0.0270
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026123/23 [==============================] - 0s 2ms/step - loss: 0.0262
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031923/23 [==============================] - 0s 2ms/step - loss: 0.0272
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025623/23 [==============================] - 0s 2ms/step - loss: 0.0261
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025323/23 [==============================] - 0s 2ms/step - loss: 0.0262
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025323/23 [==============================] - 0s 2ms/step - loss: 0.0258
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024923/23 [==============================] - 0s 2ms/step - loss: 0.0257
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027123/23 [==============================] - 0s 2ms/step - loss: 0.0256
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.027423/23 [==============================] - 0s 2ms/step - loss: 0.0263
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.025823/23 [==============================] - 0s 2ms/step - loss: 0.0249
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021923/23 [==============================] - 0s 2ms/step - loss: 0.0233
Epoch 41/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021223/23 [==============================] - 0s 2ms/step - loss: 0.0232
Epoch 42/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024123/23 [==============================] - 0s 2ms/step - loss: 0.0233
Epoch 43/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022123/23 [==============================] - 0s 2ms/step - loss: 0.0230
Epoch 44/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022423/23 [==============================] - 0s 2ms/step - loss: 0.0229
Epoch 45/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024723/23 [==============================] - 0s 2ms/step - loss: 0.0230
Epoch 46/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022823/23 [==============================] - 0s 2ms/step - loss: 0.0226
Epoch 47/500
 1/23 [>.............................] - ETA: 0s - loss: 0.023523/23 [==============================] - 0s 2ms/step - loss: 0.0221
Epoch 48/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022723/23 [==============================] - 0s 2ms/step - loss: 0.0224
Epoch 49/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022023/23 [==============================] - 0s 2ms/step - loss: 0.0226
Epoch 50/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021523/23 [==============================] - 0s 2ms/step - loss: 0.0222
Epoch 51/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020123/23 [==============================] - 0s 2ms/step - loss: 0.0225
[get_model] Fit autoencoder
Beta: 0.013445606910207318  | Score: 0.682526661197703
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running wfo
[get_model] Finished running wfo
Beta: 0.001530140441282302  | Score: 0.40249609984399376
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running wfo
[get_model] Finished running wfo
Beta: 0.0006870225315013231  | Score: 0.0
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 6s - loss: 0.052323/23 [==============================] - 0s 2ms/step - loss: 0.0504
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.042823/23 [==============================] - 0s 2ms/step - loss: 0.0398
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031223/23 [==============================] - 0s 2ms/step - loss: 0.0278
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019023/23 [==============================] - 0s 2ms/step - loss: 0.0164
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.012623/23 [==============================] - 0s 2ms/step - loss: 0.0113
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.008623/23 [==============================] - 0s 2ms/step - loss: 0.0096
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.010023/23 [==============================] - 0s 2ms/step - loss: 0.0096
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.010223/23 [==============================] - 0s 2ms/step - loss: 0.0095
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009623/23 [==============================] - 0s 2ms/step - loss: 0.0089
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009723/23 [==============================] - 0s 2ms/step - loss: 0.0089
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007823/23 [==============================] - 0s 2ms/step - loss: 0.0082
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.005523/23 [==============================] - 0s 2ms/step - loss: 0.0046
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002923/23 [==============================] - 0s 2ms/step - loss: 0.0036
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002823/23 [==============================] - 0s 2ms/step - loss: 0.0034
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004223/23 [==============================] - 0s 2ms/step - loss: 0.0033
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002123/23 [==============================] - 0s 2ms/step - loss: 0.0030
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003223/23 [==============================] - 0s 2ms/step - loss: 0.0032
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002023/23 [==============================] - 0s 2ms/step - loss: 0.0029
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002623/23 [==============================] - 0s 2ms/step - loss: 0.0032
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003323/23 [==============================] - 0s 2ms/step - loss: 0.0031
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002123/23 [==============================] - 0s 2ms/step - loss: 0.0030
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002323/23 [==============================] - 0s 2ms/step - loss: 0.0028
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004123/23 [==============================] - 0s 2ms/step - loss: 0.0029
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002323/23 [==============================] - 0s 2ms/step - loss: 0.0027
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002323/23 [==============================] - 0s 2ms/step - loss: 0.0023
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001723/23 [==============================] - 0s 2ms/step - loss: 0.0021
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002623/23 [==============================] - 0s 2ms/step - loss: 0.0022
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002323/23 [==============================] - 0s 2ms/step - loss: 0.0021
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002023/23 [==============================] - 0s 2ms/step - loss: 0.0019
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002123/23 [==============================] - 0s 2ms/step - loss: 0.0019
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001423/23 [==============================] - 0s 2ms/step - loss: 0.0018
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001523/23 [==============================] - 0s 2ms/step - loss: 0.0018
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001723/23 [==============================] - 0s 2ms/step - loss: 0.0018
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002323/23 [==============================] - 0s 2ms/step - loss: 0.0018
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002023/23 [==============================] - 0s 2ms/step - loss: 0.0018
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001823/23 [==============================] - 0s 2ms/step - loss: 0.0018
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001323/23 [==============================] - 0s 2ms/step - loss: 0.0017
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
Beta: 0.0004992772384669474  | Score: 0.682526661197703
Accuracy: 0.682526661197703
Time: 20.105809211730957

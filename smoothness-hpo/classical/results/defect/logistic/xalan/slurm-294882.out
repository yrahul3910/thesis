2023-03-25 22:56:28.764600: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
2023-03-25 22:56:35.176996: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-25 22:56:35.234352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-03-25 22:56:35.996490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.65GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2023-03-25 22:56:35.996561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 22:56:36.109503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 22:56:36.109586: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-25 22:56:36.164262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-25 22:56:36.201224: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-25 22:56:36.346118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-03-25 22:56:36.370898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-25 22:56:36.392211: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-25 22:56:36.405674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-03-25 22:56:36.406241: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-25 22:56:36.408790: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-25 22:56:36.409175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.65GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2023-03-25 22:56:36.409222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 22:56:36.409250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 22:56:36.409275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-25 22:56:36.409298: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-25 22:56:36.409321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-25 22:56:36.409335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-03-25 22:56:36.409345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-25 22:56:36.409355: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-25 22:56:36.409675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-03-25 22:56:36.419052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-25 22:56:39.301306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-03-25 22:56:39.301690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2023-03-25 22:56:39.301705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2023-03-25 22:56:39.309376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7281 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:41:00.0, compute capability: 7.5)
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
2023-03-25 22:56:39.792859: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-03-25 22:56:39.834902: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2994460000 Hz
Epoch 1/500
2023-03-25 22:56:40.382688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-25 22:56:43.030845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
 1/23 [>.............................] - ETA: 1:14 - loss: 0.052223/23 [==============================] - ETA: 0s - loss: 0.0499  23/23 [==============================] - 3s 2ms/step - loss: 0.0499
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.042823/23 [==============================] - 0s 2ms/step - loss: 0.0406
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033423/23 [==============================] - 0s 2ms/step - loss: 0.0312
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024123/23 [==============================] - 0s 2ms/step - loss: 0.0214
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015623/23 [==============================] - 0s 2ms/step - loss: 0.0142
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009523/23 [==============================] - 0s 2ms/step - loss: 0.0105
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.010223/23 [==============================] - 0s 2ms/step - loss: 0.0090
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.011723/23 [==============================] - 0s 2ms/step - loss: 0.0089
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006723/23 [==============================] - 0s 2ms/step - loss: 0.0077
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007023/23 [==============================] - 0s 2ms/step - loss: 0.0077
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.008723/23 [==============================] - 0s 2ms/step - loss: 0.0076
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007023/23 [==============================] - 0s 2ms/step - loss: 0.0068
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.006523/23 [==============================] - 0s 2ms/step - loss: 0.0060
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.005023/23 [==============================] - 0s 2ms/step - loss: 0.0052
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.005223/23 [==============================] - 0s 2ms/step - loss: 0.0048
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004823/23 [==============================] - 0s 2ms/step - loss: 0.0042
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004523/23 [==============================] - 0s 2ms/step - loss: 0.0040
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004623/23 [==============================] - 0s 2ms/step - loss: 0.0036
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002723/23 [==============================] - 0s 2ms/step - loss: 0.0030
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002923/23 [==============================] - 0s 2ms/step - loss: 0.0026
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002723/23 [==============================] - 0s 2ms/step - loss: 0.0024
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002323/23 [==============================] - 0s 2ms/step - loss: 0.0022
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001623/23 [==============================] - 0s 2ms/step - loss: 0.0018
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002223/23 [==============================] - 0s 2ms/step - loss: 0.0018
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001723/23 [==============================] - 0s 2ms/step - loss: 0.0016
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001423/23 [==============================] - 0s 2ms/step - loss: 0.0015
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001623/23 [==============================] - 0s 2ms/step - loss: 0.0015
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001523/23 [==============================] - 0s 2ms/step - loss: 0.0015
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001523/23 [==============================] - 0s 2ms/step - loss: 0.0014
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001423/23 [==============================] - 0s 2ms/step - loss: 0.0014
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 9.6713e-0423/23 [==============================] - 0s 2ms/step - loss: 0.0013
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 6s - loss: 0.107523/23 [==============================] - 0s 2ms/step - loss: 0.1067
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.101323/23 [==============================] - 0s 2ms/step - loss: 0.0922
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.077323/23 [==============================] - 0s 2ms/step - loss: 0.0720
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.062023/23 [==============================] - 0s 2ms/step - loss: 0.0559
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.055223/23 [==============================] - 0s 2ms/step - loss: 0.0494
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.048023/23 [==============================] - 0s 2ms/step - loss: 0.0454
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.041823/23 [==============================] - 0s 2ms/step - loss: 0.0418
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044023/23 [==============================] - 0s 2ms/step - loss: 0.0398
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034523/23 [==============================] - 0s 2ms/step - loss: 0.0353
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.035123/23 [==============================] - 0s 2ms/step - loss: 0.0339
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033023/23 [==============================] - 0s 2ms/step - loss: 0.0321
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.028623/23 [==============================] - 0s 2ms/step - loss: 0.0299
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.032423/23 [==============================] - 0s 2ms/step - loss: 0.0292
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.024523/23 [==============================] - 0s 2ms/step - loss: 0.0270
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.023823/23 [==============================] - 0s 2ms/step - loss: 0.0259
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026723/23 [==============================] - 0s 2ms/step - loss: 0.0248
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022823/23 [==============================] - 0s 2ms/step - loss: 0.0238
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.023523/23 [==============================] - 0s 2ms/step - loss: 0.0228
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020523/23 [==============================] - 0s 2ms/step - loss: 0.0222
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019423/23 [==============================] - 0s 2ms/step - loss: 0.0207
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016723/23 [==============================] - 0s 2ms/step - loss: 0.0198
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.020623/23 [==============================] - 0s 2ms/step - loss: 0.0202
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015723/23 [==============================] - 0s 2ms/step - loss: 0.0188
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021423/23 [==============================] - 0s 2ms/step - loss: 0.0195
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015123/23 [==============================] - 0s 2ms/step - loss: 0.0177
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.021823/23 [==============================] - 0s 2ms/step - loss: 0.0190
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.019523/23 [==============================] - 0s 2ms/step - loss: 0.0183
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.022323/23 [==============================] - 0s 2ms/step - loss: 0.0181
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017723/23 [==============================] - 0s 2ms/step - loss: 0.0180
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017123/23 [==============================] - 0s 2ms/step - loss: 0.0176
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015423/23 [==============================] - 0s 2ms/step - loss: 0.0164
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017723/23 [==============================] - 0s 2ms/step - loss: 0.0166
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017223/23 [==============================] - 0s 2ms/step - loss: 0.0168
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017923/23 [==============================] - 0s 2ms/step - loss: 0.0165
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016523/23 [==============================] - 0s 2ms/step - loss: 0.0167
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018223/23 [==============================] - 0s 2ms/step - loss: 0.0169
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017323/23 [==============================] - 0s 2ms/step - loss: 0.0165
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016423/23 [==============================] - 0s 2ms/step - loss: 0.0161
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017623/23 [==============================] - 0s 2ms/step - loss: 0.0163
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014123/23 [==============================] - 0s 2ms/step - loss: 0.0152
Epoch 41/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016523/23 [==============================] - 0s 2ms/step - loss: 0.0161
Epoch 42/500
 1/23 [>.............................] - ETA: 0s - loss: 0.018123/23 [==============================] - 0s 2ms/step - loss: 0.0166
Epoch 43/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016323/23 [==============================] - 0s 2ms/step - loss: 0.0157
Epoch 44/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017623/23 [==============================] - 0s 2ms/step - loss: 0.0160
Epoch 45/500
 1/23 [>.............................] - ETA: 0s - loss: 0.016723/23 [==============================] - 0s 2ms/step - loss: 0.0160
Epoch 46/500
 1/23 [>.............................] - ETA: 0s - loss: 0.017823/23 [==============================] - 0s 2ms/step - loss: 0.0167
Epoch 47/500
 1/23 [>.............................] - ETA: 0s - loss: 0.012523/23 [==============================] - 0s 2ms/step - loss: 0.0151
Epoch 48/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014923/23 [==============================] - 0s 2ms/step - loss: 0.0157
Epoch 49/500
 1/23 [>.............................] - ETA: 0s - loss: 0.015423/23 [==============================] - 0s 2ms/step - loss: 0.0154
[get_model] Fit autoencoder
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running smooth
[get_model] Finished running smooth
Beta: 1.4905194317371073  | Score: 0.0
[get_model] Running smooth
[get_model] Finished running smooth
Beta: 0.0035983669420262447  | Score: 0.0
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 6s - loss: 0.104423/23 [==============================] - 0s 2ms/step - loss: 0.1076
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.103623/23 [==============================] - 0s 2ms/step - loss: 0.0956
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.077223/23 [==============================] - 0s 2ms/step - loss: 0.0829
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.071723/23 [==============================] - 0s 2ms/step - loss: 0.0712
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.065223/23 [==============================] - 0s 2ms/step - loss: 0.0643
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.061123/23 [==============================] - 0s 2ms/step - loss: 0.0615
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.054923/23 [==============================] - 0s 2ms/step - loss: 0.0590
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.058223/23 [==============================] - 0s 2ms/step - loss: 0.0588
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.054223/23 [==============================] - 0s 2ms/step - loss: 0.0582
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.056123/23 [==============================] - 0s 2ms/step - loss: 0.0574
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.057523/23 [==============================] - 0s 2ms/step - loss: 0.0581
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.055123/23 [==============================] - 0s 2ms/step - loss: 0.0576
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.051923/23 [==============================] - 0s 2ms/step - loss: 0.0556
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.057823/23 [==============================] - 0s 2ms/step - loss: 0.0563
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.054723/23 [==============================] - 0s 2ms/step - loss: 0.0555
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.054123/23 [==============================] - 0s 2ms/step - loss: 0.0546
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.052023/23 [==============================] - 0s 2ms/step - loss: 0.0547
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.052723/23 [==============================] - 0s 2ms/step - loss: 0.0535
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.057323/23 [==============================] - 0s 2ms/step - loss: 0.0552
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.051723/23 [==============================] - 0s 2ms/step - loss: 0.0541
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.047923/23 [==============================] - 0s 2ms/step - loss: 0.0527
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.053023/23 [==============================] - 0s 2ms/step - loss: 0.0529
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.052823/23 [==============================] - 0s 2ms/step - loss: 0.0522
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.055223/23 [==============================] - 0s 2ms/step - loss: 0.0524
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.052823/23 [==============================] - 0s 2ms/step - loss: 0.0523
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.056423/23 [==============================] - 0s 2ms/step - loss: 0.0525
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045323/23 [==============================] - 0s 2ms/step - loss: 0.0508
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.049223/23 [==============================] - 0s 2ms/step - loss: 0.0522
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.050123/23 [==============================] - 0s 2ms/step - loss: 0.0510
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.046823/23 [==============================] - 0s 2ms/step - loss: 0.0510
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.051423/23 [==============================] - 0s 2ms/step - loss: 0.0509
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.055223/23 [==============================] - 0s 2ms/step - loss: 0.0520
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.048223/23 [==============================] - 0s 2ms/step - loss: 0.0508
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.055123/23 [==============================] - 0s 2ms/step - loss: 0.0516
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.047723/23 [==============================] - 0s 2ms/step - loss: 0.0496
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.051823/23 [==============================] - 0s 2ms/step - loss: 0.0497
Epoch 37/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044723/23 [==============================] - 0s 2ms/step - loss: 0.0466
Epoch 38/500
 1/23 [>.............................] - ETA: 0s - loss: 0.045923/23 [==============================] - 0s 2ms/step - loss: 0.0409
Epoch 39/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034023/23 [==============================] - 0s 2ms/step - loss: 0.0382
Epoch 40/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031823/23 [==============================] - 0s 2ms/step - loss: 0.0363
Epoch 41/500
 1/23 [>.............................] - ETA: 0s - loss: 0.038623/23 [==============================] - 0s 2ms/step - loss: 0.0370
Epoch 42/500
 1/23 [>.............................] - ETA: 0s - loss: 0.037823/23 [==============================] - 0s 2ms/step - loss: 0.0365
Epoch 43/500
 1/23 [>.............................] - ETA: 0s - loss: 0.037223/23 [==============================] - 0s 2ms/step - loss: 0.0360
Epoch 44/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034123/23 [==============================] - 0s 2ms/step - loss: 0.0335
Epoch 45/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034823/23 [==============================] - 0s 2ms/step - loss: 0.0332
Epoch 46/500
 1/23 [>.............................] - ETA: 0s - loss: 0.033323/23 [==============================] - 0s 2ms/step - loss: 0.0324
Epoch 47/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031523/23 [==============================] - 0s 2ms/step - loss: 0.0319
Epoch 48/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029023/23 [==============================] - 0s 2ms/step - loss: 0.0319
Epoch 49/500
 1/23 [>.............................] - ETA: 0s - loss: 0.032523/23 [==============================] - 0s 2ms/step - loss: 0.0316
Epoch 50/500
 1/23 [>.............................] - ETA: 0s - loss: 0.037723/23 [==============================] - 0s 2ms/step - loss: 0.0321
Epoch 51/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030923/23 [==============================] - 0s 2ms/step - loss: 0.0305
Epoch 52/500
 1/23 [>.............................] - ETA: 0s - loss: 0.028223/23 [==============================] - 0s 2ms/step - loss: 0.0304
Epoch 53/500
 1/23 [>.............................] - ETA: 0s - loss: 0.034923/23 [==============================] - 0s 2ms/step - loss: 0.0309
Epoch 54/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031323/23 [==============================] - 0s 2ms/step - loss: 0.0302
Epoch 55/500
 1/23 [>.............................] - ETA: 0s - loss: 0.032923/23 [==============================] - 0s 2ms/step - loss: 0.0302
Epoch 56/500
 1/23 [>.............................] - ETA: 0s - loss: 0.026623/23 [==============================] - 0s 2ms/step - loss: 0.0302
Epoch 57/500
 1/23 [>.............................] - ETA: 0s - loss: 0.032223/23 [==============================] - 0s 2ms/step - loss: 0.0300
Epoch 58/500
 1/23 [>.............................] - ETA: 0s - loss: 0.028623/23 [==============================] - 0s 2ms/step - loss: 0.0301
Epoch 59/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030023/23 [==============================] - 0s 2ms/step - loss: 0.0301
Epoch 60/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030423/23 [==============================] - 0s 2ms/step - loss: 0.0298
Epoch 61/500
 1/23 [>.............................] - ETA: 0s - loss: 0.029523/23 [==============================] - 0s 2ms/step - loss: 0.0296
Epoch 62/500
 1/23 [>.............................] - ETA: 0s - loss: 0.032823/23 [==============================] - 0s 2ms/step - loss: 0.0304
Epoch 63/500
 1/23 [>.............................] - ETA: 0s - loss: 0.030023/23 [==============================] - 0s 2ms/step - loss: 0.0293
Epoch 64/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031523/23 [==============================] - 0s 2ms/step - loss: 0.0293
[get_model] Fit autoencoder
Beta: 0.0032153223696969285  | Score: 0.5522914218566393
[get_model] Running smooth
[get_model] Finished running smooth
Beta: 0.002537524791336383  | Score: 0.0
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
 1/23 [>.............................] - ETA: 6s - loss: 0.052423/23 [==============================] - 0s 2ms/step - loss: 0.0520
Epoch 2/500
 1/23 [>.............................] - ETA: 0s - loss: 0.050323/23 [==============================] - 0s 2ms/step - loss: 0.0491
Epoch 3/500
 1/23 [>.............................] - ETA: 0s - loss: 0.044423/23 [==============================] - 0s 2ms/step - loss: 0.0413
Epoch 4/500
 1/23 [>.............................] - ETA: 0s - loss: 0.031123/23 [==============================] - 0s 2ms/step - loss: 0.0261
Epoch 5/500
 1/23 [>.............................] - ETA: 0s - loss: 0.014423/23 [==============================] - 0s 2ms/step - loss: 0.0114
Epoch 6/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009823/23 [==============================] - 0s 2ms/step - loss: 0.0086
Epoch 7/500
 1/23 [>.............................] - ETA: 0s - loss: 0.010423/23 [==============================] - 0s 2ms/step - loss: 0.0082
Epoch 8/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009823/23 [==============================] - 0s 2ms/step - loss: 0.0077
Epoch 9/500
 1/23 [>.............................] - ETA: 0s - loss: 0.007423/23 [==============================] - 0s 2ms/step - loss: 0.0068
Epoch 10/500
 1/23 [>.............................] - ETA: 0s - loss: 0.009223/23 [==============================] - 0s 2ms/step - loss: 0.0068
Epoch 11/500
 1/23 [>.............................] - ETA: 0s - loss: 0.005123/23 [==============================] - 0s 2ms/step - loss: 0.0058
Epoch 12/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004823/23 [==============================] - 0s 2ms/step - loss: 0.0054
Epoch 13/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004023/23 [==============================] - 0s 2ms/step - loss: 0.0049
Epoch 14/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004623/23 [==============================] - 0s 2ms/step - loss: 0.0046
Epoch 15/500
 1/23 [>.............................] - ETA: 0s - loss: 0.005323/23 [==============================] - 0s 2ms/step - loss: 0.0045
Epoch 16/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004823/23 [==============================] - 0s 2ms/step - loss: 0.0041
Epoch 17/500
 1/23 [>.............................] - ETA: 0s - loss: 0.004023/23 [==============================] - 0s 2ms/step - loss: 0.0039
Epoch 18/500
 1/23 [>.............................] - ETA: 0s - loss: 0.003323/23 [==============================] - 0s 2ms/step - loss: 0.0033
Epoch 19/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002823/23 [==============================] - 0s 2ms/step - loss: 0.0030
Epoch 20/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002123/23 [==============================] - 0s 2ms/step - loss: 0.0027
Epoch 21/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002323/23 [==============================] - 0s 2ms/step - loss: 0.0026
Epoch 22/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002423/23 [==============================] - 0s 2ms/step - loss: 0.0026
Epoch 23/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002123/23 [==============================] - 0s 2ms/step - loss: 0.0026
Epoch 24/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002823/23 [==============================] - 0s 2ms/step - loss: 0.0026
Epoch 25/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002523/23 [==============================] - 0s 2ms/step - loss: 0.0025
Epoch 26/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002623/23 [==============================] - 0s 2ms/step - loss: 0.0024
Epoch 27/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002223/23 [==============================] - 0s 2ms/step - loss: 0.0023
Epoch 28/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002523/23 [==============================] - 0s 2ms/step - loss: 0.0023
Epoch 29/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002423/23 [==============================] - 0s 2ms/step - loss: 0.0022
Epoch 30/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002323/23 [==============================] - 0s 2ms/step - loss: 0.0022
Epoch 31/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002023/23 [==============================] - 0s 2ms/step - loss: 0.0021
Epoch 32/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001923/23 [==============================] - 0s 2ms/step - loss: 0.0021
Epoch 33/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002123/23 [==============================] - 0s 2ms/step - loss: 0.0020
Epoch 34/500
 1/23 [>.............................] - ETA: 0s - loss: 0.001623/23 [==============================] - 0s 2ms/step - loss: 0.0021
Epoch 35/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002023/23 [==============================] - 0s 2ms/step - loss: 0.0020
Epoch 36/500
 1/23 [>.............................] - ETA: 0s - loss: 0.002123/23 [==============================] - 0s 2ms/step - loss: 0.0020
[get_model] Fit autoencoder
[get_model] Running wfo
[get_model] Finished running wfo
Beta: 0.0006740656350835679  | Score: 0.682526661197703
Accuracy: 0.682526661197703
Time: 19.55286431312561

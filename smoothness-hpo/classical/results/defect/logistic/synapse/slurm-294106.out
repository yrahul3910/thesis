2023-03-22 21:40:28.738609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
2023-03-22 21:40:39.830570: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-22 21:40:39.913735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-03-22 21:40:41.022151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:af:00.0 name: Quadro P4000 computeCapability: 6.1
coreClock: 1.48GHz coreCount: 14 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 226.62GiB/s
2023-03-22 21:40:41.022228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-22 21:40:41.129789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-22 21:40:41.129911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-22 21:40:41.187601: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-22 21:40:41.218958: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-22 21:40:41.348898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-03-22 21:40:41.379365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-22 21:40:41.402270: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-22 21:40:41.420337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-03-22 21:40:41.421172: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-22 21:40:41.422412: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-03-22 21:40:41.422750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:af:00.0 name: Quadro P4000 computeCapability: 6.1
coreClock: 1.48GHz coreCount: 14 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 226.62GiB/s
2023-03-22 21:40:41.422793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-22 21:40:41.422831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-22 21:40:41.422851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-03-22 21:40:41.422871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-03-22 21:40:41.422890: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-03-22 21:40:41.422910: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-03-22 21:40:41.422929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-03-22 21:40:41.422949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-03-22 21:40:41.423337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-03-22 21:40:41.426589: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-03-22 21:40:43.935660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-03-22 21:40:43.935707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2023-03-22 21:40:43.935718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2023-03-22 21:40:43.948755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7450 MB memory) -> physical GPU (device: 0, name: Quadro P4000, pci bus id: 0000:af:00.0, compute capability: 6.1)
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
2023-03-22 21:40:44.543784: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-03-22 21:40:44.579275: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
Epoch 1/500
2023-03-22 21:40:45.237581: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-03-22 21:40:47.322721: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
1/6 [====>.........................] - ETA: 14s - loss: 0.04866/6 [==============================] - 3s 3ms/step - loss: 0.0476
Epoch 2/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04436/6 [==============================] - 0s 3ms/step - loss: 0.0436
Epoch 3/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04046/6 [==============================] - 0s 3ms/step - loss: 0.0399
Epoch 4/500
1/6 [====>.........................] - ETA: 0s - loss: 0.03666/6 [==============================] - 0s 3ms/step - loss: 0.0362
Epoch 5/500
1/6 [====>.........................] - ETA: 0s - loss: 0.03276/6 [==============================] - 0s 4ms/step - loss: 0.0325
Epoch 6/500
1/6 [====>.........................] - ETA: 0s - loss: 0.02976/6 [==============================] - 0s 4ms/step - loss: 0.0290
Epoch 7/500
1/6 [====>.........................] - ETA: 0s - loss: 0.02716/6 [==============================] - 0s 3ms/step - loss: 0.0260
Epoch 8/500
1/6 [====>.........................] - ETA: 0s - loss: 0.02276/6 [==============================] - 0s 3ms/step - loss: 0.0227
Epoch 9/500
1/6 [====>.........................] - ETA: 0s - loss: 0.02066/6 [==============================] - 0s 3ms/step - loss: 0.0202
Epoch 10/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01766/6 [==============================] - 0s 3ms/step - loss: 0.0175
Epoch 11/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01446/6 [==============================] - 0s 3ms/step - loss: 0.0150
Epoch 12/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01316/6 [==============================] - 0s 3ms/step - loss: 0.0129
Epoch 13/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01226/6 [==============================] - 0s 3ms/step - loss: 0.0115
Epoch 14/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00926/6 [==============================] - 0s 3ms/step - loss: 0.0096
Epoch 15/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01056/6 [==============================] - 0s 3ms/step - loss: 0.0091
Epoch 16/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00806/6 [==============================] - 0s 3ms/step - loss: 0.0077
Epoch 17/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00696/6 [==============================] - 0s 3ms/step - loss: 0.0068
Epoch 18/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00606/6 [==============================] - 0s 3ms/step - loss: 0.0061
Epoch 19/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00506/6 [==============================] - 0s 3ms/step - loss: 0.0051
Epoch 20/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00396/6 [==============================] - 0s 3ms/step - loss: 0.0046
Epoch 21/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00486/6 [==============================] - 0s 3ms/step - loss: 0.0045
Epoch 22/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00416/6 [==============================] - 0s 4ms/step - loss: 0.0040
Epoch 23/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00376/6 [==============================] - 0s 3ms/step - loss: 0.0037
Epoch 24/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00356/6 [==============================] - 0s 3ms/step - loss: 0.0036
Epoch 25/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00356/6 [==============================] - 0s 3ms/step - loss: 0.0035
Epoch 26/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00346/6 [==============================] - 0s 3ms/step - loss: 0.0034
Epoch 27/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00276/6 [==============================] - 0s 4ms/step - loss: 0.0031
Epoch 28/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00296/6 [==============================] - 0s 3ms/step - loss: 0.0030
Epoch 29/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00286/6 [==============================] - 0s 3ms/step - loss: 0.0031
Epoch 30/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00356/6 [==============================] - 0s 3ms/step - loss: 0.0031
Epoch 31/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00296/6 [==============================] - 0s 4ms/step - loss: 0.0030
Epoch 32/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00266/6 [==============================] - 0s 3ms/step - loss: 0.0028
Epoch 33/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00276/6 [==============================] - 0s 3ms/step - loss: 0.0028
Epoch 34/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00306/6 [==============================] - 0s 3ms/step - loss: 0.0028
[get_model] Fit autoencoder
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
1/6 [====>.........................] - ETA: 1s - loss: 0.05036/6 [==============================] - 0s 3ms/step - loss: 0.0501
Epoch 2/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04856/6 [==============================] - 0s 3ms/step - loss: 0.0475
Epoch 3/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04546/6 [==============================] - 0s 3ms/step - loss: 0.0445
Epoch 4/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04176/6 [==============================] - 0s 3ms/step - loss: 0.0411
Epoch 5/500
1/6 [====>.........................] - ETA: 0s - loss: 0.03856/6 [==============================] - 0s 4ms/step - loss: 0.0377
Epoch 6/500
1/6 [====>.........................] - ETA: 0s - loss: 0.03456/6 [==============================] - 0s 3ms/step - loss: 0.0337
Epoch 7/500
1/6 [====>.........................] - ETA: 0s - loss: 0.03006/6 [==============================] - 0s 3ms/step - loss: 0.0294
Epoch 8/500
1/6 [====>.........................] - ETA: 0s - loss: 0.02616/6 [==============================] - 0s 3ms/step - loss: 0.0251
Epoch 9/500
1/6 [====>.........................] - ETA: 0s - loss: 0.02206/6 [==============================] - 0s 3ms/step - loss: 0.0210
Epoch 10/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01816/6 [==============================] - 0s 3ms/step - loss: 0.0171
Epoch 11/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01416/6 [==============================] - 0s 3ms/step - loss: 0.0136
Epoch 12/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01156/6 [==============================] - 0s 3ms/step - loss: 0.0113
Epoch 13/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01016/6 [==============================] - 0s 3ms/step - loss: 0.0099
Epoch 14/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01016/6 [==============================] - 0s 3ms/step - loss: 0.0091
Epoch 15/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00796/6 [==============================] - 0s 3ms/step - loss: 0.0084
Epoch 16/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00916/6 [==============================] - 0s 3ms/step - loss: 0.0084
Epoch 17/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00936/6 [==============================] - 0s 3ms/step - loss: 0.0087
Epoch 18/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00846/6 [==============================] - 0s 3ms/step - loss: 0.0083
Epoch 19/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00666/6 [==============================] - 0s 3ms/step - loss: 0.0077
Epoch 20/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00836/6 [==============================] - 0s 3ms/step - loss: 0.0084
Epoch 21/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00756/6 [==============================] - 0s 3ms/step - loss: 0.0078
Epoch 22/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00786/6 [==============================] - 0s 3ms/step - loss: 0.0080
Epoch 23/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00686/6 [==============================] - 0s 3ms/step - loss: 0.0072
Epoch 24/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00746/6 [==============================] - 0s 3ms/step - loss: 0.0074
Epoch 25/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00886/6 [==============================] - 0s 3ms/step - loss: 0.0078
Epoch 26/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00766/6 [==============================] - 0s 3ms/step - loss: 0.0074
Epoch 27/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00806/6 [==============================] - 0s 4ms/step - loss: 0.0075
Epoch 28/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00756/6 [==============================] - 0s 3ms/step - loss: 0.0075
Epoch 29/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00656/6 [==============================] - 0s 3ms/step - loss: 0.0069
Epoch 30/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00686/6 [==============================] - 0s 3ms/step - loss: 0.0070
Epoch 31/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00746/6 [==============================] - 0s 3ms/step - loss: 0.0072
Epoch 32/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00706/6 [==============================] - 0s 3ms/step - loss: 0.0071
Epoch 33/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00736/6 [==============================] - 0s 3ms/step - loss: 0.0069
Epoch 34/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00696/6 [==============================] - 0s 3ms/step - loss: 0.0070
[get_model] Fit autoencoder
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running wfo
[get_model] Finished running wfo
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
1/6 [====>.........................] - ETA: 1s - loss: 0.05326/6 [==============================] - 0s 3ms/step - loss: 0.0526
Epoch 2/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05066/6 [==============================] - 0s 3ms/step - loss: 0.0497
Epoch 3/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04626/6 [==============================] - 0s 3ms/step - loss: 0.0455
Epoch 4/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04236/6 [==============================] - 0s 3ms/step - loss: 0.0413
Epoch 5/500
1/6 [====>.........................] - ETA: 0s - loss: 0.03756/6 [==============================] - 0s 3ms/step - loss: 0.0366
Epoch 6/500
1/6 [====>.........................] - ETA: 0s - loss: 0.03416/6 [==============================] - 0s 3ms/step - loss: 0.0317
Epoch 7/500
1/6 [====>.........................] - ETA: 0s - loss: 0.02676/6 [==============================] - 0s 3ms/step - loss: 0.0261
Epoch 8/500
1/6 [====>.........................] - ETA: 0s - loss: 0.02166/6 [==============================] - 0s 3ms/step - loss: 0.0212
Epoch 9/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01716/6 [==============================] - 0s 3ms/step - loss: 0.0168
Epoch 10/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01466/6 [==============================] - 0s 3ms/step - loss: 0.0139
Epoch 11/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01126/6 [==============================] - 0s 3ms/step - loss: 0.0115
Epoch 12/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00786/6 [==============================] - 0s 3ms/step - loss: 0.0095
Epoch 13/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00956/6 [==============================] - 0s 3ms/step - loss: 0.0095
Epoch 14/500
1/6 [====>.........................] - ETA: 0s - loss: 0.01056/6 [==============================] - 0s 3ms/step - loss: 0.0095
Epoch 15/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00796/6 [==============================] - 0s 3ms/step - loss: 0.0087
Epoch 16/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00956/6 [==============================] - 0s 3ms/step - loss: 0.0088
Epoch 17/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00826/6 [==============================] - 0s 3ms/step - loss: 0.0083
Epoch 18/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00756/6 [==============================] - 0s 3ms/step - loss: 0.0081
Epoch 19/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00626/6 [==============================] - 0s 3ms/step - loss: 0.0076
Epoch 20/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00796/6 [==============================] - 0s 3ms/step - loss: 0.0079
Epoch 21/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00836/6 [==============================] - 0s 3ms/step - loss: 0.0081
Epoch 22/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00796/6 [==============================] - 0s 4ms/step - loss: 0.0078
Epoch 23/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00846/6 [==============================] - 0s 3ms/step - loss: 0.0077
Epoch 24/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00756/6 [==============================] - 0s 3ms/step - loss: 0.0080
Epoch 25/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00706/6 [==============================] - 0s 3ms/step - loss: 0.0075
Epoch 26/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00706/6 [==============================] - 0s 3ms/step - loss: 0.0075
Epoch 27/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00756/6 [==============================] - 0s 3ms/step - loss: 0.0076
Epoch 28/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00686/6 [==============================] - 0s 3ms/step - loss: 0.0074
Epoch 29/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00566/6 [==============================] - 0s 3ms/step - loss: 0.0071
Epoch 30/500
1/6 [====>.........................] - ETA: 0s - loss: 0.00956/6 [==============================] - 0s 3ms/step - loss: 0.0078
[get_model] Fit autoencoder
Beta: inf  | Score: 0.0
[get_model] Running smooth
[get_model] Finished running smooth
Beta: 0.03860983575856238  | Score: 0.0
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running ultrasample:wfo
[get_model] Finished running ultrasample:wfo
Model: "model_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 19)]              0         
_________________________________________________________________
layer_0 (Dense)              (None, 10)                200       
_________________________________________________________________
layer_1 (Dense)              (None, 7)                 77        
_________________________________________________________________
encoded (Dense)              (None, 5)                 40        
_________________________________________________________________
layer_2 (Dense)              (None, 7)                 42        
_________________________________________________________________
layer_3 (Dense)              (None, 10)                80        
_________________________________________________________________
decoded (Dense)              (None, 19)                209       
=================================================================
Total params: 648
Trainable params: 648
Non-trainable params: 0
_________________________________________________________________
[get_model] Fitting autoencoder
Epoch 1/500
1/6 [====>.........................] - ETA: 1s - loss: 0.05456/6 [==============================] - 0s 3ms/step - loss: 0.0536
Epoch 2/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05316/6 [==============================] - 0s 3ms/step - loss: 0.0531
Epoch 3/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05316/6 [==============================] - 0s 3ms/step - loss: 0.0528
Epoch 4/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05226/6 [==============================] - 0s 3ms/step - loss: 0.0523
Epoch 5/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05226/6 [==============================] - 0s 3ms/step - loss: 0.0521
Epoch 6/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05226/6 [==============================] - 0s 3ms/step - loss: 0.0520
Epoch 7/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05166/6 [==============================] - 0s 3ms/step - loss: 0.0517
Epoch 8/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05176/6 [==============================] - 0s 4ms/step - loss: 0.0516
Epoch 9/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05176/6 [==============================] - 0s 3ms/step - loss: 0.0515
Epoch 10/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05166/6 [==============================] - 0s 3ms/step - loss: 0.0513
Epoch 11/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05056/6 [==============================] - 0s 4ms/step - loss: 0.0510
Epoch 12/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05076/6 [==============================] - 0s 3ms/step - loss: 0.0507
Epoch 13/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04996/6 [==============================] - 0s 3ms/step - loss: 0.0504
Epoch 14/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04916/6 [==============================] - 0s 3ms/step - loss: 0.0503
Epoch 15/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05076/6 [==============================] - 0s 3ms/step - loss: 0.0504
Epoch 16/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05126/6 [==============================] - 0s 3ms/step - loss: 0.0504
Epoch 17/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05086/6 [==============================] - 0s 3ms/step - loss: 0.0503
Epoch 18/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05026/6 [==============================] - 0s 3ms/step - loss: 0.0502
Epoch 19/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05006/6 [==============================] - 0s 3ms/step - loss: 0.0499
Epoch 20/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04806/6 [==============================] - 0s 3ms/step - loss: 0.0493
Epoch 21/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04876/6 [==============================] - 0s 3ms/step - loss: 0.0493
Epoch 22/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04986/6 [==============================] - 0s 3ms/step - loss: 0.0494
Epoch 23/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04966/6 [==============================] - 0s 4ms/step - loss: 0.0494
Epoch 24/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05106/6 [==============================] - 0s 3ms/step - loss: 0.0496
Epoch 25/500
1/6 [====>.........................] - ETA: 0s - loss: 0.05006/6 [==============================] - 0s 3ms/step - loss: 0.0491
Epoch 26/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04806/6 [==============================] - 0s 3ms/step - loss: 0.0489
Epoch 27/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04966/6 [==============================] - 0s 3ms/step - loss: 0.0490
Epoch 28/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04856/6 [==============================] - 0s 3ms/step - loss: 0.0486
Epoch 29/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04836/6 [==============================] - 0s 3ms/step - loss: 0.0487
Epoch 30/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04856/6 [==============================] - 0s 3ms/step - loss: 0.0486
Epoch 31/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04926/6 [==============================] - 0s 3ms/step - loss: 0.0486
Epoch 32/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04936/6 [==============================] - 0s 3ms/step - loss: 0.0485
Epoch 33/500
1/6 [====>.........................] - ETA: 0s - loss: 0.04786/6 [==============================] - 0s 3ms/step - loss: 0.0480
[get_model] Fit autoencoder
Beta: 0.021131012154852837  | Score: 0.8437499999999999
Beta: 0.008378899383117956  | Score: 0.0
[get_model] Running smooth
[get_model] Finished running smooth
[get_model] Running wfo
[get_model] Finished running wfo
Beta: 0.0028166152611634175  | Score: 0.0
Accuracy: 0.8437499999999999
Time: 13.307918787002563

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c82abc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33fb1ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raise_utils.interpret import ScottKnott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f2fdb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset: str, task='issue-close-time'):\n",
    "    results = {}\n",
    "    for dir in os.listdir(f'./classical/results/{task}'):\n",
    "        if dir == 'ff' and task != 'defect':\n",
    "            results[dir] = [0.718, 0.644]\n",
    "            continue\n",
    "            \n",
    "        if dataset in os.listdir(f'./classical/results/{task}/{dir}'):\n",
    "            result = []\n",
    "            for file in os.listdir(f'./classical/results/{task}/{dir}/{dataset}'):\n",
    "                with open(f'./classical/results/{task}/{dir}/{dataset}/{file}') as f:\n",
    "                    lines = f.readlines()\n",
    "                    lines = [x for x in lines if x.startswith('Accuracy')]\n",
    "                    lines = [float(x.split(': ')[1]) for x in lines]\n",
    "\n",
    "                    result.append(lines[0])\n",
    "\n",
    "            results[dir] = result\n",
    "        \n",
    "    # Now do ff\n",
    "    if task == 'defect':\n",
    "        if dataset in os.listdir(f'./results/{task}/'):\n",
    "            result = []\n",
    "            for file in os.listdir(f'./results/{task}/{dataset}'):\n",
    "                with open(f'./results/{task}/{dataset}/{file}') as f:\n",
    "                    lines = f.readlines()\n",
    "                    lines = [x for x in lines if x.startswith('[main] Accuracy')]\n",
    "                    lines = [eval(x.split(': ')[1]) for x in lines]\n",
    "\n",
    "                    result.extend(max(lines))\n",
    "\n",
    "            results['ff'] = result\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "322be6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stats(data):\n",
    "    # Perform Kruskal-Wallis test\n",
    "    _, p_value = stats.kruskal(*data.values())\n",
    "    print(f\"Kruskal-Wallis test p-value: {p_value}\")\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        # Calculate medians for each group\n",
    "        group_medians = {key: np.median(val) for key, val in data.items()}\n",
    "        print(f\"Group medians: {group_medians}\")\n",
    "\n",
    "        # Find the group with the largest median\n",
    "        max_group = max(group_medians, key=group_medians.get)\n",
    "        print(f\"Group with the largest median: {max_group}\")\n",
    "\n",
    "        # Perform pairwise Mann-Whitney U tests\n",
    "        groups = list(data.keys())\n",
    "        num_groups = len(groups)\n",
    "        p_values = np.zeros((num_groups, num_groups))\n",
    "\n",
    "        for i in range(num_groups):\n",
    "            for j in range(i+1, num_groups):\n",
    "                _, p = stats.mannwhitneyu(data[groups[i]], data[groups[j]], alternative='two-sided')\n",
    "                p_values[i, j] = p\n",
    "                p_values[j, i] = p\n",
    "\n",
    "        print('Pairwise Mann-Whitney U tests')\n",
    "        print(pd.DataFrame(p_values, index=groups, columns=groups))\n",
    "        print()\n",
    "\n",
    "        # Apply Bonferroni correction for multiple comparisons\n",
    "        adjusted_p_values = multipletests(p_values.ravel(), method='fdr_bh')[1].reshape(p_values.shape)\n",
    "        post_hoc = pd.DataFrame(adjusted_p_values, index=groups, columns=groups)\n",
    "\n",
    "        print(\"Pairwise Mann-Whitney U tests with Benjamini/Hochberg correction:\")\n",
    "        print(post_hoc)\n",
    "        print()\n",
    "\n",
    "        # Check if the group with the largest median is significantly better than the others\n",
    "        significantly_better = True\n",
    "        for key in data.keys():\n",
    "            if key != max_group and post_hoc.loc[max_group, key] >= 0.05:\n",
    "                significantly_better = False\n",
    "                break\n",
    "\n",
    "        if significantly_better:\n",
    "            print(f\"The group '{max_group}' with the largest median IS significantly better than the others, \", end='')\n",
    "        else:\n",
    "            print(\"The group with the largest median IS NOT significantly better than all the others, \", end='')\n",
    "        \n",
    "        print(f'and the highest p-value is {round(max(post_hoc[max_group]), 2)}')\n",
    "    else:\n",
    "        print(\"There is no significant difference among the groups.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d032a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('firefox-3class', task='issue-close-time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a4a688d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis test p-value: 0.027758946516771684\n",
      "Group medians: {'logistic': 0.4932289583452374, 'random-5': 0.4610879378321239, 'nb': 0.49497171590194844, 'ff': 0.681}\n",
      "Group with the largest median: ff\n",
      "Pairwise Mann-Whitney U tests\n",
      "          logistic  random-5        nb        ff\n",
      "logistic  0.000000  0.053103  0.967635  0.008658\n",
      "random-5  0.053103  0.000000  0.194128  0.008658\n",
      "nb        0.967635  0.194128  0.000000  0.008658\n",
      "ff        0.008658  0.008658  0.008658  0.000000\n",
      "\n",
      "Pairwise Mann-Whitney U tests with Benjamini/Hochberg correction:\n",
      "          logistic  random-5        nb        ff\n",
      "logistic  0.000000  0.070804  0.967635  0.013853\n",
      "random-5  0.070804  0.000000  0.221860  0.013853\n",
      "nb        0.967635  0.221860  0.000000  0.013853\n",
      "ff        0.013853  0.013853  0.013853  0.000000\n",
      "\n",
      "The group 'ff' with the largest median IS significantly better than the others, and the highest p-value is 0.01\n"
     ]
    }
   ],
   "source": [
    "run_stats(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c3f29",
   "metadata": {},
   "source": [
    "## Scott-Knott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f701c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1   logistic (                         |     *                  ), 0.581,  0.620,  0.625,  0.631,  0.636\n",
      "   2         nb (                         |     *                  ), 0.621,  0.625,  0.631,  0.638,  0.647\n",
      "   3         ff (                         |       --*              ), 0.673,  0.673,  0.712,  0.712,  0.712\n",
      "   4   random-5 (                         |             -*-        ), 0.787,  0.788,  0.809,  0.836,  0.845\n"
     ]
    }
   ],
   "source": [
    "sk = ScottKnott(data)\n",
    "sk.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c60b8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

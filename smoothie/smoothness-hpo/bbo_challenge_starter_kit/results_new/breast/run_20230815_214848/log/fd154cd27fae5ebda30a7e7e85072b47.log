running: {'--uuid': 'fd154cd27fae5ebda30a7e7e85072b47', '-db-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230815_214848', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d breast -o hyperopt -u fd154cd27fae5ebda30a7e7e85072b47 -m acc -n 45 -p 1 -dir /Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20230815_214848
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/Users/ryedida/miniforge3/lib/python3.9/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study hyperopt MLP-adam breast acc 45 1
with data root: None
suggestion time taken 0.002013 iter 0 next_points [{'alpha': 0.004150823546140622, 'batch_size': 76, 'beta_1': 0.7468720709344645, 'beta_2': 0.9593105339439773, 'epsilon': 3.8275132960616093e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.005788115976072146, 'tol': 0.0652927639565955, 'validation_fraction': 0.8702221128105325}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.177386 value -0.859341 suggestion {'alpha': 0.004150823546140622, 'batch_size': 76, 'beta_1': 0.7468720709344645, 'beta_2': 0.9593105339439773, 'epsilon': 3.8275132960616093e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.005788115976072146, 'tol': 0.0652927639565955, 'validation_fraction': 0.8702221128105325}
observation time 0.000027, current best -0.859341 at iter 0
suggestion time taken 0.001976 iter 1 next_points [{'alpha': 0.0002911209542189744, 'batch_size': 152, 'beta_1': 0.9268408429809906, 'beta_2': 0.9990117858509009, 'epsilon': 4.502742657026091e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.04374581645642128, 'tol': 0.009552041092410563, 'validation_fraction': 0.55431113295884}]
function_evaluation time 0.257118 value -0.909890 suggestion {'alpha': 0.0002911209542189744, 'batch_size': 152, 'beta_1': 0.9268408429809906, 'beta_2': 0.9990117858509009, 'epsilon': 4.502742657026091e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.04374581645642128, 'tol': 0.009552041092410563, 'validation_fraction': 0.55431113295884}
observation time 0.000021, current best -0.909890 at iter 1
suggestion time taken 0.003056 iter 2 next_points [{'alpha': 0.002293367101878421, 'batch_size': 178, 'beta_1': 0.6383597951973672, 'beta_2': 0.9756059009340767, 'epsilon': 4.74345672072168e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 6.590886650286651e-05, 'tol': 0.003038393636227098, 'validation_fraction': 0.8894759306536552}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.096616 value -0.417582 suggestion {'alpha': 0.002293367101878421, 'batch_size': 178, 'beta_1': 0.6383597951973672, 'beta_2': 0.9756059009340767, 'epsilon': 4.74345672072168e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 6.590886650286651e-05, 'tol': 0.003038393636227098, 'validation_fraction': 0.8894759306536552}
observation time 0.000042, current best -0.909890 at iter 2
suggestion time taken 0.006384 iter 3 next_points [{'alpha': 1.4050109788716303, 'batch_size': 191, 'beta_1': 0.5750089262241638, 'beta_2': 0.9172373426774433, 'epsilon': 1.8648267896808125e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.0007432232870252473, 'tol': 0.00011751266331868882, 'validation_fraction': 0.21658775358256468}]
function_evaluation time 0.462577 value -0.905495 suggestion {'alpha': 1.4050109788716303, 'batch_size': 191, 'beta_1': 0.5750089262241638, 'beta_2': 0.9172373426774433, 'epsilon': 1.8648267896808125e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.0007432232870252473, 'tol': 0.00011751266331868882, 'validation_fraction': 0.21658775358256468}
observation time 0.000048, current best -0.909890 at iter 3
suggestion time taken 0.003255 iter 4 next_points [{'alpha': 0.00039368167453686197, 'batch_size': 122, 'beta_1': 0.8007762480661428, 'beta_2': 0.9521087052224542, 'epsilon': 1.3433466873247568e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.09792862260539628, 'tol': 0.006172391116876982, 'validation_fraction': 0.2635602209662474}]
function_evaluation time 0.447321 value -0.846154 suggestion {'alpha': 0.00039368167453686197, 'batch_size': 122, 'beta_1': 0.8007762480661428, 'beta_2': 0.9521087052224542, 'epsilon': 1.3433466873247568e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.09792862260539628, 'tol': 0.006172391116876982, 'validation_fraction': 0.2635602209662474}
observation time 0.000025, current best -0.909890 at iter 4
suggestion time taken 0.002131 iter 5 next_points [{'alpha': 0.00012281633772087377, 'batch_size': 214, 'beta_1': 0.9772325412889086, 'beta_2': 0.9131396932349743, 'epsilon': 7.594638298883892e-08, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.008043714995359235, 'tol': 0.0016687126239137444, 'validation_fraction': 0.6505974957230362}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.412043 value -0.795604 suggestion {'alpha': 0.00012281633772087377, 'batch_size': 214, 'beta_1': 0.9772325412889086, 'beta_2': 0.9131396932349743, 'epsilon': 7.594638298883892e-08, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.008043714995359235, 'tol': 0.0016687126239137444, 'validation_fraction': 0.6505974957230362}
observation time 0.000024, current best -0.909890 at iter 5
suggestion time taken 0.002096 iter 6 next_points [{'alpha': 3.286483429870958, 'batch_size': 104, 'beta_1': 0.8262759499118005, 'beta_2': 0.9250322423038239, 'epsilon': 3.9212914557371893e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 1.3937742979444279e-05, 'tol': 0.00552782934053518, 'validation_fraction': 0.1967996193648278}]
function_evaluation time 0.116426 value -0.472527 suggestion {'alpha': 3.286483429870958, 'batch_size': 104, 'beta_1': 0.8262759499118005, 'beta_2': 0.9250322423038239, 'epsilon': 3.9212914557371893e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 1.3937742979444279e-05, 'tol': 0.00552782934053518, 'validation_fraction': 0.1967996193648278}
observation time 0.000046, current best -0.909890 at iter 6
suggestion time taken 0.003912 iter 7 next_points [{'alpha': 0.08581479628906888, 'batch_size': 94, 'beta_1': 0.8020534873929063, 'beta_2': 0.9377136460191311, 'epsilon': 8.435353405968335e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 4.2959807065622286e-05, 'tol': 0.01070094962523174, 'validation_fraction': 0.5332968145399642}]
function_evaluation time 0.122257 value -0.472527 suggestion {'alpha': 0.08581479628906888, 'batch_size': 94, 'beta_1': 0.8020534873929063, 'beta_2': 0.9377136460191311, 'epsilon': 8.435353405968335e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 4.2959807065622286e-05, 'tol': 0.01070094962523174, 'validation_fraction': 0.5332968145399642}
observation time 0.000021, current best -0.909890 at iter 7
suggestion time taken 0.001916 iter 8 next_points [{'alpha': 6.31719276085314, 'batch_size': 188, 'beta_1': 0.5647773519375344, 'beta_2': 0.9955700572512668, 'epsilon': 5.344132771033407e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.014643957346405993, 'tol': 0.000624337208344084, 'validation_fraction': 0.32316337566405706}]
function_evaluation time 0.370638 value -0.916484 suggestion {'alpha': 6.31719276085314, 'batch_size': 188, 'beta_1': 0.5647773519375344, 'beta_2': 0.9955700572512668, 'epsilon': 5.344132771033407e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.014643957346405993, 'tol': 0.000624337208344084, 'validation_fraction': 0.32316337566405706}
observation time 0.000050, current best -0.916484 at iter 8
suggestion time taken 0.007434 iter 9 next_points [{'alpha': 0.007664596593097939, 'batch_size': 152, 'beta_1': 0.5228736263726915, 'beta_2': 0.9093006608701537, 'epsilon': 1.2289087436338815e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 3.816014736494316e-05, 'tol': 2.946615765964538e-05, 'validation_fraction': 0.10095961121699117}]
function_evaluation time 0.468283 value -0.637363 suggestion {'alpha': 0.007664596593097939, 'batch_size': 152, 'beta_1': 0.5228736263726915, 'beta_2': 0.9093006608701537, 'epsilon': 1.2289087436338815e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 3.816014736494316e-05, 'tol': 2.946615765964538e-05, 'validation_fraction': 0.10095961121699117}
observation time 0.000025, current best -0.916484 at iter 9
suggestion time taken 0.002117 iter 10 next_points [{'alpha': 0.10543571734365663, 'batch_size': 149, 'beta_1': 0.8744513490527537, 'beta_2': 0.9647076323226526, 'epsilon': 1.7293239678410552e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.0002890375003670544, 'tol': 0.002488414975379252, 'validation_fraction': 0.15913846514818927}]
function_evaluation time 0.833798 value -0.828571 suggestion {'alpha': 0.10543571734365663, 'batch_size': 149, 'beta_1': 0.8744513490527537, 'beta_2': 0.9647076323226526, 'epsilon': 1.7293239678410552e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.0002890375003670544, 'tol': 0.002488414975379252, 'validation_fraction': 0.15913846514818927}
observation time 0.000026, current best -0.916484 at iter 10
suggestion time taken 0.002121 iter 11 next_points [{'alpha': 2.2707966662725854, 'batch_size': 168, 'beta_1': 0.5145082034071188, 'beta_2': 0.9210925954907624, 'epsilon': 5.167234217759553e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 1.3849634618236443e-05, 'tol': 0.00010843039366482223, 'validation_fraction': 0.18061509922934607}]
function_evaluation time 0.242972 value -0.362637 suggestion {'alpha': 2.2707966662725854, 'batch_size': 168, 'beta_1': 0.5145082034071188, 'beta_2': 0.9210925954907624, 'epsilon': 5.167234217759553e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 1.3849634618236443e-05, 'tol': 0.00010843039366482223, 'validation_fraction': 0.18061509922934607}
observation time 0.000026, current best -0.916484 at iter 11
suggestion time taken 0.002095 iter 12 next_points [{'alpha': 0.4356667388779564, 'batch_size': 150, 'beta_1': 0.8222216918638061, 'beta_2': 0.9882705607908566, 'epsilon': 1.0673136363271611e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.021735319140809294, 'tol': 0.013772752647437957, 'validation_fraction': 0.21376168121046357}]
function_evaluation time 0.340893 value -0.905495 suggestion {'alpha': 0.4356667388779564, 'batch_size': 150, 'beta_1': 0.8222216918638061, 'beta_2': 0.9882705607908566, 'epsilon': 1.0673136363271611e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.021735319140809294, 'tol': 0.013772752647437957, 'validation_fraction': 0.21376168121046357}
observation time 0.000028, current best -0.916484 at iter 12
suggestion time taken 0.001917 iter 13 next_points [{'alpha': 0.010821617029073832, 'batch_size': 79, 'beta_1': 0.8154720516904675, 'beta_2': 0.9333147563615694, 'epsilon': 1.9542700129230912e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.045493505506350396, 'tol': 0.0007517816276205321, 'validation_fraction': 0.48354853464245534}]
function_evaluation time 0.421276 value -0.903297 suggestion {'alpha': 0.010821617029073832, 'batch_size': 79, 'beta_1': 0.8154720516904675, 'beta_2': 0.9333147563615694, 'epsilon': 1.9542700129230912e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.045493505506350396, 'tol': 0.0007517816276205321, 'validation_fraction': 0.48354853464245534}
observation time 0.000050, current best -0.916484 at iter 13
suggestion time taken 0.004897 iter 14 next_points [{'alpha': 8.967576950032807, 'batch_size': 169, 'beta_1': 0.9826533500435722, 'beta_2': 0.9222287790209851, 'epsilon': 3.215509337133836e-08, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.000706121438209128, 'tol': 7.100705317230523e-05, 'validation_fraction': 0.570455576983421}]
function_evaluation time 0.374720 value -0.734066 suggestion {'alpha': 8.967576950032807, 'batch_size': 169, 'beta_1': 0.9826533500435722, 'beta_2': 0.9222287790209851, 'epsilon': 3.215509337133836e-08, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.000706121438209128, 'tol': 7.100705317230523e-05, 'validation_fraction': 0.570455576983421}
observation time 0.000026, current best -0.916484 at iter 14
suggestion time taken 0.004012 iter 15 next_points [{'alpha': 0.00015000008694772096, 'batch_size': 194, 'beta_1': 0.5391268831130838, 'beta_2': 0.908295956226631, 'epsilon': 1.316958830739984e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.003683998292064531, 'tol': 1.3749042529949021e-05, 'validation_fraction': 0.13869216049667374}]
function_evaluation time 0.264984 value -0.892308 suggestion {'alpha': 0.00015000008694772096, 'batch_size': 194, 'beta_1': 0.5391268831130838, 'beta_2': 0.908295956226631, 'epsilon': 1.316958830739984e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.003683998292064531, 'tol': 1.3749042529949021e-05, 'validation_fraction': 0.13869216049667374}
observation time 0.000027, current best -0.916484 at iter 15
suggestion time taken 0.002089 iter 16 next_points [{'alpha': 0.18383654530128685, 'batch_size': 174, 'beta_1': 0.6425429507034176, 'beta_2': 0.9819114522607063, 'epsilon': 5.655710015528641e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.00025126234789041464, 'tol': 0.013419993891721778, 'validation_fraction': 0.3296267264661455}]
function_evaluation time 0.304947 value -0.716484 suggestion {'alpha': 0.18383654530128685, 'batch_size': 174, 'beta_1': 0.6425429507034176, 'beta_2': 0.9819114522607063, 'epsilon': 5.655710015528641e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.00025126234789041464, 'tol': 0.013419993891721778, 'validation_fraction': 0.3296267264661455}
observation time 0.000055, current best -0.916484 at iter 16
suggestion time taken 0.006581 iter 17 next_points [{'alpha': 0.047957991180870276, 'batch_size': 130, 'beta_1': 0.6489541152677206, 'beta_2': 0.9450248926478257, 'epsilon': 1.3656976843338827e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.0007239387647549941, 'tol': 8.505834309757434e-05, 'validation_fraction': 0.11433668449895183}]
function_evaluation time 0.392634 value -0.890110 suggestion {'alpha': 0.047957991180870276, 'batch_size': 130, 'beta_1': 0.6489541152677206, 'beta_2': 0.9450248926478257, 'epsilon': 1.3656976843338827e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.0007239387647549941, 'tol': 8.505834309757434e-05, 'validation_fraction': 0.11433668449895183}
observation time 0.000028, current best -0.916484 at iter 17
suggestion time taken 0.002116 iter 18 next_points [{'alpha': 0.001892420919141694, 'batch_size': 83, 'beta_1': 0.9226766160150913, 'beta_2': 0.9421395183882784, 'epsilon': 7.353789755400643e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.0031887065242640865, 'tol': 0.012456075826672672, 'validation_fraction': 0.6339672744735171}]
function_evaluation time 0.322901 value -0.912088 suggestion {'alpha': 0.001892420919141694, 'batch_size': 83, 'beta_1': 0.9226766160150913, 'beta_2': 0.9421395183882784, 'epsilon': 7.353789755400643e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.0031887065242640865, 'tol': 0.012456075826672672, 'validation_fraction': 0.6339672744735171}
observation time 0.000027, current best -0.916484 at iter 18
suggestion time taken 0.001950 iter 19 next_points [{'alpha': 0.046948836872173126, 'batch_size': 163, 'beta_1': 0.7106762348272121, 'beta_2': 0.9629620741388091, 'epsilon': 1.5751356378304356e-09, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.003444245087188133, 'tol': 7.950243308668676e-05, 'validation_fraction': 0.5105083169821995}]
function_evaluation time 0.436958 value -0.907692 suggestion {'alpha': 0.046948836872173126, 'batch_size': 163, 'beta_1': 0.7106762348272121, 'beta_2': 0.9629620741388091, 'epsilon': 1.5751356378304356e-09, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.003444245087188133, 'tol': 7.950243308668676e-05, 'validation_fraction': 0.5105083169821995}
observation time 0.000054, current best -0.916484 at iter 19
suggestion time taken 0.014580 iter 20 next_points [{'alpha': 2.5543366557586685e-05, 'batch_size': 20, 'beta_1': 0.5879567282867119, 'beta_2': 0.9984402196407551, 'epsilon': 2.952106349132986e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.011102912740142561, 'tol': 0.0004723331386384813, 'validation_fraction': 0.34531717268282147}]
function_evaluation time 0.579101 value -0.907692 suggestion {'alpha': 2.5543366557586685e-05, 'batch_size': 20, 'beta_1': 0.5879567282867119, 'beta_2': 0.9984402196407551, 'epsilon': 2.952106349132986e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.011102912740142561, 'tol': 0.0004723331386384813, 'validation_fraction': 0.34531717268282147}
observation time 0.000029, current best -0.916484 at iter 20
suggestion time taken 0.006739 iter 21 next_points [{'alpha': 0.0011198802985227727, 'batch_size': 237, 'beta_1': 0.5868168289274598, 'beta_2': 0.9457816732909078, 'epsilon': 9.684666786111433e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.0021243347662624193, 'tol': 0.05961212479080201, 'validation_fraction': 0.3929865647678303}]
function_evaluation time 0.242516 value -0.896703 suggestion {'alpha': 0.0011198802985227727, 'batch_size': 237, 'beta_1': 0.5868168289274598, 'beta_2': 0.9457816732909078, 'epsilon': 9.684666786111433e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.0021243347662624193, 'tol': 0.05961212479080201, 'validation_fraction': 0.3929865647678303}
observation time 0.000029, current best -0.916484 at iter 21
suggestion time taken 0.006863 iter 22 next_points [{'alpha': 1.8266487525200807e-05, 'batch_size': 46, 'beta_1': 0.6926144963339178, 'beta_2': 0.9298323947188826, 'epsilon': 3.358702798851773e-09, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.01925065587165476, 'tol': 0.00032708879101506086, 'validation_fraction': 0.7094740525026294}]
function_evaluation time 0.303089 value -0.903297 suggestion {'alpha': 1.8266487525200807e-05, 'batch_size': 46, 'beta_1': 0.6926144963339178, 'beta_2': 0.9298323947188826, 'epsilon': 3.358702798851773e-09, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.01925065587165476, 'tol': 0.00032708879101506086, 'validation_fraction': 0.7094740525026294}
observation time 0.000055, current best -0.916484 at iter 22
suggestion time taken 0.015493 iter 23 next_points [{'alpha': 0.017609329124052685, 'batch_size': 249, 'beta_1': 0.9114817925273698, 'beta_2': 0.9019464170789264, 'epsilon': 5.357360010640122e-09, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001607431586325371, 'tol': 0.02832839072057029, 'validation_fraction': 0.41919960788205757}]
function_evaluation time 0.290099 value -0.791209 suggestion {'alpha': 0.017609329124052685, 'batch_size': 249, 'beta_1': 0.9114817925273698, 'beta_2': 0.9019464170789264, 'epsilon': 5.357360010640122e-09, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001607431586325371, 'tol': 0.02832839072057029, 'validation_fraction': 0.41919960788205757}
observation time 0.000026, current best -0.916484 at iter 23
suggestion time taken 0.014209 iter 24 next_points [{'alpha': 0.000897030914117364, 'batch_size': 47, 'beta_1': 0.5524021013363549, 'beta_2': 0.9550180990426733, 'epsilon': 9.719233565268585e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.0643467545658433, 'tol': 0.0003011247529765088, 'validation_fraction': 0.2600336271211293}]
function_evaluation time 0.778759 value -0.903297 suggestion {'alpha': 0.000897030914117364, 'batch_size': 47, 'beta_1': 0.5524021013363549, 'beta_2': 0.9550180990426733, 'epsilon': 9.719233565268585e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.0643467545658433, 'tol': 0.0003011247529765088, 'validation_fraction': 0.2600336271211293}
observation time 0.000060, current best -0.916484 at iter 24
suggestion time taken 0.015359 iter 25 next_points [{'alpha': 5.509588165436529e-05, 'batch_size': 226, 'beta_1': 0.502450900485807, 'beta_2': 0.9735774072274526, 'epsilon': 7.528618630283507e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.018464068332935835, 'tol': 0.0011325359029811688, 'validation_fraction': 0.7982631264903957}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.333412 value -0.903297 suggestion {'alpha': 5.509588165436529e-05, 'batch_size': 226, 'beta_1': 0.502450900485807, 'beta_2': 0.9735774072274526, 'epsilon': 7.528618630283507e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.018464068332935835, 'tol': 0.0011325359029811688, 'validation_fraction': 0.7982631264903957}
observation time 0.000028, current best -0.916484 at iter 25
suggestion time taken 0.008959 iter 26 next_points [{'alpha': 0.5405253319126665, 'batch_size': 11, 'beta_1': 0.7249247781044645, 'beta_2': 0.9386974868292123, 'epsilon': 2.2136902335308466e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0002701865703933964, 'tol': 0.029077528292490613, 'validation_fraction': 0.2606367196267868}]
function_evaluation time 0.724252 value -0.909890 suggestion {'alpha': 0.5405253319126665, 'batch_size': 11, 'beta_1': 0.7249247781044645, 'beta_2': 0.9386974868292123, 'epsilon': 2.2136902335308466e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0002701865703933964, 'tol': 0.029077528292490613, 'validation_fraction': 0.2606367196267868}
observation time 0.000068, current best -0.916484 at iter 26
suggestion time taken 0.009596 iter 27 next_points [{'alpha': 9.448073386690982, 'batch_size': 55, 'beta_1': 0.6127301337944852, 'beta_2': 0.9698773831502698, 'epsilon': 6.225252262265349e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.004778160699212265, 'tol': 0.00020823891340029222, 'validation_fraction': 0.4216665434632393}]
function_evaluation time 0.220985 value -0.896703 suggestion {'alpha': 9.448073386690982, 'batch_size': 55, 'beta_1': 0.6127301337944852, 'beta_2': 0.9698773831502698, 'epsilon': 6.225252262265349e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.004778160699212265, 'tol': 0.00020823891340029222, 'validation_fraction': 0.4216665434632393}
observation time 0.000026, current best -0.916484 at iter 27
suggestion time taken 0.008862 iter 28 next_points [{'alpha': 0.003913025338910883, 'batch_size': 121, 'beta_1': 0.7667204783848848, 'beta_2': 0.9891482213861527, 'epsilon': 2.332075364450415e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0016350311443964172, 'tol': 0.0488131991667696, 'validation_fraction': 0.7823310141918994}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.164363 value -0.800000 suggestion {'alpha': 0.003913025338910883, 'batch_size': 121, 'beta_1': 0.7667204783848848, 'beta_2': 0.9891482213861527, 'epsilon': 2.332075364450415e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0016350311443964172, 'tol': 0.0488131991667696, 'validation_fraction': 0.7823310141918994}
observation time 0.000027, current best -0.916484 at iter 28
suggestion time taken 0.007537 iter 29 next_points [{'alpha': 0.0012797186989746447, 'batch_size': 64, 'beta_1': 0.685917863831745, 'beta_2': 0.9583393235763402, 'epsilon': 4.937138507856282e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.029125794446110544, 'tol': 0.0008182491904234895, 'validation_fraction': 0.28972708842684003}]
function_evaluation time 0.452040 value -0.901099 suggestion {'alpha': 0.0012797186989746447, 'batch_size': 64, 'beta_1': 0.685917863831745, 'beta_2': 0.9583393235763402, 'epsilon': 4.937138507856282e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.029125794446110544, 'tol': 0.0008182491904234895, 'validation_fraction': 0.28972708842684003}
observation time 0.000027, current best -0.916484 at iter 29
suggestion time taken 0.014620 iter 30 next_points [{'alpha': 0.020840860954122447, 'batch_size': 29, 'beta_1': 0.9345093265384867, 'beta_2': 0.9476899138242683, 'epsilon': 3.3627609885985333e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.006721108483337501, 'tol': 0.09170461563690849, 'validation_fraction': 0.612983712450803}]
function_evaluation time 0.240623 value -0.892308 suggestion {'alpha': 0.020840860954122447, 'batch_size': 29, 'beta_1': 0.9345093265384867, 'beta_2': 0.9476899138242683, 'epsilon': 3.3627609885985333e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.006721108483337501, 'tol': 0.09170461563690849, 'validation_fraction': 0.612983712450803}
observation time 0.000030, current best -0.916484 at iter 30
suggestion time taken 0.011572 iter 31 next_points [{'alpha': 0.0004053546995867214, 'batch_size': 93, 'beta_1': 0.7535176099620811, 'beta_2': 0.998019058289065, 'epsilon': 1.6859313379942706e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.011585113952714578, 'tol': 0.004292991225327062, 'validation_fraction': 0.36405571473043313}]
function_evaluation time 0.390740 value -0.903297 suggestion {'alpha': 0.0004053546995867214, 'batch_size': 93, 'beta_1': 0.7535176099620811, 'beta_2': 0.998019058289065, 'epsilon': 1.6859313379942706e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.011585113952714578, 'tol': 0.004292991225327062, 'validation_fraction': 0.36405571473043313}
observation time 0.000028, current best -0.916484 at iter 31
suggestion time taken 0.019041 iter 32 next_points [{'alpha': 0.004037975433139836, 'batch_size': 200, 'beta_1': 0.6624130528898191, 'beta_2': 0.929395020046883, 'epsilon': 2.3597522897528503e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.09426096801602474, 'tol': 0.0015594614901830368, 'validation_fraction': 0.4660771354194565}]
function_evaluation time 0.283436 value -0.740659 suggestion {'alpha': 0.004037975433139836, 'batch_size': 200, 'beta_1': 0.6624130528898191, 'beta_2': 0.929395020046883, 'epsilon': 2.3597522897528503e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.09426096801602474, 'tol': 0.0015594614901830368, 'validation_fraction': 0.4660771354194565}
observation time 0.000070, current best -0.916484 at iter 32
suggestion time taken 0.012512 iter 33 next_points [{'alpha': 0.7822911488364218, 'batch_size': 135, 'beta_1': 0.5605150149266116, 'beta_2': 0.9419617982194719, 'epsilon': 3.0098607278027865e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.00012812007972492576, 'tol': 3.610470298285827e-05, 'validation_fraction': 0.8910795344343088}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.138421 value -0.610989 suggestion {'alpha': 0.7822911488364218, 'batch_size': 135, 'beta_1': 0.5605150149266116, 'beta_2': 0.9419617982194719, 'epsilon': 3.0098607278027865e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.00012812007972492576, 'tol': 3.610470298285827e-05, 'validation_fraction': 0.8910795344343088}
observation time 0.000030, current best -0.916484 at iter 33
suggestion time taken 0.012971 iter 34 next_points [{'alpha': 0.0023065349170281243, 'batch_size': 109, 'beta_1': 0.6150727210617057, 'beta_2': 0.9818369950866788, 'epsilon': 9.32584305391545e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.002698443413604503, 'tol': 0.002829510132954472, 'validation_fraction': 0.3160231384733915}]
function_evaluation time 0.314272 value -0.901099 suggestion {'alpha': 0.0023065349170281243, 'batch_size': 109, 'beta_1': 0.6150727210617057, 'beta_2': 0.9818369950866788, 'epsilon': 9.32584305391545e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.002698443413604503, 'tol': 0.002829510132954472, 'validation_fraction': 0.3160231384733915}
observation time 0.000028, current best -0.916484 at iter 34
suggestion time taken 0.007374 iter 35 next_points [{'alpha': 7.381426039951133e-05, 'batch_size': 212, 'beta_1': 0.6104523462414579, 'beta_2': 0.9538520036771684, 'epsilon': 1.962843444560895e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.001022167911933959, 'tol': 0.024827884608083887, 'validation_fraction': 0.6923187581568625}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.107553 value -0.551648 suggestion {'alpha': 7.381426039951133e-05, 'batch_size': 212, 'beta_1': 0.6104523462414579, 'beta_2': 0.9538520036771684, 'epsilon': 1.962843444560895e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.001022167911933959, 'tol': 0.024827884608083887, 'validation_fraction': 0.6923187581568625}
observation time 0.000025, current best -0.916484 at iter 35
suggestion time taken 0.012970 iter 36 next_points [{'alpha': 0.00048012905532004264, 'batch_size': 182, 'beta_1': 0.8762134814849929, 'beta_2': 0.9662372204477826, 'epsilon': 6.135315369323843e-08, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.011023347185572515, 'tol': 0.006256761077600034, 'validation_fraction': 0.28700945948450257}]
function_evaluation time 0.285259 value -0.901099 suggestion {'alpha': 0.00048012905532004264, 'batch_size': 182, 'beta_1': 0.8762134814849929, 'beta_2': 0.9662372204477826, 'epsilon': 6.135315369323843e-08, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.011023347185572515, 'tol': 0.006256761077600034, 'validation_fraction': 0.28700945948450257}
observation time 0.000031, current best -0.916484 at iter 36
suggestion time taken 0.015449 iter 37 next_points [{'alpha': 0.2617942563647277, 'batch_size': 73, 'beta_1': 0.8514863176216458, 'beta_2': 0.9922784788052, 'epsilon': 1.0645265315800882e-09, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.03792497716296345, 'tol': 0.0006410618784381784, 'validation_fraction': 0.22626132091999}]
function_evaluation time 0.535000 value -0.896703 suggestion {'alpha': 0.2617942563647277, 'batch_size': 73, 'beta_1': 0.8514863176216458, 'beta_2': 0.9922784788052, 'epsilon': 1.0645265315800882e-09, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.03792497716296345, 'tol': 0.0006410618784381784, 'validation_fraction': 0.22626132091999}
observation time 0.000032, current best -0.916484 at iter 37
suggestion time taken 0.007687 iter 38 next_points [{'alpha': 0.007125758389628793, 'batch_size': 88, 'beta_1': 0.9458877073486404, 'beta_2': 0.9759489235881448, 'epsilon': 8.725160999884567e-08, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.0011109087985664613, 'tol': 0.0017339370313239637, 'validation_fraction': 0.1302133293749222}]
function_evaluation time 0.557695 value -0.881319 suggestion {'alpha': 0.007125758389628793, 'batch_size': 88, 'beta_1': 0.9458877073486404, 'beta_2': 0.9759489235881448, 'epsilon': 8.725160999884567e-08, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.0011109087985664613, 'tol': 0.0017339370313239637, 'validation_fraction': 0.1302133293749222}
observation time 0.000062, current best -0.916484 at iter 38
suggestion time taken 0.011796 iter 39 next_points [{'alpha': 5.72101945701236, 'batch_size': 107, 'beta_1': 0.7834777106566273, 'beta_2': 0.9173559026463249, 'epsilon': 1.321852835179679e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.006645450381789687, 'tol': 1.1877245387369724e-05, 'validation_fraction': 0.1695490814575954}]
function_evaluation time 0.457972 value -0.894505 suggestion {'alpha': 5.72101945701236, 'batch_size': 107, 'beta_1': 0.7834777106566273, 'beta_2': 0.9173559026463249, 'epsilon': 1.321852835179679e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.006645450381789687, 'tol': 1.1877245387369724e-05, 'validation_fraction': 0.1695490814575954}
observation time 0.000064, current best -0.916484 at iter 39
suggestion time taken 0.008786 iter 40 next_points [{'alpha': 0.0001642755543998022, 'batch_size': 138, 'beta_1': 0.7381493090540002, 'beta_2': 0.9003585265289954, 'epsilon': 5.121666867645351e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.00044470327863852405, 'tol': 0.00017684900966139834, 'validation_fraction': 0.5654322089009458}]
function_evaluation time 0.258628 value -0.734066 suggestion {'alpha': 0.0001642755543998022, 'batch_size': 138, 'beta_1': 0.7381493090540002, 'beta_2': 0.9003585265289954, 'epsilon': 5.121666867645351e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.00044470327863852405, 'tol': 0.00017684900966139834, 'validation_fraction': 0.5654322089009458}
observation time 0.000031, current best -0.916484 at iter 40
suggestion time taken 0.008436 iter 41 next_points [{'alpha': 1.2573774718887867, 'batch_size': 210, 'beta_1': 0.6747972680888398, 'beta_2': 0.9506648934346061, 'epsilon': 2.3149047215009356e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.07941012740153225, 'tol': 0.008273983142806023, 'validation_fraction': 0.23903428317543457}]
function_evaluation time 0.376243 value -0.894505 suggestion {'alpha': 1.2573774718887867, 'batch_size': 210, 'beta_1': 0.6747972680888398, 'beta_2': 0.9506648934346061, 'epsilon': 2.3149047215009356e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.07941012740153225, 'tol': 0.008273983142806023, 'validation_fraction': 0.23903428317543457}
observation time 0.000032, current best -0.916484 at iter 41
suggestion time taken 0.007957 iter 42 next_points [{'alpha': 0.036023277012254454, 'batch_size': 227, 'beta_1': 0.8990969604419574, 'beta_2': 0.9352578987214103, 'epsilon': 1.5386488415709285e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.0001364445204499217, 'tol': 0.004474852272223263, 'validation_fraction': 0.19542243756742844}]
function_evaluation time 0.401136 value -0.516484 suggestion {'alpha': 0.036023277012254454, 'batch_size': 227, 'beta_1': 0.8990969604419574, 'beta_2': 0.9352578987214103, 'epsilon': 1.5386488415709285e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.0001364445204499217, 'tol': 0.004474852272223263, 'validation_fraction': 0.19542243756742844}
observation time 0.000030, current best -0.916484 at iter 42
suggestion time taken 0.018792 iter 43 next_points [{'alpha': 2.5835742476774795, 'batch_size': 118, 'beta_1': 0.5238719122839033, 'beta_2': 0.9592364572414581, 'epsilon': 8.65060183308797e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.00044176372165476114, 'tol': 0.0011821477511135077, 'validation_fraction': 0.44711992135143014}]
function_evaluation time 0.477875 value -0.843956 suggestion {'alpha': 2.5835742476774795, 'batch_size': 118, 'beta_1': 0.5238719122839033, 'beta_2': 0.9592364572414581, 'epsilon': 8.65060183308797e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.00044176372165476114, 'tol': 0.0011821477511135077, 'validation_fraction': 0.44711992135143014}
observation time 0.000061, current best -0.916484 at iter 43
suggestion time taken 0.013758 iter 44 next_points [{'alpha': 1.1372755833552646e-05, 'batch_size': 184, 'beta_1': 0.9682112530885297, 'beta_2': 0.9792466120664213, 'epsilon': 1.3941390846513972e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.0046957036642117705, 'tol': 0.01902436640054497, 'validation_fraction': 0.38100787988528817}]
function_evaluation time 0.332702 value -0.846154 suggestion {'alpha': 1.1372755833552646e-05, 'batch_size': 184, 'beta_1': 0.9682112530885297, 'beta_2': 0.9792466120664213, 'epsilon': 1.3941390846513972e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.0046957036642117705, 'tol': 0.01902436640054497, 'validation_fraction': 0.38100787988528817}
observation time 0.000033, current best -0.916484 at iter 44
saving meta data: {'args': {'--uuid': 'fd154cd27fae5ebda30a7e7e85072b47', '-db-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230815_214848', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '15afe07dda2058db86aec4b046242757', '-db-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230815_214848', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random/optimizer.py -c MLP-adam -d breast -o random -u 15afe07dda2058db86aec4b046242757 -m acc -n 45 -p 1 -dir /Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20230815_214848
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/Users/ryedida/miniforge3/lib/python3.9/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 45 1
with data root: None
suggestion time taken 0.003795 iter 0 next_points [{'alpha': 0.2610382559880974, 'batch_size': 78, 'beta_1': 0.9881008653036051, 'beta_2': 0.9999438861125576, 'epsilon': 3.959856883363855e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0014097563317368082, 'tol': 0.00015086962054726278, 'validation_fraction': 0.8962240812367995}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.139443 value -0.584615 suggestion {'alpha': 0.2610382559880974, 'batch_size': 78, 'beta_1': 0.9881008653036051, 'beta_2': 0.9999438861125576, 'epsilon': 3.959856883363855e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0014097563317368082, 'tol': 0.00015086962054726278, 'validation_fraction': 0.8962240812367995}
observation time 0.000002, current best -0.584615 at iter 0
suggestion time taken 0.001823 iter 1 next_points [{'alpha': 0.15918753006979236, 'batch_size': 21, 'beta_1': 0.5343595757793563, 'beta_2': 0.9996845924783139, 'epsilon': 4.976422612876389e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.04831687297073396, 'tol': 0.0002693686653123976, 'validation_fraction': 0.30809133010278505}]
function_evaluation time 0.582082 value -0.905495 suggestion {'alpha': 0.15918753006979236, 'batch_size': 21, 'beta_1': 0.5343595757793563, 'beta_2': 0.9996845924783139, 'epsilon': 4.976422612876389e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.04831687297073396, 'tol': 0.0002693686653123976, 'validation_fraction': 0.30809133010278505}
observation time 0.000001, current best -0.905495 at iter 1
suggestion time taken 0.005901 iter 2 next_points [{'alpha': 0.403069027522293, 'batch_size': 35, 'beta_1': 0.7681806012881914, 'beta_2': 0.9988389333721079, 'epsilon': 5.879429427159055e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.003992249327579392, 'tol': 0.014428885799908853, 'validation_fraction': 0.6109197538452578}]
function_evaluation time 0.293594 value -0.909890 suggestion {'alpha': 0.403069027522293, 'batch_size': 35, 'beta_1': 0.7681806012881914, 'beta_2': 0.9988389333721079, 'epsilon': 5.879429427159055e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.003992249327579392, 'tol': 0.014428885799908853, 'validation_fraction': 0.6109197538452578}
observation time 0.000001, current best -0.909890 at iter 2
suggestion time taken 0.001642 iter 3 next_points [{'alpha': 0.002197364110300886, 'batch_size': 37, 'beta_1': 0.9144035429918159, 'beta_2': 0.9998960448326807, 'epsilon': 4.239944246132589e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.01922694772093909, 'tol': 0.0005125043718451543, 'validation_fraction': 0.8411482837603776}]
function_evaluation time 0.317904 value -0.898901 suggestion {'alpha': 0.002197364110300886, 'batch_size': 37, 'beta_1': 0.9144035429918159, 'beta_2': 0.9998960448326807, 'epsilon': 4.239944246132589e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.01922694772093909, 'tol': 0.0005125043718451543, 'validation_fraction': 0.8411482837603776}
observation time 0.000001, current best -0.909890 at iter 3
suggestion time taken 0.001645 iter 4 next_points [{'alpha': 0.0010712748033397, 'batch_size': 111, 'beta_1': 0.8931480416960781, 'beta_2': 0.9812087587754276, 'epsilon': 1.1617154163213868e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 3.952936045809283e-05, 'tol': 0.06128757864110841, 'validation_fraction': 0.8820149813668794}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.113307 value -0.527473 suggestion {'alpha': 0.0010712748033397, 'batch_size': 111, 'beta_1': 0.8931480416960781, 'beta_2': 0.9812087587754276, 'epsilon': 1.1617154163213868e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 3.952936045809283e-05, 'tol': 0.06128757864110841, 'validation_fraction': 0.8820149813668794}
observation time 0.000001, current best -0.909890 at iter 4
suggestion time taken 0.001614 iter 5 next_points [{'alpha': 0.0018995944523979022, 'batch_size': 11, 'beta_1': 0.9737037082437634, 'beta_2': 0.9947063461543538, 'epsilon': 1.200146519441445e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.00027014444139209756, 'tol': 0.0002717493188533662, 'validation_fraction': 0.1553405806709532}]
function_evaluation time 0.821708 value -0.914286 suggestion {'alpha': 0.0018995944523979022, 'batch_size': 11, 'beta_1': 0.9737037082437634, 'beta_2': 0.9947063461543538, 'epsilon': 1.200146519441445e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.00027014444139209756, 'tol': 0.0002717493188533662, 'validation_fraction': 0.1553405806709532}
observation time 0.000001, current best -0.914286 at iter 5
suggestion time taken 0.003186 iter 6 next_points [{'alpha': 0.001294444583467493, 'batch_size': 110, 'beta_1': 0.985412641895907, 'beta_2': 0.9543314981778666, 'epsilon': 1.2156598889290817e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.00020519998560622067, 'tol': 0.01572993872505529, 'validation_fraction': 0.45891188889876433}]
function_evaluation time 0.347196 value -0.621978 suggestion {'alpha': 0.001294444583467493, 'batch_size': 110, 'beta_1': 0.985412641895907, 'beta_2': 0.9543314981778666, 'epsilon': 1.2156598889290817e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.00020519998560622067, 'tol': 0.01572993872505529, 'validation_fraction': 0.45891188889876433}
observation time 0.000002, current best -0.914286 at iter 6
suggestion time taken 0.007415 iter 7 next_points [{'alpha': 0.40991569698806274, 'batch_size': 24, 'beta_1': 0.7887698927040465, 'beta_2': 0.9999899250384274, 'epsilon': 1.7831810122478215e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.004968744806275691, 'tol': 1.313162600876857e-05, 'validation_fraction': 0.26307811962855465}]
function_evaluation time 0.558387 value -0.916484 suggestion {'alpha': 0.40991569698806274, 'batch_size': 24, 'beta_1': 0.7887698927040465, 'beta_2': 0.9999899250384274, 'epsilon': 1.7831810122478215e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.004968744806275691, 'tol': 1.313162600876857e-05, 'validation_fraction': 0.26307811962855465}
observation time 0.000001, current best -0.916484 at iter 7
suggestion time taken 0.001791 iter 8 next_points [{'alpha': 0.3940729345266194, 'batch_size': 172, 'beta_1': 0.983341143689984, 'beta_2': 0.9999930295308594, 'epsilon': 2.3587391165229644e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 6.570713416194852e-05, 'tol': 0.05861601552564135, 'validation_fraction': 0.11985662688889809}]
function_evaluation time 0.217926 value -0.558242 suggestion {'alpha': 0.3940729345266194, 'batch_size': 172, 'beta_1': 0.983341143689984, 'beta_2': 0.9999930295308594, 'epsilon': 2.3587391165229644e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 6.570713416194852e-05, 'tol': 0.05861601552564135, 'validation_fraction': 0.11985662688889809}
observation time 0.000001, current best -0.916484 at iter 8
suggestion time taken 0.001637 iter 9 next_points [{'alpha': 0.004404738986170891, 'batch_size': 107, 'beta_1': 0.5052560769988953, 'beta_2': 0.9526831119881082, 'epsilon': 2.3802801570640218e-07, 'hidden_layer_sizes': 169, 'learning_rate_init': 5.219459123192484e-05, 'tol': 0.038816395510258166, 'validation_fraction': 0.3279074243981075}]
function_evaluation time 0.396492 value -0.676923 suggestion {'alpha': 0.004404738986170891, 'batch_size': 107, 'beta_1': 0.5052560769988953, 'beta_2': 0.9526831119881082, 'epsilon': 2.3802801570640218e-07, 'hidden_layer_sizes': 169, 'learning_rate_init': 5.219459123192484e-05, 'tol': 0.038816395510258166, 'validation_fraction': 0.3279074243981075}
observation time 0.000001, current best -0.916484 at iter 9
suggestion time taken 0.001637 iter 10 next_points [{'alpha': 2.2908879586481428e-05, 'batch_size': 211, 'beta_1': 0.9636900139332767, 'beta_2': 0.9999885123689968, 'epsilon': 1.2426735197125066e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.00020398349621955202, 'tol': 0.0007317026520175643, 'validation_fraction': 0.10814032604825995}]
function_evaluation time 0.444104 value -0.683516 suggestion {'alpha': 2.2908879586481428e-05, 'batch_size': 211, 'beta_1': 0.9636900139332767, 'beta_2': 0.9999885123689968, 'epsilon': 1.2426735197125066e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.00020398349621955202, 'tol': 0.0007317026520175643, 'validation_fraction': 0.10814032604825995}
observation time 0.000001, current best -0.916484 at iter 10
suggestion time taken 0.001767 iter 11 next_points [{'alpha': 0.00023310812410033986, 'batch_size': 102, 'beta_1': 0.6938241992710616, 'beta_2': 0.9999983342905291, 'epsilon': 1.2861165133028966e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.001347039304458882, 'tol': 0.018921511365593946, 'validation_fraction': 0.1909787338965498}]
function_evaluation time 0.381349 value -0.905495 suggestion {'alpha': 0.00023310812410033986, 'batch_size': 102, 'beta_1': 0.6938241992710616, 'beta_2': 0.9999983342905291, 'epsilon': 1.2861165133028966e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.001347039304458882, 'tol': 0.018921511365593946, 'validation_fraction': 0.1909787338965498}
observation time 0.000001, current best -0.916484 at iter 11
suggestion time taken 0.005545 iter 12 next_points [{'alpha': 0.0057633090404065725, 'batch_size': 219, 'beta_1': 0.9053663094535628, 'beta_2': 0.9973873608149589, 'epsilon': 8.201441347999037e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.00038550936145920867, 'tol': 0.005641923151197654, 'validation_fraction': 0.6263228734108773}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.271997 value -0.621978 suggestion {'alpha': 0.0057633090404065725, 'batch_size': 219, 'beta_1': 0.9053663094535628, 'beta_2': 0.9973873608149589, 'epsilon': 8.201441347999037e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.00038550936145920867, 'tol': 0.005641923151197654, 'validation_fraction': 0.6263228734108773}
observation time 0.000001, current best -0.916484 at iter 12
suggestion time taken 0.001797 iter 13 next_points [{'alpha': 0.00010991507173368417, 'batch_size': 104, 'beta_1': 0.7262313123457546, 'beta_2': 0.9937304148982966, 'epsilon': 7.294827099605919e-07, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.023404175921459287, 'tol': 0.0008123882584108766, 'validation_fraction': 0.37133335749120394}]
function_evaluation time 0.452044 value -0.898901 suggestion {'alpha': 0.00010991507173368417, 'batch_size': 104, 'beta_1': 0.7262313123457546, 'beta_2': 0.9937304148982966, 'epsilon': 7.294827099605919e-07, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.023404175921459287, 'tol': 0.0008123882584108766, 'validation_fraction': 0.37133335749120394}
observation time 0.000003, current best -0.916484 at iter 13
suggestion time taken 0.004966 iter 14 next_points [{'alpha': 0.06272452745901227, 'batch_size': 133, 'beta_1': 0.5904775005518866, 'beta_2': 0.9865653887290201, 'epsilon': 5.995384786704757e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0019769769103358268, 'tol': 1.4869972230063596e-05, 'validation_fraction': 0.566722641477352}]
function_evaluation time 0.430748 value -0.898901 suggestion {'alpha': 0.06272452745901227, 'batch_size': 133, 'beta_1': 0.5904775005518866, 'beta_2': 0.9865653887290201, 'epsilon': 5.995384786704757e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0019769769103358268, 'tol': 1.4869972230063596e-05, 'validation_fraction': 0.566722641477352}
observation time 0.000002, current best -0.916484 at iter 14
suggestion time taken 0.004880 iter 15 next_points [{'alpha': 3.430327040088445e-05, 'batch_size': 58, 'beta_1': 0.7882216997947047, 'beta_2': 0.9999902170660091, 'epsilon': 1.833934033492245e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.000165672255228427, 'tol': 0.08931460774242607, 'validation_fraction': 0.3495256362445484}]
function_evaluation time 0.117008 value -0.628571 suggestion {'alpha': 3.430327040088445e-05, 'batch_size': 58, 'beta_1': 0.7882216997947047, 'beta_2': 0.9999902170660091, 'epsilon': 1.833934033492245e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.000165672255228427, 'tol': 0.08931460774242607, 'validation_fraction': 0.3495256362445484}
observation time 0.000001, current best -0.916484 at iter 15
suggestion time taken 0.001763 iter 16 next_points [{'alpha': 1.021281769116467e-05, 'batch_size': 208, 'beta_1': 0.9492683199558691, 'beta_2': 0.9702597210800213, 'epsilon': 7.173821556659244e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 2.617767898641902e-05, 'tol': 0.0044454406832750894, 'validation_fraction': 0.11836038990050593}]
function_evaluation time 0.241613 value -0.637363 suggestion {'alpha': 1.021281769116467e-05, 'batch_size': 208, 'beta_1': 0.9492683199558691, 'beta_2': 0.9702597210800213, 'epsilon': 7.173821556659244e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 2.617767898641902e-05, 'tol': 0.0044454406832750894, 'validation_fraction': 0.11836038990050593}
observation time 0.000001, current best -0.916484 at iter 16
suggestion time taken 0.001780 iter 17 next_points [{'alpha': 0.0025091008210788215, 'batch_size': 115, 'beta_1': 0.5823142247057178, 'beta_2': 0.9915234688944494, 'epsilon': 1.5809198532708043e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0004371671914877338, 'tol': 0.0006229732635833345, 'validation_fraction': 0.8852562776494983}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.415233 value -0.756044 suggestion {'alpha': 0.0025091008210788215, 'batch_size': 115, 'beta_1': 0.5823142247057178, 'beta_2': 0.9915234688944494, 'epsilon': 1.5809198532708043e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0004371671914877338, 'tol': 0.0006229732635833345, 'validation_fraction': 0.8852562776494983}
observation time 0.000002, current best -0.916484 at iter 17
suggestion time taken 0.005052 iter 18 next_points [{'alpha': 0.0005754702625401797, 'batch_size': 62, 'beta_1': 0.9876227245427739, 'beta_2': 0.9154097807849306, 'epsilon': 3.0386155937757617e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.04212061269190622, 'tol': 0.08036428368024578, 'validation_fraction': 0.5525894221842945}]
function_evaluation time 0.590535 value -0.872527 suggestion {'alpha': 0.0005754702625401797, 'batch_size': 62, 'beta_1': 0.9876227245427739, 'beta_2': 0.9154097807849306, 'epsilon': 3.0386155937757617e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.04212061269190622, 'tol': 0.08036428368024578, 'validation_fraction': 0.5525894221842945}
observation time 0.000003, current best -0.916484 at iter 18
suggestion time taken 0.004700 iter 19 next_points [{'alpha': 0.05366502888670133, 'batch_size': 239, 'beta_1': 0.9187408526072304, 'beta_2': 0.9032969893942034, 'epsilon': 2.8512502185268023e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.04433225408546424, 'tol': 0.0010758573212616303, 'validation_fraction': 0.6279028788827488}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 1.012901 value -0.901099 suggestion {'alpha': 0.05366502888670133, 'batch_size': 239, 'beta_1': 0.9187408526072304, 'beta_2': 0.9032969893942034, 'epsilon': 2.8512502185268023e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.04433225408546424, 'tol': 0.0010758573212616303, 'validation_fraction': 0.6279028788827488}
observation time 0.000001, current best -0.916484 at iter 19
suggestion time taken 0.001773 iter 20 next_points [{'alpha': 0.7415841765466178, 'batch_size': 217, 'beta_1': 0.9764598372408718, 'beta_2': 0.9999967574399522, 'epsilon': 1.5223437407225122e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.00046882248696411316, 'tol': 0.030301879473004112, 'validation_fraction': 0.17310303205530117}]
function_evaluation time 0.255175 value -0.725275 suggestion {'alpha': 0.7415841765466178, 'batch_size': 217, 'beta_1': 0.9764598372408718, 'beta_2': 0.9999967574399522, 'epsilon': 1.5223437407225122e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.00046882248696411316, 'tol': 0.030301879473004112, 'validation_fraction': 0.17310303205530117}
observation time 0.000002, current best -0.916484 at iter 20
suggestion time taken 0.004675 iter 21 next_points [{'alpha': 0.35049071710870433, 'batch_size': 10, 'beta_1': 0.791624120114405, 'beta_2': 0.998705373854246, 'epsilon': 6.775204182494993e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 5.1154636635666316e-05, 'tol': 0.003645684962341414, 'validation_fraction': 0.8526251862759519}]
function_evaluation time 0.339229 value -0.564835 suggestion {'alpha': 0.35049071710870433, 'batch_size': 10, 'beta_1': 0.791624120114405, 'beta_2': 0.998705373854246, 'epsilon': 6.775204182494993e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 5.1154636635666316e-05, 'tol': 0.003645684962341414, 'validation_fraction': 0.8526251862759519}
observation time 0.000002, current best -0.916484 at iter 21
suggestion time taken 0.003412 iter 22 next_points [{'alpha': 1.9743293275258118, 'batch_size': 150, 'beta_1': 0.5250633110106621, 'beta_2': 0.9973662334966664, 'epsilon': 8.908746729523601e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.013020577099845141, 'tol': 0.007390102104476864, 'validation_fraction': 0.5068862526641651}]
function_evaluation time 0.357971 value -0.909890 suggestion {'alpha': 1.9743293275258118, 'batch_size': 150, 'beta_1': 0.5250633110106621, 'beta_2': 0.9973662334966664, 'epsilon': 8.908746729523601e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.013020577099845141, 'tol': 0.007390102104476864, 'validation_fraction': 0.5068862526641651}
observation time 0.000001, current best -0.916484 at iter 22
suggestion time taken 0.001633 iter 23 next_points [{'alpha': 0.0018432710377411941, 'batch_size': 155, 'beta_1': 0.9453902362114633, 'beta_2': 0.9422653914112133, 'epsilon': 9.816358183280054e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 2.6078826094107623e-05, 'tol': 0.0002710272146555376, 'validation_fraction': 0.7789591355066503}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.322527 value -0.472527 suggestion {'alpha': 0.0018432710377411941, 'batch_size': 155, 'beta_1': 0.9453902362114633, 'beta_2': 0.9422653914112133, 'epsilon': 9.816358183280054e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 2.6078826094107623e-05, 'tol': 0.0002710272146555376, 'validation_fraction': 0.7789591355066503}
observation time 0.000002, current best -0.916484 at iter 23
suggestion time taken 0.001622 iter 24 next_points [{'alpha': 1.2446662950476257, 'batch_size': 246, 'beta_1': 0.9693359404906776, 'beta_2': 0.9411396740077572, 'epsilon': 9.096473978024125e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 1.2469944927608746e-05, 'tol': 0.001280237456246695, 'validation_fraction': 0.2948184764400842}]
function_evaluation time 0.267031 value -0.527473 suggestion {'alpha': 1.2446662950476257, 'batch_size': 246, 'beta_1': 0.9693359404906776, 'beta_2': 0.9411396740077572, 'epsilon': 9.096473978024125e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 1.2469944927608746e-05, 'tol': 0.001280237456246695, 'validation_fraction': 0.2948184764400842}
observation time 0.000001, current best -0.916484 at iter 24
suggestion time taken 0.003221 iter 25 next_points [{'alpha': 0.01788009619998253, 'batch_size': 95, 'beta_1': 0.9669660073116698, 'beta_2': 0.9444344059623091, 'epsilon': 2.764028353977488e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.014705857604620294, 'tol': 5.511096914227998e-05, 'validation_fraction': 0.5808339471251227}]
function_evaluation time 0.542032 value -0.909890 suggestion {'alpha': 0.01788009619998253, 'batch_size': 95, 'beta_1': 0.9669660073116698, 'beta_2': 0.9444344059623091, 'epsilon': 2.764028353977488e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.014705857604620294, 'tol': 5.511096914227998e-05, 'validation_fraction': 0.5808339471251227}
observation time 0.000002, current best -0.916484 at iter 25
suggestion time taken 0.003784 iter 26 next_points [{'alpha': 0.00025731508432182425, 'batch_size': 242, 'beta_1': 0.8385007551053085, 'beta_2': 0.9987283193189083, 'epsilon': 1.3361436651947363e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.02219924331431927, 'tol': 3.532059535364589e-05, 'validation_fraction': 0.17853583210407636}]
function_evaluation time 0.298528 value -0.905495 suggestion {'alpha': 0.00025731508432182425, 'batch_size': 242, 'beta_1': 0.8385007551053085, 'beta_2': 0.9987283193189083, 'epsilon': 1.3361436651947363e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.02219924331431927, 'tol': 3.532059535364589e-05, 'validation_fraction': 0.17853583210407636}
observation time 0.000002, current best -0.916484 at iter 26
suggestion time taken 0.002139 iter 27 next_points [{'alpha': 0.5153075044350554, 'batch_size': 100, 'beta_1': 0.8417630236069621, 'beta_2': 0.9999979666969877, 'epsilon': 2.016934564602113e-08, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.044669262449385114, 'tol': 0.0004953274759028843, 'validation_fraction': 0.892926325570164}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.211304 value -0.892308 suggestion {'alpha': 0.5153075044350554, 'batch_size': 100, 'beta_1': 0.8417630236069621, 'beta_2': 0.9999979666969877, 'epsilon': 2.016934564602113e-08, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.044669262449385114, 'tol': 0.0004953274759028843, 'validation_fraction': 0.892926325570164}
observation time 0.000001, current best -0.916484 at iter 27
suggestion time taken 0.001604 iter 28 next_points [{'alpha': 0.2306923789725722, 'batch_size': 221, 'beta_1': 0.9538223028661413, 'beta_2': 0.9374124408789023, 'epsilon': 2.0635152260222315e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.000298689789709113, 'tol': 0.00032114033540186956, 'validation_fraction': 0.7801187279373509}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.190125 value -0.516484 suggestion {'alpha': 0.2306923789725722, 'batch_size': 221, 'beta_1': 0.9538223028661413, 'beta_2': 0.9374124408789023, 'epsilon': 2.0635152260222315e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.000298689789709113, 'tol': 0.00032114033540186956, 'validation_fraction': 0.7801187279373509}
observation time 0.000001, current best -0.916484 at iter 28
suggestion time taken 0.001622 iter 29 next_points [{'alpha': 0.00020145335870102506, 'batch_size': 123, 'beta_1': 0.9322063741964386, 'beta_2': 0.9953075643051734, 'epsilon': 8.88269827562898e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.001670610929457758, 'tol': 8.66231834122771e-05, 'validation_fraction': 0.897149066875341}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.187704 value -0.830769 suggestion {'alpha': 0.00020145335870102506, 'batch_size': 123, 'beta_1': 0.9322063741964386, 'beta_2': 0.9953075643051734, 'epsilon': 8.88269827562898e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.001670610929457758, 'tol': 8.66231834122771e-05, 'validation_fraction': 0.897149066875341}
observation time 0.000002, current best -0.916484 at iter 29
suggestion time taken 0.004609 iter 30 next_points [{'alpha': 1.0311480745491156e-05, 'batch_size': 243, 'beta_1': 0.9265149431015018, 'beta_2': 0.9481829876043429, 'epsilon': 1.441399336039021e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0002477986851803853, 'tol': 0.00023895880373605812, 'validation_fraction': 0.5932611021595674}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.111055 value -0.573626 suggestion {'alpha': 1.0311480745491156e-05, 'batch_size': 243, 'beta_1': 0.9265149431015018, 'beta_2': 0.9481829876043429, 'epsilon': 1.441399336039021e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0002477986851803853, 'tol': 0.00023895880373605812, 'validation_fraction': 0.5932611021595674}
observation time 0.000002, current best -0.916484 at iter 30
suggestion time taken 0.005310 iter 31 next_points [{'alpha': 0.014426534253501782, 'batch_size': 104, 'beta_1': 0.950429853866422, 'beta_2': 0.9993591280219706, 'epsilon': 1.8101707622272028e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.01264148480092285, 'tol': 6.602211763894851e-05, 'validation_fraction': 0.2260113787051971}]
function_evaluation time 0.151039 value -0.872527 suggestion {'alpha': 0.014426534253501782, 'batch_size': 104, 'beta_1': 0.950429853866422, 'beta_2': 0.9993591280219706, 'epsilon': 1.8101707622272028e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.01264148480092285, 'tol': 6.602211763894851e-05, 'validation_fraction': 0.2260113787051971}
observation time 0.000001, current best -0.916484 at iter 31
suggestion time taken 0.004402 iter 32 next_points [{'alpha': 0.0001520950236630958, 'batch_size': 90, 'beta_1': 0.6416522126566412, 'beta_2': 0.999994847857666, 'epsilon': 2.8403619359545183e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 2.1041141095831847e-05, 'tol': 0.051635841976207304, 'validation_fraction': 0.1735062998733839}]
function_evaluation time 0.188761 value -0.523077 suggestion {'alpha': 0.0001520950236630958, 'batch_size': 90, 'beta_1': 0.6416522126566412, 'beta_2': 0.999994847857666, 'epsilon': 2.8403619359545183e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 2.1041141095831847e-05, 'tol': 0.051635841976207304, 'validation_fraction': 0.1735062998733839}
observation time 0.000001, current best -0.916484 at iter 32
suggestion time taken 0.001603 iter 33 next_points [{'alpha': 0.03004895718709023, 'batch_size': 86, 'beta_1': 0.852025141414245, 'beta_2': 0.9999977871418801, 'epsilon': 5.291615922279593e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 3.7349497610599676e-05, 'tol': 2.076277333190115e-05, 'validation_fraction': 0.6230115027347677}]
function_evaluation time 0.138432 value -0.527473 suggestion {'alpha': 0.03004895718709023, 'batch_size': 86, 'beta_1': 0.852025141414245, 'beta_2': 0.9999977871418801, 'epsilon': 5.291615922279593e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 3.7349497610599676e-05, 'tol': 2.076277333190115e-05, 'validation_fraction': 0.6230115027347677}
observation time 0.000001, current best -0.916484 at iter 33
suggestion time taken 0.001646 iter 34 next_points [{'alpha': 0.03611843415610535, 'batch_size': 11, 'beta_1': 0.9834967779847117, 'beta_2': 0.9997443349982365, 'epsilon': 3.7304449820871434e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.045407301152579856, 'tol': 0.011275889859594029, 'validation_fraction': 0.4372269938395143}]
function_evaluation time 0.416920 value -0.837363 suggestion {'alpha': 0.03611843415610535, 'batch_size': 11, 'beta_1': 0.9834967779847117, 'beta_2': 0.9997443349982365, 'epsilon': 3.7304449820871434e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.045407301152579856, 'tol': 0.011275889859594029, 'validation_fraction': 0.4372269938395143}
observation time 0.000001, current best -0.916484 at iter 34
suggestion time taken 0.001613 iter 35 next_points [{'alpha': 2.3816453061052816e-05, 'batch_size': 105, 'beta_1': 0.9879553123036751, 'beta_2': 0.9714895607151591, 'epsilon': 8.994606086444908e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.005518051970223189, 'tol': 0.0023286066221215756, 'validation_fraction': 0.6184329023188846}]
function_evaluation time 0.241175 value -0.898901 suggestion {'alpha': 2.3816453061052816e-05, 'batch_size': 105, 'beta_1': 0.9879553123036751, 'beta_2': 0.9714895607151591, 'epsilon': 8.994606086444908e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.005518051970223189, 'tol': 0.0023286066221215756, 'validation_fraction': 0.6184329023188846}
observation time 0.000001, current best -0.916484 at iter 35
suggestion time taken 0.001625 iter 36 next_points [{'alpha': 0.00014057719266810938, 'batch_size': 143, 'beta_1': 0.9888902313105242, 'beta_2': 0.9999987114832598, 'epsilon': 8.695410482610561e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 1.6039843430288034e-05, 'tol': 0.014620045340315638, 'validation_fraction': 0.15672621529714126}]
function_evaluation time 0.165000 value -0.417582 suggestion {'alpha': 0.00014057719266810938, 'batch_size': 143, 'beta_1': 0.9888902313105242, 'beta_2': 0.9999987114832598, 'epsilon': 8.695410482610561e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 1.6039843430288034e-05, 'tol': 0.014620045340315638, 'validation_fraction': 0.15672621529714126}
observation time 0.000001, current best -0.916484 at iter 36
suggestion time taken 0.001761 iter 37 next_points [{'alpha': 8.994763968699722e-05, 'batch_size': 154, 'beta_1': 0.525876906752021, 'beta_2': 0.999364087947733, 'epsilon': 1.1456526826538204e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 2.3068713152281654e-05, 'tol': 0.046260374878031967, 'validation_fraction': 0.14949945800587197}]
function_evaluation time 0.173207 value -0.582418 suggestion {'alpha': 8.994763968699722e-05, 'batch_size': 154, 'beta_1': 0.525876906752021, 'beta_2': 0.999364087947733, 'epsilon': 1.1456526826538204e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 2.3068713152281654e-05, 'tol': 0.046260374878031967, 'validation_fraction': 0.14949945800587197}
observation time 0.000001, current best -0.916484 at iter 37
suggestion time taken 0.001614 iter 38 next_points [{'alpha': 0.7940648504839938, 'batch_size': 167, 'beta_1': 0.9804376599333653, 'beta_2': 0.9972894388419236, 'epsilon': 1.2922177719842025e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 1.207978538385502e-05, 'tol': 7.261080137642558e-05, 'validation_fraction': 0.8757443612545189}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.176097 value -0.472527 suggestion {'alpha': 0.7940648504839938, 'batch_size': 167, 'beta_1': 0.9804376599333653, 'beta_2': 0.9972894388419236, 'epsilon': 1.2922177719842025e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 1.207978538385502e-05, 'tol': 7.261080137642558e-05, 'validation_fraction': 0.8757443612545189}
observation time 0.000001, current best -0.916484 at iter 38
suggestion time taken 0.001620 iter 39 next_points [{'alpha': 0.05823868838463929, 'batch_size': 43, 'beta_1': 0.9417078172759308, 'beta_2': 0.9985028882961108, 'epsilon': 2.752815888303312e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 1.144895326926063e-05, 'tol': 0.00012176851239111164, 'validation_fraction': 0.2702167360660228}]
function_evaluation time 0.239945 value -0.683516 suggestion {'alpha': 0.05823868838463929, 'batch_size': 43, 'beta_1': 0.9417078172759308, 'beta_2': 0.9985028882961108, 'epsilon': 2.752815888303312e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 1.144895326926063e-05, 'tol': 0.00012176851239111164, 'validation_fraction': 0.2702167360660228}
observation time 0.000001, current best -0.916484 at iter 39
suggestion time taken 0.001757 iter 40 next_points [{'alpha': 0.0009040185917278668, 'batch_size': 93, 'beta_1': 0.6018261799700161, 'beta_2': 0.9999698540083394, 'epsilon': 5.0652236375348724e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 7.529357214869913e-05, 'tol': 0.001078918657089382, 'validation_fraction': 0.24390389986975453}]
function_evaluation time 0.088764 value -0.573626 suggestion {'alpha': 0.0009040185917278668, 'batch_size': 93, 'beta_1': 0.6018261799700161, 'beta_2': 0.9999698540083394, 'epsilon': 5.0652236375348724e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 7.529357214869913e-05, 'tol': 0.001078918657089382, 'validation_fraction': 0.24390389986975453}
observation time 0.000001, current best -0.916484 at iter 40
suggestion time taken 0.001732 iter 41 next_points [{'alpha': 8.596403780508606, 'batch_size': 144, 'beta_1': 0.6539319821882954, 'beta_2': 0.9903762684025097, 'epsilon': 2.841744309649051e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 9.083001660352492e-05, 'tol': 0.00011727242378268924, 'validation_fraction': 0.8176824612135202}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.206915 value -0.648352 suggestion {'alpha': 8.596403780508606, 'batch_size': 144, 'beta_1': 0.6539319821882954, 'beta_2': 0.9903762684025097, 'epsilon': 2.841744309649051e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 9.083001660352492e-05, 'tol': 0.00011727242378268924, 'validation_fraction': 0.8176824612135202}
observation time 0.000002, current best -0.916484 at iter 41
suggestion time taken 0.001624 iter 42 next_points [{'alpha': 0.00072611323096004, 'batch_size': 241, 'beta_1': 0.9795011551331211, 'beta_2': 0.9999246266595089, 'epsilon': 5.240815867795684e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.05140834367429085, 'tol': 2.464361599666907e-05, 'validation_fraction': 0.7724953470875345}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.230128 value -0.703297 suggestion {'alpha': 0.00072611323096004, 'batch_size': 241, 'beta_1': 0.9795011551331211, 'beta_2': 0.9999246266595089, 'epsilon': 5.240815867795684e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.05140834367429085, 'tol': 2.464361599666907e-05, 'validation_fraction': 0.7724953470875345}
observation time 0.000001, current best -0.916484 at iter 42
suggestion time taken 0.001626 iter 43 next_points [{'alpha': 9.88885265195843e-05, 'batch_size': 50, 'beta_1': 0.9854014802487618, 'beta_2': 0.9507922729717752, 'epsilon': 2.070440721500026e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0380886560265865, 'tol': 5.1196202862299376e-05, 'validation_fraction': 0.820685153494336}]
function_evaluation time 0.209480 value -0.841758 suggestion {'alpha': 9.88885265195843e-05, 'batch_size': 50, 'beta_1': 0.9854014802487618, 'beta_2': 0.9507922729717752, 'epsilon': 2.070440721500026e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0380886560265865, 'tol': 5.1196202862299376e-05, 'validation_fraction': 0.820685153494336}
observation time 0.000001, current best -0.916484 at iter 43
suggestion time taken 0.001604 iter 44 next_points [{'alpha': 0.11748795761716159, 'batch_size': 95, 'beta_1': 0.9823390601572276, 'beta_2': 0.9857253841023913, 'epsilon': 1.652285383792294e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.01745843938901561, 'tol': 5.417563233988328e-05, 'validation_fraction': 0.40004839346202126}]
function_evaluation time 0.328657 value -0.898901 suggestion {'alpha': 0.11748795761716159, 'batch_size': 95, 'beta_1': 0.9823390601572276, 'beta_2': 0.9857253841023913, 'epsilon': 1.652285383792294e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.01745843938901561, 'tol': 5.417563233988328e-05, 'validation_fraction': 0.40004839346202126}
observation time 0.000001, current best -0.916484 at iter 44
saving meta data: {'args': {'--uuid': '15afe07dda2058db86aec4b046242757', '-db-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230815_214848', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '9252b169878554ed8937d95c90913beb', '-db-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230815_214848', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random/optimizer.py -c MLP-adam -d breast -o random -u 9252b169878554ed8937d95c90913beb -m acc -n 45 -p 1 -dir /Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20230815_214848
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/Users/ryedida/miniforge3/lib/python3.9/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 45 1
with data root: None
suggestion time taken 0.001637 iter 0 next_points [{'alpha': 2.4782802209248514e-05, 'batch_size': 177, 'beta_1': 0.8532953292557797, 'beta_2': 0.999987584860438, 'epsilon': 2.7972315977185643e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.00016206436463596312, 'tol': 0.0023992801783070967, 'validation_fraction': 0.387263347555447}]
function_evaluation time 0.462817 value -0.771429 suggestion {'alpha': 2.4782802209248514e-05, 'batch_size': 177, 'beta_1': 0.8532953292557797, 'beta_2': 0.999987584860438, 'epsilon': 2.7972315977185643e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.00016206436463596312, 'tol': 0.0023992801783070967, 'validation_fraction': 0.387263347555447}
observation time 0.000010, current best -0.771429 at iter 0
suggestion time taken 0.005369 iter 1 next_points [{'alpha': 2.517936525203319e-05, 'batch_size': 134, 'beta_1': 0.851622158766365, 'beta_2': 0.998418751654495, 'epsilon': 6.372033514470192e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.001589527266587754, 'tol': 0.025896954690747796, 'validation_fraction': 0.32514897809335663}]
function_evaluation time 0.379236 value -0.905495 suggestion {'alpha': 2.517936525203319e-05, 'batch_size': 134, 'beta_1': 0.851622158766365, 'beta_2': 0.998418751654495, 'epsilon': 6.372033514470192e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.001589527266587754, 'tol': 0.025896954690747796, 'validation_fraction': 0.32514897809335663}
observation time 0.000001, current best -0.905495 at iter 1
suggestion time taken 0.001658 iter 2 next_points [{'alpha': 0.0003763327575349728, 'batch_size': 198, 'beta_1': 0.9144778396199571, 'beta_2': 0.9463443474058023, 'epsilon': 7.02385633873924e-09, 'hidden_layer_sizes': 185, 'learning_rate_init': 9.458475907842417e-05, 'tol': 3.5446454333712605e-05, 'validation_fraction': 0.15517493561986637}]
function_evaluation time 0.371679 value -0.617582 suggestion {'alpha': 0.0003763327575349728, 'batch_size': 198, 'beta_1': 0.9144778396199571, 'beta_2': 0.9463443474058023, 'epsilon': 7.02385633873924e-09, 'hidden_layer_sizes': 185, 'learning_rate_init': 9.458475907842417e-05, 'tol': 3.5446454333712605e-05, 'validation_fraction': 0.15517493561986637}
observation time 0.000001, current best -0.905495 at iter 2
suggestion time taken 0.001668 iter 3 next_points [{'alpha': 0.0003725159277966883, 'batch_size': 142, 'beta_1': 0.9875165453371232, 'beta_2': 0.9999085837534952, 'epsilon': 7.535113564483308e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.07140936464775662, 'tol': 0.0007943435649768826, 'validation_fraction': 0.2596519609143226}]
function_evaluation time 0.355273 value -0.905495 suggestion {'alpha': 0.0003725159277966883, 'batch_size': 142, 'beta_1': 0.9875165453371232, 'beta_2': 0.9999085837534952, 'epsilon': 7.535113564483308e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.07140936464775662, 'tol': 0.0007943435649768826, 'validation_fraction': 0.2596519609143226}
observation time 0.000001, current best -0.905495 at iter 3
suggestion time taken 0.001807 iter 4 next_points [{'alpha': 0.18383245188576275, 'batch_size': 166, 'beta_1': 0.9885039751229057, 'beta_2': 0.9250145787108283, 'epsilon': 2.749268585572693e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.059718517869265436, 'tol': 0.00010378736626674168, 'validation_fraction': 0.8333786278180393}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.171329 value -0.780220 suggestion {'alpha': 0.18383245188576275, 'batch_size': 166, 'beta_1': 0.9885039751229057, 'beta_2': 0.9250145787108283, 'epsilon': 2.749268585572693e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.059718517869265436, 'tol': 0.00010378736626674168, 'validation_fraction': 0.8333786278180393}
observation time 0.000001, current best -0.905495 at iter 4
suggestion time taken 0.001812 iter 5 next_points [{'alpha': 0.018033297941187694, 'batch_size': 44, 'beta_1': 0.9870146918618371, 'beta_2': 0.9999985978660804, 'epsilon': 3.4040574866390875e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 3.4094024896125976e-05, 'tol': 0.00022747005143223362, 'validation_fraction': 0.6955757576780884}]
function_evaluation time 0.215445 value -0.621978 suggestion {'alpha': 0.018033297941187694, 'batch_size': 44, 'beta_1': 0.9870146918618371, 'beta_2': 0.9999985978660804, 'epsilon': 3.4040574866390875e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 3.4094024896125976e-05, 'tol': 0.00022747005143223362, 'validation_fraction': 0.6955757576780884}
observation time 0.000001, current best -0.905495 at iter 5
suggestion time taken 0.001780 iter 6 next_points [{'alpha': 0.0034554705164473606, 'batch_size': 197, 'beta_1': 0.9342499812223791, 'beta_2': 0.9999988737216103, 'epsilon': 4.851407864699834e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 2.628517239548604e-05, 'tol': 6.902235521656987e-05, 'validation_fraction': 0.7212389503791485}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.199175 value -0.509890 suggestion {'alpha': 0.0034554705164473606, 'batch_size': 197, 'beta_1': 0.9342499812223791, 'beta_2': 0.9999988737216103, 'epsilon': 4.851407864699834e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 2.628517239548604e-05, 'tol': 6.902235521656987e-05, 'validation_fraction': 0.7212389503791485}
observation time 0.000001, current best -0.905495 at iter 6
suggestion time taken 0.001707 iter 7 next_points [{'alpha': 0.005154149644788742, 'batch_size': 79, 'beta_1': 0.9714992459283888, 'beta_2': 0.9928962999868156, 'epsilon': 3.809133329357048e-09, 'hidden_layer_sizes': 136, 'learning_rate_init': 7.864002232404423e-05, 'tol': 0.0005545685477381068, 'validation_fraction': 0.3353342639630057}]
function_evaluation time 0.532930 value -0.582418 suggestion {'alpha': 0.005154149644788742, 'batch_size': 79, 'beta_1': 0.9714992459283888, 'beta_2': 0.9928962999868156, 'epsilon': 3.809133329357048e-09, 'hidden_layer_sizes': 136, 'learning_rate_init': 7.864002232404423e-05, 'tol': 0.0005545685477381068, 'validation_fraction': 0.3353342639630057}
observation time 0.000001, current best -0.905495 at iter 7
suggestion time taken 0.001650 iter 8 next_points [{'alpha': 9.510906279005006e-05, 'batch_size': 82, 'beta_1': 0.9523190208376588, 'beta_2': 0.9999791540299696, 'epsilon': 1.8569365722247812e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 3.29982861278185e-05, 'tol': 0.0004145459412866972, 'validation_fraction': 0.773203971115958}]
function_evaluation time 0.164623 value -0.580220 suggestion {'alpha': 9.510906279005006e-05, 'batch_size': 82, 'beta_1': 0.9523190208376588, 'beta_2': 0.9999791540299696, 'epsilon': 1.8569365722247812e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 3.29982861278185e-05, 'tol': 0.0004145459412866972, 'validation_fraction': 0.773203971115958}
observation time 0.000001, current best -0.905495 at iter 8
suggestion time taken 0.001785 iter 9 next_points [{'alpha': 1.9064394382797482e-05, 'batch_size': 97, 'beta_1': 0.9751061822561827, 'beta_2': 0.9999930315044965, 'epsilon': 6.452757628909939e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 2.971090606362337e-05, 'tol': 0.06672368447529861, 'validation_fraction': 0.14761858184592014}]
function_evaluation time 0.112128 value -0.525275 suggestion {'alpha': 1.9064394382797482e-05, 'batch_size': 97, 'beta_1': 0.9751061822561827, 'beta_2': 0.9999930315044965, 'epsilon': 6.452757628909939e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 2.971090606362337e-05, 'tol': 0.06672368447529861, 'validation_fraction': 0.14761858184592014}
observation time 0.000001, current best -0.905495 at iter 9
suggestion time taken 0.003806 iter 10 next_points [{'alpha': 0.0027544522838134225, 'batch_size': 143, 'beta_1': 0.9821341934969181, 'beta_2': 0.9999964167102698, 'epsilon': 9.087423583845701e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.00033474482961431116, 'tol': 0.0010013250886423879, 'validation_fraction': 0.21674874167499514}]
function_evaluation time 0.441687 value -0.731868 suggestion {'alpha': 0.0027544522838134225, 'batch_size': 143, 'beta_1': 0.9821341934969181, 'beta_2': 0.9999964167102698, 'epsilon': 9.087423583845701e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.00033474482961431116, 'tol': 0.0010013250886423879, 'validation_fraction': 0.21674874167499514}
observation time 0.000001, current best -0.905495 at iter 10
suggestion time taken 0.001798 iter 11 next_points [{'alpha': 2.14425250754254, 'batch_size': 248, 'beta_1': 0.9518160361339723, 'beta_2': 0.9919048520565649, 'epsilon': 5.890113893287539e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.024252653152133694, 'tol': 3.261852610075295e-05, 'validation_fraction': 0.6409773351448376}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.287419 value -0.868132 suggestion {'alpha': 2.14425250754254, 'batch_size': 248, 'beta_1': 0.9518160361339723, 'beta_2': 0.9919048520565649, 'epsilon': 5.890113893287539e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.024252653152133694, 'tol': 3.261852610075295e-05, 'validation_fraction': 0.6409773351448376}
observation time 0.000002, current best -0.905495 at iter 11
suggestion time taken 0.001783 iter 12 next_points [{'alpha': 3.233700736291649, 'batch_size': 46, 'beta_1': 0.9666136295094314, 'beta_2': 0.9546520119437969, 'epsilon': 2.1563716826949615e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0018995561447404464, 'tol': 0.009248723004540885, 'validation_fraction': 0.15530026484757684}]
function_evaluation time 0.399878 value -0.898901 suggestion {'alpha': 3.233700736291649, 'batch_size': 46, 'beta_1': 0.9666136295094314, 'beta_2': 0.9546520119437969, 'epsilon': 2.1563716826949615e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0018995561447404464, 'tol': 0.009248723004540885, 'validation_fraction': 0.15530026484757684}
observation time 0.000001, current best -0.905495 at iter 12
suggestion time taken 0.001797 iter 13 next_points [{'alpha': 0.0003282323185823893, 'batch_size': 171, 'beta_1': 0.5989861266032035, 'beta_2': 0.9999967527962265, 'epsilon': 7.152396435548999e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 4.712677099587611e-05, 'tol': 0.005168761593851328, 'validation_fraction': 0.15343470151783964}]
function_evaluation time 0.222829 value -0.527473 suggestion {'alpha': 0.0003282323185823893, 'batch_size': 171, 'beta_1': 0.5989861266032035, 'beta_2': 0.9999967527962265, 'epsilon': 7.152396435548999e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 4.712677099587611e-05, 'tol': 0.005168761593851328, 'validation_fraction': 0.15343470151783964}
observation time 0.000001, current best -0.905495 at iter 13
suggestion time taken 0.001628 iter 14 next_points [{'alpha': 0.00011845511831487167, 'batch_size': 133, 'beta_1': 0.951073186893213, 'beta_2': 0.9999978733061832, 'epsilon': 9.447769760495734e-08, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.0008877851491902999, 'tol': 0.0001080312322918255, 'validation_fraction': 0.3050652794775521}]
function_evaluation time 0.201222 value -0.841758 suggestion {'alpha': 0.00011845511831487167, 'batch_size': 133, 'beta_1': 0.951073186893213, 'beta_2': 0.9999978733061832, 'epsilon': 9.447769760495734e-08, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.0008877851491902999, 'tol': 0.0001080312322918255, 'validation_fraction': 0.3050652794775521}
observation time 0.000001, current best -0.905495 at iter 14
suggestion time taken 0.002181 iter 15 next_points [{'alpha': 2.2436185154400912e-05, 'batch_size': 101, 'beta_1': 0.9250674514113664, 'beta_2': 0.9987535764981664, 'epsilon': 1.1144078918722739e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 1.0713996568520525e-05, 'tol': 0.01026120112616393, 'validation_fraction': 0.14218660944162448}]
function_evaluation time 0.331720 value -0.584615 suggestion {'alpha': 2.2436185154400912e-05, 'batch_size': 101, 'beta_1': 0.9250674514113664, 'beta_2': 0.9987535764981664, 'epsilon': 1.1144078918722739e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 1.0713996568520525e-05, 'tol': 0.01026120112616393, 'validation_fraction': 0.14218660944162448}
observation time 0.000000, current best -0.905495 at iter 15
suggestion time taken 0.001786 iter 16 next_points [{'alpha': 7.479472857500977, 'batch_size': 101, 'beta_1': 0.8322977173520317, 'beta_2': 0.9941976826537656, 'epsilon': 2.702215410766607e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.02563016129912282, 'tol': 4.764345817021788e-05, 'validation_fraction': 0.6607298919582966}]
function_evaluation time 0.506697 value -0.896703 suggestion {'alpha': 7.479472857500977, 'batch_size': 101, 'beta_1': 0.8322977173520317, 'beta_2': 0.9941976826537656, 'epsilon': 2.702215410766607e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.02563016129912282, 'tol': 4.764345817021788e-05, 'validation_fraction': 0.6607298919582966}
observation time 0.000001, current best -0.905495 at iter 16
suggestion time taken 0.001738 iter 17 next_points [{'alpha': 9.586367701285832, 'batch_size': 68, 'beta_1': 0.9755271945900004, 'beta_2': 0.9800485748333098, 'epsilon': 5.936057052625762e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 3.159257133863661e-05, 'tol': 0.008672323565795094, 'validation_fraction': 0.27759021700611325}]
function_evaluation time 0.264920 value -0.617582 suggestion {'alpha': 9.586367701285832, 'batch_size': 68, 'beta_1': 0.9755271945900004, 'beta_2': 0.9800485748333098, 'epsilon': 5.936057052625762e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 3.159257133863661e-05, 'tol': 0.008672323565795094, 'validation_fraction': 0.27759021700611325}
observation time 0.000001, current best -0.905495 at iter 17
suggestion time taken 0.001768 iter 18 next_points [{'alpha': 9.126890284654976, 'batch_size': 45, 'beta_1': 0.6604539185381355, 'beta_2': 0.9878954901264324, 'epsilon': 2.3420673032810695e-08, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.002883714845305476, 'tol': 0.002839638738868908, 'validation_fraction': 0.5793928966279429}]
function_evaluation time 0.501751 value -0.916484 suggestion {'alpha': 9.126890284654976, 'batch_size': 45, 'beta_1': 0.6604539185381355, 'beta_2': 0.9878954901264324, 'epsilon': 2.3420673032810695e-08, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.002883714845305476, 'tol': 0.002839638738868908, 'validation_fraction': 0.5793928966279429}
observation time 0.000001, current best -0.916484 at iter 18
suggestion time taken 0.005117 iter 19 next_points [{'alpha': 0.021325251913311145, 'batch_size': 136, 'beta_1': 0.9227456424247401, 'beta_2': 0.9598553169127183, 'epsilon': 1.0153903967949451e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.018249227994129032, 'tol': 0.04959498376094845, 'validation_fraction': 0.13473642887580614}]
function_evaluation time 0.290624 value -0.865934 suggestion {'alpha': 0.021325251913311145, 'batch_size': 136, 'beta_1': 0.9227456424247401, 'beta_2': 0.9598553169127183, 'epsilon': 1.0153903967949451e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.018249227994129032, 'tol': 0.04959498376094845, 'validation_fraction': 0.13473642887580614}
observation time 0.000001, current best -0.916484 at iter 19
suggestion time taken 0.007249 iter 20 next_points [{'alpha': 8.198311194247125, 'batch_size': 113, 'beta_1': 0.5301707974908372, 'beta_2': 0.9998253151637516, 'epsilon': 2.725780563893404e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 9.030116905006292e-05, 'tol': 0.00010757103591034812, 'validation_fraction': 0.7800048458102944}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.169894 value -0.520879 suggestion {'alpha': 8.198311194247125, 'batch_size': 113, 'beta_1': 0.5301707974908372, 'beta_2': 0.9998253151637516, 'epsilon': 2.725780563893404e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 9.030116905006292e-05, 'tol': 0.00010757103591034812, 'validation_fraction': 0.7800048458102944}
observation time 0.000001, current best -0.916484 at iter 20
suggestion time taken 0.001611 iter 21 next_points [{'alpha': 0.05623700720461071, 'batch_size': 21, 'beta_1': 0.9876384849501296, 'beta_2': 0.9979666418186914, 'epsilon': 2.6675685034949707e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.01178556440579518, 'tol': 2.8225799344198388e-05, 'validation_fraction': 0.17509962140029356}]
function_evaluation time 0.491176 value -0.896703 suggestion {'alpha': 0.05623700720461071, 'batch_size': 21, 'beta_1': 0.9876384849501296, 'beta_2': 0.9979666418186914, 'epsilon': 2.6675685034949707e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.01178556440579518, 'tol': 2.8225799344198388e-05, 'validation_fraction': 0.17509962140029356}
observation time 0.000001, current best -0.916484 at iter 21
suggestion time taken 0.001625 iter 22 next_points [{'alpha': 6.762123619858757e-05, 'batch_size': 154, 'beta_1': 0.983113368166385, 'beta_2': 0.9999907376992553, 'epsilon': 1.4724938351878566e-08, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.04253303329178009, 'tol': 0.0024013682986429937, 'validation_fraction': 0.6682916096701575}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.301156 value -0.852747 suggestion {'alpha': 6.762123619858757e-05, 'batch_size': 154, 'beta_1': 0.983113368166385, 'beta_2': 0.9999907376992553, 'epsilon': 1.4724938351878566e-08, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.04253303329178009, 'tol': 0.0024013682986429937, 'validation_fraction': 0.6682916096701575}
observation time 0.000001, current best -0.916484 at iter 22
suggestion time taken 0.001629 iter 23 next_points [{'alpha': 3.613969742117212e-05, 'batch_size': 66, 'beta_1': 0.9797546618084353, 'beta_2': 0.9870961528507246, 'epsilon': 5.326063665150059e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0002065272999793251, 'tol': 0.0007180531646010824, 'validation_fraction': 0.5593878825783996}]
function_evaluation time 0.504477 value -0.821978 suggestion {'alpha': 3.613969742117212e-05, 'batch_size': 66, 'beta_1': 0.9797546618084353, 'beta_2': 0.9870961528507246, 'epsilon': 5.326063665150059e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0002065272999793251, 'tol': 0.0007180531646010824, 'validation_fraction': 0.5593878825783996}
observation time 0.000001, current best -0.916484 at iter 23
suggestion time taken 0.001781 iter 24 next_points [{'alpha': 0.47403226813074867, 'batch_size': 204, 'beta_1': 0.6717653921798135, 'beta_2': 0.9998063327210475, 'epsilon': 9.222306719466389e-08, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.08138894285829522, 'tol': 4.7969093963488236e-05, 'validation_fraction': 0.8143588816398415}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.872843 value -0.850549 suggestion {'alpha': 0.47403226813074867, 'batch_size': 204, 'beta_1': 0.6717653921798135, 'beta_2': 0.9998063327210475, 'epsilon': 9.222306719466389e-08, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.08138894285829522, 'tol': 4.7969093963488236e-05, 'validation_fraction': 0.8143588816398415}
observation time 0.000001, current best -0.916484 at iter 24
suggestion time taken 0.001659 iter 25 next_points [{'alpha': 0.00014008218624381345, 'batch_size': 63, 'beta_1': 0.9731855279985084, 'beta_2': 0.9988787957876049, 'epsilon': 3.3597510223333294e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 2.826465374127486e-05, 'tol': 2.1888404024162028e-05, 'validation_fraction': 0.8779972968252857}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.146474 value -0.582418 suggestion {'alpha': 0.00014008218624381345, 'batch_size': 63, 'beta_1': 0.9731855279985084, 'beta_2': 0.9988787957876049, 'epsilon': 3.3597510223333294e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 2.826465374127486e-05, 'tol': 2.1888404024162028e-05, 'validation_fraction': 0.8779972968252857}
observation time 0.000002, current best -0.916484 at iter 25
suggestion time taken 0.005527 iter 26 next_points [{'alpha': 0.02064955779443377, 'batch_size': 121, 'beta_1': 0.6442261466919027, 'beta_2': 0.9889722463017383, 'epsilon': 9.18877376867339e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.003028635500567893, 'tol': 1.8154838276520748e-05, 'validation_fraction': 0.44529114732418934}]
function_evaluation time 0.296676 value -0.890110 suggestion {'alpha': 0.02064955779443377, 'batch_size': 121, 'beta_1': 0.6442261466919027, 'beta_2': 0.9889722463017383, 'epsilon': 9.18877376867339e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.003028635500567893, 'tol': 1.8154838276520748e-05, 'validation_fraction': 0.44529114732418934}
observation time 0.000002, current best -0.916484 at iter 26
suggestion time taken 0.005023 iter 27 next_points [{'alpha': 0.4427093037930148, 'batch_size': 109, 'beta_1': 0.9692157338111105, 'beta_2': 0.977553887750924, 'epsilon': 5.495814384675327e-09, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.005120720071918914, 'tol': 2.9407395208118525e-05, 'validation_fraction': 0.836008360624991}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.420132 value -0.850549 suggestion {'alpha': 0.4427093037930148, 'batch_size': 109, 'beta_1': 0.9692157338111105, 'beta_2': 0.977553887750924, 'epsilon': 5.495814384675327e-09, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.005120720071918914, 'tol': 2.9407395208118525e-05, 'validation_fraction': 0.836008360624991}
observation time 0.000001, current best -0.916484 at iter 27
suggestion time taken 0.001781 iter 28 next_points [{'alpha': 0.00013204472281826032, 'batch_size': 217, 'beta_1': 0.6473924323143965, 'beta_2': 0.9999916351122494, 'epsilon': 1.899203486284488e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.009842075484887308, 'tol': 2.2013745476195007e-05, 'validation_fraction': 0.6231932423281994}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.804309 value -0.907692 suggestion {'alpha': 0.00013204472281826032, 'batch_size': 217, 'beta_1': 0.6473924323143965, 'beta_2': 0.9999916351122494, 'epsilon': 1.899203486284488e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.009842075484887308, 'tol': 2.2013745476195007e-05, 'validation_fraction': 0.6231932423281994}
observation time 0.000001, current best -0.916484 at iter 28
suggestion time taken 0.001633 iter 29 next_points [{'alpha': 0.48910226982007327, 'batch_size': 185, 'beta_1': 0.9716811970005582, 'beta_2': 0.9998870995150403, 'epsilon': 2.333875761109453e-08, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.001297760289829036, 'tol': 0.014191526505943972, 'validation_fraction': 0.37381200933251485}]
function_evaluation time 0.434883 value -0.854945 suggestion {'alpha': 0.48910226982007327, 'batch_size': 185, 'beta_1': 0.9716811970005582, 'beta_2': 0.9998870995150403, 'epsilon': 2.333875761109453e-08, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.001297760289829036, 'tol': 0.014191526505943972, 'validation_fraction': 0.37381200933251485}
observation time 0.000000, current best -0.916484 at iter 29
suggestion time taken 0.001638 iter 30 next_points [{'alpha': 0.6265661213593864, 'batch_size': 51, 'beta_1': 0.9818885510617665, 'beta_2': 0.9942542841402093, 'epsilon': 2.040041104257628e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 1.1617487204717534e-05, 'tol': 0.0012428992334299431, 'validation_fraction': 0.8198173169334378}]
function_evaluation time 0.143162 value -0.479121 suggestion {'alpha': 0.6265661213593864, 'batch_size': 51, 'beta_1': 0.9818885510617665, 'beta_2': 0.9942542841402093, 'epsilon': 2.040041104257628e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 1.1617487204717534e-05, 'tol': 0.0012428992334299431, 'validation_fraction': 0.8198173169334378}
observation time 0.000001, current best -0.916484 at iter 30
suggestion time taken 0.001767 iter 31 next_points [{'alpha': 0.0021404468184368923, 'batch_size': 219, 'beta_1': 0.9839529365085483, 'beta_2': 0.9697744899312178, 'epsilon': 3.072615578933973e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 7.120311383879359e-05, 'tol': 0.0004269819350434327, 'validation_fraction': 0.3316333777124486}]
function_evaluation time 0.251306 value -0.624176 suggestion {'alpha': 0.0021404468184368923, 'batch_size': 219, 'beta_1': 0.9839529365085483, 'beta_2': 0.9697744899312178, 'epsilon': 3.072615578933973e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 7.120311383879359e-05, 'tol': 0.0004269819350434327, 'validation_fraction': 0.3316333777124486}
observation time 0.000001, current best -0.916484 at iter 31
suggestion time taken 0.001772 iter 32 next_points [{'alpha': 3.1609344454565407, 'batch_size': 131, 'beta_1': 0.9477261141089144, 'beta_2': 0.9998579742715361, 'epsilon': 1.5076119763616813e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 3.278328092591045e-05, 'tol': 0.00012948533664456965, 'validation_fraction': 0.2728496634699344}]
function_evaluation time 0.234690 value -0.472527 suggestion {'alpha': 3.1609344454565407, 'batch_size': 131, 'beta_1': 0.9477261141089144, 'beta_2': 0.9998579742715361, 'epsilon': 1.5076119763616813e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 3.278328092591045e-05, 'tol': 0.00012948533664456965, 'validation_fraction': 0.2728496634699344}
observation time 0.000001, current best -0.916484 at iter 32
suggestion time taken 0.001609 iter 33 next_points [{'alpha': 0.02290241208189378, 'batch_size': 41, 'beta_1': 0.6168943727831097, 'beta_2': 0.9999856957198378, 'epsilon': 7.943010603650837e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.00038842516908166037, 'tol': 0.0008790881711937884, 'validation_fraction': 0.21174031888236275}]
function_evaluation time 0.471483 value -0.890110 suggestion {'alpha': 0.02290241208189378, 'batch_size': 41, 'beta_1': 0.6168943727831097, 'beta_2': 0.9999856957198378, 'epsilon': 7.943010603650837e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.00038842516908166037, 'tol': 0.0008790881711937884, 'validation_fraction': 0.21174031888236275}
observation time 0.000001, current best -0.916484 at iter 33
suggestion time taken 0.003140 iter 34 next_points [{'alpha': 0.1861852372662653, 'batch_size': 147, 'beta_1': 0.820565681835561, 'beta_2': 0.9999278317766074, 'epsilon': 1.1744377982741855e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.009232691502707627, 'tol': 5.230008533936094e-05, 'validation_fraction': 0.8835134856983755}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.320696 value -0.912088 suggestion {'alpha': 0.1861852372662653, 'batch_size': 147, 'beta_1': 0.820565681835561, 'beta_2': 0.9999278317766074, 'epsilon': 1.1744377982741855e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.009232691502707627, 'tol': 5.230008533936094e-05, 'validation_fraction': 0.8835134856983755}
observation time 0.000001, current best -0.916484 at iter 34
suggestion time taken 0.001808 iter 35 next_points [{'alpha': 0.11060705732288231, 'batch_size': 86, 'beta_1': 0.6854086717894557, 'beta_2': 0.9616583736148954, 'epsilon': 1.382121545168997e-09, 'hidden_layer_sizes': 103, 'learning_rate_init': 1.7470058336964227e-05, 'tol': 1.2317762273872154e-05, 'validation_fraction': 0.32080369563590266}]
function_evaluation time 0.332075 value -0.591209 suggestion {'alpha': 0.11060705732288231, 'batch_size': 86, 'beta_1': 0.6854086717894557, 'beta_2': 0.9616583736148954, 'epsilon': 1.382121545168997e-09, 'hidden_layer_sizes': 103, 'learning_rate_init': 1.7470058336964227e-05, 'tol': 1.2317762273872154e-05, 'validation_fraction': 0.32080369563590266}
observation time 0.000001, current best -0.916484 at iter 35
suggestion time taken 0.001627 iter 36 next_points [{'alpha': 7.477152344843611, 'batch_size': 179, 'beta_1': 0.8146388949698192, 'beta_2': 0.9841034205095068, 'epsilon': 3.734399773654045e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.010098643640543624, 'tol': 0.014094606304912053, 'validation_fraction': 0.3000686042884447}]
function_evaluation time 0.267949 value -0.905495 suggestion {'alpha': 7.477152344843611, 'batch_size': 179, 'beta_1': 0.8146388949698192, 'beta_2': 0.9841034205095068, 'epsilon': 3.734399773654045e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.010098643640543624, 'tol': 0.014094606304912053, 'validation_fraction': 0.3000686042884447}
observation time 0.000001, current best -0.916484 at iter 36
suggestion time taken 0.001645 iter 37 next_points [{'alpha': 1.361249691236434, 'batch_size': 182, 'beta_1': 0.9769363536768929, 'beta_2': 0.9997649014404524, 'epsilon': 2.6593159898432373e-09, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.022686952231978988, 'tol': 0.0068341119866456934, 'validation_fraction': 0.5219500367982259}]
function_evaluation time 0.434521 value -0.839560 suggestion {'alpha': 1.361249691236434, 'batch_size': 182, 'beta_1': 0.9769363536768929, 'beta_2': 0.9997649014404524, 'epsilon': 2.6593159898432373e-09, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.022686952231978988, 'tol': 0.0068341119866456934, 'validation_fraction': 0.5219500367982259}
observation time 0.000001, current best -0.916484 at iter 37
suggestion time taken 0.001642 iter 38 next_points [{'alpha': 0.001618542908836183, 'batch_size': 23, 'beta_1': 0.5030080577435269, 'beta_2': 0.9999454672544908, 'epsilon': 2.1780592957198375e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 1.5376397549501182e-05, 'tol': 0.0019371555311286485, 'validation_fraction': 0.32829445221332576}]
function_evaluation time 0.389127 value -0.417582 suggestion {'alpha': 0.001618542908836183, 'batch_size': 23, 'beta_1': 0.5030080577435269, 'beta_2': 0.9999454672544908, 'epsilon': 2.1780592957198375e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 1.5376397549501182e-05, 'tol': 0.0019371555311286485, 'validation_fraction': 0.32829445221332576}
observation time 0.000001, current best -0.916484 at iter 38
suggestion time taken 0.001736 iter 39 next_points [{'alpha': 0.00031651126536131604, 'batch_size': 204, 'beta_1': 0.9383253733339025, 'beta_2': 0.9999952262779829, 'epsilon': 2.555748651176007e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.03935012618627157, 'tol': 0.07056890764634408, 'validation_fraction': 0.7683045590596934}]
/Users/ryedida/miniforge3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.291811 value -0.749451 suggestion {'alpha': 0.00031651126536131604, 'batch_size': 204, 'beta_1': 0.9383253733339025, 'beta_2': 0.9999952262779829, 'epsilon': 2.555748651176007e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.03935012618627157, 'tol': 0.07056890764634408, 'validation_fraction': 0.7683045590596934}
observation time 0.000001, current best -0.916484 at iter 39
suggestion time taken 0.001623 iter 40 next_points [{'alpha': 1.2592993921619782e-05, 'batch_size': 126, 'beta_1': 0.8996882689453642, 'beta_2': 0.958898214565835, 'epsilon': 2.9310168056725416e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.016030894375511508, 'tol': 0.013712617852296462, 'validation_fraction': 0.11182495982417498}]
function_evaluation time 0.365872 value -0.894505 suggestion {'alpha': 1.2592993921619782e-05, 'batch_size': 126, 'beta_1': 0.8996882689453642, 'beta_2': 0.958898214565835, 'epsilon': 2.9310168056725416e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.016030894375511508, 'tol': 0.013712617852296462, 'validation_fraction': 0.11182495982417498}
observation time 0.000001, current best -0.916484 at iter 40
suggestion time taken 0.001790 iter 41 next_points [{'alpha': 0.17064684831446503, 'batch_size': 75, 'beta_1': 0.9396433058879867, 'beta_2': 0.9998458097763167, 'epsilon': 2.7961794915754593e-08, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.00011680602266055489, 'tol': 0.018270168664360216, 'validation_fraction': 0.23440833786886145}]
function_evaluation time 0.693607 value -0.731868 suggestion {'alpha': 0.17064684831446503, 'batch_size': 75, 'beta_1': 0.9396433058879867, 'beta_2': 0.9998458097763167, 'epsilon': 2.7961794915754593e-08, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.00011680602266055489, 'tol': 0.018270168664360216, 'validation_fraction': 0.23440833786886145}
observation time 0.000001, current best -0.916484 at iter 41
suggestion time taken 0.001788 iter 42 next_points [{'alpha': 3.1880053356143335e-05, 'batch_size': 143, 'beta_1': 0.9893501969520382, 'beta_2': 0.9999982405720363, 'epsilon': 5.717381697645711e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.023267892619332653, 'tol': 0.0624653638420352, 'validation_fraction': 0.13341464804950115}]
function_evaluation time 0.425378 value -0.859341 suggestion {'alpha': 3.1880053356143335e-05, 'batch_size': 143, 'beta_1': 0.9893501969520382, 'beta_2': 0.9999982405720363, 'epsilon': 5.717381697645711e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.023267892619332653, 'tol': 0.0624653638420352, 'validation_fraction': 0.13341464804950115}
observation time 0.000001, current best -0.916484 at iter 42
suggestion time taken 0.002657 iter 43 next_points [{'alpha': 6.103264183722498e-05, 'batch_size': 231, 'beta_1': 0.8314336212819231, 'beta_2': 0.9997965116671562, 'epsilon': 2.0633121362934426e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 1.2637183670657035e-05, 'tol': 0.0021444964914181627, 'validation_fraction': 0.26775402733009523}]
function_evaluation time 0.193692 value -0.545055 suggestion {'alpha': 6.103264183722498e-05, 'batch_size': 231, 'beta_1': 0.8314336212819231, 'beta_2': 0.9997965116671562, 'epsilon': 2.0633121362934426e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 1.2637183670657035e-05, 'tol': 0.0021444964914181627, 'validation_fraction': 0.26775402733009523}
observation time 0.000001, current best -0.916484 at iter 43
suggestion time taken 0.001624 iter 44 next_points [{'alpha': 0.00010128345132364133, 'batch_size': 40, 'beta_1': 0.6460849705211807, 'beta_2': 0.9999452126507351, 'epsilon': 5.52365215146888e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 2.3477028111213484e-05, 'tol': 0.001128287991957936, 'validation_fraction': 0.12287985178709082}]
function_evaluation time 0.276100 value -0.468132 suggestion {'alpha': 0.00010128345132364133, 'batch_size': 40, 'beta_1': 0.6460849705211807, 'beta_2': 0.9999452126507351, 'epsilon': 5.52365215146888e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 2.3477028111213484e-05, 'tol': 0.001128287991957936, 'validation_fraction': 0.12287985178709082}
observation time 0.000002, current best -0.916484 at iter 44
saving meta data: {'args': {'--uuid': '9252b169878554ed8937d95c90913beb', '-db-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/Users/ryedida/Desktop/menzies/thesis/smoothness-hpo/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230815_214848', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

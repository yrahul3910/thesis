running: {'--uuid': 'c1c52b1284a553d199bbc9d05df0890b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_194925', '--opt': 'hyperopt', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d wine -o hyperopt -u c1c52b1284a553d199bbc9d05df0890b -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_194925
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [16.063962273407764, 23.274250254613083, 19.80193088400322, 3.463918210725012, 15.210579700922176])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_wine_nll betwen [15.51998549 22.35390307 19.16402613  3.37792524 14.64310022] and [16.06396227 23.27425025 19.80193088  3.46391821 15.2105797 ]
  warnings.warn(

Signature errors:
                          0         1         2         3         4       max
MLP-adam_wine_nll  0.543977  0.920347  0.637905  0.085993  0.567479  0.920347
max                0.543977  0.920347  0.637905  0.085993  0.567479  0.920347
starting sklearn study hyperopt MLP-adam wine nll 15 1
with data root: None
suggestion time taken 0.002365 iter 0 next_points [{'alpha': 0.00047559907967903697, 'batch_size': 217, 'beta_1': 0.5057055575327782, 'beta_2': 0.9305321922371506, 'epsilon': 1.2242103015262557e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 4.533170641337929e-05, 'tol': 1.4609865735914042e-05, 'validation_fraction': 0.1380816319482986}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.047035 value 22.159610 suggestion {'alpha': 0.00047559907967903697, 'batch_size': 217, 'beta_1': 0.5057055575327782, 'beta_2': 0.9305321922371506, 'epsilon': 1.2242103015262557e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 4.533170641337929e-05, 'tol': 1.4609865735914042e-05, 'validation_fraction': 0.1380816319482986}
observation time 0.000077, current best 22.159610 at iter 0
suggestion time taken 0.002392 iter 1 next_points [{'alpha': 0.08106915903467998, 'batch_size': 112, 'beta_1': 0.9823639458315012, 'beta_2': 0.9449216652400436, 'epsilon': 1.4411226780470261e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0025634245103349816, 'tol': 4.0681443108282846e-05, 'validation_fraction': 0.7844154115321323}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.066851 value 9.755470 suggestion {'alpha': 0.08106915903467998, 'batch_size': 112, 'beta_1': 0.9823639458315012, 'beta_2': 0.9449216652400436, 'epsilon': 1.4411226780470261e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0025634245103349816, 'tol': 4.0681443108282846e-05, 'validation_fraction': 0.7844154115321323}
observation time 0.000071, current best 9.755470 at iter 1
suggestion time taken 0.002162 iter 2 next_points [{'alpha': 0.03759952775200668, 'batch_size': 27, 'beta_1': 0.5072169596461823, 'beta_2': 0.9458408340010102, 'epsilon': 3.4127623388653574e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0003684358698760859, 'tol': 0.00019512016380679478, 'validation_fraction': 0.3665125430674986}]
function_evaluation time 0.155148 value 11.257118 suggestion {'alpha': 0.03759952775200668, 'batch_size': 27, 'beta_1': 0.5072169596461823, 'beta_2': 0.9458408340010102, 'epsilon': 3.4127623388653574e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0003684358698760859, 'tol': 0.00019512016380679478, 'validation_fraction': 0.3665125430674986}
observation time 0.000069, current best 9.755470 at iter 2
suggestion time taken 0.002157 iter 3 next_points [{'alpha': 0.0003936810434928947, 'batch_size': 51, 'beta_1': 0.6484093635277921, 'beta_2': 0.9602815142991961, 'epsilon': 1.114239165391432e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 7.520967527370314e-05, 'tol': 0.0042707616874581925, 'validation_fraction': 0.13755022763345234}]
function_evaluation time 0.068828 value 21.205426 suggestion {'alpha': 0.0003936810434928947, 'batch_size': 51, 'beta_1': 0.6484093635277921, 'beta_2': 0.9602815142991961, 'epsilon': 1.114239165391432e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 7.520967527370314e-05, 'tol': 0.0042707616874581925, 'validation_fraction': 0.13755022763345234}
observation time 0.000074, current best 9.755470 at iter 3
suggestion time taken 0.002120 iter 4 next_points [{'alpha': 8.261011751906546, 'batch_size': 114, 'beta_1': 0.6115664455057631, 'beta_2': 0.9558244834697243, 'epsilon': 6.078848437485926e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0009585948782786294, 'tol': 0.00010452008341837473, 'validation_fraction': 0.15133196343079314}]
function_evaluation time 0.119247 value 5.493088 suggestion {'alpha': 8.261011751906546, 'batch_size': 114, 'beta_1': 0.6115664455057631, 'beta_2': 0.9558244834697243, 'epsilon': 6.078848437485926e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0009585948782786294, 'tol': 0.00010452008341837473, 'validation_fraction': 0.15133196343079314}
observation time 0.000075, current best 5.493088 at iter 4
suggestion time taken 0.002121 iter 5 next_points [{'alpha': 0.011806839452076532, 'batch_size': 65, 'beta_1': 0.9452462809148549, 'beta_2': 0.9444353481726138, 'epsilon': 5.809956337462812e-09, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.056057621694768134, 'tol': 0.0005445845410472324, 'validation_fraction': 0.3365066832989697}]
function_evaluation time 0.094846 value 11.116812 suggestion {'alpha': 0.011806839452076532, 'batch_size': 65, 'beta_1': 0.9452462809148549, 'beta_2': 0.9444353481726138, 'epsilon': 5.809956337462812e-09, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.056057621694768134, 'tol': 0.0005445845410472324, 'validation_fraction': 0.3365066832989697}
observation time 0.000072, current best 5.493088 at iter 5
suggestion time taken 0.002106 iter 6 next_points [{'alpha': 1.0350424012489383e-05, 'batch_size': 150, 'beta_1': 0.508865455830092, 'beta_2': 0.9487857940993727, 'epsilon': 4.593791362736763e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0008794084963581158, 'tol': 9.323379578908099e-05, 'validation_fraction': 0.1689172890681386}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.074277 value 7.089841 suggestion {'alpha': 1.0350424012489383e-05, 'batch_size': 150, 'beta_1': 0.508865455830092, 'beta_2': 0.9487857940993727, 'epsilon': 4.593791362736763e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0008794084963581158, 'tol': 9.323379578908099e-05, 'validation_fraction': 0.1689172890681386}
observation time 0.000073, current best 5.493088 at iter 6
suggestion time taken 0.002207 iter 7 next_points [{'alpha': 5.916103327380862, 'batch_size': 152, 'beta_1': 0.9069016201951293, 'beta_2': 0.9953664856663532, 'epsilon': 2.607597723702844e-07, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.00284181682796901, 'tol': 0.012193982505359295, 'validation_fraction': 0.3342861806539802}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.080633 value 11.920511 suggestion {'alpha': 5.916103327380862, 'batch_size': 152, 'beta_1': 0.9069016201951293, 'beta_2': 0.9953664856663532, 'epsilon': 2.607597723702844e-07, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.00284181682796901, 'tol': 0.012193982505359295, 'validation_fraction': 0.3342861806539802}
observation time 0.000073, current best 5.493088 at iter 7
suggestion time taken 0.002145 iter 8 next_points [{'alpha': 7.314245994806233, 'batch_size': 147, 'beta_1': 0.5793572151050399, 'beta_2': 0.9662620282080784, 'epsilon': 8.898397501646737e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0027495410026082204, 'tol': 0.0657545638282121, 'validation_fraction': 0.33059950506283237}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.058630 value 7.380926 suggestion {'alpha': 7.314245994806233, 'batch_size': 147, 'beta_1': 0.5793572151050399, 'beta_2': 0.9662620282080784, 'epsilon': 8.898397501646737e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0027495410026082204, 'tol': 0.0657545638282121, 'validation_fraction': 0.33059950506283237}
observation time 0.000081, current best 5.493088 at iter 8
suggestion time taken 0.002122 iter 9 next_points [{'alpha': 0.002942420487052947, 'batch_size': 248, 'beta_1': 0.5366491239877437, 'beta_2': 0.9584302491372099, 'epsilon': 8.511580264804909e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.004891810965284473, 'tol': 0.0005956374524303324, 'validation_fraction': 0.3963547047040383}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.109572 value 3.580526 suggestion {'alpha': 0.002942420487052947, 'batch_size': 248, 'beta_1': 0.5366491239877437, 'beta_2': 0.9584302491372099, 'epsilon': 8.511580264804909e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.004891810965284473, 'tol': 0.0005956374524303324, 'validation_fraction': 0.3963547047040383}
observation time 0.000073, current best 3.580526 at iter 9
suggestion time taken 0.002190 iter 10 next_points [{'alpha': 0.0003011397221280136, 'batch_size': 110, 'beta_1': 0.8103581643069647, 'beta_2': 0.9835037742037934, 'epsilon': 1.8185512773438478e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.006129116718781654, 'tol': 0.009221509758371148, 'validation_fraction': 0.3196907275359874}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.141025 value 1.000120 suggestion {'alpha': 0.0003011397221280136, 'batch_size': 110, 'beta_1': 0.8103581643069647, 'beta_2': 0.9835037742037934, 'epsilon': 1.8185512773438478e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.006129116718781654, 'tol': 0.009221509758371148, 'validation_fraction': 0.3196907275359874}
observation time 0.000077, current best 1.000120 at iter 10
suggestion time taken 0.002161 iter 11 next_points [{'alpha': 0.02121343741212718, 'batch_size': 132, 'beta_1': 0.5782760441769058, 'beta_2': 0.9851853220517199, 'epsilon': 5.6896627105522134e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0001888381644658696, 'tol': 0.0263279934883271, 'validation_fraction': 0.20917767441077856}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.054014 value 24.241837 suggestion {'alpha': 0.02121343741212718, 'batch_size': 132, 'beta_1': 0.5782760441769058, 'beta_2': 0.9851853220517199, 'epsilon': 5.6896627105522134e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0001888381644658696, 'tol': 0.0263279934883271, 'validation_fraction': 0.20917767441077856}
observation time 0.000076, current best 1.000120 at iter 11
suggestion time taken 0.002244 iter 12 next_points [{'alpha': 0.0009671638308425672, 'batch_size': 49, 'beta_1': 0.58328906656556, 'beta_2': 0.9971175243439464, 'epsilon': 5.410375737489994e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.0006250144741931968, 'tol': 0.00015561058677126402, 'validation_fraction': 0.304010243639925}]
function_evaluation time 0.146044 value 5.452765 suggestion {'alpha': 0.0009671638308425672, 'batch_size': 49, 'beta_1': 0.58328906656556, 'beta_2': 0.9971175243439464, 'epsilon': 5.410375737489994e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.0006250144741931968, 'tol': 0.00015561058677126402, 'validation_fraction': 0.304010243639925}
observation time 0.000076, current best 1.000120 at iter 12
suggestion time taken 0.002203 iter 13 next_points [{'alpha': 0.06228257860840075, 'batch_size': 91, 'beta_1': 0.8202492070723417, 'beta_2': 0.9637093638410752, 'epsilon': 1.6681343465663764e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 1.2982980294416224e-05, 'tol': 0.010561847988721172, 'validation_fraction': 0.16516180405201566}]
function_evaluation time 0.064770 value 17.431324 suggestion {'alpha': 0.06228257860840075, 'batch_size': 91, 'beta_1': 0.8202492070723417, 'beta_2': 0.9637093638410752, 'epsilon': 1.6681343465663764e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 1.2982980294416224e-05, 'tol': 0.010561847988721172, 'validation_fraction': 0.16516180405201566}
observation time 0.000074, current best 1.000120 at iter 13
suggestion time taken 0.002169 iter 14 next_points [{'alpha': 0.009574197708857911, 'batch_size': 24, 'beta_1': 0.662329030807986, 'beta_2': 0.9649700754296179, 'epsilon': 6.735285498224623e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.00010416776930977384, 'tol': 0.007449778282437541, 'validation_fraction': 0.6539415449316194}]
function_evaluation time 0.120767 value 13.343837 suggestion {'alpha': 0.009574197708857911, 'batch_size': 24, 'beta_1': 0.662329030807986, 'beta_2': 0.9649700754296179, 'epsilon': 6.735285498224623e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.00010416776930977384, 'tol': 0.007449778282437541, 'validation_fraction': 0.6539415449316194}
observation time 0.000075, current best 1.000120 at iter 14
saving meta data: {'args': {'--uuid': 'c1c52b1284a553d199bbc9d05df0890b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_194925', '--opt': 'hyperopt', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [16.063962273407764, 23.274250254613083, 19.80193088400322, 3.463918210725012, 15.210579700922176])}
saving results
saving timing
saving suggest log
done

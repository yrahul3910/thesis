running: {'--uuid': '423268a4bb1056ef9d7a5f9738681aab', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d breast -o hyperopt -u 423268a4bb1056ef9d7a5f9738681aab -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230422_030001
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_nll betwen [ 4.58589285 14.6438765   8.74044796  0.67466158  3.06872636] and [ 8.10456652 20.07092365 12.33228572  5.26978359  3.49043108]
  warnings.warn(

Signature errors:
                            0         1         2         3         4       max
MLP-adam_breast_nll  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
max                  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
starting sklearn study hyperopt MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.002278 iter 0 next_points [{'alpha': 0.0013518865504764876, 'batch_size': 135, 'beta_1': 0.5613640548741266, 'beta_2': 0.9329314843563421, 'epsilon': 2.201657794414606e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0074306701936913515, 'tol': 5.6896454892730355e-05, 'validation_fraction': 0.15230531481503115}]
function_evaluation time 0.274087 value 0.580549 suggestion {'alpha': 0.0013518865504764876, 'batch_size': 135, 'beta_1': 0.5613640548741266, 'beta_2': 0.9329314843563421, 'epsilon': 2.201657794414606e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0074306701936913515, 'tol': 5.6896454892730355e-05, 'validation_fraction': 0.15230531481503115}
observation time 0.000071, current best 0.580549 at iter 0
suggestion time taken 0.002376 iter 1 next_points [{'alpha': 0.0019167692455776771, 'batch_size': 94, 'beta_1': 0.5707267715786606, 'beta_2': 0.9441146472087326, 'epsilon': 1.1379400863632896e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.004518182165267332, 'tol': 3.6217435037823896e-05, 'validation_fraction': 0.6334713285498682}]
function_evaluation time 0.204919 value 0.603748 suggestion {'alpha': 0.0019167692455776771, 'batch_size': 94, 'beta_1': 0.5707267715786606, 'beta_2': 0.9441146472087326, 'epsilon': 1.1379400863632896e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.004518182165267332, 'tol': 3.6217435037823896e-05, 'validation_fraction': 0.6334713285498682}
observation time 0.000060, current best 0.580549 at iter 1
suggestion time taken 0.002040 iter 2 next_points [{'alpha': 4.526360051753903, 'batch_size': 85, 'beta_1': 0.5915084243299081, 'beta_2': 0.9744200721576897, 'epsilon': 1.27221382882531e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.002277203003302159, 'tol': 0.022076861755980077, 'validation_fraction': 0.3272815752284758}]
function_evaluation time 0.215400 value 0.331470 suggestion {'alpha': 4.526360051753903, 'batch_size': 85, 'beta_1': 0.5915084243299081, 'beta_2': 0.9744200721576897, 'epsilon': 1.27221382882531e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.002277203003302159, 'tol': 0.022076861755980077, 'validation_fraction': 0.3272815752284758}
observation time 0.000057, current best 0.331470 at iter 2
suggestion time taken 0.002085 iter 3 next_points [{'alpha': 0.07651323460450928, 'batch_size': 152, 'beta_1': 0.8777749545226086, 'beta_2': 0.928882806123408, 'epsilon': 1.9247370260782054e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.03211011492043745, 'tol': 0.0570774970064056, 'validation_fraction': 0.23353927955330056}]
function_evaluation time 0.182299 value 1.300538 suggestion {'alpha': 0.07651323460450928, 'batch_size': 152, 'beta_1': 0.8777749545226086, 'beta_2': 0.928882806123408, 'epsilon': 1.9247370260782054e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.03211011492043745, 'tol': 0.0570774970064056, 'validation_fraction': 0.23353927955330056}
observation time 0.000056, current best 0.331470 at iter 3
suggestion time taken 0.002206 iter 4 next_points [{'alpha': 3.8879485699430796, 'batch_size': 104, 'beta_1': 0.5245412616125191, 'beta_2': 0.9814305490145475, 'epsilon': 1.2230763513644294e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.004315606581730484, 'tol': 0.031248458563800156, 'validation_fraction': 0.7062423208032877}]
function_evaluation time 0.160392 value 5.781048 suggestion {'alpha': 3.8879485699430796, 'batch_size': 104, 'beta_1': 0.5245412616125191, 'beta_2': 0.9814305490145475, 'epsilon': 1.2230763513644294e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.004315606581730484, 'tol': 0.031248458563800156, 'validation_fraction': 0.7062423208032877}
observation time 0.000078, current best 0.331470 at iter 4
suggestion time taken 0.002099 iter 5 next_points [{'alpha': 4.419796375587517e-05, 'batch_size': 39, 'beta_1': 0.7568971270210186, 'beta_2': 0.9394162880135243, 'epsilon': 8.345325519299982e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 2.4330971280070758e-05, 'tol': 0.027579452397485504, 'validation_fraction': 0.10190781429325955}]
function_evaluation time 0.148686 value 16.931297 suggestion {'alpha': 4.419796375587517e-05, 'batch_size': 39, 'beta_1': 0.7568971270210186, 'beta_2': 0.9394162880135243, 'epsilon': 8.345325519299982e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 2.4330971280070758e-05, 'tol': 0.027579452397485504, 'validation_fraction': 0.10190781429325955}
observation time 0.000067, current best 0.331470 at iter 5
suggestion time taken 0.002095 iter 6 next_points [{'alpha': 0.8555342582052688, 'batch_size': 111, 'beta_1': 0.5495499630156929, 'beta_2': 0.9033306592417436, 'epsilon': 3.9769063500860266e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.004248745998850922, 'tol': 0.08419391921196526, 'validation_fraction': 0.1158610182031196}]
function_evaluation time 0.188281 value 0.851850 suggestion {'alpha': 0.8555342582052688, 'batch_size': 111, 'beta_1': 0.5495499630156929, 'beta_2': 0.9033306592417436, 'epsilon': 3.9769063500860266e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.004248745998850922, 'tol': 0.08419391921196526, 'validation_fraction': 0.1158610182031196}
observation time 0.000066, current best 0.331470 at iter 6
suggestion time taken 0.002128 iter 7 next_points [{'alpha': 0.002012583467679462, 'batch_size': 207, 'beta_1': 0.793417644951092, 'beta_2': 0.9312419151795128, 'epsilon': 1.0438771452477177e-08, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.00028708944533178905, 'tol': 7.329441065488489e-05, 'validation_fraction': 0.17201847855050367}]
function_evaluation time 0.203338 value 10.146166 suggestion {'alpha': 0.002012583467679462, 'batch_size': 207, 'beta_1': 0.793417644951092, 'beta_2': 0.9312419151795128, 'epsilon': 1.0438771452477177e-08, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.00028708944533178905, 'tol': 7.329441065488489e-05, 'validation_fraction': 0.17201847855050367}
observation time 0.000064, current best 0.331470 at iter 7
suggestion time taken 0.002105 iter 8 next_points [{'alpha': 0.0008272631619298649, 'batch_size': 138, 'beta_1': 0.9381057675878768, 'beta_2': 0.9709707109514445, 'epsilon': 2.210626732785054e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.07463085742626899, 'tol': 5.176281458086378e-05, 'validation_fraction': 0.5861071738422817}]
function_evaluation time 0.188820 value 2.928516 suggestion {'alpha': 0.0008272631619298649, 'batch_size': 138, 'beta_1': 0.9381057675878768, 'beta_2': 0.9709707109514445, 'epsilon': 2.210626732785054e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.07463085742626899, 'tol': 5.176281458086378e-05, 'validation_fraction': 0.5861071738422817}
observation time 0.000074, current best 0.331470 at iter 8
suggestion time taken 0.002151 iter 9 next_points [{'alpha': 1.582111782825787e-05, 'batch_size': 39, 'beta_1': 0.8979697090052887, 'beta_2': 0.9261075360155686, 'epsilon': 3.529605259265702e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0016079258543033683, 'tol': 0.0048892403290065915, 'validation_fraction': 0.41101800844089353}]
function_evaluation time 0.317172 value 0.259404 suggestion {'alpha': 1.582111782825787e-05, 'batch_size': 39, 'beta_1': 0.8979697090052887, 'beta_2': 0.9261075360155686, 'epsilon': 3.529605259265702e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0016079258543033683, 'tol': 0.0048892403290065915, 'validation_fraction': 0.41101800844089353}
observation time 0.000073, current best 0.259404 at iter 9
suggestion time taken 0.002116 iter 10 next_points [{'alpha': 0.06567792342853962, 'batch_size': 193, 'beta_1': 0.9437280808376655, 'beta_2': 0.9785676728617412, 'epsilon': 1.3122348315214004e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.011920841019929667, 'tol': 0.024915452872953082, 'validation_fraction': 0.2038880625657768}]
function_evaluation time 0.169505 value 0.875908 suggestion {'alpha': 0.06567792342853962, 'batch_size': 193, 'beta_1': 0.9437280808376655, 'beta_2': 0.9785676728617412, 'epsilon': 1.3122348315214004e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.011920841019929667, 'tol': 0.024915452872953082, 'validation_fraction': 0.2038880625657768}
observation time 0.000059, current best 0.259404 at iter 10
suggestion time taken 0.002064 iter 11 next_points [{'alpha': 0.14471926575758592, 'batch_size': 73, 'beta_1': 0.6358751487200383, 'beta_2': 0.9430650753148938, 'epsilon': 3.4912635755802095e-08, 'hidden_layer_sizes': 187, 'learning_rate_init': 1.1483878695580575e-05, 'tol': 0.01596853262479997, 'validation_fraction': 0.1982879794825153}]
function_evaluation time 0.211093 value 14.471653 suggestion {'alpha': 0.14471926575758592, 'batch_size': 73, 'beta_1': 0.6358751487200383, 'beta_2': 0.9430650753148938, 'epsilon': 3.4912635755802095e-08, 'hidden_layer_sizes': 187, 'learning_rate_init': 1.1483878695580575e-05, 'tol': 0.01596853262479997, 'validation_fraction': 0.1982879794825153}
observation time 0.000063, current best 0.259404 at iter 11
suggestion time taken 0.002052 iter 12 next_points [{'alpha': 0.0655537889374453, 'batch_size': 163, 'beta_1': 0.5040122184880119, 'beta_2': 0.9197980144622462, 'epsilon': 2.8230940498178964e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.022551865241322286, 'tol': 0.002621292911588816, 'validation_fraction': 0.6851162407794479}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.221314 value 1.339693 suggestion {'alpha': 0.0655537889374453, 'batch_size': 163, 'beta_1': 0.5040122184880119, 'beta_2': 0.9197980144622462, 'epsilon': 2.8230940498178964e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.022551865241322286, 'tol': 0.002621292911588816, 'validation_fraction': 0.6851162407794479}
observation time 0.000059, current best 0.259404 at iter 12
suggestion time taken 0.002105 iter 13 next_points [{'alpha': 0.007288643602246099, 'batch_size': 204, 'beta_1': 0.7046934144924737, 'beta_2': 0.9773008362353037, 'epsilon': 5.305732095858494e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 1.1475288125094737e-05, 'tol': 1.1697268695944658e-05, 'validation_fraction': 0.6736225345254455}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.106623 value 14.697291 suggestion {'alpha': 0.007288643602246099, 'batch_size': 204, 'beta_1': 0.7046934144924737, 'beta_2': 0.9773008362353037, 'epsilon': 5.305732095858494e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 1.1475288125094737e-05, 'tol': 1.1697268695944658e-05, 'validation_fraction': 0.6736225345254455}
observation time 0.000075, current best 0.259404 at iter 13
suggestion time taken 0.002336 iter 14 next_points [{'alpha': 0.040609783559277544, 'batch_size': 246, 'beta_1': 0.6399041886095514, 'beta_2': 0.9703308129010686, 'epsilon': 5.715285913159337e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 5.8775373933030054e-05, 'tol': 0.00562388053406364, 'validation_fraction': 0.11722476179929754}]
function_evaluation time 0.171721 value 16.445221 suggestion {'alpha': 0.040609783559277544, 'batch_size': 246, 'beta_1': 0.6399041886095514, 'beta_2': 0.9703308129010686, 'epsilon': 5.715285913159337e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 5.8775373933030054e-05, 'tol': 0.00562388053406364, 'validation_fraction': 0.11722476179929754}
observation time 0.000063, current best 0.259404 at iter 14
saving meta data: {'args': {'--uuid': '423268a4bb1056ef9d7a5f9738681aab', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])}
saving results
saving timing
saving suggest log
done

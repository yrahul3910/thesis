running: {'--uuid': 'c1a1e5075d3b5643a5bc34fe5e16a318', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d breast -o hyperopt -u c1a1e5075d3b5643a5bc34fe5e16a318 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230422_030001
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_nll betwen [ 4.58589285 14.6438765   8.74044796  0.67466158  3.06872636] and [ 8.10456652 20.07092365 12.33228572  5.26978359  3.49043108]
  warnings.warn(

Signature errors:
                            0         1         2         3         4       max
MLP-adam_breast_nll  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
max                  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
starting sklearn study hyperopt MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.002599 iter 0 next_points [{'alpha': 0.005889055350412757, 'batch_size': 118, 'beta_1': 0.663249747346763, 'beta_2': 0.9828098514936275, 'epsilon': 6.953803513779656e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.00015302566982165915, 'tol': 0.0016535546121367855, 'validation_fraction': 0.31139724217333453}]
function_evaluation time 0.196139 value 4.848812 suggestion {'alpha': 0.005889055350412757, 'batch_size': 118, 'beta_1': 0.663249747346763, 'beta_2': 0.9828098514936275, 'epsilon': 6.953803513779656e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.00015302566982165915, 'tol': 0.0016535546121367855, 'validation_fraction': 0.31139724217333453}
observation time 0.000077, current best 4.848812 at iter 0
suggestion time taken 0.002360 iter 1 next_points [{'alpha': 8.805427386349274, 'batch_size': 129, 'beta_1': 0.7231993279535927, 'beta_2': 0.9696920680410654, 'epsilon': 8.284694430357854e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.00012201600220982006, 'tol': 0.0002299675446498386, 'validation_fraction': 0.2674636700321222}]
function_evaluation time 0.155217 value 7.330290 suggestion {'alpha': 8.805427386349274, 'batch_size': 129, 'beta_1': 0.7231993279535927, 'beta_2': 0.9696920680410654, 'epsilon': 8.284694430357854e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.00012201600220982006, 'tol': 0.0002299675446498386, 'validation_fraction': 0.2674636700321222}
observation time 0.000066, current best 4.848812 at iter 1
suggestion time taken 0.002122 iter 2 next_points [{'alpha': 0.053038682709045104, 'batch_size': 67, 'beta_1': 0.9503385431996947, 'beta_2': 0.921945745548354, 'epsilon': 1.2187072404512332e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.0009887500941612795, 'tol': 0.06450974075290139, 'validation_fraction': 0.430473259467122}]
function_evaluation time 0.268601 value 0.687621 suggestion {'alpha': 0.053038682709045104, 'batch_size': 67, 'beta_1': 0.9503385431996947, 'beta_2': 0.921945745548354, 'epsilon': 1.2187072404512332e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.0009887500941612795, 'tol': 0.06450974075290139, 'validation_fraction': 0.430473259467122}
observation time 0.000070, current best 0.687621 at iter 2
suggestion time taken 0.002126 iter 3 next_points [{'alpha': 0.0002716761706800366, 'batch_size': 127, 'beta_1': 0.646475050432139, 'beta_2': 0.9361161588548432, 'epsilon': 6.07680964450677e-07, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.043439650435266014, 'tol': 0.0053696296172307005, 'validation_fraction': 0.15313050924667435}]
function_evaluation time 0.243393 value 0.822858 suggestion {'alpha': 0.0002716761706800366, 'batch_size': 127, 'beta_1': 0.646475050432139, 'beta_2': 0.9361161588548432, 'epsilon': 6.07680964450677e-07, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.043439650435266014, 'tol': 0.0053696296172307005, 'validation_fraction': 0.15313050924667435}
observation time 0.000067, current best 0.687621 at iter 3
suggestion time taken 0.002337 iter 4 next_points [{'alpha': 0.2141366593690658, 'batch_size': 222, 'beta_1': 0.5305887732616981, 'beta_2': 0.9072827308718902, 'epsilon': 7.57729549252278e-08, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.04629899703297789, 'tol': 0.000764357195696332, 'validation_fraction': 0.8172813125058483}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.188945 value 0.612652 suggestion {'alpha': 0.2141366593690658, 'batch_size': 222, 'beta_1': 0.5305887732616981, 'beta_2': 0.9072827308718902, 'epsilon': 7.57729549252278e-08, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.04629899703297789, 'tol': 0.000764357195696332, 'validation_fraction': 0.8172813125058483}
observation time 0.000072, current best 0.612652 at iter 4
suggestion time taken 0.002155 iter 5 next_points [{'alpha': 4.827366955919297, 'batch_size': 46, 'beta_1': 0.6889580955877532, 'beta_2': 0.9675784361133226, 'epsilon': 1.0049291851346424e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.03877569063389313, 'tol': 4.8887386789336076e-05, 'validation_fraction': 0.1760020694359132}]
function_evaluation time 0.420219 value 0.346886 suggestion {'alpha': 4.827366955919297, 'batch_size': 46, 'beta_1': 0.6889580955877532, 'beta_2': 0.9675784361133226, 'epsilon': 1.0049291851346424e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.03877569063389313, 'tol': 4.8887386789336076e-05, 'validation_fraction': 0.1760020694359132}
observation time 0.000072, current best 0.346886 at iter 5
suggestion time taken 0.002136 iter 6 next_points [{'alpha': 0.6949984908349933, 'batch_size': 65, 'beta_1': 0.7339267962988614, 'beta_2': 0.9591255366651215, 'epsilon': 1.507966070156591e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 7.726880721591795e-05, 'tol': 0.03753851597403982, 'validation_fraction': 0.2987919914589588}]
function_evaluation time 0.218754 value 6.252599 suggestion {'alpha': 0.6949984908349933, 'batch_size': 65, 'beta_1': 0.7339267962988614, 'beta_2': 0.9591255366651215, 'epsilon': 1.507966070156591e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 7.726880721591795e-05, 'tol': 0.03753851597403982, 'validation_fraction': 0.2987919914589588}
observation time 0.000074, current best 0.346886 at iter 6
suggestion time taken 0.002236 iter 7 next_points [{'alpha': 0.055810484038177066, 'batch_size': 17, 'beta_1': 0.9717334251470111, 'beta_2': 0.9482607708876452, 'epsilon': 1.6296102855970354e-08, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.06505978126527749, 'tol': 0.00011758169674851113, 'validation_fraction': 0.39246105734245046}]
function_evaluation time 0.729046 value 2.211674 suggestion {'alpha': 0.055810484038177066, 'batch_size': 17, 'beta_1': 0.9717334251470111, 'beta_2': 0.9482607708876452, 'epsilon': 1.6296102855970354e-08, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.06505978126527749, 'tol': 0.00011758169674851113, 'validation_fraction': 0.39246105734245046}
observation time 0.000071, current best 0.346886 at iter 7
suggestion time taken 0.002138 iter 8 next_points [{'alpha': 0.00021506158327927984, 'batch_size': 24, 'beta_1': 0.5529056968059439, 'beta_2': 0.9211358812622107, 'epsilon': 5.761844572247807e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.002025746732858723, 'tol': 0.018687125406968267, 'validation_fraction': 0.20958197390325412}]
function_evaluation time 0.297532 value 0.331004 suggestion {'alpha': 0.00021506158327927984, 'batch_size': 24, 'beta_1': 0.5529056968059439, 'beta_2': 0.9211358812622107, 'epsilon': 5.761844572247807e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.002025746732858723, 'tol': 0.018687125406968267, 'validation_fraction': 0.20958197390325412}
observation time 0.000077, current best 0.331004 at iter 8
suggestion time taken 0.002128 iter 9 next_points [{'alpha': 7.374339341495121, 'batch_size': 165, 'beta_1': 0.7140795158764717, 'beta_2': 0.9466211446713038, 'epsilon': 7.844543010781786e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 2.803327657747313e-05, 'tol': 0.00012811114494634454, 'validation_fraction': 0.7469700896907554}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.122568 value 14.397673 suggestion {'alpha': 7.374339341495121, 'batch_size': 165, 'beta_1': 0.7140795158764717, 'beta_2': 0.9466211446713038, 'epsilon': 7.844543010781786e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 2.803327657747313e-05, 'tol': 0.00012811114494634454, 'validation_fraction': 0.7469700896907554}
observation time 0.000074, current best 0.331004 at iter 9
suggestion time taken 0.002118 iter 10 next_points [{'alpha': 0.025167838695291957, 'batch_size': 242, 'beta_1': 0.5289423808409199, 'beta_2': 0.9286738049209162, 'epsilon': 4.492953636003595e-07, 'hidden_layer_sizes': 150, 'learning_rate_init': 2.0683255442322214e-05, 'tol': 1.4347135881578238e-05, 'validation_fraction': 0.3878194583059809}]
function_evaluation time 0.120134 value 15.730140 suggestion {'alpha': 0.025167838695291957, 'batch_size': 242, 'beta_1': 0.5289423808409199, 'beta_2': 0.9286738049209162, 'epsilon': 4.492953636003595e-07, 'hidden_layer_sizes': 150, 'learning_rate_init': 2.0683255442322214e-05, 'tol': 1.4347135881578238e-05, 'validation_fraction': 0.3878194583059809}
observation time 0.000065, current best 0.331004 at iter 10
suggestion time taken 0.002135 iter 11 next_points [{'alpha': 0.023417308207590127, 'batch_size': 125, 'beta_1': 0.7598114472677895, 'beta_2': 0.9800427802902828, 'epsilon': 4.595640753894409e-07, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.00011273090137813732, 'tol': 0.0036847416894196265, 'validation_fraction': 0.8062658142200498}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.123201 value 16.547027 suggestion {'alpha': 0.023417308207590127, 'batch_size': 125, 'beta_1': 0.7598114472677895, 'beta_2': 0.9800427802902828, 'epsilon': 4.595640753894409e-07, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.00011273090137813732, 'tol': 0.0036847416894196265, 'validation_fraction': 0.8062658142200498}
observation time 0.000079, current best 0.331004 at iter 11
suggestion time taken 0.002195 iter 12 next_points [{'alpha': 0.02926460517681564, 'batch_size': 196, 'beta_1': 0.6430262766829907, 'beta_2': 0.9715580656471511, 'epsilon': 4.197987324627665e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.04639935638484094, 'tol': 6.360458316875081e-05, 'validation_fraction': 0.4299621403693233}]
function_evaluation time 0.218182 value 0.696168 suggestion {'alpha': 0.02926460517681564, 'batch_size': 196, 'beta_1': 0.6430262766829907, 'beta_2': 0.9715580656471511, 'epsilon': 4.197987324627665e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.04639935638484094, 'tol': 6.360458316875081e-05, 'validation_fraction': 0.4299621403693233}
observation time 0.000074, current best 0.331004 at iter 12
suggestion time taken 0.002397 iter 13 next_points [{'alpha': 0.0003469898729203449, 'batch_size': 117, 'beta_1': 0.7413268098913036, 'beta_2': 0.9638464257171622, 'epsilon': 4.1094765854353986e-07, 'hidden_layer_sizes': 53, 'learning_rate_init': 6.550450885030402e-05, 'tol': 0.001367017127863941, 'validation_fraction': 0.4642331020527818}]
function_evaluation time 0.083426 value 15.155648 suggestion {'alpha': 0.0003469898729203449, 'batch_size': 117, 'beta_1': 0.7413268098913036, 'beta_2': 0.9638464257171622, 'epsilon': 4.1094765854353986e-07, 'hidden_layer_sizes': 53, 'learning_rate_init': 6.550450885030402e-05, 'tol': 0.001367017127863941, 'validation_fraction': 0.4642331020527818}
observation time 0.000077, current best 0.331004 at iter 13
suggestion time taken 0.002131 iter 14 next_points [{'alpha': 0.3868962158219534, 'batch_size': 98, 'beta_1': 0.9461410790746102, 'beta_2': 0.973262883413833, 'epsilon': 2.897825879819378e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.06781501474290887, 'tol': 3.381843881569203e-05, 'validation_fraction': 0.25856169704958515}]
function_evaluation time 0.226986 value 2.852453 suggestion {'alpha': 0.3868962158219534, 'batch_size': 98, 'beta_1': 0.9461410790746102, 'beta_2': 0.973262883413833, 'epsilon': 2.897825879819378e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.06781501474290887, 'tol': 3.381843881569203e-05, 'validation_fraction': 0.25856169704958515}
observation time 0.000075, current best 0.331004 at iter 14
saving meta data: {'args': {'--uuid': 'c1a1e5075d3b5643a5bc34fe5e16a318', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])}
saving results
saving timing
saving suggest log
done

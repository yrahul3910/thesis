running: {'--uuid': '1bb89304f76a5adfbe29a2054425e1fd', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d breast -o hyperopt -u 1bb89304f76a5adfbe29a2054425e1fd -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230422_030001
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_nll betwen [ 4.58589285 14.6438765   8.74044796  0.67466158  3.06872636] and [ 8.10456652 20.07092365 12.33228572  5.26978359  3.49043108]
  warnings.warn(

Signature errors:
                            0         1         2         3         4       max
MLP-adam_breast_nll  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
max                  3.518674  5.427047  3.591838  4.595122  0.421705  5.427047
starting sklearn study hyperopt MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.002262 iter 0 next_points [{'alpha': 0.0034209635021373148, 'batch_size': 39, 'beta_1': 0.9096279133546836, 'beta_2': 0.9202731721494538, 'epsilon': 1.6026462326315174e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.029177269836604312, 'tol': 0.00018075469334736795, 'validation_fraction': 0.33767743476217565}]
function_evaluation time 0.332128 value 0.832081 suggestion {'alpha': 0.0034209635021373148, 'batch_size': 39, 'beta_1': 0.9096279133546836, 'beta_2': 0.9202731721494538, 'epsilon': 1.6026462326315174e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.029177269836604312, 'tol': 0.00018075469334736795, 'validation_fraction': 0.33767743476217565}
observation time 0.000072, current best 0.832081 at iter 0
suggestion time taken 0.002396 iter 1 next_points [{'alpha': 0.013524736983765846, 'batch_size': 41, 'beta_1': 0.5787386818497645, 'beta_2': 0.9234057631869197, 'epsilon': 8.39178649185946e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 8.583230885101864e-05, 'tol': 0.0060963786641978325, 'validation_fraction': 0.17257532536710873}]
function_evaluation time 0.406873 value 9.913401 suggestion {'alpha': 0.013524736983765846, 'batch_size': 41, 'beta_1': 0.5787386818497645, 'beta_2': 0.9234057631869197, 'epsilon': 8.39178649185946e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 8.583230885101864e-05, 'tol': 0.0060963786641978325, 'validation_fraction': 0.17257532536710873}
observation time 0.000066, current best 0.832081 at iter 1
suggestion time taken 0.002061 iter 2 next_points [{'alpha': 0.0003364436047489883, 'batch_size': 173, 'beta_1': 0.8271266164401453, 'beta_2': 0.9300470023632184, 'epsilon': 4.668032782587672e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.00784202262113567, 'tol': 0.0009158565726927075, 'validation_fraction': 0.3120371307823962}]
function_evaluation time 0.266521 value 0.555565 suggestion {'alpha': 0.0003364436047489883, 'batch_size': 173, 'beta_1': 0.8271266164401453, 'beta_2': 0.9300470023632184, 'epsilon': 4.668032782587672e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.00784202262113567, 'tol': 0.0009158565726927075, 'validation_fraction': 0.3120371307823962}
observation time 0.000075, current best 0.555565 at iter 2
suggestion time taken 0.002131 iter 3 next_points [{'alpha': 0.006779207918855439, 'batch_size': 249, 'beta_1': 0.6562023631181723, 'beta_2': 0.9740966499020004, 'epsilon': 8.028688881909841e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 6.957174249693874e-05, 'tol': 0.0005754450732910608, 'validation_fraction': 0.2190679922998087}]
function_evaluation time 0.161588 value 8.026628 suggestion {'alpha': 0.006779207918855439, 'batch_size': 249, 'beta_1': 0.6562023631181723, 'beta_2': 0.9740966499020004, 'epsilon': 8.028688881909841e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 6.957174249693874e-05, 'tol': 0.0005754450732910608, 'validation_fraction': 0.2190679922998087}
observation time 0.000062, current best 0.555565 at iter 3
suggestion time taken 0.002086 iter 4 next_points [{'alpha': 0.00018451894759234983, 'batch_size': 23, 'beta_1': 0.9723575974732271, 'beta_2': 0.9009897893943073, 'epsilon': 1.18582102074335e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.037972418911124094, 'tol': 2.5605627512467643e-05, 'validation_fraction': 0.15509491802696565}]
function_evaluation time 0.362547 value 0.423398 suggestion {'alpha': 0.00018451894759234983, 'batch_size': 23, 'beta_1': 0.9723575974732271, 'beta_2': 0.9009897893943073, 'epsilon': 1.18582102074335e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.037972418911124094, 'tol': 2.5605627512467643e-05, 'validation_fraction': 0.15509491802696565}
observation time 0.000070, current best 0.423398 at iter 4
suggestion time taken 0.002129 iter 5 next_points [{'alpha': 6.922611753865756e-05, 'batch_size': 216, 'beta_1': 0.6250243783206378, 'beta_2': 0.9531839749963084, 'epsilon': 1.3890896502979816e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.015830286250787636, 'tol': 0.015265617921337201, 'validation_fraction': 0.2984433328292159}]
function_evaluation time 0.236063 value 1.102905 suggestion {'alpha': 6.922611753865756e-05, 'batch_size': 216, 'beta_1': 0.6250243783206378, 'beta_2': 0.9531839749963084, 'epsilon': 1.3890896502979816e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.015830286250787636, 'tol': 0.015265617921337201, 'validation_fraction': 0.2984433328292159}
observation time 0.000069, current best 0.423398 at iter 5
suggestion time taken 0.002090 iter 6 next_points [{'alpha': 0.0054086606151928064, 'batch_size': 249, 'beta_1': 0.9222337205876194, 'beta_2': 0.9754660025884986, 'epsilon': 8.890219767700904e-08, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.0563691475917599, 'tol': 1.1677529402267904e-05, 'validation_fraction': 0.3058427546148271}]
function_evaluation time 0.199885 value 3.144660 suggestion {'alpha': 0.0054086606151928064, 'batch_size': 249, 'beta_1': 0.9222337205876194, 'beta_2': 0.9754660025884986, 'epsilon': 8.890219767700904e-08, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.0563691475917599, 'tol': 1.1677529402267904e-05, 'validation_fraction': 0.3058427546148271}
observation time 0.000070, current best 0.423398 at iter 6
suggestion time taken 0.002188 iter 7 next_points [{'alpha': 0.0007273282046536588, 'batch_size': 222, 'beta_1': 0.6907489141816162, 'beta_2': 0.9875867765700758, 'epsilon': 2.684066321165224e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.01241324369394479, 'tol': 0.015382052758437091, 'validation_fraction': 0.7537407799927078}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.153030 value 2.589786 suggestion {'alpha': 0.0007273282046536588, 'batch_size': 222, 'beta_1': 0.6907489141816162, 'beta_2': 0.9875867765700758, 'epsilon': 2.684066321165224e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.01241324369394479, 'tol': 0.015382052758437091, 'validation_fraction': 0.7537407799927078}
observation time 0.000075, current best 0.423398 at iter 7
suggestion time taken 0.002119 iter 8 next_points [{'alpha': 0.03397128514749157, 'batch_size': 105, 'beta_1': 0.5907493649132933, 'beta_2': 0.9145937714818516, 'epsilon': 4.975615415723747e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.0014246192228016788, 'tol': 0.0018229882015421766, 'validation_fraction': 0.222221647523989}]
function_evaluation time 0.291837 value 0.306804 suggestion {'alpha': 0.03397128514749157, 'batch_size': 105, 'beta_1': 0.5907493649132933, 'beta_2': 0.9145937714818516, 'epsilon': 4.975615415723747e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.0014246192228016788, 'tol': 0.0018229882015421766, 'validation_fraction': 0.222221647523989}
observation time 0.000079, current best 0.306804 at iter 8
suggestion time taken 0.002160 iter 9 next_points [{'alpha': 0.32281251166320624, 'batch_size': 217, 'beta_1': 0.932577016674599, 'beta_2': 0.9426620218023581, 'epsilon': 1.2433142027386512e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0005173275538290764, 'tol': 0.0006575366771619824, 'validation_fraction': 0.23157132257420215}]
function_evaluation time 0.226307 value 6.235526 suggestion {'alpha': 0.32281251166320624, 'batch_size': 217, 'beta_1': 0.932577016674599, 'beta_2': 0.9426620218023581, 'epsilon': 1.2433142027386512e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0005173275538290764, 'tol': 0.0006575366771619824, 'validation_fraction': 0.23157132257420215}
observation time 0.000074, current best 0.306804 at iter 9
suggestion time taken 0.002110 iter 10 next_points [{'alpha': 2.649305068814048, 'batch_size': 83, 'beta_1': 0.6241993224263087, 'beta_2': 0.9636226646805593, 'epsilon': 4.680735645970706e-07, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.00440523052363828, 'tol': 0.011353102698840498, 'validation_fraction': 0.15280464235898308}]
function_evaluation time 0.255063 value 0.522574 suggestion {'alpha': 2.649305068814048, 'batch_size': 83, 'beta_1': 0.6241993224263087, 'beta_2': 0.9636226646805593, 'epsilon': 4.680735645970706e-07, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.00440523052363828, 'tol': 0.011353102698840498, 'validation_fraction': 0.15280464235898308}
observation time 0.000065, current best 0.306804 at iter 10
suggestion time taken 0.002099 iter 11 next_points [{'alpha': 1.4414227277788656, 'batch_size': 175, 'beta_1': 0.5065771059573174, 'beta_2': 0.9452006463169552, 'epsilon': 9.628874693343642e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.060762406121355216, 'tol': 7.970984623382095e-05, 'validation_fraction': 0.1680052282001252}]
function_evaluation time 0.209566 value 0.718862 suggestion {'alpha': 1.4414227277788656, 'batch_size': 175, 'beta_1': 0.5065771059573174, 'beta_2': 0.9452006463169552, 'epsilon': 9.628874693343642e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.060762406121355216, 'tol': 7.970984623382095e-05, 'validation_fraction': 0.1680052282001252}
observation time 0.000057, current best 0.306804 at iter 11
suggestion time taken 0.002076 iter 12 next_points [{'alpha': 0.0019181165962602919, 'batch_size': 95, 'beta_1': 0.6605534324055479, 'beta_2': 0.9773871511935969, 'epsilon': 1.790345236754842e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 8.809530201051313e-05, 'tol': 0.041024891575045394, 'validation_fraction': 0.5000059688658751}]
function_evaluation time 0.116702 value 13.895910 suggestion {'alpha': 0.0019181165962602919, 'batch_size': 95, 'beta_1': 0.6605534324055479, 'beta_2': 0.9773871511935969, 'epsilon': 1.790345236754842e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 8.809530201051313e-05, 'tol': 0.041024891575045394, 'validation_fraction': 0.5000059688658751}
observation time 0.000063, current best 0.306804 at iter 12
suggestion time taken 0.002108 iter 13 next_points [{'alpha': 3.3665029288292256, 'batch_size': 112, 'beta_1': 0.9380451435089453, 'beta_2': 0.9727316087387925, 'epsilon': 2.8009411744249723e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.000610353767771027, 'tol': 0.0014119039594457546, 'validation_fraction': 0.11354848145950998}]
function_evaluation time 0.360918 value 0.441109 suggestion {'alpha': 3.3665029288292256, 'batch_size': 112, 'beta_1': 0.9380451435089453, 'beta_2': 0.9727316087387925, 'epsilon': 2.8009411744249723e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.000610353767771027, 'tol': 0.0014119039594457546, 'validation_fraction': 0.11354848145950998}
observation time 0.000075, current best 0.306804 at iter 13
suggestion time taken 0.002108 iter 14 next_points [{'alpha': 3.4176866560246033, 'batch_size': 95, 'beta_1': 0.806528235105491, 'beta_2': 0.9203070957699225, 'epsilon': 9.5040320421967e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 1.3039304176011981e-05, 'tol': 0.004765561877816174, 'validation_fraction': 0.6860380761561411}]
function_evaluation time 0.103882 value 17.031616 suggestion {'alpha': 3.4176866560246033, 'batch_size': 95, 'beta_1': 0.806528235105491, 'beta_2': 0.9203070957699225, 'epsilon': 9.5040320421967e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 1.3039304176011981e-05, 'tol': 0.004765561877816174, 'validation_fraction': 0.6860380761561411}
observation time 0.000060, current best 0.306804 at iter 14
saving meta data: {'args': {'--uuid': '1bb89304f76a5adfbe29a2054425e1fd', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'hyperopt', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.2697835894868685, 3.490431081639362])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '9ce487713c745eb88211024d029b3349', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'turbo', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d breast -o turbo -u 9ce487713c745eb88211024d029b3349 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230422_030001
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_breast_acc betwen [-0.80659341 -0.56703297 -0.66593407 -0.87912088 -0.85934066] and [-0.67692308 -0.41758242 -0.54505495 -0.78241758 -0.84395604]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_breast_acc  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
max                  0.12967  0.149451  0.120879  0.096703  0.015385  0.149451
starting sklearn study turbo MLP-adam breast acc 15 1
with data root: None
suggestion time taken 0.002196 iter 0 next_points [{'alpha': 0.13144684621611186, 'batch_size': 108, 'beta_1': 0.727104854228132, 'beta_2': 0.9999910096752738, 'epsilon': 5.6232036737257664e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.04737152815868323, 'tol': 9.833907858089186e-05, 'validation_fraction': 0.43717281688810883}]
function_evaluation time 0.212174 value -0.896703 suggestion {'alpha': 0.13144684621611186, 'batch_size': 108, 'beta_1': 0.727104854228132, 'beta_2': 0.9999910096752738, 'epsilon': 5.6232036737257664e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.04737152815868323, 'tol': 9.833907858089186e-05, 'validation_fraction': 0.43717281688810883}
observation time 0.001434, current best -0.896703 at iter 0
suggestion time taken 0.002083 iter 1 next_points [{'alpha': 0.00015532950268294963, 'batch_size': 185, 'beta_1': 0.9871380160090305, 'beta_2': 0.9999660833530911, 'epsilon': 5.0788969219137865e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.003961040654491267, 'tol': 0.002183835825573202, 'validation_fraction': 0.26324861890222256}]
function_evaluation time 0.307494 value -0.896703 suggestion {'alpha': 0.00015532950268294963, 'batch_size': 185, 'beta_1': 0.9871380160090305, 'beta_2': 0.9999660833530911, 'epsilon': 5.0788969219137865e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.003961040654491267, 'tol': 0.002183835825573202, 'validation_fraction': 0.26324861890222256}
observation time 0.001438, current best -0.896703 at iter 1
suggestion time taken 0.001758 iter 2 next_points [{'alpha': 0.06936814493377734, 'batch_size': 125, 'beta_1': 0.9766733032633174, 'beta_2': 0.9999518913664719, 'epsilon': 1.5722828877287694e-09, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.07762920580322401, 'tol': 0.0008761059746618027, 'validation_fraction': 0.132127240493311}]
function_evaluation time 0.234725 value -0.762637 suggestion {'alpha': 0.06936814493377734, 'batch_size': 125, 'beta_1': 0.9766733032633174, 'beta_2': 0.9999518913664719, 'epsilon': 1.5722828877287694e-09, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.07762920580322401, 'tol': 0.0008761059746618027, 'validation_fraction': 0.132127240493311}
observation time 0.001451, current best -0.896703 at iter 2
suggestion time taken 0.001799 iter 3 next_points [{'alpha': 0.034330564460286865, 'batch_size': 117, 'beta_1': 0.5336666618556141, 'beta_2': 0.9998731348812914, 'epsilon': 1.3581133801764622e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.003014465658593142, 'tol': 0.010785451020719282, 'validation_fraction': 0.3585911284277147}]
function_evaluation time 0.202421 value -0.892308 suggestion {'alpha': 0.034330564460286865, 'batch_size': 117, 'beta_1': 0.5336666618556141, 'beta_2': 0.9998731348812914, 'epsilon': 1.3581133801764622e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.003014465658593142, 'tol': 0.010785451020719282, 'validation_fraction': 0.3585911284277147}
observation time 0.001689, current best -0.896703 at iter 3
suggestion time taken 0.001801 iter 4 next_points [{'alpha': 0.005864555945378481, 'batch_size': 214, 'beta_1': 0.966887328774875, 'beta_2': 0.9584489742068326, 'epsilon': 8.29835491245052e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 1.8861032791209348e-05, 'tol': 0.006759855534310955, 'validation_fraction': 0.48655388162421515}]
function_evaluation time 0.168213 value -0.512088 suggestion {'alpha': 0.005864555945378481, 'batch_size': 214, 'beta_1': 0.966887328774875, 'beta_2': 0.9584489742068326, 'epsilon': 8.29835491245052e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 1.8861032791209348e-05, 'tol': 0.006759855534310955, 'validation_fraction': 0.48655388162421515}
observation time 0.001429, current best -0.896703 at iter 4
suggestion time taken 0.001785 iter 5 next_points [{'alpha': 0.027317343437329285, 'batch_size': 161, 'beta_1': 0.7024331162000176, 'beta_2': 0.9999960057576586, 'epsilon': 3.4330964870444064e-08, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0006274573330268373, 'tol': 0.00015565047590441813, 'validation_fraction': 0.4071802886678879}]
function_evaluation time 0.220364 value -0.846154 suggestion {'alpha': 0.027317343437329285, 'batch_size': 161, 'beta_1': 0.7024331162000176, 'beta_2': 0.9999960057576586, 'epsilon': 3.4330964870444064e-08, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0006274573330268373, 'tol': 0.00015565047590441813, 'validation_fraction': 0.4071802886678879}
observation time 0.001646, current best -0.896703 at iter 5
suggestion time taken 0.001846 iter 6 next_points [{'alpha': 0.5006872350679057, 'batch_size': 25, 'beta_1': 0.9878447059749667, 'beta_2': 0.9241199773833478, 'epsilon': 4.961654332103867e-07, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.00019616368757666128, 'tol': 0.044202754390481165, 'validation_fraction': 0.6652785823392583}]
function_evaluation time 0.281337 value -0.846154 suggestion {'alpha': 0.5006872350679057, 'batch_size': 25, 'beta_1': 0.9878447059749667, 'beta_2': 0.9241199773833478, 'epsilon': 4.961654332103867e-07, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.00019616368757666128, 'tol': 0.044202754390481165, 'validation_fraction': 0.6652785823392583}
observation time 0.001413, current best -0.896703 at iter 6
suggestion time taken 0.001824 iter 7 next_points [{'alpha': 5.107612575210232, 'batch_size': 210, 'beta_1': 0.9732850688728191, 'beta_2': 0.9944222714161615, 'epsilon': 7.327813298145746e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.026961979014777697, 'tol': 0.00027867363594449537, 'validation_fraction': 0.19673707844399757}]
function_evaluation time 0.255900 value -0.898901 suggestion {'alpha': 5.107612575210232, 'batch_size': 210, 'beta_1': 0.9732850688728191, 'beta_2': 0.9944222714161615, 'epsilon': 7.327813298145746e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.026961979014777697, 'tol': 0.00027867363594449537, 'validation_fraction': 0.19673707844399757}
observation time 0.001412, current best -0.898901 at iter 7
suggestion time taken 0.001973 iter 8 next_points [{'alpha': 0.00027169878864570523, 'batch_size': 66, 'beta_1': 0.8957920615625112, 'beta_2': 0.9999973001355535, 'epsilon': 4.1360586535195277e-07, 'hidden_layer_sizes': 125, 'learning_rate_init': 6.712441546976999e-05, 'tol': 3.8343164365649857e-05, 'validation_fraction': 0.24905243376631447}]
function_evaluation time 0.184128 value -0.472527 suggestion {'alpha': 0.00027169878864570523, 'batch_size': 66, 'beta_1': 0.8957920615625112, 'beta_2': 0.9999973001355535, 'epsilon': 4.1360586535195277e-07, 'hidden_layer_sizes': 125, 'learning_rate_init': 6.712441546976999e-05, 'tol': 3.8343164365649857e-05, 'validation_fraction': 0.24905243376631447}
observation time 0.001410, current best -0.898901 at iter 8
suggestion time taken 0.001714 iter 9 next_points [{'alpha': 0.00045746692634673913, 'batch_size': 98, 'beta_1': 0.9554192252282693, 'beta_2': 0.9996771940832888, 'epsilon': 7.688722483779602e-08, 'hidden_layer_sizes': 83, 'learning_rate_init': 7.021750933066748e-05, 'tol': 5.3627521344822436e-05, 'validation_fraction': 0.8728181813439974}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.084248 value -0.582418 suggestion {'alpha': 0.00045746692634673913, 'batch_size': 98, 'beta_1': 0.9554192252282693, 'beta_2': 0.9996771940832888, 'epsilon': 7.688722483779602e-08, 'hidden_layer_sizes': 83, 'learning_rate_init': 7.021750933066748e-05, 'tol': 5.3627521344822436e-05, 'validation_fraction': 0.8728181813439974}
observation time 0.001343, current best -0.898901 at iter 9
suggestion time taken 0.001751 iter 10 next_points [{'alpha': 1.8862498362404282e-05, 'batch_size': 79, 'beta_1': 0.8182964300185085, 'beta_2': 0.9997956362251624, 'epsilon': 1.0111449154001295e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 3.0284937561632748e-05, 'tol': 0.00484620803144821, 'validation_fraction': 0.5699752403145004}]
function_evaluation time 0.126904 value -0.472527 suggestion {'alpha': 1.8862498362404282e-05, 'batch_size': 79, 'beta_1': 0.8182964300185085, 'beta_2': 0.9997956362251624, 'epsilon': 1.0111449154001295e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 3.0284937561632748e-05, 'tol': 0.00484620803144821, 'validation_fraction': 0.5699752403145004}
observation time 0.001397, current best -0.898901 at iter 10
suggestion time taken 0.001740 iter 11 next_points [{'alpha': 8.015368644000106e-05, 'batch_size': 248, 'beta_1': 0.9255141775295381, 'beta_2': 0.9988691582980138, 'epsilon': 1.2112606825205057e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0009288517023796586, 'tol': 0.023698142004166728, 'validation_fraction': 0.8803381903074518}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.091776 value -0.593407 suggestion {'alpha': 8.015368644000106e-05, 'batch_size': 248, 'beta_1': 0.9255141775295381, 'beta_2': 0.9988691582980138, 'epsilon': 1.2112606825205057e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0009288517023796586, 'tol': 0.023698142004166728, 'validation_fraction': 0.8803381903074518}
observation time 0.001389, current best -0.898901 at iter 11
suggestion time taken 0.001792 iter 12 next_points [{'alpha': 1.9512791316346225, 'batch_size': 173, 'beta_1': 0.8042785320127006, 'beta_2': 0.9968511851559795, 'epsilon': 1.8423767698617526e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.00012809280769359127, 'tol': 0.09601594349849064, 'validation_fraction': 0.8163596968538949}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.081470 value -0.520879 suggestion {'alpha': 1.9512791316346225, 'batch_size': 173, 'beta_1': 0.8042785320127006, 'beta_2': 0.9968511851559795, 'epsilon': 1.8423767698617526e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.00012809280769359127, 'tol': 0.09601594349849064, 'validation_fraction': 0.8163596968538949}
observation time 0.001407, current best -0.898901 at iter 12
suggestion time taken 0.001782 iter 13 next_points [{'alpha': 1.033008711795424, 'batch_size': 58, 'beta_1': 0.947418777917762, 'beta_2': 0.9999985642159173, 'epsilon': 4.074819640547655e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 1.1101883431302863e-05, 'tol': 2.515029796275247e-05, 'validation_fraction': 0.6019814621766395}]
function_evaluation time 0.145136 value -0.527473 suggestion {'alpha': 1.033008711795424, 'batch_size': 58, 'beta_1': 0.947418777917762, 'beta_2': 0.9999985642159173, 'epsilon': 4.074819640547655e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 1.1101883431302863e-05, 'tol': 2.515029796275247e-05, 'validation_fraction': 0.6019814621766395}
observation time 0.001419, current best -0.898901 at iter 13
suggestion time taken 0.001729 iter 14 next_points [{'alpha': 2.6621427412455803, 'batch_size': 36, 'beta_1': 0.9831242399149454, 'beta_2': 0.9984387704322869, 'epsilon': 1.5248372060633184e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.0002989720595205877, 'tol': 0.0005118348971748941, 'validation_fraction': 0.8235774505665056}]
function_evaluation time 0.153990 value -0.626374 suggestion {'alpha': 2.6621427412455803, 'batch_size': 36, 'beta_1': 0.9831242399149454, 'beta_2': 0.9984387704322869, 'epsilon': 1.5248372060633184e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.0002989720595205877, 'tol': 0.0005118348971748941, 'validation_fraction': 0.8235774505665056}
observation time 0.001379, current best -0.898901 at iter 14
saving meta data: {'args': {'--uuid': '9ce487713c745eb88211024d029b3349', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230422_030001', '--opt': 'turbo', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': 'f40954e2e2965432835be936deaa54eb', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d diabetes -o hyperopt -u f40954e2e2965432835be936deaa54eb -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_055340
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study hyperopt MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002364 iter 0 next_points [{'alpha': 0.00046366377701694054, 'batch_size': 60, 'beta_1': 0.550728168002373, 'beta_2': 0.9798833057453166, 'epsilon': 6.500158917428268e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 2.2059380454260517e-05, 'tol': 1.1460307967045534e-05, 'validation_fraction': 0.10866722241527332}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.010448 value 151.286699 suggestion {'alpha': 0.00046366377701694054, 'batch_size': 60, 'beta_1': 0.550728168002373, 'beta_2': 0.9798833057453166, 'epsilon': 6.500158917428268e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 2.2059380454260517e-05, 'tol': 1.1460307967045534e-05, 'validation_fraction': 0.10866722241527332}
observation time 0.000064, current best 151.286699 at iter 0
suggestion time taken 0.002572 iter 1 next_points [{'alpha': 9.35647116194729e-05, 'batch_size': 100, 'beta_1': 0.874131244685986, 'beta_2': 0.9566546570877095, 'epsilon': 1.6184242423171698e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0011395072153915027, 'tol': 0.05852676844489125, 'validation_fraction': 0.17617434666855103}]
function_evaluation time 0.049691 value 151.358465 suggestion {'alpha': 9.35647116194729e-05, 'batch_size': 100, 'beta_1': 0.874131244685986, 'beta_2': 0.9566546570877095, 'epsilon': 1.6184242423171698e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0011395072153915027, 'tol': 0.05852676844489125, 'validation_fraction': 0.17617434666855103}
observation time 0.000068, current best 151.286699 at iter 1
suggestion time taken 0.002146 iter 2 next_points [{'alpha': 1.1954471160523128, 'batch_size': 70, 'beta_1': 0.5214075644341989, 'beta_2': 0.9953084223690103, 'epsilon': 1.0187659272660704e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.02264572786440692, 'tol': 1.1285411876749498e-05, 'validation_fraction': 0.34713786671364594}]
function_evaluation time 0.534743 value 44.971390 suggestion {'alpha': 1.1954471160523128, 'batch_size': 70, 'beta_1': 0.5214075644341989, 'beta_2': 0.9953084223690103, 'epsilon': 1.0187659272660704e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.02264572786440692, 'tol': 1.1285411876749498e-05, 'validation_fraction': 0.34713786671364594}
observation time 0.000070, current best 44.971390 at iter 2
suggestion time taken 0.002188 iter 3 next_points [{'alpha': 0.0100532987309645, 'batch_size': 171, 'beta_1': 0.7726939977754492, 'beta_2': 0.9148897647523515, 'epsilon': 3.285649127043119e-08, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.0005834577930191412, 'tol': 0.0005012489804860743, 'validation_fraction': 0.5146165049159496}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.334995 value 151.073014 suggestion {'alpha': 0.0100532987309645, 'batch_size': 171, 'beta_1': 0.7726939977754492, 'beta_2': 0.9148897647523515, 'epsilon': 3.285649127043119e-08, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.0005834577930191412, 'tol': 0.0005012489804860743, 'validation_fraction': 0.5146165049159496}
observation time 0.000069, current best 44.971390 at iter 3
suggestion time taken 0.002130 iter 4 next_points [{'alpha': 2.4271756178875598e-05, 'batch_size': 168, 'beta_1': 0.9207699934873191, 'beta_2': 0.9224054271044692, 'epsilon': 1.0294215741600293e-07, 'hidden_layer_sizes': 124, 'learning_rate_init': 6.212655143176952e-05, 'tol': 0.00027551460054082706, 'validation_fraction': 0.24998575180744942}]
function_evaluation time 0.077764 value 151.561091 suggestion {'alpha': 2.4271756178875598e-05, 'batch_size': 168, 'beta_1': 0.9207699934873191, 'beta_2': 0.9224054271044692, 'epsilon': 1.0294215741600293e-07, 'hidden_layer_sizes': 124, 'learning_rate_init': 6.212655143176952e-05, 'tol': 0.00027551460054082706, 'validation_fraction': 0.24998575180744942}
observation time 0.000069, current best 44.971390 at iter 4
suggestion time taken 0.002170 iter 5 next_points [{'alpha': 0.08704402456137801, 'batch_size': 145, 'beta_1': 0.5910363273699948, 'beta_2': 0.9339690915213855, 'epsilon': 9.482220136074804e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.019599893309487845, 'tol': 0.0001012368485954567, 'validation_fraction': 0.2260464883681695}]
function_evaluation time 0.645094 value 44.750977 suggestion {'alpha': 0.08704402456137801, 'batch_size': 145, 'beta_1': 0.5910363273699948, 'beta_2': 0.9339690915213855, 'epsilon': 9.482220136074804e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.019599893309487845, 'tol': 0.0001012368485954567, 'validation_fraction': 0.2260464883681695}
observation time 0.000072, current best 44.750977 at iter 5
suggestion time taken 0.002109 iter 6 next_points [{'alpha': 0.05797655649577368, 'batch_size': 193, 'beta_1': 0.5429281396125021, 'beta_2': 0.9015136259858539, 'epsilon': 2.1905268775097547e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0101241063851436, 'tol': 0.023486020140579017, 'validation_fraction': 0.448802330131049}]
function_evaluation time 0.134210 value 148.786001 suggestion {'alpha': 0.05797655649577368, 'batch_size': 193, 'beta_1': 0.5429281396125021, 'beta_2': 0.9015136259858539, 'epsilon': 2.1905268775097547e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0101241063851436, 'tol': 0.023486020140579017, 'validation_fraction': 0.448802330131049}
observation time 0.000068, current best 44.750977 at iter 6
suggestion time taken 0.002327 iter 7 next_points [{'alpha': 2.444525291491958, 'batch_size': 186, 'beta_1': 0.640202247794737, 'beta_2': 0.9675025462036507, 'epsilon': 4.1412338257689237e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0823633329264204, 'tol': 0.0032570424680796062, 'validation_fraction': 0.11344576636864663}]
function_evaluation time 0.213878 value 50.537657 suggestion {'alpha': 2.444525291491958, 'batch_size': 186, 'beta_1': 0.640202247794737, 'beta_2': 0.9675025462036507, 'epsilon': 4.1412338257689237e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0823633329264204, 'tol': 0.0032570424680796062, 'validation_fraction': 0.11344576636864663}
observation time 0.000066, current best 44.750977 at iter 7
suggestion time taken 0.002293 iter 8 next_points [{'alpha': 0.0351352927727932, 'batch_size': 229, 'beta_1': 0.7905141572348003, 'beta_2': 0.95333644383201, 'epsilon': 1.3058558498836442e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 3.330021054481529e-05, 'tol': 0.09154996281949834, 'validation_fraction': 0.6133546254165675}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.050138 value 151.575436 suggestion {'alpha': 0.0351352927727932, 'batch_size': 229, 'beta_1': 0.7905141572348003, 'beta_2': 0.95333644383201, 'epsilon': 1.3058558498836442e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 3.330021054481529e-05, 'tol': 0.09154996281949834, 'validation_fraction': 0.6133546254165675}
observation time 0.000070, current best 44.750977 at iter 8
suggestion time taken 0.002355 iter 9 next_points [{'alpha': 0.9077173849583443, 'batch_size': 234, 'beta_1': 0.6071968973335231, 'beta_2': 0.922299236348427, 'epsilon': 2.1348970770078702e-08, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0008124021267985001, 'tol': 0.0034550414615410674, 'validation_fraction': 0.40811328478649633}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.064222 value 151.626367 suggestion {'alpha': 0.9077173849583443, 'batch_size': 234, 'beta_1': 0.6071968973335231, 'beta_2': 0.922299236348427, 'epsilon': 2.1348970770078702e-08, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0008124021267985001, 'tol': 0.0034550414615410674, 'validation_fraction': 0.40811328478649633}
observation time 0.000081, current best 44.750977 at iter 9
suggestion time taken 0.002146 iter 10 next_points [{'alpha': 6.005177710771384e-05, 'batch_size': 40, 'beta_1': 0.6675700238865643, 'beta_2': 0.9028537684307119, 'epsilon': 9.386974829677334e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.00017617835692432514, 'tol': 6.871042382465666e-05, 'validation_fraction': 0.7872266954373316}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.855939 value 150.846264 suggestion {'alpha': 6.005177710771384e-05, 'batch_size': 40, 'beta_1': 0.6675700238865643, 'beta_2': 0.9028537684307119, 'epsilon': 9.386974829677334e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.00017617835692432514, 'tol': 6.871042382465666e-05, 'validation_fraction': 0.7872266954373316}
observation time 0.000076, current best 44.750977 at iter 10
suggestion time taken 0.002109 iter 11 next_points [{'alpha': 1.3668895558881133, 'batch_size': 11, 'beta_1': 0.9453101123058611, 'beta_2': 0.9643850720830341, 'epsilon': 1.7527943274402744e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.008548530298527252, 'tol': 0.032233066571027, 'validation_fraction': 0.36880003564531527}]
function_evaluation time 0.379855 value 52.321279 suggestion {'alpha': 1.3668895558881133, 'batch_size': 11, 'beta_1': 0.9453101123058611, 'beta_2': 0.9643850720830341, 'epsilon': 1.7527943274402744e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.008548530298527252, 'tol': 0.032233066571027, 'validation_fraction': 0.36880003564531527}
observation time 0.000072, current best 44.750977 at iter 11
suggestion time taken 0.002155 iter 12 next_points [{'alpha': 1.2147590054516915e-05, 'batch_size': 131, 'beta_1': 0.5406997416095802, 'beta_2': 0.9211288318127439, 'epsilon': 6.972969564036081e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.00041995829839343583, 'tol': 0.00026850084415941915, 'validation_fraction': 0.5484032753530123}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.827957 value 150.329183 suggestion {'alpha': 1.2147590054516915e-05, 'batch_size': 131, 'beta_1': 0.5406997416095802, 'beta_2': 0.9211288318127439, 'epsilon': 6.972969564036081e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.00041995829839343583, 'tol': 0.00026850084415941915, 'validation_fraction': 0.5484032753530123}
observation time 0.000071, current best 44.750977 at iter 12
suggestion time taken 0.002145 iter 13 next_points [{'alpha': 2.6751717707951683, 'batch_size': 186, 'beta_1': 0.7022786743271056, 'beta_2': 0.9089200598281785, 'epsilon': 1.3203620848156507e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.028540213630583674, 'tol': 0.006073370370296662, 'validation_fraction': 0.10005465352780374}]
function_evaluation time 0.284523 value 48.095750 suggestion {'alpha': 2.6751717707951683, 'batch_size': 186, 'beta_1': 0.7022786743271056, 'beta_2': 0.9089200598281785, 'epsilon': 1.3203620848156507e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.028540213630583674, 'tol': 0.006073370370296662, 'validation_fraction': 0.10005465352780374}
observation time 0.000070, current best 44.750977 at iter 13
suggestion time taken 0.002143 iter 14 next_points [{'alpha': 1.3882419463330458, 'batch_size': 109, 'beta_1': 0.6966682757128968, 'beta_2': 0.9898372625213627, 'epsilon': 7.424133625652919e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0006009236483356657, 'tol': 0.0022751906040615606, 'validation_fraction': 0.7324599809807365}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.051521 value 151.431558 suggestion {'alpha': 1.3882419463330458, 'batch_size': 109, 'beta_1': 0.6966682757128968, 'beta_2': 0.9898372625213627, 'epsilon': 7.424133625652919e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0006009236483356657, 'tol': 0.0022751906040615606, 'validation_fraction': 0.7324599809807365}
observation time 0.000070, current best 44.750977 at iter 14
saving meta data: {'args': {'--uuid': 'f40954e2e2965432835be936deaa54eb', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

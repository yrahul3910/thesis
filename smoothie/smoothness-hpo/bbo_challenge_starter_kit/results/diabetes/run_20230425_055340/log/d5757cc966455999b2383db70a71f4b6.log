running: {'--uuid': 'd5757cc966455999b2383db70a71f4b6', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d diabetes -o opentuner -u d5757cc966455999b2383db70a71f4b6 -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_055340
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study opentuner MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.017614 iter 0 next_points [{'hidden_layer_sizes': 155, 'alpha': 8.257939300084557, 'batch_size': 89, 'learning_rate_init': 0.07983522500497935, 'tol': 0.07922053557676205, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.5294904942198044, 'beta_2': 0.9842414641028592, 'epsilon': 9.60774739239805e-07}]
function_evaluation time 0.119262 value 47.129881 suggestion {'hidden_layer_sizes': 155, 'alpha': 8.257939300084557, 'batch_size': 89, 'learning_rate_init': 0.07983522500497935, 'tol': 0.07922053557676205, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.5294904942198044, 'beta_2': 0.9842414641028592, 'epsilon': 9.60774739239805e-07}
observation time 0.004131, current best 47.129881 at iter 0
suggestion time taken 0.021520 iter 1 next_points [{'alpha': 0.720781424665584, 'tol': 0.001566639861894471, 'learning_rate_init': 0.052826480602329244, 'batch_size': 160, 'beta_2': 0.9208070863600119, 'validation_fraction': 0.6831393734352516, 'beta_1': 0.8582458218120423, 'epsilon': 8.256164975300729e-07, 'hidden_layer_sizes': 79}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.267640 value 49.754471 suggestion {'alpha': 0.720781424665584, 'tol': 0.001566639861894471, 'learning_rate_init': 0.052826480602329244, 'batch_size': 160, 'beta_2': 0.9208070863600119, 'validation_fraction': 0.6831393734352516, 'beta_1': 0.8582458218120423, 'epsilon': 8.256164975300729e-07, 'hidden_layer_sizes': 79}
observation time 0.002182, current best 47.129881 at iter 1
suggestion time taken 0.007152 iter 2 next_points [{'hidden_layer_sizes': 155, 'alpha': 8.257939300084557, 'batch_size': 89, 'learning_rate_init': 0.07983522500497935, 'tol': 0.07922053557676205, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.5294904942198044, 'beta_2': 0.9469071743157936, 'epsilon': 3.6262607419676365e-07}]
function_evaluation time 0.119867 value 47.305891 suggestion {'hidden_layer_sizes': 155, 'alpha': 8.257939300084557, 'batch_size': 89, 'learning_rate_init': 0.07983522500497935, 'tol': 0.07922053557676205, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.5294904942198044, 'beta_2': 0.9469071743157936, 'epsilon': 3.6262607419676365e-07}
observation time 0.001845, current best 47.129881 at iter 2
suggestion time taken 0.046287 iter 3 next_points [{'epsilon': 6.706079175583236e-07, 'alpha': 9.134803001308224, 'beta_2': 0.9261870993949445, 'learning_rate_init': 0.09142352266982227, 'beta_1': 0.5754309080933949, 'validation_fraction': 0.8258559499660695, 'tol': 0.05304561354683817, 'hidden_layer_sizes': 91, 'batch_size': 160}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.108960 value 52.296552 suggestion {'epsilon': 6.706079175583236e-07, 'alpha': 9.134803001308224, 'beta_2': 0.9261870993949445, 'learning_rate_init': 0.09142352266982227, 'beta_1': 0.5754309080933949, 'validation_fraction': 0.8258559499660695, 'tol': 0.05304561354683817, 'hidden_layer_sizes': 91, 'batch_size': 160}
observation time 0.001774, current best 47.129881 at iter 3
suggestion time taken 0.006999 iter 4 next_points [{'hidden_layer_sizes': 155, 'alpha': 8.257939300084557, 'batch_size': 89, 'learning_rate_init': 0.07983522500497935, 'tol': 0.07922053557676205, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.5294904942198044, 'beta_2': 0.9916090232871473, 'epsilon': 8.322185899583824e-07}]
function_evaluation time 0.119476 value 47.813342 suggestion {'hidden_layer_sizes': 155, 'alpha': 8.257939300084557, 'batch_size': 89, 'learning_rate_init': 0.07983522500497935, 'tol': 0.07922053557676205, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.5294904942198044, 'beta_2': 0.9916090232871473, 'epsilon': 8.322185899583824e-07}
observation time 0.002095, current best 47.129881 at iter 4
suggestion time taken 0.007374 iter 5 next_points [{'hidden_layer_sizes': 155, 'alpha': 7.738584271107641, 'batch_size': 89, 'learning_rate_init': 0.07983522500497935, 'tol': 0.08201070227663491, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.501996686728599, 'beta_2': 0.9967645770497982, 'epsilon': 9.002430187149125e-07}]
function_evaluation time 0.120650 value 46.518161 suggestion {'hidden_layer_sizes': 155, 'alpha': 7.738584271107641, 'batch_size': 89, 'learning_rate_init': 0.07983522500497935, 'tol': 0.08201070227663491, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.501996686728599, 'beta_2': 0.9967645770497982, 'epsilon': 9.002430187149125e-07}
observation time 0.001985, current best 46.518161 at iter 5
suggestion time taken 0.006976 iter 6 next_points [{'hidden_layer_sizes': 155, 'alpha': 7.738584271107641, 'batch_size': 89, 'learning_rate_init': 0.07983522500497935, 'tol': 0.08201070227663491, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.5319846307688668, 'beta_2': 0.9967645770497982, 'epsilon': 8.283645821788022e-07}]
function_evaluation time 0.117851 value 47.345231 suggestion {'hidden_layer_sizes': 155, 'alpha': 7.738584271107641, 'batch_size': 89, 'learning_rate_init': 0.07983522500497935, 'tol': 0.08201070227663491, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.5319846307688668, 'beta_2': 0.9967645770497982, 'epsilon': 8.283645821788022e-07}
observation time 0.001850, current best 46.518161 at iter 6
suggestion time taken 0.007441 iter 7 next_points [{'hidden_layer_sizes': 155, 'alpha': 8.27301869027879, 'batch_size': 89, 'learning_rate_init': 0.07983522500497935, 'tol': 0.08201070227663491, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.501996686728599, 'beta_2': 0.9899382335495321, 'epsilon': 9.002430187149125e-07}]
function_evaluation time 0.120988 value 47.856251 suggestion {'hidden_layer_sizes': 155, 'alpha': 8.27301869027879, 'batch_size': 89, 'learning_rate_init': 0.07983522500497935, 'tol': 0.08201070227663491, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.501996686728599, 'beta_2': 0.9899382335495321, 'epsilon': 9.002430187149125e-07}
observation time 0.001969, current best 46.518161 at iter 7
suggestion time taken 0.006969 iter 8 next_points [{'hidden_layer_sizes': 155, 'alpha': 7.738584271107641, 'batch_size': 89, 'learning_rate_init': 0.07983522500497935, 'tol': 0.0742078379903081, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.501996686728599, 'beta_2': 0.9967645770497982, 'epsilon': 8.225188374016691e-07}]
function_evaluation time 0.118419 value 46.949126 suggestion {'hidden_layer_sizes': 155, 'alpha': 7.738584271107641, 'batch_size': 89, 'learning_rate_init': 0.07983522500497935, 'tol': 0.0742078379903081, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.501996686728599, 'beta_2': 0.9967645770497982, 'epsilon': 8.225188374016691e-07}
observation time 0.001814, current best 46.518161 at iter 8
suggestion time taken 0.007479 iter 9 next_points [{'hidden_layer_sizes': 135, 'alpha': 7.738584271107641, 'batch_size': 89, 'learning_rate_init': 0.07983522500497935, 'tol': 0.08201070227663491, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.5320489893874918, 'beta_2': 0.9941652842005998, 'epsilon': 7.836268990651641e-07}]
function_evaluation time 0.116844 value 47.770752 suggestion {'hidden_layer_sizes': 135, 'alpha': 7.738584271107641, 'batch_size': 89, 'learning_rate_init': 0.07983522500497935, 'tol': 0.08201070227663491, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.5320489893874918, 'beta_2': 0.9941652842005998, 'epsilon': 7.836268990651641e-07}
observation time 0.001814, current best 46.518161 at iter 9
suggestion time taken 0.007925 iter 10 next_points [{'hidden_layer_sizes': 141, 'alpha': 8.96811963951529, 'batch_size': 116, 'learning_rate_init': 0.07983522500497935, 'tol': 0.08065399545049583, 'validation_fraction': 0.32380336137077403, 'beta_1': 0.5529432434147511, 'beta_2': 0.9907460866751656, 'epsilon': 9.002430187149125e-07}]
function_evaluation time 0.122076 value 47.010506 suggestion {'hidden_layer_sizes': 141, 'alpha': 8.96811963951529, 'batch_size': 116, 'learning_rate_init': 0.07983522500497935, 'tol': 0.08065399545049583, 'validation_fraction': 0.32380336137077403, 'beta_1': 0.5529432434147511, 'beta_2': 0.9907460866751656, 'epsilon': 9.002430187149125e-07}
observation time 0.001996, current best 46.518161 at iter 10
suggestion time taken 0.007534 iter 11 next_points [{'hidden_layer_sizes': 155, 'alpha': 7.738584271107641, 'batch_size': 61, 'learning_rate_init': 0.07983522500497935, 'tol': 0.08010993758129918, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.501996686728599, 'beta_2': 0.9871981548553173, 'epsilon': 9.002430187149125e-07}]
function_evaluation time 0.126147 value 46.920702 suggestion {'hidden_layer_sizes': 155, 'alpha': 7.738584271107641, 'batch_size': 61, 'learning_rate_init': 0.07983522500497935, 'tol': 0.08010993758129918, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.501996686728599, 'beta_2': 0.9871981548553173, 'epsilon': 9.002430187149125e-07}
observation time 0.001929, current best 46.518161 at iter 11
suggestion time taken 0.005477 iter 12 next_points [{'epsilon': 1.8945598281913567e-07, 'alpha': 1.8726467086474217, 'beta_2': 0.9449335577809723, 'learning_rate_init': 0.09094659915141283, 'beta_1': 0.7141902765031981, 'validation_fraction': 0.4818772609693077, 'tol': 0.06758483213115644, 'hidden_layer_sizes': 170, 'batch_size': 155}]
function_evaluation time 0.127301 value 47.669759 suggestion {'epsilon': 1.8945598281913567e-07, 'alpha': 1.8726467086474217, 'beta_2': 0.9449335577809723, 'learning_rate_init': 0.09094659915141283, 'beta_1': 0.7141902765031981, 'validation_fraction': 0.4818772609693077, 'tol': 0.06758483213115644, 'hidden_layer_sizes': 170, 'batch_size': 155}
observation time 0.002033, current best 46.518161 at iter 12
suggestion time taken 0.006956 iter 13 next_points [{'hidden_layer_sizes': 155, 'alpha': 7.738584271107641, 'batch_size': 140, 'learning_rate_init': 0.07983522500497935, 'tol': 0.09756274681779258, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.501996686728599, 'beta_2': 0.9433882909329232, 'epsilon': 9.002430187149125e-07}]
function_evaluation time 0.121740 value 52.189168 suggestion {'hidden_layer_sizes': 155, 'alpha': 7.738584271107641, 'batch_size': 140, 'learning_rate_init': 0.07983522500497935, 'tol': 0.09756274681779258, 'validation_fraction': 0.4772984382168778, 'beta_1': 0.501996686728599, 'beta_2': 0.9433882909329232, 'epsilon': 9.002430187149125e-07}
observation time 0.001855, current best 46.518161 at iter 13
suggestion time taken 0.005929 iter 14 next_points [{'alpha': 3.1035470429670533, 'tol': 0.013757896174638896, 'learning_rate_init': 0.0878881293020523, 'batch_size': 156, 'beta_2': 0.9776579175257776, 'validation_fraction': 0.7484227186651252, 'beta_1': 0.7160772532847881, 'epsilon': 8.151632426017508e-07, 'hidden_layer_sizes': 171}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.148329 value 47.758585 suggestion {'alpha': 3.1035470429670533, 'tol': 0.013757896174638896, 'learning_rate_init': 0.0878881293020523, 'batch_size': 156, 'beta_2': 0.9776579175257776, 'validation_fraction': 0.7484227186651252, 'beta_1': 0.7160772532847881, 'epsilon': 8.151632426017508e-07, 'hidden_layer_sizes': 171}
observation time 0.002039, current best 46.518161 at iter 14
saving meta data: {'args': {'--uuid': 'd5757cc966455999b2383db70a71f4b6', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

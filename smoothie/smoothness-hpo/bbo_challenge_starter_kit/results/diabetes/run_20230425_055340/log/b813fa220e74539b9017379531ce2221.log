running: {'--uuid': 'b813fa220e74539b9017379531ce2221', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d diabetes -o turbo -u b813fa220e74539b9017379531ce2221 -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_055340
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study turbo MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002069 iter 0 next_points [{'alpha': 1.5422609513678105e-05, 'batch_size': 80, 'beta_1': 0.7720791742983684, 'beta_2': 0.9999969143090737, 'epsilon': 1.2140557855413502e-08, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.006216825051347647, 'tol': 3.447392421695076e-05, 'validation_fraction': 0.8930482527432676}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.755499 value 4011.558395 suggestion {'alpha': 1.5422609513678105e-05, 'batch_size': 80, 'beta_1': 0.7720791742983684, 'beta_2': 0.9999969143090737, 'epsilon': 1.2140557855413502e-08, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.006216825051347647, 'tol': 3.447392421695076e-05, 'validation_fraction': 0.8930482527432676}
observation time 0.001433, current best 4011.558395 at iter 0
suggestion time taken 0.001993 iter 1 next_points [{'alpha': 0.0019829362963602374, 'batch_size': 238, 'beta_1': 0.9406480518262516, 'beta_2': 0.9999182564523159, 'epsilon': 1.1458280062516013e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 3.9590584136947395e-05, 'tol': 0.0012080169657567692, 'validation_fraction': 0.17180836483476977}]
function_evaluation time 0.065659 value 29144.678087 suggestion {'alpha': 0.0019829362963602374, 'batch_size': 238, 'beta_1': 0.9406480518262516, 'beta_2': 0.9999182564523159, 'epsilon': 1.1458280062516013e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 3.9590584136947395e-05, 'tol': 0.0012080169657567692, 'validation_fraction': 0.17180836483476977}
observation time 0.001389, current best 4011.558395 at iter 1
suggestion time taken 0.001762 iter 2 next_points [{'alpha': 0.07169150014435335, 'batch_size': 186, 'beta_1': 0.9525613973473825, 'beta_2': 0.953274782384336, 'epsilon': 1.9430981129899938e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0008417971094198117, 'tol': 4.590644662763323e-05, 'validation_fraction': 0.6532132365461991}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.695168 value 28283.882531 suggestion {'alpha': 0.07169150014435335, 'batch_size': 186, 'beta_1': 0.9525613973473825, 'beta_2': 0.953274782384336, 'epsilon': 1.9430981129899938e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0008417971094198117, 'tol': 4.590644662763323e-05, 'validation_fraction': 0.6532132365461991}
observation time 0.001441, current best 4011.558395 at iter 2
suggestion time taken 0.001706 iter 3 next_points [{'alpha': 1.752421408494241, 'batch_size': 235, 'beta_1': 0.8766053183003469, 'beta_2': 0.9997945260228397, 'epsilon': 1.2914480278410034e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.09550136041606284, 'tol': 0.00037706503033812204, 'validation_fraction': 0.1830600692322481}]
function_evaluation time 0.247230 value 3589.829751 suggestion {'alpha': 1.752421408494241, 'batch_size': 235, 'beta_1': 0.8766053183003469, 'beta_2': 0.9997945260228397, 'epsilon': 1.2914480278410034e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.09550136041606284, 'tol': 0.00037706503033812204, 'validation_fraction': 0.1830600692322481}
observation time 0.001396, current best 3589.829751 at iter 3
suggestion time taken 0.001709 iter 4 next_points [{'alpha': 4.539923346416467, 'batch_size': 202, 'beta_1': 0.9173760621141425, 'beta_2': 0.9999731630328446, 'epsilon': 2.2229191992583326e-07, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.003833257706051217, 'tol': 0.0015822908998562874, 'validation_fraction': 0.34158805680223925}]
function_evaluation time 1.012875 value 8980.424618 suggestion {'alpha': 4.539923346416467, 'batch_size': 202, 'beta_1': 0.9173760621141425, 'beta_2': 0.9999731630328446, 'epsilon': 2.2229191992583326e-07, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.003833257706051217, 'tol': 0.0015822908998562874, 'validation_fraction': 0.34158805680223925}
observation time 0.001422, current best 3589.829751 at iter 4
suggestion time taken 0.001724 iter 5 next_points [{'alpha': 0.0009824082326697244, 'batch_size': 45, 'beta_1': 0.9812561980709669, 'beta_2': 0.9991993965226161, 'epsilon': 3.9831924070594646e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.02145547111429255, 'tol': 0.0520303981942081, 'validation_fraction': 0.7965612636905062}]
function_evaluation time 0.238591 value 4279.399353 suggestion {'alpha': 0.0009824082326697244, 'batch_size': 45, 'beta_1': 0.9812561980709669, 'beta_2': 0.9991993965226161, 'epsilon': 3.9831924070594646e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.02145547111429255, 'tol': 0.0520303981942081, 'validation_fraction': 0.7965612636905062}
observation time 0.001376, current best 3589.829751 at iter 5
suggestion time taken 0.001740 iter 6 next_points [{'alpha': 0.0001680888051285268, 'batch_size': 221, 'beta_1': 0.8201866465070403, 'beta_2': 0.9201146142829228, 'epsilon': 4.07262501192256e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0002655571354266036, 'tol': 0.0995261207726818, 'validation_fraction': 0.26356179627053655}]
function_evaluation time 0.052877 value 29102.697938 suggestion {'alpha': 0.0001680888051285268, 'batch_size': 221, 'beta_1': 0.8201866465070403, 'beta_2': 0.9201146142829228, 'epsilon': 4.07262501192256e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0002655571354266036, 'tol': 0.0995261207726818, 'validation_fraction': 0.26356179627053655}
observation time 0.001385, current best 3589.829751 at iter 6
suggestion time taken 0.001762 iter 7 next_points [{'alpha': 0.04565838855582281, 'batch_size': 69, 'beta_1': 0.72430439776151, 'beta_2': 0.9997429495882861, 'epsilon': 1.6176894815848052e-09, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.03609873714962713, 'tol': 1.5301575294267155e-05, 'validation_fraction': 0.4587672285243846}]
function_evaluation time 0.441047 value 2964.347495 suggestion {'alpha': 0.04565838855582281, 'batch_size': 69, 'beta_1': 0.72430439776151, 'beta_2': 0.9997429495882861, 'epsilon': 1.6176894815848052e-09, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.03609873714962713, 'tol': 1.5301575294267155e-05, 'validation_fraction': 0.4587672285243846}
observation time 0.001435, current best 2964.347495 at iter 7
suggestion time taken 0.001709 iter 8 next_points [{'alpha': 1.1160621755451767, 'batch_size': 189, 'beta_1': 0.9312827012026067, 'beta_2': 0.9999858924500545, 'epsilon': 2.4999617912818103e-09, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.0003884401881521052, 'tol': 7.618647350574811e-05, 'validation_fraction': 0.8525606534664207}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.677172 value 28686.243740 suggestion {'alpha': 1.1160621755451767, 'batch_size': 189, 'beta_1': 0.9312827012026067, 'beta_2': 0.9999858924500545, 'epsilon': 2.4999617912818103e-09, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.0003884401881521052, 'tol': 7.618647350574811e-05, 'validation_fraction': 0.8525606534664207}
observation time 0.001375, current best 2964.347495 at iter 8
suggestion time taken 0.001724 iter 9 next_points [{'alpha': 0.1926892980858829, 'batch_size': 136, 'beta_1': 0.9880765037590987, 'beta_2': 0.9964591601421019, 'epsilon': 2.469259250927173e-07, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.001509677903703845, 'tol': 0.0001908918344835034, 'validation_fraction': 0.5745221736317271}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.878529 value 26603.305133 suggestion {'alpha': 0.1926892980858829, 'batch_size': 136, 'beta_1': 0.9880765037590987, 'beta_2': 0.9964591601421019, 'epsilon': 2.469259250927173e-07, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.001509677903703845, 'tol': 0.0001908918344835034, 'validation_fraction': 0.5745221736317271}
observation time 0.001386, current best 2964.347495 at iter 9
suggestion time taken 0.001728 iter 10 next_points [{'alpha': 0.023793576119754245, 'batch_size': 155, 'beta_1': 0.9711383742889754, 'beta_2': 0.9999981977495869, 'epsilon': 6.3049060106765855e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 2.1147728333726618e-05, 'tol': 0.002762843425851144, 'validation_fraction': 0.24544252463246044}]
function_evaluation time 0.067201 value 29110.334591 suggestion {'alpha': 0.023793576119754245, 'batch_size': 155, 'beta_1': 0.9711383742889754, 'beta_2': 0.9999981977495869, 'epsilon': 6.3049060106765855e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 2.1147728333726618e-05, 'tol': 0.002762843425851144, 'validation_fraction': 0.24544252463246044}
observation time 0.001361, current best 2964.347495 at iter 10
suggestion time taken 0.001667 iter 11 next_points [{'alpha': 0.0007460956206220286, 'batch_size': 115, 'beta_1': 0.6046383354444832, 'beta_2': 0.9789920764096279, 'epsilon': 6.756401776641308e-08, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0005711739908039489, 'tol': 0.003459741771237783, 'validation_fraction': 0.7169911921154952}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.055087 value 29080.913952 suggestion {'alpha': 0.0007460956206220286, 'batch_size': 115, 'beta_1': 0.6046383354444832, 'beta_2': 0.9789920764096279, 'epsilon': 6.756401776641308e-08, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0005711739908039489, 'tol': 0.003459741771237783, 'validation_fraction': 0.7169911921154952}
observation time 0.001450, current best 2964.347495 at iter 11
suggestion time taken 0.001726 iter 12 next_points [{'alpha': 2.3882201075720645e-05, 'batch_size': 104, 'beta_1': 0.978233466791091, 'beta_2': 0.9999965878517231, 'epsilon': 6.551695886367744e-07, 'hidden_layer_sizes': 171, 'learning_rate_init': 5.68765891916658e-05, 'tol': 0.011710531979454755, 'validation_fraction': 0.11445987978955924}]
function_evaluation time 0.104474 value 29096.590684 suggestion {'alpha': 2.3882201075720645e-05, 'batch_size': 104, 'beta_1': 0.978233466791091, 'beta_2': 0.9999965878517231, 'epsilon': 6.551695886367744e-07, 'hidden_layer_sizes': 171, 'learning_rate_init': 5.68765891916658e-05, 'tol': 0.011710531979454755, 'validation_fraction': 0.11445987978955924}
observation time 0.001373, current best 2964.347495 at iter 12
suggestion time taken 0.001706 iter 13 next_points [{'alpha': 0.00956806368461261, 'batch_size': 92, 'beta_1': 0.7417762904056873, 'beta_2': 0.9999925827011388, 'epsilon': 2.9199665081513884e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.046277310240428714, 'tol': 0.0001369344047068108, 'validation_fraction': 0.4775600603454138}]
function_evaluation time 0.382900 value 2964.612527 suggestion {'alpha': 0.00956806368461261, 'batch_size': 92, 'beta_1': 0.7417762904056873, 'beta_2': 0.9999925827011388, 'epsilon': 2.9199665081513884e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.046277310240428714, 'tol': 0.0001369344047068108, 'validation_fraction': 0.4775600603454138}
observation time 0.001391, current best 2964.347495 at iter 13
suggestion time taken 0.001756 iter 14 next_points [{'alpha': 0.004361529407797842, 'batch_size': 50, 'beta_1': 0.6299233273114625, 'beta_2': 0.9973492824782519, 'epsilon': 1.3391871543241587e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0020953238759962856, 'tol': 0.007931579829595024, 'validation_fraction': 0.4135586851948865}]
function_evaluation time 0.192010 value 28783.236282 suggestion {'alpha': 0.004361529407797842, 'batch_size': 50, 'beta_1': 0.6299233273114625, 'beta_2': 0.9973492824782519, 'epsilon': 1.3391871543241587e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0020953238759962856, 'tol': 0.007931579829595024, 'validation_fraction': 0.4135586851948865}
observation time 0.001646, current best 2964.347495 at iter 14
saving meta data: {'args': {'--uuid': 'b813fa220e74539b9017379531ce2221', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

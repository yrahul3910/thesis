running: {'--uuid': '78a94ea1797351da80223187752cf82e', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d diabetes -o opentuner -u 78a94ea1797351da80223187752cf82e -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230425_055340
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study opentuner MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.057012 iter 0 next_points [{'hidden_layer_sizes': 123, 'alpha': 2.3421955351567894, 'batch_size': 149, 'learning_rate_init': 0.05185180580831233, 'tol': 0.0315478659443335, 'validation_fraction': 0.5630236999801107, 'beta_1': 0.919754030211172, 'beta_2': 0.9945431462899386, 'epsilon': 2.3389713557694824e-07}]
function_evaluation time 0.175869 value 4042.372285 suggestion {'hidden_layer_sizes': 123, 'alpha': 2.3421955351567894, 'batch_size': 149, 'learning_rate_init': 0.05185180580831233, 'tol': 0.0315478659443335, 'validation_fraction': 0.5630236999801107, 'beta_1': 0.919754030211172, 'beta_2': 0.9945431462899386, 'epsilon': 2.3389713557694824e-07}
observation time 0.004115, current best 4042.372285 at iter 0
suggestion time taken 0.007406 iter 1 next_points [{'hidden_layer_sizes': 128, 'alpha': 2.3421955351567894, 'batch_size': 149, 'learning_rate_init': 0.05185180580831233, 'tol': 0.0315478659443335, 'validation_fraction': 0.5630236999801107, 'beta_1': 0.919754030211172, 'beta_2': 0.9945431462899386, 'epsilon': 2.3389713557694824e-07}]
function_evaluation time 0.176165 value 4024.550307 suggestion {'hidden_layer_sizes': 128, 'alpha': 2.3421955351567894, 'batch_size': 149, 'learning_rate_init': 0.05185180580831233, 'tol': 0.0315478659443335, 'validation_fraction': 0.5630236999801107, 'beta_1': 0.919754030211172, 'beta_2': 0.9945431462899386, 'epsilon': 2.3389713557694824e-07}
observation time 0.001845, current best 4024.550307 at iter 1
suggestion time taken 0.007844 iter 2 next_points [{'hidden_layer_sizes': 125, 'alpha': 1.8000223962189081, 'batch_size': 149, 'learning_rate_init': 0.05185180580831233, 'tol': 0.0315478659443335, 'validation_fraction': 0.5630236999801107, 'beta_1': 0.8734641488876396, 'beta_2': 0.9945431462899386, 'epsilon': 2.3389713557694824e-07}]
function_evaluation time 0.171525 value 3921.865918 suggestion {'hidden_layer_sizes': 125, 'alpha': 1.8000223962189081, 'batch_size': 149, 'learning_rate_init': 0.05185180580831233, 'tol': 0.0315478659443335, 'validation_fraction': 0.5630236999801107, 'beta_1': 0.8734641488876396, 'beta_2': 0.9945431462899386, 'epsilon': 2.3389713557694824e-07}
observation time 0.002013, current best 3921.865918 at iter 2
suggestion time taken 0.021374 iter 3 next_points [{'beta_1': 0.828646968388056, 'validation_fraction': 0.28382830231627354, 'tol': 0.07011874942569289, 'beta_2': 0.9492264191819708, 'hidden_layer_sizes': 82, 'batch_size': 26, 'learning_rate_init': 0.013592931860928404, 'epsilon': 7.577242947814634e-07, 'alpha': 1.5348885848924754}]
function_evaluation time 0.203115 value 3592.471427 suggestion {'beta_1': 0.828646968388056, 'validation_fraction': 0.28382830231627354, 'tol': 0.07011874942569289, 'beta_2': 0.9492264191819708, 'hidden_layer_sizes': 82, 'batch_size': 26, 'learning_rate_init': 0.013592931860928404, 'epsilon': 7.577242947814634e-07, 'alpha': 1.5348885848924754}
observation time 0.001993, current best 3592.471427 at iter 3
suggestion time taken 0.006042 iter 4 next_points [{'beta_1': 0.6408763806565627, 'validation_fraction': 0.8550849492309435, 'tol': 0.06549127269348125, 'beta_2': 0.9374257905254249, 'hidden_layer_sizes': 63, 'batch_size': 165, 'learning_rate_init': 0.05129912770047589, 'epsilon': 7.602536969461459e-08, 'alpha': 3.677807972275693}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.136050 value 4255.655059 suggestion {'beta_1': 0.6408763806565627, 'validation_fraction': 0.8550849492309435, 'tol': 0.06549127269348125, 'beta_2': 0.9374257905254249, 'hidden_layer_sizes': 63, 'batch_size': 165, 'learning_rate_init': 0.05129912770047589, 'epsilon': 7.602536969461459e-08, 'alpha': 3.677807972275693}
observation time 0.001861, current best 3592.471427 at iter 4
suggestion time taken 0.006766 iter 5 next_points [{'beta_1': 0.828646968388056, 'validation_fraction': 0.31442912136785967, 'tol': 0.07011874942569289, 'beta_2': 0.9492264191819708, 'hidden_layer_sizes': 89, 'batch_size': 41, 'learning_rate_init': 0.013592931860928404, 'epsilon': 7.577242947814634e-07, 'alpha': 1.5348885848924754}]
function_evaluation time 0.211216 value 3794.812948 suggestion {'beta_1': 0.828646968388056, 'validation_fraction': 0.31442912136785967, 'tol': 0.07011874942569289, 'beta_2': 0.9492264191819708, 'hidden_layer_sizes': 89, 'batch_size': 41, 'learning_rate_init': 0.013592931860928404, 'epsilon': 7.577242947814634e-07, 'alpha': 1.5348885848924754}
observation time 0.002152, current best 3592.471427 at iter 5
suggestion time taken 0.005433 iter 6 next_points [{'hidden_layer_sizes': 108, 'alpha': 2.030890317838112, 'batch_size': 238, 'learning_rate_init': 0.07489712402838793, 'tol': 0.05734199301570036, 'validation_fraction': 0.7370562448157293, 'beta_1': 0.5935258243183053, 'beta_2': 0.9872224040502307, 'epsilon': 8.681625586487152e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.113346 value 3720.981891 suggestion {'hidden_layer_sizes': 108, 'alpha': 2.030890317838112, 'batch_size': 238, 'learning_rate_init': 0.07489712402838793, 'tol': 0.05734199301570036, 'validation_fraction': 0.7370562448157293, 'beta_1': 0.5935258243183053, 'beta_2': 0.9872224040502307, 'epsilon': 8.681625586487152e-07}
observation time 0.002115, current best 3592.471427 at iter 6
suggestion time taken 0.007290 iter 7 next_points [{'beta_1': 0.828646968388056, 'validation_fraction': 0.28382830231627354, 'tol': 0.07011874942569289, 'beta_2': 0.9492264191819708, 'hidden_layer_sizes': 82, 'batch_size': 26, 'learning_rate_init': 0.05926873579329988, 'epsilon': 1.7377642405666426e-07, 'alpha': 1.5348885848924754}]
function_evaluation time 0.121064 value 2915.986920 suggestion {'beta_1': 0.828646968388056, 'validation_fraction': 0.28382830231627354, 'tol': 0.07011874942569289, 'beta_2': 0.9492264191819708, 'hidden_layer_sizes': 82, 'batch_size': 26, 'learning_rate_init': 0.05926873579329988, 'epsilon': 1.7377642405666426e-07, 'alpha': 1.5348885848924754}
observation time 0.001813, current best 2915.986920 at iter 7
suggestion time taken 0.007033 iter 8 next_points [{'beta_1': 0.828646968388056, 'validation_fraction': 0.7484967183859158, 'tol': 0.07011874942569289, 'beta_2': 0.9492264191819708, 'hidden_layer_sizes': 82, 'batch_size': 26, 'learning_rate_init': 0.05926873579329988, 'epsilon': 2.580582824379386e-07, 'alpha': 1.5348885848924754}]
function_evaluation time 0.130391 value 3420.826136 suggestion {'beta_1': 0.828646968388056, 'validation_fraction': 0.7484967183859158, 'tol': 0.07011874942569289, 'beta_2': 0.9492264191819708, 'hidden_layer_sizes': 82, 'batch_size': 26, 'learning_rate_init': 0.05926873579329988, 'epsilon': 2.580582824379386e-07, 'alpha': 1.5348885848924754}
observation time 0.001891, current best 2915.986920 at iter 8
suggestion time taken 0.007035 iter 9 next_points [{'beta_1': 0.7193343258629167, 'validation_fraction': 0.28382830231627354, 'tol': 0.07011874942569289, 'beta_2': 0.9170158799185631, 'hidden_layer_sizes': 82, 'batch_size': 74, 'learning_rate_init': 0.05926873579329988, 'epsilon': 9.781322742047062e-07, 'alpha': 1.5348885848924754}]
function_evaluation time 0.090477 value 3272.417340 suggestion {'beta_1': 0.7193343258629167, 'validation_fraction': 0.28382830231627354, 'tol': 0.07011874942569289, 'beta_2': 0.9170158799185631, 'hidden_layer_sizes': 82, 'batch_size': 74, 'learning_rate_init': 0.05926873579329988, 'epsilon': 9.781322742047062e-07, 'alpha': 1.5348885848924754}
observation time 0.001853, current best 2915.986920 at iter 9
suggestion time taken 0.007612 iter 10 next_points [{'beta_1': 0.828646968388056, 'validation_fraction': 0.23842264384606326, 'tol': 0.07011874942569289, 'beta_2': 0.9492264191819708, 'hidden_layer_sizes': 82, 'batch_size': 21, 'learning_rate_init': 0.05926873579329988, 'epsilon': 1.4005802176417125e-07, 'alpha': 1.5348885848924754}]
function_evaluation time 0.150890 value 2930.700964 suggestion {'beta_1': 0.828646968388056, 'validation_fraction': 0.23842264384606326, 'tol': 0.07011874942569289, 'beta_2': 0.9492264191819708, 'hidden_layer_sizes': 82, 'batch_size': 21, 'learning_rate_init': 0.05926873579329988, 'epsilon': 1.4005802176417125e-07, 'alpha': 1.5348885848924754}
observation time 0.002735, current best 2915.986920 at iter 10
suggestion time taken 0.005058 iter 11 next_points [{'hidden_layer_sizes': 158, 'alpha': 5.645828251178234, 'batch_size': 100, 'learning_rate_init': 0.043935894723446216, 'tol': 0.003260455746303116, 'validation_fraction': 0.10866624748375751, 'beta_1': 0.9275309277148698, 'beta_2': 0.9066574266005614, 'epsilon': 3.8575269636961686e-07}]
function_evaluation time 0.353615 value 3027.292244 suggestion {'hidden_layer_sizes': 158, 'alpha': 5.645828251178234, 'batch_size': 100, 'learning_rate_init': 0.043935894723446216, 'tol': 0.003260455746303116, 'validation_fraction': 0.10866624748375751, 'beta_1': 0.9275309277148698, 'beta_2': 0.9066574266005614, 'epsilon': 3.8575269636961686e-07}
observation time 0.001859, current best 2915.986920 at iter 11
suggestion time taken 0.006014 iter 12 next_points [{'beta_1': 0.8957390454709311, 'validation_fraction': 0.3284803908319559, 'tol': 0.026853975209691173, 'beta_2': 0.9520327203119496, 'hidden_layer_sizes': 110, 'batch_size': 246, 'learning_rate_init': 0.08106565271356662, 'epsilon': 3.1888865428872273e-07, 'alpha': 6.510434126882673}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.169573 value 4034.535457 suggestion {'beta_1': 0.8957390454709311, 'validation_fraction': 0.3284803908319559, 'tol': 0.026853975209691173, 'beta_2': 0.9520327203119496, 'hidden_layer_sizes': 110, 'batch_size': 246, 'learning_rate_init': 0.08106565271356662, 'epsilon': 3.1888865428872273e-07, 'alpha': 6.510434126882673}
observation time 0.001913, current best 2915.986920 at iter 12
suggestion time taken 0.007122 iter 13 next_points [{'beta_1': 0.7630133845184116, 'validation_fraction': 0.28382830231627354, 'tol': 0.07972881987025075, 'beta_2': 0.9492264191819708, 'hidden_layer_sizes': 82, 'batch_size': 26, 'learning_rate_init': 0.05926873579329988, 'epsilon': 1.7377642405666426e-07, 'alpha': 1.5348885848924754}]
function_evaluation time 0.117753 value 2988.709264 suggestion {'beta_1': 0.7630133845184116, 'validation_fraction': 0.28382830231627354, 'tol': 0.07972881987025075, 'beta_2': 0.9492264191819708, 'hidden_layer_sizes': 82, 'batch_size': 26, 'learning_rate_init': 0.05926873579329988, 'epsilon': 1.7377642405666426e-07, 'alpha': 1.5348885848924754}
observation time 0.001839, current best 2915.986920 at iter 13
suggestion time taken 0.006757 iter 14 next_points [{'beta_1': 0.828646968388056, 'validation_fraction': 0.28382830231627354, 'tol': 0.07011874942569289, 'beta_2': 0.9478568058034078, 'hidden_layer_sizes': 199, 'batch_size': 26, 'learning_rate_init': 0.05926873579329988, 'epsilon': 1.7377642405666426e-07, 'alpha': 1.5348885848924754}]
function_evaluation time 0.211717 value 2922.419712 suggestion {'beta_1': 0.828646968388056, 'validation_fraction': 0.28382830231627354, 'tol': 0.07011874942569289, 'beta_2': 0.9478568058034078, 'hidden_layer_sizes': 199, 'batch_size': 26, 'learning_rate_init': 0.05926873579329988, 'epsilon': 1.7377642405666426e-07, 'alpha': 1.5348885848924754}
observation time 0.001917, current best 2915.986920 at iter 14
saving meta data: {'args': {'--uuid': '78a94ea1797351da80223187752cf82e', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230425_055340', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

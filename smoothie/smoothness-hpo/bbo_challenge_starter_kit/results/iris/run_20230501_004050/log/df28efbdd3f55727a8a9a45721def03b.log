running: {'--uuid': 'df28efbdd3f55727a8a9a45721def03b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230501_004050', '--opt': 'opentuner', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d iris -o opentuner -u df28efbdd3f55727a8a9a45721def03b -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230501_004050
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [1.3105719841770722, 1.7760947732249062, 1.4322107566090756, 0.9097804858215804, 0.5745987066718419])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_iris_nll betwen [1.31057198 1.56976556 1.25224472 0.90978049 0.39813052] and [1.32439241 1.77609477 1.43221076 0.9966468  0.57459871]
  warnings.warn(

Signature errors:
                         0         1         2         3         4       max
MLP-adam_iris_nll  0.01382  0.206329  0.179966  0.086866  0.176468  0.206329
max                0.01382  0.206329  0.179966  0.086866  0.176468  0.206329
starting sklearn study opentuner MLP-adam iris nll 15 1
with data root: None
suggestion time taken 0.018555 iter 0 next_points [{'hidden_layer_sizes': 86, 'alpha': 4.576386432454967, 'batch_size': 70, 'learning_rate_init': 0.06060714634600666, 'tol': 0.05759546562183376, 'validation_fraction': 0.14152720665451676, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 9.300965519159755e-07}]
function_evaluation time 0.091044 value 0.534927 suggestion {'hidden_layer_sizes': 86, 'alpha': 4.576386432454967, 'batch_size': 70, 'learning_rate_init': 0.06060714634600666, 'tol': 0.05759546562183376, 'validation_fraction': 0.14152720665451676, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 9.300965519159755e-07}
observation time 0.004378, current best 0.534927 at iter 0
suggestion time taken 0.022529 iter 1 next_points [{'tol': 0.022782273365502027, 'validation_fraction': 0.4713366165961207, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.043959290372402364, 'alpha': 1.0153391668068772, 'beta_1': 0.7500005993439625, 'batch_size': 49, 'epsilon': 4.841229374335777e-07, 'beta_2': 0.9929208607719116}]
function_evaluation time 0.067730 value 1.017797 suggestion {'tol': 0.022782273365502027, 'validation_fraction': 0.4713366165961207, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.043959290372402364, 'alpha': 1.0153391668068772, 'beta_1': 0.7500005993439625, 'batch_size': 49, 'epsilon': 4.841229374335777e-07, 'beta_2': 0.9929208607719116}
observation time 0.002052, current best 0.534927 at iter 1
suggestion time taken 0.007195 iter 2 next_points [{'hidden_layer_sizes': 81, 'alpha': 3.369683108195012, 'batch_size': 53, 'learning_rate_init': 0.06060714634600666, 'tol': 0.05759546562183376, 'validation_fraction': 0.1884201104433011, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 9.376470277161198e-07}]
function_evaluation time 0.084819 value 0.355048 suggestion {'hidden_layer_sizes': 81, 'alpha': 3.369683108195012, 'batch_size': 53, 'learning_rate_init': 0.06060714634600666, 'tol': 0.05759546562183376, 'validation_fraction': 0.1884201104433011, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 9.376470277161198e-07}
observation time 0.001877, current best 0.355048 at iter 2
suggestion time taken 0.047359 iter 3 next_points [{'batch_size': 81, 'epsilon': 1.923809450915238e-07, 'validation_fraction': 0.2660859378427066, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.02968812814528381, 'beta_2': 0.9373991854674288, 'tol': 0.027424030653249987, 'beta_1': 0.5189405585358645, 'alpha': 0.6369139029597591}]
function_evaluation time 0.080293 value 0.392427 suggestion {'batch_size': 81, 'epsilon': 1.923809450915238e-07, 'validation_fraction': 0.2660859378427066, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.02968812814528381, 'beta_2': 0.9373991854674288, 'tol': 0.027424030653249987, 'beta_1': 0.5189405585358645, 'alpha': 0.6369139029597591}
observation time 0.001998, current best 0.355048 at iter 3
suggestion time taken 0.007068 iter 4 next_points [{'hidden_layer_sizes': 173, 'alpha': 3.369683108195012, 'batch_size': 169, 'learning_rate_init': 0.06060714634600666, 'tol': 0.05759546562183376, 'validation_fraction': 0.1884201104433011, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 8.344829402212307e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.073548 value 0.482392 suggestion {'hidden_layer_sizes': 173, 'alpha': 3.369683108195012, 'batch_size': 169, 'learning_rate_init': 0.06060714634600666, 'tol': 0.05759546562183376, 'validation_fraction': 0.1884201104433011, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 8.344829402212307e-07}
observation time 0.001923, current best 0.355048 at iter 4
suggestion time taken 0.007113 iter 5 next_points [{'hidden_layer_sizes': 92, 'alpha': 3.108649976078628, 'batch_size': 53, 'learning_rate_init': 0.05326778755944111, 'tol': 0.05759546562183376, 'validation_fraction': 0.1884201104433011, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 9.376470277161198e-07}]
function_evaluation time 0.073736 value 0.380217 suggestion {'hidden_layer_sizes': 92, 'alpha': 3.108649976078628, 'batch_size': 53, 'learning_rate_init': 0.05326778755944111, 'tol': 0.05759546562183376, 'validation_fraction': 0.1884201104433011, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 9.376470277161198e-07}
observation time 0.002244, current best 0.355048 at iter 5
suggestion time taken 0.007050 iter 6 next_points [{'hidden_layer_sizes': 81, 'alpha': 3.369683108195012, 'batch_size': 53, 'learning_rate_init': 0.06060714634600666, 'tol': 0.05759546562183376, 'validation_fraction': 0.4552216909086886, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 9.376470277161198e-07}]
function_evaluation time 0.077883 value 0.398501 suggestion {'hidden_layer_sizes': 81, 'alpha': 3.369683108195012, 'batch_size': 53, 'learning_rate_init': 0.06060714634600666, 'tol': 0.05759546562183376, 'validation_fraction': 0.4552216909086886, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 9.376470277161198e-07}
observation time 0.001881, current best 0.355048 at iter 6
suggestion time taken 0.007108 iter 7 next_points [{'hidden_layer_sizes': 64, 'alpha': 3.369683108195012, 'batch_size': 59, 'learning_rate_init': 0.053828554616490214, 'tol': 0.05759546562183376, 'validation_fraction': 0.24100292590881872, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 9.376470277161198e-07}]
function_evaluation time 0.072408 value 0.482628 suggestion {'hidden_layer_sizes': 64, 'alpha': 3.369683108195012, 'batch_size': 59, 'learning_rate_init': 0.053828554616490214, 'tol': 0.05759546562183376, 'validation_fraction': 0.24100292590881872, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 9.376470277161198e-07}
observation time 0.002058, current best 0.355048 at iter 7
suggestion time taken 0.007010 iter 8 next_points [{'hidden_layer_sizes': 81, 'alpha': 3.369683108195012, 'batch_size': 53, 'learning_rate_init': 0.05518564107374518, 'tol': 0.05759546562183376, 'validation_fraction': 0.1884201104433011, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 9.376470277161198e-07}]
function_evaluation time 0.077206 value 0.358465 suggestion {'hidden_layer_sizes': 81, 'alpha': 3.369683108195012, 'batch_size': 53, 'learning_rate_init': 0.05518564107374518, 'tol': 0.05759546562183376, 'validation_fraction': 0.1884201104433011, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 9.376470277161198e-07}
observation time 0.001846, current best 0.355048 at iter 8
suggestion time taken 0.006752 iter 9 next_points [{'hidden_layer_sizes': 80, 'alpha': 3.369683108195012, 'batch_size': 53, 'learning_rate_init': 0.06060714634600666, 'tol': 0.05759546562183376, 'validation_fraction': 0.1884201104433011, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 9.376470277161198e-07}]
function_evaluation time 0.079954 value 0.405680 suggestion {'hidden_layer_sizes': 80, 'alpha': 3.369683108195012, 'batch_size': 53, 'learning_rate_init': 0.06060714634600666, 'tol': 0.05759546562183376, 'validation_fraction': 0.1884201104433011, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 9.376470277161198e-07}
observation time 0.003017, current best 0.355048 at iter 9
suggestion time taken 0.007295 iter 10 next_points [{'hidden_layer_sizes': 84, 'alpha': 3.369683108195012, 'batch_size': 53, 'learning_rate_init': 0.05207116052861321, 'tol': 0.06720902965055202, 'validation_fraction': 0.149353919233116, 'beta_1': 0.9743329519308797, 'beta_2': 0.9409097610757153, 'epsilon': 9.376470277161198e-07}]
function_evaluation time 0.078604 value 0.444692 suggestion {'hidden_layer_sizes': 84, 'alpha': 3.369683108195012, 'batch_size': 53, 'learning_rate_init': 0.05207116052861321, 'tol': 0.06720902965055202, 'validation_fraction': 0.149353919233116, 'beta_1': 0.9743329519308797, 'beta_2': 0.9409097610757153, 'epsilon': 9.376470277161198e-07}
observation time 0.001860, current best 0.355048 at iter 10
suggestion time taken 0.007101 iter 11 next_points [{'hidden_layer_sizes': 94, 'alpha': 3.369683108195012, 'batch_size': 23, 'learning_rate_init': 0.06060714634600666, 'tol': 0.05759546562183376, 'validation_fraction': 0.1884201104433011, 'beta_1': 0.9165066951466485, 'beta_2': 0.9414632137888371, 'epsilon': 8.482359296352039e-07}]
function_evaluation time 0.103383 value 0.524909 suggestion {'hidden_layer_sizes': 94, 'alpha': 3.369683108195012, 'batch_size': 23, 'learning_rate_init': 0.06060714634600666, 'tol': 0.05759546562183376, 'validation_fraction': 0.1884201104433011, 'beta_1': 0.9165066951466485, 'beta_2': 0.9414632137888371, 'epsilon': 8.482359296352039e-07}
observation time 0.002065, current best 0.355048 at iter 11
suggestion time taken 0.006033 iter 12 next_points [{'tol': 0.08719090023149582, 'validation_fraction': 0.40765342006228644, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.0533932364113811, 'alpha': 6.806474118378805, 'beta_1': 0.5908461923287458, 'batch_size': 76, 'epsilon': 3.240373766260897e-07, 'beta_2': 0.9910208914803245}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.069261 value 0.458423 suggestion {'tol': 0.08719090023149582, 'validation_fraction': 0.40765342006228644, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.0533932364113811, 'alpha': 6.806474118378805, 'beta_1': 0.5908461923287458, 'batch_size': 76, 'epsilon': 3.240373766260897e-07, 'beta_2': 0.9910208914803245}
observation time 0.001900, current best 0.355048 at iter 12
suggestion time taken 0.005155 iter 13 next_points [{'batch_size': 193, 'epsilon': 7.11513695656445e-07, 'validation_fraction': 0.6659283486916423, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.03971995280988321, 'beta_2': 0.9022388873250893, 'tol': 0.08724264161597166, 'beta_1': 0.6439118504632255, 'alpha': 2.0976861592269764}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.069913 value 0.374722 suggestion {'batch_size': 193, 'epsilon': 7.11513695656445e-07, 'validation_fraction': 0.6659283486916423, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.03971995280988321, 'beta_2': 0.9022388873250893, 'tol': 0.08724264161597166, 'beta_1': 0.6439118504632255, 'alpha': 2.0976861592269764}
observation time 0.001894, current best 0.355048 at iter 13
suggestion time taken 0.007242 iter 14 next_points [{'hidden_layer_sizes': 81, 'alpha': 3.369683108195012, 'batch_size': 53, 'learning_rate_init': 0.06060714634600666, 'tol': 0.05759546562183376, 'validation_fraction': 0.1884201104433011, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 7.510848908659208e-07}]
function_evaluation time 0.071070 value 0.419899 suggestion {'hidden_layer_sizes': 81, 'alpha': 3.369683108195012, 'batch_size': 53, 'learning_rate_init': 0.06060714634600666, 'tol': 0.05759546562183376, 'validation_fraction': 0.1884201104433011, 'beta_1': 0.9743329519308797, 'beta_2': 0.9414632137888371, 'epsilon': 7.510848908659208e-07}
observation time 0.001876, current best 0.355048 at iter 14
saving meta data: {'args': {'--uuid': 'df28efbdd3f55727a8a9a45721def03b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230501_004050', '--opt': 'opentuner', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [1.3105719841770722, 1.7760947732249062, 1.4322107566090756, 0.9097804858215804, 0.5745987066718419])}
saving results
saving timing
saving suggest log
done

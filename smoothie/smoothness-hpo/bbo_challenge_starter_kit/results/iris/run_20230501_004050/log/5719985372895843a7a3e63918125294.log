running: {'--uuid': '5719985372895843a7a3e63918125294', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230501_004050', '--opt': 'smoothness', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d iris -o smoothness -u 5719985372895843a7a3e63918125294 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230501_004050
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [1.3105719841770722, 1.7760947732249062, 1.4322107566090756, 0.9097804858215804, 0.5745987066718419])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_iris_nll betwen [1.31057198 1.56976556 1.25224472 0.90978049 0.39813052] and [1.32439241 1.77609477 1.43221076 0.9966468  0.57459871]
  warnings.warn(

Signature errors:
                         0         1         2         3         4       max
MLP-adam_iris_nll  0.01382  0.206329  0.179966  0.086866  0.176468  0.206329
max                0.01382  0.206329  0.179966  0.086866  0.176468  0.206329
starting sklearn study smoothness MLP-adam iris nll 15 1
with data root: None
suggestion time taken 9.518947 iter 0 next_points [{'alpha': 0.19969601605494097, 'batch_size': 26, 'beta_1': 0.8116329192972639, 'beta_2': 0.9779757229252292, 'epsilon': 3.885090380813774e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0001744041755122983, 'tol': 8.4120481271845e-05, 'validation_fraction': 0.8653428583815664}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.048512 value 1.491079 suggestion {'alpha': 0.19969601605494097, 'batch_size': 26, 'beta_1': 0.8116329192972639, 'beta_2': 0.9779757229252292, 'epsilon': 3.885090380813774e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0001744041755122983, 'tol': 8.4120481271845e-05, 'validation_fraction': 0.8653428583815664}
observation time 0.000006, current best 1.491079 at iter 0
suggestion time taken 9.449377 iter 1 next_points [{'alpha': 0.19802818229502606, 'batch_size': 19, 'beta_1': 0.9809395261108015, 'beta_2': 0.9999857529742225, 'epsilon': 4.2908440653899933e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.020691102191869756, 'tol': 0.00019652821558042367, 'validation_fraction': 0.45645633531280483}]
function_evaluation time 0.113445 value 0.278957 suggestion {'alpha': 0.19802818229502606, 'batch_size': 19, 'beta_1': 0.9809395261108015, 'beta_2': 0.9999857529742225, 'epsilon': 4.2908440653899933e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.020691102191869756, 'tol': 0.00019652821558042367, 'validation_fraction': 0.45645633531280483}
observation time 0.000006, current best 0.278957 at iter 1
suggestion time taken 9.425416 iter 2 next_points [{'alpha': 0.00902403304893174, 'batch_size': 19, 'beta_1': 0.5009447937179217, 'beta_2': 0.9800336311918917, 'epsilon': 4.829307106368561e-07, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.0003396544695763897, 'tol': 0.0005171348189861981, 'validation_fraction': 0.8663535500870357}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.064189 value 1.213084 suggestion {'alpha': 0.00902403304893174, 'batch_size': 19, 'beta_1': 0.5009447937179217, 'beta_2': 0.9800336311918917, 'epsilon': 4.829307106368561e-07, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.0003396544695763897, 'tol': 0.0005171348189861981, 'validation_fraction': 0.8663535500870357}
observation time 0.000006, current best 0.278957 at iter 2
suggestion time taken 9.691977 iter 3 next_points [{'alpha': 1.0459237531308332, 'batch_size': 30, 'beta_1': 0.7679276978860854, 'beta_2': 0.9999727956848652, 'epsilon': 5.976135470536075e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.00031804554647205997, 'tol': 0.0004494765070349204, 'validation_fraction': 0.1040702925944575}]
function_evaluation time 0.083768 value 1.359059 suggestion {'alpha': 1.0459237531308332, 'batch_size': 30, 'beta_1': 0.7679276978860854, 'beta_2': 0.9999727956848652, 'epsilon': 5.976135470536075e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.00031804554647205997, 'tol': 0.0004494765070349204, 'validation_fraction': 0.1040702925944575}
observation time 0.000006, current best 0.278957 at iter 3
suggestion time taken 9.402746 iter 4 next_points [{'alpha': 0.5246888235202015, 'batch_size': 17, 'beta_1': 0.8965567802219687, 'beta_2': 0.9829376193297564, 'epsilon': 1.0274418864539727e-07, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.0007132782520835209, 'tol': 8.557581475247913e-05, 'validation_fraction': 0.26979683447849545}]
function_evaluation time 0.169122 value 0.769067 suggestion {'alpha': 0.5246888235202015, 'batch_size': 17, 'beta_1': 0.8965567802219687, 'beta_2': 0.9829376193297564, 'epsilon': 1.0274418864539727e-07, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.0007132782520835209, 'tol': 8.557581475247913e-05, 'validation_fraction': 0.26979683447849545}
observation time 0.000007, current best 0.278957 at iter 4
suggestion time taken 9.390368 iter 5 next_points [{'alpha': 0.6418627640587994, 'batch_size': 20, 'beta_1': 0.7022224774259544, 'beta_2': 0.9953536559885706, 'epsilon': 5.008035827529024e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.00011895083943869072, 'tol': 0.0002953585382772185, 'validation_fraction': 0.1512677773807772}]
function_evaluation time 0.107297 value 1.312318 suggestion {'alpha': 0.6418627640587994, 'batch_size': 20, 'beta_1': 0.7022224774259544, 'beta_2': 0.9953536559885706, 'epsilon': 5.008035827529024e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.00011895083943869072, 'tol': 0.0002953585382772185, 'validation_fraction': 0.1512677773807772}
observation time 0.000006, current best 0.278957 at iter 5
suggestion time taken 9.402416 iter 6 next_points [{'alpha': 0.016992236027026753, 'batch_size': 14, 'beta_1': 0.9544738881541682, 'beta_2': 0.9998056102824172, 'epsilon': 1.2595447172936113e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0020353955254091417, 'tol': 0.0005604694741508491, 'validation_fraction': 0.853882695677721}]
function_evaluation time 0.073879 value 0.949102 suggestion {'alpha': 0.016992236027026753, 'batch_size': 14, 'beta_1': 0.9544738881541682, 'beta_2': 0.9998056102824172, 'epsilon': 1.2595447172936113e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0020353955254091417, 'tol': 0.0005604694741508491, 'validation_fraction': 0.853882695677721}
observation time 0.000006, current best 0.278957 at iter 6
suggestion time taken 9.378890 iter 7 next_points [{'alpha': 0.0015766613951728463, 'batch_size': 28, 'beta_1': 0.864879448576884, 'beta_2': 0.9992313192274344, 'epsilon': 2.0106224406544355e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.00023321985322266112, 'tol': 0.0005706259259324624, 'validation_fraction': 0.2872312106701848}]
function_evaluation time 0.095146 value 1.383550 suggestion {'alpha': 0.0015766613951728463, 'batch_size': 28, 'beta_1': 0.864879448576884, 'beta_2': 0.9992313192274344, 'epsilon': 2.0106224406544355e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.00023321985322266112, 'tol': 0.0005706259259324624, 'validation_fraction': 0.2872312106701848}
observation time 0.000006, current best 0.278957 at iter 7
suggestion time taken 9.348526 iter 8 next_points [{'alpha': 1.1886842283912127, 'batch_size': 10, 'beta_1': 0.9195596760806156, 'beta_2': 0.9989350464454705, 'epsilon': 9.466406558959835e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 1.2493329695671396e-05, 'tol': 1.1408475357704674e-05, 'validation_fraction': 0.7596843767900646}]
function_evaluation time 0.060699 value 1.673939 suggestion {'alpha': 1.1886842283912127, 'batch_size': 10, 'beta_1': 0.9195596760806156, 'beta_2': 0.9989350464454705, 'epsilon': 9.466406558959835e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 1.2493329695671396e-05, 'tol': 1.1408475357704674e-05, 'validation_fraction': 0.7596843767900646}
observation time 0.000006, current best 0.278957 at iter 8
suggestion time taken 9.380639 iter 9 next_points [{'alpha': 0.08012611060887674, 'batch_size': 34, 'beta_1': 0.9777777484277366, 'beta_2': 0.9999459091740182, 'epsilon': 1.1367380267339467e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0013071593172395615, 'tol': 2.2477274725991436e-05, 'validation_fraction': 0.29218942381947227}]
function_evaluation time 0.094142 value 0.858264 suggestion {'alpha': 0.08012611060887674, 'batch_size': 34, 'beta_1': 0.9777777484277366, 'beta_2': 0.9999459091740182, 'epsilon': 1.1367380267339467e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0013071593172395615, 'tol': 2.2477274725991436e-05, 'validation_fraction': 0.29218942381947227}
observation time 0.000006, current best 0.278957 at iter 9
suggestion time taken 9.365873 iter 10 next_points [{'alpha': 3.4242775696832615, 'batch_size': 13, 'beta_1': 0.8902304449080951, 'beta_2': 0.9997552172138504, 'epsilon': 5.27152843423776e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.00010754937832670256, 'tol': 1.1222883207497311e-05, 'validation_fraction': 0.8622336815443915}]
function_evaluation time 0.043022 value 1.571479 suggestion {'alpha': 3.4242775696832615, 'batch_size': 13, 'beta_1': 0.8902304449080951, 'beta_2': 0.9997552172138504, 'epsilon': 5.27152843423776e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.00010754937832670256, 'tol': 1.1222883207497311e-05, 'validation_fraction': 0.8622336815443915}
observation time 0.000007, current best 0.278957 at iter 10
suggestion time taken 9.395474 iter 11 next_points [{'alpha': 0.33389316406487635, 'batch_size': 36, 'beta_1': 0.9190920376202287, 'beta_2': 0.9992656706879606, 'epsilon': 4.4012023825809345e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0017925237871678277, 'tol': 0.012411373782311674, 'validation_fraction': 0.7230854590150348}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.077315 value 1.058597 suggestion {'alpha': 0.33389316406487635, 'batch_size': 36, 'beta_1': 0.9190920376202287, 'beta_2': 0.9992656706879606, 'epsilon': 4.4012023825809345e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0017925237871678277, 'tol': 0.012411373782311674, 'validation_fraction': 0.7230854590150348}
observation time 0.000006, current best 0.278957 at iter 11
suggestion time taken 9.431684 iter 12 next_points [{'alpha': 0.0049646083174693855, 'batch_size': 16, 'beta_1': 0.7680711260085118, 'beta_2': 0.9226932158813096, 'epsilon': 3.5270393986196346e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.031531359514552465, 'tol': 6.168341601734529e-05, 'validation_fraction': 0.5068371125018726}]
function_evaluation time 0.100398 value 0.282990 suggestion {'alpha': 0.0049646083174693855, 'batch_size': 16, 'beta_1': 0.7680711260085118, 'beta_2': 0.9226932158813096, 'epsilon': 3.5270393986196346e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.031531359514552465, 'tol': 6.168341601734529e-05, 'validation_fraction': 0.5068371125018726}
observation time 0.000006, current best 0.278957 at iter 12
suggestion time taken 9.453716 iter 13 next_points [{'alpha': 0.42021868856520106, 'batch_size': 15, 'beta_1': 0.9457175676688516, 'beta_2': 0.9998612383007917, 'epsilon': 3.2856003847726506e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.06255142328509267, 'tol': 0.0001024441130904416, 'validation_fraction': 0.6509882538643633}]
function_evaluation time 0.103695 value 0.338682 suggestion {'alpha': 0.42021868856520106, 'batch_size': 15, 'beta_1': 0.9457175676688516, 'beta_2': 0.9998612383007917, 'epsilon': 3.2856003847726506e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.06255142328509267, 'tol': 0.0001024441130904416, 'validation_fraction': 0.6509882538643633}
observation time 0.000005, current best 0.278957 at iter 13
suggestion time taken 9.405576 iter 14 next_points [{'alpha': 6.86781917086515e-05, 'batch_size': 38, 'beta_1': 0.6026301451352334, 'beta_2': 0.9999633169137829, 'epsilon': 9.617540183824562e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0005860297932571674, 'tol': 0.0013041421504422076, 'validation_fraction': 0.885833745965886}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.046967 value 1.230542 suggestion {'alpha': 6.86781917086515e-05, 'batch_size': 38, 'beta_1': 0.6026301451352334, 'beta_2': 0.9999633169137829, 'epsilon': 9.617540183824562e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0005860297932571674, 'tol': 0.0013041421504422076, 'validation_fraction': 0.885833745965886}
observation time 0.000006, current best 0.278957 at iter 14
saving meta data: {'args': {'--uuid': '5719985372895843a7a3e63918125294', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230501_004050', '--opt': 'smoothness', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [1.3105719841770722, 1.7760947732249062, 1.4322107566090756, 0.9097804858215804, 0.5745987066718419])}
saving results
saving timing
saving suggest log
done

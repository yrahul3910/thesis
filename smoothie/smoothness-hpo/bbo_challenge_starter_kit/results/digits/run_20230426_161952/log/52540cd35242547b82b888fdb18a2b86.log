running: {'--uuid': '52540cd35242547b82b888fdb18a2b86', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_161952', '--opt': 'turbo', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d wine -o turbo -u 52540cd35242547b82b888fdb18a2b86 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_161952
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])
Signature errors:
                     0    1    2    3    4  max
MLP-adam_wine_acc  0.0  0.0  0.0  0.0  0.0  0.0
max                0.0  0.0  0.0  0.0  0.0  0.0
starting sklearn study turbo MLP-adam wine acc 15 1
with data root: None
suggestion time taken 0.002202 iter 0 next_points [{'alpha': 0.001977281077054064, 'batch_size': 50, 'beta_1': 0.9854730894837538, 'beta_2': 0.9265671066026108, 'epsilon': 5.49674906027565e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 3.2212197484687846e-05, 'tol': 0.003664565442314734, 'validation_fraction': 0.8731570715426155}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.070973 value -0.444089 suggestion {'alpha': 0.001977281077054064, 'batch_size': 50, 'beta_1': 0.9854730894837538, 'beta_2': 0.9265671066026108, 'epsilon': 5.49674906027565e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 3.2212197484687846e-05, 'tol': 0.003664565442314734, 'validation_fraction': 0.8731570715426155}
observation time 0.001452, current best -0.444089 at iter 0
suggestion time taken 0.001780 iter 1 next_points [{'alpha': 0.00355891128442945, 'batch_size': 63, 'beta_1': 0.701420557357691, 'beta_2': 0.9999686921324569, 'epsilon': 4.197478434268913e-09, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.002997090045519894, 'tol': 0.04701321875236402, 'validation_fraction': 0.8914714768166483}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.094952 value -0.678571 suggestion {'alpha': 0.00355891128442945, 'batch_size': 63, 'beta_1': 0.701420557357691, 'beta_2': 0.9999686921324569, 'epsilon': 4.197478434268913e-09, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.002997090045519894, 'tol': 0.04701321875236402, 'validation_fraction': 0.8914714768166483}
observation time 0.001489, current best -0.678571 at iter 1
suggestion time taken 0.001739 iter 2 next_points [{'alpha': 9.588053700161139e-05, 'batch_size': 231, 'beta_1': 0.6612737828738859, 'beta_2': 0.9997462610096328, 'epsilon': 4.355758399175555e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.00742215423084746, 'tol': 0.00228067438754091, 'validation_fraction': 0.24365808290615645}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.079385 value -0.640148 suggestion {'alpha': 9.588053700161139e-05, 'batch_size': 231, 'beta_1': 0.6612737828738859, 'beta_2': 0.9997462610096328, 'epsilon': 4.355758399175555e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.00742215423084746, 'tol': 0.00228067438754091, 'validation_fraction': 0.24365808290615645}
observation time 0.001510, current best -0.678571 at iter 2
suggestion time taken 0.001923 iter 3 next_points [{'alpha': 1.321182803995298, 'batch_size': 74, 'beta_1': 0.7868425307203692, 'beta_2': 0.9999936261820069, 'epsilon': 1.102673516498146e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.0010124734050843526, 'tol': 0.025151904578495962, 'validation_fraction': 0.10785015687743041}]
function_evaluation time 0.079100 value -0.457635 suggestion {'alpha': 1.321182803995298, 'batch_size': 74, 'beta_1': 0.7868425307203692, 'beta_2': 0.9999936261820069, 'epsilon': 1.102673516498146e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.0010124734050843526, 'tol': 0.025151904578495962, 'validation_fraction': 0.10785015687743041}
observation time 0.001347, current best -0.678571 at iter 3
suggestion time taken 0.002076 iter 4 next_points [{'alpha': 3.588745074688778, 'batch_size': 46, 'beta_1': 0.9170043646594964, 'beta_2': 0.9936032365988573, 'epsilon': 6.069259097295695e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.00020159364283945725, 'tol': 0.0001906059812691727, 'validation_fraction': 0.4078404826537438}]
function_evaluation time 0.061669 value -0.407635 suggestion {'alpha': 3.588745074688778, 'batch_size': 46, 'beta_1': 0.9170043646594964, 'beta_2': 0.9936032365988573, 'epsilon': 6.069259097295695e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.00020159364283945725, 'tol': 0.0001906059812691727, 'validation_fraction': 0.4078404826537438}
observation time 0.001377, current best -0.678571 at iter 4
suggestion time taken 0.001735 iter 5 next_points [{'alpha': 0.0011976771241097104, 'batch_size': 183, 'beta_1': 0.8301684618181076, 'beta_2': 0.9999981806590261, 'epsilon': 5.2602105942119166e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 6.659724951268882e-05, 'tol': 0.07994623320817244, 'validation_fraction': 0.13279646913647944}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.046280 value -0.380788 suggestion {'alpha': 0.0011976771241097104, 'batch_size': 183, 'beta_1': 0.8301684618181076, 'beta_2': 0.9999981806590261, 'epsilon': 5.2602105942119166e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 6.659724951268882e-05, 'tol': 0.07994623320817244, 'validation_fraction': 0.13279646913647944}
observation time 0.001427, current best -0.678571 at iter 5
suggestion time taken 0.001763 iter 6 next_points [{'alpha': 0.0005851693553239371, 'batch_size': 132, 'beta_1': 0.60204983592484, 'beta_2': 0.9994906756750844, 'epsilon': 1.4418239373120973e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.03513758419217865, 'tol': 1.3027386431924941e-05, 'validation_fraction': 0.308465003561088}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.128205 value -0.746305 suggestion {'alpha': 0.0005851693553239371, 'batch_size': 132, 'beta_1': 0.60204983592484, 'beta_2': 0.9994906756750844, 'epsilon': 1.4418239373120973e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.03513758419217865, 'tol': 1.3027386431924941e-05, 'validation_fraction': 0.308465003561088}
observation time 0.001388, current best -0.746305 at iter 6
suggestion time taken 0.001784 iter 7 next_points [{'alpha': 0.04700582757911764, 'batch_size': 17, 'beta_1': 0.8831096877916855, 'beta_2': 0.9592285613249028, 'epsilon': 7.034050464752995e-09, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.04060265074085072, 'tol': 0.0008377096523771969, 'validation_fraction': 0.19597743238265064}]
function_evaluation time 0.152495 value -0.789901 suggestion {'alpha': 0.04700582757911764, 'batch_size': 17, 'beta_1': 0.8831096877916855, 'beta_2': 0.9592285613249028, 'epsilon': 7.034050464752995e-09, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.04060265074085072, 'tol': 0.0008377096523771969, 'validation_fraction': 0.19597743238265064}
observation time 0.001441, current best -0.789901 at iter 7
suggestion time taken 0.001702 iter 8 next_points [{'alpha': 0.07013896784541944, 'batch_size': 94, 'beta_1': 0.9779963147447045, 'beta_2': 0.9997587803179184, 'epsilon': 2.6868562910927968e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.00012904388090327176, 'tol': 0.00011693692096297168, 'validation_fraction': 0.43691419389684727}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.073156 value -0.436207 suggestion {'alpha': 0.07013896784541944, 'batch_size': 94, 'beta_1': 0.9779963147447045, 'beta_2': 0.9997587803179184, 'epsilon': 2.6868562910927968e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.00012904388090327176, 'tol': 0.00011693692096297168, 'validation_fraction': 0.43691419389684727}
observation time 0.001397, current best -0.789901 at iter 8
suggestion time taken 0.001716 iter 9 next_points [{'alpha': 0.9122892735178267, 'batch_size': 242, 'beta_1': 0.972981199212056, 'beta_2': 0.9999477057631537, 'epsilon': 2.304881949613615e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.009835436520186955, 'tol': 0.011647835320108008, 'validation_fraction': 0.8101362191982647}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.081429 value -0.647783 suggestion {'alpha': 0.9122892735178267, 'batch_size': 242, 'beta_1': 0.972981199212056, 'beta_2': 0.9999477057631537, 'epsilon': 2.304881949613615e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.009835436520186955, 'tol': 0.011647835320108008, 'validation_fraction': 0.8101362191982647}
observation time 0.001405, current best -0.789901 at iter 9
suggestion time taken 0.001720 iter 10 next_points [{'alpha': 0.022190183047579914, 'batch_size': 147, 'beta_1': 0.9890051374641657, 'beta_2': 0.9999871002296659, 'epsilon': 7.564118160035665e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 1.3443226701394214e-05, 'tol': 0.0007446502722622688, 'validation_fraction': 0.6297308995054143}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.062416 value -0.346552 suggestion {'alpha': 0.022190183047579914, 'batch_size': 147, 'beta_1': 0.9890051374641657, 'beta_2': 0.9999871002296659, 'epsilon': 7.564118160035665e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 1.3443226701394214e-05, 'tol': 0.0007446502722622688, 'validation_fraction': 0.6297308995054143}
observation time 0.001350, current best -0.789901 at iter 10
suggestion time taken 0.001750 iter 11 next_points [{'alpha': 1.4116784886510528e-05, 'batch_size': 160, 'beta_1': 0.846957623204225, 'beta_2': 0.9999068307182288, 'epsilon': 1.0846156512785259e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.0019047795137766303, 'tol': 2.2107856289581647e-05, 'validation_fraction': 0.7514468572196186}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.128595 value -0.563300 suggestion {'alpha': 1.4116784886510528e-05, 'batch_size': 160, 'beta_1': 0.846957623204225, 'beta_2': 0.9999068307182288, 'epsilon': 1.0846156512785259e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.0019047795137766303, 'tol': 2.2107856289581647e-05, 'validation_fraction': 0.7514468572196186}
observation time 0.001360, current best -0.789901 at iter 11
suggestion time taken 0.001755 iter 12 next_points [{'alpha': 5.3909586470445065e-05, 'batch_size': 122, 'beta_1': 0.5272922704438531, 'beta_2': 0.9974944200591565, 'epsilon': 2.560722339178701e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0893589068303103, 'tol': 2.700738361785418e-05, 'validation_fraction': 0.1734576547232223}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.070968 value -0.521182 suggestion {'alpha': 5.3909586470445065e-05, 'batch_size': 122, 'beta_1': 0.5272922704438531, 'beta_2': 0.9974944200591565, 'epsilon': 2.560722339178701e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0893589068303103, 'tol': 2.700738361785418e-05, 'validation_fraction': 0.1734576547232223}
observation time 0.001376, current best -0.789901 at iter 12
suggestion time taken 0.001755 iter 13 next_points [{'alpha': 0.18774673712901657, 'batch_size': 200, 'beta_1': 0.9645262930331471, 'beta_2': 0.9810181303384135, 'epsilon': 7.309399582755499e-08, 'hidden_layer_sizes': 144, 'learning_rate_init': 2.5133189673105087e-05, 'tol': 5.6778935537004125e-05, 'validation_fraction': 0.6930113527085988}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.047312 value -0.358867 suggestion {'alpha': 0.18774673712901657, 'batch_size': 200, 'beta_1': 0.9645262930331471, 'beta_2': 0.9810181303384135, 'epsilon': 7.309399582755499e-08, 'hidden_layer_sizes': 144, 'learning_rate_init': 2.5133189673105087e-05, 'tol': 5.6778935537004125e-05, 'validation_fraction': 0.6930113527085988}
observation time 0.001392, current best -0.789901 at iter 13
suggestion time taken 0.001748 iter 14 next_points [{'alpha': 0.37860519586822444, 'batch_size': 164, 'beta_1': 0.983380686037972, 'beta_2': 0.9999979356192696, 'epsilon': 1.3703061394141445e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 7.805390316190847e-05, 'tol': 0.00010473715683568003, 'validation_fraction': 0.26973545290308293}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.052392 value -0.359360 suggestion {'alpha': 0.37860519586822444, 'batch_size': 164, 'beta_1': 0.983380686037972, 'beta_2': 0.9999979356192696, 'epsilon': 1.3703061394141445e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 7.805390316190847e-05, 'tol': 0.00010473715683568003, 'validation_fraction': 0.26973545290308293}
observation time 0.001361, current best -0.789901 at iter 14
saving meta data: {'args': {'--uuid': '52540cd35242547b82b888fdb18a2b86', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_161952', '--opt': 'turbo', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '822bae7e4bc052b99e8dc77030db3f3f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u 822bae7e4bc052b99e8dc77030db3f3f -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study turbo MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002193 iter 0 next_points [{'alpha': 0.003872829701523953, 'batch_size': 49, 'beta_1': 0.9581118092135416, 'beta_2': 0.9997685874108658, 'epsilon': 9.68282590514909e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.056326091563262425, 'tol': 0.0008988591881946356, 'validation_fraction': 0.4377734100521284}]
function_evaluation time 1.228268 value 1.341534 suggestion {'alpha': 0.003872829701523953, 'batch_size': 49, 'beta_1': 0.9581118092135416, 'beta_2': 0.9997685874108658, 'epsilon': 9.68282590514909e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.056326091563262425, 'tol': 0.0008988591881946356, 'validation_fraction': 0.4377734100521284}
observation time 0.001399, current best 1.341534 at iter 0
suggestion time taken 0.001754 iter 1 next_points [{'alpha': 0.04280412590735293, 'batch_size': 217, 'beta_1': 0.9617046200395273, 'beta_2': 0.999997774067895, 'epsilon': 2.271038471497249e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.0003070805464954478, 'tol': 0.0203145742059264, 'validation_fraction': 0.8678176007951368}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.139955 value 6.641723 suggestion {'alpha': 0.04280412590735293, 'batch_size': 217, 'beta_1': 0.9617046200395273, 'beta_2': 0.999997774067895, 'epsilon': 2.271038471497249e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.0003070805464954478, 'tol': 0.0203145742059264, 'validation_fraction': 0.8678176007951368}
observation time 0.001410, current best 1.341534 at iter 1
suggestion time taken 0.001770 iter 2 next_points [{'alpha': 0.28022002099044285, 'batch_size': 205, 'beta_1': 0.51183458081028, 'beta_2': 0.9584309702197847, 'epsilon': 2.7327453090395627e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.01996779634859417, 'tol': 3.92579243977302e-05, 'validation_fraction': 0.5640983161768087}]
function_evaluation time 0.539575 value 0.160526 suggestion {'alpha': 0.28022002099044285, 'batch_size': 205, 'beta_1': 0.51183458081028, 'beta_2': 0.9584309702197847, 'epsilon': 2.7327453090395627e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.01996779634859417, 'tol': 3.92579243977302e-05, 'validation_fraction': 0.5640983161768087}
observation time 0.001359, current best 0.160526 at iter 2
suggestion time taken 0.001714 iter 3 next_points [{'alpha': 0.00899996993571293, 'batch_size': 32, 'beta_1': 0.9195262411585343, 'beta_2': 0.9999205137746873, 'epsilon': 2.3836560962131974e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0010414773716485185, 'tol': 1.6246234426502587e-05, 'validation_fraction': 0.16200483637301827}]
function_evaluation time 2.228318 value 0.114360 suggestion {'alpha': 0.00899996993571293, 'batch_size': 32, 'beta_1': 0.9195262411585343, 'beta_2': 0.9999205137746873, 'epsilon': 2.3836560962131974e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0010414773716485185, 'tol': 1.6246234426502587e-05, 'validation_fraction': 0.16200483637301827}
observation time 0.001382, current best 0.114360 at iter 3
suggestion time taken 0.001734 iter 4 next_points [{'alpha': 0.08149312002930265, 'batch_size': 111, 'beta_1': 0.9780256234203099, 'beta_2': 0.9866406023949887, 'epsilon': 1.6235599129186627e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 6.939952456444863e-05, 'tol': 0.003187036395324245, 'validation_fraction': 0.1059022056792785}]
function_evaluation time 3.326726 value 0.206052 suggestion {'alpha': 0.08149312002930265, 'batch_size': 111, 'beta_1': 0.9780256234203099, 'beta_2': 0.9866406023949887, 'epsilon': 1.6235599129186627e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 6.939952456444863e-05, 'tol': 0.003187036395324245, 'validation_fraction': 0.1059022056792785}
observation time 0.001371, current best 0.114360 at iter 4
suggestion time taken 0.001745 iter 5 next_points [{'alpha': 0.1506229721446206, 'batch_size': 230, 'beta_1': 0.5637556319739595, 'beta_2': 0.9360653466557497, 'epsilon': 2.4445953322806864e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0002061037547924239, 'tol': 0.030488641081133767, 'validation_fraction': 0.5220199810142556}]
function_evaluation time 0.229325 value 4.847641 suggestion {'alpha': 0.1506229721446206, 'batch_size': 230, 'beta_1': 0.5637556319739595, 'beta_2': 0.9360653466557497, 'epsilon': 2.4445953322806864e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0002061037547924239, 'tol': 0.030488641081133767, 'validation_fraction': 0.5220199810142556}
observation time 0.001408, current best 0.114360 at iter 5
suggestion time taken 0.001762 iter 6 next_points [{'alpha': 0.6067321770401959, 'batch_size': 193, 'beta_1': 0.8006327206502375, 'beta_2': 0.9999693905477104, 'epsilon': 4.514543328712332e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0036188435322625345, 'tol': 0.009104093196681361, 'validation_fraction': 0.8188477863210717}]
function_evaluation time 0.391693 value 0.385890 suggestion {'alpha': 0.6067321770401959, 'batch_size': 193, 'beta_1': 0.8006327206502375, 'beta_2': 0.9999693905477104, 'epsilon': 4.514543328712332e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0036188435322625345, 'tol': 0.009104093196681361, 'validation_fraction': 0.8188477863210717}
observation time 0.001364, current best 0.114360 at iter 6
suggestion time taken 0.001759 iter 7 next_points [{'alpha': 0.0002591292399922389, 'batch_size': 41, 'beta_1': 0.6269794636186379, 'beta_2': 0.9999904220735107, 'epsilon': 5.5002777476774714e-08, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.002414222295335277, 'tol': 0.000427570894717505, 'validation_fraction': 0.2562716087715588}]
function_evaluation time 1.594456 value 0.100478 suggestion {'alpha': 0.0002591292399922389, 'batch_size': 41, 'beta_1': 0.6269794636186379, 'beta_2': 0.9999904220735107, 'epsilon': 5.5002777476774714e-08, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.002414222295335277, 'tol': 0.000427570894717505, 'validation_fraction': 0.2562716087715588}
observation time 0.001338, current best 0.100478 at iter 7
suggestion time taken 0.001748 iter 8 next_points [{'alpha': 0.028161178753563353, 'batch_size': 174, 'beta_1': 0.8902307316313242, 'beta_2': 0.9986377236333805, 'epsilon': 4.058710128107993e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.027759909086854866, 'tol': 0.0007650249621227788, 'validation_fraction': 0.3903273422133024}]
function_evaluation time 0.827247 value 0.202549 suggestion {'alpha': 0.028161178753563353, 'batch_size': 174, 'beta_1': 0.8902307316313242, 'beta_2': 0.9986377236333805, 'epsilon': 4.058710128107993e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.027759909086854866, 'tol': 0.0007650249621227788, 'validation_fraction': 0.3903273422133024}
observation time 0.001412, current best 0.100478 at iter 8
suggestion time taken 0.001755 iter 9 next_points [{'alpha': 0.0009456853678694003, 'batch_size': 128, 'beta_1': 0.9823590630458503, 'beta_2': 0.995202012514165, 'epsilon': 2.466513114383274e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 9.32694515546447e-05, 'tol': 0.007996572944060983, 'validation_fraction': 0.7778229494914711}]
function_evaluation time 0.735866 value 5.722908 suggestion {'alpha': 0.0009456853678694003, 'batch_size': 128, 'beta_1': 0.9823590630458503, 'beta_2': 0.995202012514165, 'epsilon': 2.466513114383274e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 9.32694515546447e-05, 'tol': 0.007996572944060983, 'validation_fraction': 0.7778229494914711}
observation time 0.001340, current best 0.100478 at iter 9
suggestion time taken 0.001739 iter 10 next_points [{'alpha': 4.557298750969611, 'batch_size': 118, 'beta_1': 0.9841442199326288, 'beta_2': 0.9999947283766593, 'epsilon': 8.301518544121564e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0013141568184017005, 'tol': 0.001986555870170668, 'validation_fraction': 0.8025041034874492}]
function_evaluation time 0.785548 value 0.380080 suggestion {'alpha': 4.557298750969611, 'batch_size': 118, 'beta_1': 0.9841442199326288, 'beta_2': 0.9999947283766593, 'epsilon': 8.301518544121564e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0013141568184017005, 'tol': 0.001986555870170668, 'validation_fraction': 0.8025041034874492}
observation time 0.001355, current best 0.100478 at iter 10
suggestion time taken 0.001715 iter 11 next_points [{'alpha': 0.0005333329923313567, 'batch_size': 243, 'beta_1': 0.8251244763182246, 'beta_2': 0.9984424071006837, 'epsilon': 1.0500245219854847e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 3.465834072831744e-05, 'tol': 0.04538420097098997, 'validation_fraction': 0.29232391491304427}]
function_evaluation time 0.368931 value 8.182364 suggestion {'alpha': 0.0005333329923313567, 'batch_size': 243, 'beta_1': 0.8251244763182246, 'beta_2': 0.9984424071006837, 'epsilon': 1.0500245219854847e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 3.465834072831744e-05, 'tol': 0.04538420097098997, 'validation_fraction': 0.29232391491304427}
observation time 0.001374, current best 0.100478 at iter 11
suggestion time taken 0.001965 iter 12 next_points [{'alpha': 0.0001779645851630267, 'batch_size': 74, 'beta_1': 0.9154290639951715, 'beta_2': 0.9778866298723599, 'epsilon': 1.0741628397463422e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 1.6809666149582488e-05, 'tol': 0.00018209457594080882, 'validation_fraction': 0.666191609945435}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 4.460569 value 2.548308 suggestion {'alpha': 0.0001779645851630267, 'batch_size': 74, 'beta_1': 0.9154290639951715, 'beta_2': 0.9778866298723599, 'epsilon': 1.0741628397463422e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 1.6809666149582488e-05, 'tol': 0.00018209457594080882, 'validation_fraction': 0.666191609945435}
observation time 0.001369, current best 0.100478 at iter 12
suggestion time taken 0.001751 iter 13 next_points [{'alpha': 7.451841837458333, 'batch_size': 175, 'beta_1': 0.9894530137765044, 'beta_2': 0.9999804197771058, 'epsilon': 3.194052144538892e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.00017759570151490577, 'tol': 9.233129816766296e-05, 'validation_fraction': 0.7371122593378181}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.183463 value 1.252307 suggestion {'alpha': 7.451841837458333, 'batch_size': 175, 'beta_1': 0.9894530137765044, 'beta_2': 0.9999804197771058, 'epsilon': 3.194052144538892e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.00017759570151490577, 'tol': 9.233129816766296e-05, 'validation_fraction': 0.7371122593378181}
observation time 0.001396, current best 0.100478 at iter 13
suggestion time taken 0.001716 iter 14 next_points [{'alpha': 6.550010931175491e-05, 'batch_size': 162, 'beta_1': 0.7365121975906004, 'beta_2': 0.9909058617370569, 'epsilon': 7.293817506923448e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 1.3688949075951609e-05, 'tol': 0.004201551576977568, 'validation_fraction': 0.18711313873537286}]
function_evaluation time 0.650958 value 7.344355 suggestion {'alpha': 6.550010931175491e-05, 'batch_size': 162, 'beta_1': 0.7365121975906004, 'beta_2': 0.9909058617370569, 'epsilon': 7.293817506923448e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 1.3688949075951609e-05, 'tol': 0.004201551576977568, 'validation_fraction': 0.18711313873537286}
observation time 0.001350, current best 0.100478 at iter 14
saving meta data: {'args': {'--uuid': '822bae7e4bc052b99e8dc77030db3f3f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

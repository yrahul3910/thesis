running: {'--uuid': '27af9156ca0351dc83a6047c189f72f9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d digits -o random-search -u 27af9156ca0351dc83a6047c189f72f9 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study random-search MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002587 iter 0 next_points [{'alpha': 0.005364523325240674, 'batch_size': 167, 'beta_1': 0.9887608348797747, 'beta_2': 0.9547425571699795, 'epsilon': 3.9540615573961016e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0011466133605425811, 'tol': 0.001677411250884775, 'validation_fraction': 0.13765915187276773}]
function_evaluation time 1.246146 value -0.949202 suggestion {'alpha': 0.005364523325240674, 'batch_size': 167, 'beta_1': 0.9887608348797747, 'beta_2': 0.9547425571699795, 'epsilon': 3.9540615573961016e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0011466133605425811, 'tol': 0.001677411250884775, 'validation_fraction': 0.13765915187276773}
observation time 0.000007, current best -0.949202 at iter 0
suggestion time taken 0.002497 iter 1 next_points [{'alpha': 3.0032819259738552, 'batch_size': 117, 'beta_1': 0.911952883613497, 'beta_2': 0.9986988933930082, 'epsilon': 2.499465955150357e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.0418194967881572, 'tol': 0.0002614277592522217, 'validation_fraction': 0.8930869859529221}]
function_evaluation time 0.547349 value -0.832966 suggestion {'alpha': 3.0032819259738552, 'batch_size': 117, 'beta_1': 0.911952883613497, 'beta_2': 0.9986988933930082, 'epsilon': 2.499465955150357e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.0418194967881572, 'tol': 0.0002614277592522217, 'validation_fraction': 0.8930869859529221}
observation time 0.000005, current best -0.949202 at iter 1
suggestion time taken 0.002528 iter 2 next_points [{'alpha': 0.000262722831259314, 'batch_size': 229, 'beta_1': 0.9462698574129819, 'beta_2': 0.9651593589864814, 'epsilon': 2.6730429228224696e-09, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.005249203362370505, 'tol': 0.001459624441198521, 'validation_fraction': 0.8436818299037261}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.692451 value -0.906066 suggestion {'alpha': 0.000262722831259314, 'batch_size': 229, 'beta_1': 0.9462698574129819, 'beta_2': 0.9651593589864814, 'epsilon': 2.6730429228224696e-09, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.005249203362370505, 'tol': 0.001459624441198521, 'validation_fraction': 0.8436818299037261}
observation time 0.000005, current best -0.949202 at iter 2
suggestion time taken 0.002434 iter 3 next_points [{'alpha': 0.006273638059331528, 'batch_size': 76, 'beta_1': 0.9116186197945533, 'beta_2': 0.9999907647463298, 'epsilon': 2.7817761378275173e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.014359138693965823, 'tol': 0.0073373645525431005, 'validation_fraction': 0.8360913557058572}]
function_evaluation time 0.352555 value -0.907455 suggestion {'alpha': 0.006273638059331528, 'batch_size': 76, 'beta_1': 0.9116186197945533, 'beta_2': 0.9999907647463298, 'epsilon': 2.7817761378275173e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.014359138693965823, 'tol': 0.0073373645525431005, 'validation_fraction': 0.8360913557058572}
observation time 0.000005, current best -0.949202 at iter 3
suggestion time taken 0.002495 iter 4 next_points [{'alpha': 3.311751361611274, 'batch_size': 59, 'beta_1': 0.6811916921257685, 'beta_2': 0.9992298445768893, 'epsilon': 1.7067101318668432e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.016841727643329474, 'tol': 0.018210318692113977, 'validation_fraction': 0.12438316748907731}]
function_evaluation time 0.716295 value -0.938081 suggestion {'alpha': 3.311751361611274, 'batch_size': 59, 'beta_1': 0.6811916921257685, 'beta_2': 0.9992298445768893, 'epsilon': 1.7067101318668432e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.016841727643329474, 'tol': 0.018210318692113977, 'validation_fraction': 0.12438316748907731}
observation time 0.000004, current best -0.949202 at iter 4
suggestion time taken 0.002445 iter 5 next_points [{'alpha': 0.12541243684473108, 'batch_size': 88, 'beta_1': 0.8839556720499595, 'beta_2': 0.9928653773800518, 'epsilon': 1.0985465785771364e-07, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.013359492172030371, 'tol': 0.00027273087810871595, 'validation_fraction': 0.25358984339147544}]
function_evaluation time 1.200443 value -0.965900 suggestion {'alpha': 0.12541243684473108, 'batch_size': 88, 'beta_1': 0.8839556720499595, 'beta_2': 0.9928653773800518, 'epsilon': 1.0985465785771364e-07, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.013359492172030371, 'tol': 0.00027273087810871595, 'validation_fraction': 0.25358984339147544}
observation time 0.000004, current best -0.965900 at iter 5
suggestion time taken 0.002733 iter 6 next_points [{'alpha': 3.3566312762219135, 'batch_size': 190, 'beta_1': 0.5053458963693769, 'beta_2': 0.9999959659564474, 'epsilon': 2.444375464018788e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.052684939717718864, 'tol': 0.001281301311394202, 'validation_fraction': 0.2216869398442791}]
function_evaluation time 0.672408 value -0.934572 suggestion {'alpha': 3.3566312762219135, 'batch_size': 190, 'beta_1': 0.5053458963693769, 'beta_2': 0.9999959659564474, 'epsilon': 2.444375464018788e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.052684939717718864, 'tol': 0.001281301311394202, 'validation_fraction': 0.2216869398442791}
observation time 0.000004, current best -0.965900 at iter 6
suggestion time taken 0.002472 iter 7 next_points [{'alpha': 7.161416689362648e-05, 'batch_size': 26, 'beta_1': 0.8902481792513957, 'beta_2': 0.9999691886930626, 'epsilon': 3.166202130211756e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 5.674225208166152e-05, 'tol': 0.05210471827364571, 'validation_fraction': 0.14525959216764645}]
function_evaluation time 2.050044 value -0.842748 suggestion {'alpha': 7.161416689362648e-05, 'batch_size': 26, 'beta_1': 0.8902481792513957, 'beta_2': 0.9999691886930626, 'epsilon': 3.166202130211756e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 5.674225208166152e-05, 'tol': 0.05210471827364571, 'validation_fraction': 0.14525959216764645}
observation time 0.000004, current best -0.965900 at iter 7
suggestion time taken 0.002651 iter 8 next_points [{'alpha': 0.0010497242669338226, 'batch_size': 121, 'beta_1': 0.9217976845586983, 'beta_2': 0.9995144648063695, 'epsilon': 1.8447423013893682e-09, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.08202784199304619, 'tol': 0.02458784891923138, 'validation_fraction': 0.8868718048980443}]
function_evaluation time 0.179033 value -0.324315 suggestion {'alpha': 0.0010497242669338226, 'batch_size': 121, 'beta_1': 0.9217976845586983, 'beta_2': 0.9995144648063695, 'epsilon': 1.8447423013893682e-09, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.08202784199304619, 'tol': 0.02458784891923138, 'validation_fraction': 0.8868718048980443}
observation time 0.000005, current best -0.965900 at iter 8
suggestion time taken 0.002487 iter 9 next_points [{'alpha': 1.1082110030798661e-05, 'batch_size': 224, 'beta_1': 0.6226435189198781, 'beta_2': 0.9779527628099399, 'epsilon': 1.890017855315924e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.002818788370678724, 'tol': 0.008703481213821454, 'validation_fraction': 0.8568838211698567}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.353671 value -0.813514 suggestion {'alpha': 1.1082110030798661e-05, 'batch_size': 224, 'beta_1': 0.6226435189198781, 'beta_2': 0.9779527628099399, 'epsilon': 1.890017855315924e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.002818788370678724, 'tol': 0.008703481213821454, 'validation_fraction': 0.8568838211698567}
observation time 0.000004, current best -0.965900 at iter 9
suggestion time taken 0.002784 iter 10 next_points [{'alpha': 0.0017077511831482407, 'batch_size': 56, 'beta_1': 0.9707158235571702, 'beta_2': 0.9820611620725095, 'epsilon': 2.8117250970360202e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 6.162931368798001e-05, 'tol': 0.0009221092914958851, 'validation_fraction': 0.13522643236832418}]
function_evaluation time 3.811622 value -0.931105 suggestion {'alpha': 0.0017077511831482407, 'batch_size': 56, 'beta_1': 0.9707158235571702, 'beta_2': 0.9820611620725095, 'epsilon': 2.8117250970360202e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 6.162931368798001e-05, 'tol': 0.0009221092914958851, 'validation_fraction': 0.13522643236832418}
observation time 0.000005, current best -0.965900 at iter 10
suggestion time taken 0.002445 iter 11 next_points [{'alpha': 0.1741035822528887, 'batch_size': 12, 'beta_1': 0.9670142827808949, 'beta_2': 0.9999908275547975, 'epsilon': 2.4408815810770356e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.004272594480255366, 'tol': 0.08554636297900024, 'validation_fraction': 0.5942312917107884}]
function_evaluation time 1.101393 value -0.960342 suggestion {'alpha': 0.1741035822528887, 'batch_size': 12, 'beta_1': 0.9670142827808949, 'beta_2': 0.9999908275547975, 'epsilon': 2.4408815810770356e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.004272594480255366, 'tol': 0.08554636297900024, 'validation_fraction': 0.5942312917107884}
observation time 0.000005, current best -0.965900 at iter 11
suggestion time taken 0.002401 iter 12 next_points [{'alpha': 1.010946681386975, 'batch_size': 236, 'beta_1': 0.7618348351507467, 'beta_2': 0.9858764877223771, 'epsilon': 1.8977271476211272e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0003377269683913878, 'tol': 0.004674302985515135, 'validation_fraction': 0.2873785405676013}]
function_evaluation time 1.679600 value -0.929043 suggestion {'alpha': 1.010946681386975, 'batch_size': 236, 'beta_1': 0.7618348351507467, 'beta_2': 0.9858764877223771, 'epsilon': 1.8977271476211272e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0003377269683913878, 'tol': 0.004674302985515135, 'validation_fraction': 0.2873785405676013}
observation time 0.000004, current best -0.965900 at iter 12
suggestion time taken 0.002696 iter 13 next_points [{'alpha': 1.7842222224338413, 'batch_size': 54, 'beta_1': 0.8872107216562992, 'beta_2': 0.9919703384557257, 'epsilon': 6.16979428293728e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 9.402967602881853e-05, 'tol': 0.00015824882909004393, 'validation_fraction': 0.8653144873241674}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.774102 value -0.373076 suggestion {'alpha': 1.7842222224338413, 'batch_size': 54, 'beta_1': 0.8872107216562992, 'beta_2': 0.9919703384557257, 'epsilon': 6.16979428293728e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 9.402967602881853e-05, 'tol': 0.00015824882909004393, 'validation_fraction': 0.8653144873241674}
observation time 0.000003, current best -0.965900 at iter 13
suggestion time taken 0.002450 iter 14 next_points [{'alpha': 0.0003629565888419642, 'batch_size': 212, 'beta_1': 0.5416163983753838, 'beta_2': 0.9927875348088617, 'epsilon': 4.2804075368476076e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.0062491038310986905, 'tol': 0.0029868315216761664, 'validation_fraction': 0.5176761561944562}]
function_evaluation time 0.523221 value -0.951972 suggestion {'alpha': 0.0003629565888419642, 'batch_size': 212, 'beta_1': 0.5416163983753838, 'beta_2': 0.9927875348088617, 'epsilon': 4.2804075368476076e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.0062491038310986905, 'tol': 0.0029868315216761664, 'validation_fraction': 0.5176761561944562}
observation time 0.000005, current best -0.965900 at iter 14
saving meta data: {'args': {'--uuid': '27af9156ca0351dc83a6047c189f72f9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

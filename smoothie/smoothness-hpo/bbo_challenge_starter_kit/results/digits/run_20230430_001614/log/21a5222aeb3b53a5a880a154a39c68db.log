running: {'--uuid': '21a5222aeb3b53a5a880a154a39c68db', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u 21a5222aeb3b53a5a880a154a39c68db -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study turbo MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002206 iter 0 next_points [{'alpha': 1.3974184503593128, 'batch_size': 142, 'beta_1': 0.8543112747928522, 'beta_2': 0.9512344098890838, 'epsilon': 1.2601140390691252e-07, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.0002444607912076757, 'tol': 1.9609602553564076e-05, 'validation_fraction': 0.10807288011353951}]
function_evaluation time 1.998992 value 0.148739 suggestion {'alpha': 1.3974184503593128, 'batch_size': 142, 'beta_1': 0.8543112747928522, 'beta_2': 0.9512344098890838, 'epsilon': 1.2601140390691252e-07, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.0002444607912076757, 'tol': 1.9609602553564076e-05, 'validation_fraction': 0.10807288011353951}
observation time 0.001411, current best 0.148739 at iter 0
suggestion time taken 0.001798 iter 1 next_points [{'alpha': 3.578159548105654e-05, 'batch_size': 75, 'beta_1': 0.759825992406263, 'beta_2': 0.999998132964754, 'epsilon': 1.0601647183883562e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 1.5775639628561383e-05, 'tol': 0.0001623031593722917, 'validation_fraction': 0.752141209994051}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.068088 value 7.606655 suggestion {'alpha': 3.578159548105654e-05, 'batch_size': 75, 'beta_1': 0.759825992406263, 'beta_2': 0.999998132964754, 'epsilon': 1.0601647183883562e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 1.5775639628561383e-05, 'tol': 0.0001623031593722917, 'validation_fraction': 0.752141209994051}
observation time 0.001364, current best 0.148739 at iter 1
suggestion time taken 0.001756 iter 2 next_points [{'alpha': 7.099032665027038, 'batch_size': 129, 'beta_1': 0.586019620209986, 'beta_2': 0.9998688280431777, 'epsilon': 9.701317393830898e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0003795371552911868, 'tol': 4.272061423236311e-05, 'validation_fraction': 0.33018912997854266}]
function_evaluation time 2.872979 value 0.202804 suggestion {'alpha': 7.099032665027038, 'batch_size': 129, 'beta_1': 0.586019620209986, 'beta_2': 0.9998688280431777, 'epsilon': 9.701317393830898e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0003795371552911868, 'tol': 4.272061423236311e-05, 'validation_fraction': 0.33018912997854266}
observation time 0.001418, current best 0.148739 at iter 2
suggestion time taken 0.001759 iter 3 next_points [{'alpha': 0.04716701542601191, 'batch_size': 237, 'beta_1': 0.6536326605023837, 'beta_2': 0.9999930627074518, 'epsilon': 5.018952268585704e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.028314794496415368, 'tol': 0.0003698759747413646, 'validation_fraction': 0.7281917365188249}]
function_evaluation time 0.547076 value 0.256151 suggestion {'alpha': 0.04716701542601191, 'batch_size': 237, 'beta_1': 0.6536326605023837, 'beta_2': 0.9999930627074518, 'epsilon': 5.018952268585704e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.028314794496415368, 'tol': 0.0003698759747413646, 'validation_fraction': 0.7281917365188249}
observation time 0.001406, current best 0.148739 at iter 3
suggestion time taken 0.001721 iter 4 next_points [{'alpha': 0.0011197623909245855, 'batch_size': 61, 'beta_1': 0.9094724513727659, 'beta_2': 0.9981142483150458, 'epsilon': 2.216194826736862e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.012670846484896046, 'tol': 5.757741719119578e-05, 'validation_fraction': 0.29828444810085175}]
function_evaluation time 0.964998 value 0.102832 suggestion {'alpha': 0.0011197623909245855, 'batch_size': 61, 'beta_1': 0.9094724513727659, 'beta_2': 0.9981142483150458, 'epsilon': 2.216194826736862e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.012670846484896046, 'tol': 5.757741719119578e-05, 'validation_fraction': 0.29828444810085175}
observation time 0.001393, current best 0.102832 at iter 4
suggestion time taken 0.001737 iter 5 next_points [{'alpha': 0.06446219429960669, 'batch_size': 244, 'beta_1': 0.6995953583737453, 'beta_2': 0.9997254859624318, 'epsilon': 6.547890784775688e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.0006787096973286852, 'tol': 0.0007386153810469496, 'validation_fraction': 0.18814635530974966}]
function_evaluation time 1.700703 value 0.172561 suggestion {'alpha': 0.06446219429960669, 'batch_size': 244, 'beta_1': 0.6995953583737453, 'beta_2': 0.9997254859624318, 'epsilon': 6.547890784775688e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.0006787096973286852, 'tol': 0.0007386153810469496, 'validation_fraction': 0.18814635530974966}
observation time 0.001355, current best 0.102832 at iter 5
suggestion time taken 0.001729 iter 6 next_points [{'alpha': 0.01749828133906117, 'batch_size': 59, 'beta_1': 0.9528216245173629, 'beta_2': 0.9997948638272147, 'epsilon': 3.407151422604559e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.0038020802861643958, 'tol': 0.02403017785756454, 'validation_fraction': 0.6561961837887382}]
function_evaluation time 0.478780 value 0.194704 suggestion {'alpha': 0.01749828133906117, 'batch_size': 59, 'beta_1': 0.9528216245173629, 'beta_2': 0.9997948638272147, 'epsilon': 3.407151422604559e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.0038020802861643958, 'tol': 0.02403017785756454, 'validation_fraction': 0.6561961837887382}
observation time 0.001382, current best 0.102832 at iter 6
suggestion time taken 0.001728 iter 7 next_points [{'alpha': 0.00012344763572842287, 'batch_size': 111, 'beta_1': 0.9686848306830085, 'beta_2': 0.9999820573156747, 'epsilon': 1.0909415351982506e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.0008298205268139317, 'tol': 1.529403455078313e-05, 'validation_fraction': 0.5763701697847861}]
function_evaluation time 1.706021 value 0.183287 suggestion {'alpha': 0.00012344763572842287, 'batch_size': 111, 'beta_1': 0.9686848306830085, 'beta_2': 0.9999820573156747, 'epsilon': 1.0909415351982506e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.0008298205268139317, 'tol': 1.529403455078313e-05, 'validation_fraction': 0.5763701697847861}
observation time 0.001390, current best 0.102832 at iter 7
suggestion time taken 0.001774 iter 8 next_points [{'alpha': 1.0826574572679216e-05, 'batch_size': 34, 'beta_1': 0.8805959983240771, 'beta_2': 0.9781742803847653, 'epsilon': 1.9988392575171753e-09, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.02038796130508701, 'tol': 0.02032800020251824, 'validation_fraction': 0.8782809780333626}]
function_evaluation time 0.396563 value 0.462602 suggestion {'alpha': 1.0826574572679216e-05, 'batch_size': 34, 'beta_1': 0.8805959983240771, 'beta_2': 0.9781742803847653, 'epsilon': 1.9988392575171753e-09, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.02038796130508701, 'tol': 0.02032800020251824, 'validation_fraction': 0.8782809780333626}
observation time 0.001396, current best 0.102832 at iter 8
suggestion time taken 0.001702 iter 9 next_points [{'alpha': 0.4609450230416916, 'batch_size': 186, 'beta_1': 0.9877906044026653, 'beta_2': 0.9999285401440162, 'epsilon': 1.3389147366444102e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.04435515986563462, 'tol': 0.0407826149049574, 'validation_fraction': 0.8392686600453315}]
function_evaluation time 0.232489 value 2.284121 suggestion {'alpha': 0.4609450230416916, 'batch_size': 186, 'beta_1': 0.9877906044026653, 'beta_2': 0.9999285401440162, 'epsilon': 1.3389147366444102e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.04435515986563462, 'tol': 0.0407826149049574, 'validation_fraction': 0.8392686600453315}
observation time 0.001364, current best 0.102832 at iter 9
suggestion time taken 0.001747 iter 10 next_points [{'alpha': 0.008118127228612566, 'batch_size': 98, 'beta_1': 0.9230573029879943, 'beta_2': 0.9305392030492986, 'epsilon': 5.5777832912364206e-08, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.08127826494203012, 'tol': 0.0001002092336817812, 'validation_fraction': 0.4303977733209598}]
function_evaluation time 0.801247 value 1.151474 suggestion {'alpha': 0.008118127228612566, 'batch_size': 98, 'beta_1': 0.9230573029879943, 'beta_2': 0.9305392030492986, 'epsilon': 5.5777832912364206e-08, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.08127826494203012, 'tol': 0.0001002092336817812, 'validation_fraction': 0.4303977733209598}
observation time 0.001344, current best 0.102832 at iter 10
suggestion time taken 0.001725 iter 11 next_points [{'alpha': 0.00018749603151855252, 'batch_size': 166, 'beta_1': 0.9851270879358861, 'beta_2': 0.9999988345057295, 'epsilon': 4.748928946809677e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.003093085609377864, 'tol': 0.0023325360889621476, 'validation_fraction': 0.6267370870667507}]
function_evaluation time 0.777314 value 0.245086 suggestion {'alpha': 0.00018749603151855252, 'batch_size': 166, 'beta_1': 0.9851270879358861, 'beta_2': 0.9999988345057295, 'epsilon': 4.748928946809677e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.003093085609377864, 'tol': 0.0023325360889621476, 'validation_fraction': 0.6267370870667507}
observation time 0.001338, current best 0.102832 at iter 11
suggestion time taken 0.001701 iter 12 next_points [{'alpha': 0.00042357037277226424, 'batch_size': 210, 'beta_1': 0.7964933175618124, 'beta_2': 0.9846041944707014, 'epsilon': 3.2752070257346784e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.00012533888522633314, 'tol': 0.005477135465378534, 'validation_fraction': 0.18078661313426703}]
function_evaluation time 2.205057 value 0.295302 suggestion {'alpha': 0.00042357037277226424, 'batch_size': 210, 'beta_1': 0.7964933175618124, 'beta_2': 0.9846041944707014, 'epsilon': 3.2752070257346784e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.00012533888522633314, 'tol': 0.005477135465378534, 'validation_fraction': 0.18078661313426703}
observation time 0.001338, current best 0.102832 at iter 12
suggestion time taken 0.001958 iter 13 next_points [{'alpha': 0.0034681953104061646, 'batch_size': 156, 'beta_1': 0.9658964774296307, 'beta_2': 0.994633023753801, 'epsilon': 2.101369263440316e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.00011115917023635531, 'tol': 0.009487362950299129, 'validation_fraction': 0.39147325959069545}]
function_evaluation time 1.379302 value 1.574087 suggestion {'alpha': 0.0034681953104061646, 'batch_size': 156, 'beta_1': 0.9658964774296307, 'beta_2': 0.994633023753801, 'epsilon': 2.101369263440316e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.00011115917023635531, 'tol': 0.009487362950299129, 'validation_fraction': 0.39147325959069545}
observation time 0.001357, current best 0.102832 at iter 13
suggestion time taken 0.001735 iter 14 next_points [{'alpha': 0.2155236748478533, 'batch_size': 224, 'beta_1': 0.9443514249925989, 'beta_2': 0.9964858605313708, 'epsilon': 9.312933464586983e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.008393164292631913, 'tol': 0.0014872132160993208, 'validation_fraction': 0.8534043845655299}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.528937 value 0.375947 suggestion {'alpha': 0.2155236748478533, 'batch_size': 224, 'beta_1': 0.9443514249925989, 'beta_2': 0.9964858605313708, 'epsilon': 9.312933464586983e-09, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.008393164292631913, 'tol': 0.0014872132160993208, 'validation_fraction': 0.8534043845655299}
observation time 0.001355, current best 0.102832 at iter 14
saving meta data: {'args': {'--uuid': '21a5222aeb3b53a5a880a154a39c68db', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '27b0411335255eb5a537fa4b21217c27', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u 27b0411335255eb5a537fa4b21217c27 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study smoothness MLP-adam digits nll 15 1
with data root: None
suggestion time taken 9.447206 iter 0 next_points [{'alpha': 0.0006447176333206253, 'batch_size': 20, 'beta_1': 0.744972878846459, 'beta_2': 0.9993664693709409, 'epsilon': 7.156767084574566e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.011831801786575008, 'tol': 2.0544808296134396e-05, 'validation_fraction': 0.373542948483348}]
function_evaluation time 1.723459 value 0.150202 suggestion {'alpha': 0.0006447176333206253, 'batch_size': 20, 'beta_1': 0.744972878846459, 'beta_2': 0.9993664693709409, 'epsilon': 7.156767084574566e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.011831801786575008, 'tol': 2.0544808296134396e-05, 'validation_fraction': 0.373542948483348}
observation time 0.000007, current best 0.150202 at iter 0
suggestion time taken 9.190466 iter 1 next_points [{'alpha': 2.4093098057221388e-05, 'batch_size': 40, 'beta_1': 0.8296398880706956, 'beta_2': 0.9999097273889631, 'epsilon': 5.915588472366348e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0004933538811508637, 'tol': 0.01618986251177731, 'validation_fraction': 0.233980497542095}]
function_evaluation time 0.912173 value 0.304615 suggestion {'alpha': 2.4093098057221388e-05, 'batch_size': 40, 'beta_1': 0.8296398880706956, 'beta_2': 0.9999097273889631, 'epsilon': 5.915588472366348e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0004933538811508637, 'tol': 0.01618986251177731, 'validation_fraction': 0.233980497542095}
observation time 0.000005, current best 0.150202 at iter 1
suggestion time taken 9.185974 iter 2 next_points [{'alpha': 5.450524642591404e-05, 'batch_size': 26, 'beta_1': 0.9523330511682916, 'beta_2': 0.9999349246175695, 'epsilon': 5.9049438762223054e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.005360152804957346, 'tol': 0.0021045828920542506, 'validation_fraction': 0.806261296813355}]
function_evaluation time 0.641922 value 0.312127 suggestion {'alpha': 5.450524642591404e-05, 'batch_size': 26, 'beta_1': 0.9523330511682916, 'beta_2': 0.9999349246175695, 'epsilon': 5.9049438762223054e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.005360152804957346, 'tol': 0.0021045828920542506, 'validation_fraction': 0.806261296813355}
observation time 0.000006, current best 0.150202 at iter 2
suggestion time taken 9.442232 iter 3 next_points [{'alpha': 0.0014762043379472711, 'batch_size': 41, 'beta_1': 0.9736214746794725, 'beta_2': 0.9355972464756822, 'epsilon': 8.417416894278553e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.00020509540992562236, 'tol': 0.005077420523611739, 'validation_fraction': 0.17985647789414844}]
function_evaluation time 1.766105 value 0.168018 suggestion {'alpha': 0.0014762043379472711, 'batch_size': 41, 'beta_1': 0.9736214746794725, 'beta_2': 0.9355972464756822, 'epsilon': 8.417416894278553e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.00020509540992562236, 'tol': 0.005077420523611739, 'validation_fraction': 0.17985647789414844}
observation time 0.000006, current best 0.150202 at iter 3
suggestion time taken 9.325058 iter 4 next_points [{'alpha': 0.00010432257043757136, 'batch_size': 28, 'beta_1': 0.9407230757781224, 'beta_2': 0.9430106272954333, 'epsilon': 4.206262627372375e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.006271895663467127, 'tol': 1.6405883528174843e-05, 'validation_fraction': 0.4225078645959289}]
function_evaluation time 1.427987 value 0.240187 suggestion {'alpha': 0.00010432257043757136, 'batch_size': 28, 'beta_1': 0.9407230757781224, 'beta_2': 0.9430106272954333, 'epsilon': 4.206262627372375e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.006271895663467127, 'tol': 1.6405883528174843e-05, 'validation_fraction': 0.4225078645959289}
observation time 0.000005, current best 0.150202 at iter 4
suggestion time taken 9.233197 iter 5 next_points [{'alpha': 0.3115368163115303, 'batch_size': 36, 'beta_1': 0.9506234566338747, 'beta_2': 0.9998427607752434, 'epsilon': 2.682068062484002e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.09862715568146502, 'tol': 0.0001245748614490402, 'validation_fraction': 0.5107609058815242}]
function_evaluation time 0.822942 value 1.185185 suggestion {'alpha': 0.3115368163115303, 'batch_size': 36, 'beta_1': 0.9506234566338747, 'beta_2': 0.9998427607752434, 'epsilon': 2.682068062484002e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.09862715568146502, 'tol': 0.0001245748614490402, 'validation_fraction': 0.5107609058815242}
observation time 0.000005, current best 0.150202 at iter 5
suggestion time taken 9.170456 iter 6 next_points [{'alpha': 2.846794209757424, 'batch_size': 18, 'beta_1': 0.9845412546300851, 'beta_2': 0.9999980844037433, 'epsilon': 7.278810382732216e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0002892631937602109, 'tol': 5.0897436901602086e-05, 'validation_fraction': 0.20575172286298488}]
function_evaluation time 3.768289 value 0.220087 suggestion {'alpha': 2.846794209757424, 'batch_size': 18, 'beta_1': 0.9845412546300851, 'beta_2': 0.9999980844037433, 'epsilon': 7.278810382732216e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0002892631937602109, 'tol': 5.0897436901602086e-05, 'validation_fraction': 0.20575172286298488}
observation time 0.000004, current best 0.150202 at iter 6
suggestion time taken 9.238690 iter 7 next_points [{'alpha': 1.4051641443613265e-05, 'batch_size': 19, 'beta_1': 0.8805723918795451, 'beta_2': 0.9990224989728104, 'epsilon': 1.5743771273323698e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.001098616371964372, 'tol': 0.012686047560022768, 'validation_fraction': 0.19109794872040414}]
function_evaluation time 1.942152 value 0.107850 suggestion {'alpha': 1.4051641443613265e-05, 'batch_size': 19, 'beta_1': 0.8805723918795451, 'beta_2': 0.9990224989728104, 'epsilon': 1.5743771273323698e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.001098616371964372, 'tol': 0.012686047560022768, 'validation_fraction': 0.19109794872040414}
observation time 0.000005, current best 0.107850 at iter 7
suggestion time taken 9.213075 iter 8 next_points [{'alpha': 5.715465647404793e-05, 'batch_size': 20, 'beta_1': 0.963202091359909, 'beta_2': 0.9996645243915031, 'epsilon': 2.098738378939797e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.0018425473239770914, 'tol': 1.2127943437259362e-05, 'validation_fraction': 0.8021023986715513}]
function_evaluation time 1.489954 value 0.349771 suggestion {'alpha': 5.715465647404793e-05, 'batch_size': 20, 'beta_1': 0.963202091359909, 'beta_2': 0.9996645243915031, 'epsilon': 2.098738378939797e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.0018425473239770914, 'tol': 1.2127943437259362e-05, 'validation_fraction': 0.8021023986715513}
observation time 0.000005, current best 0.107850 at iter 8
suggestion time taken 9.293338 iter 9 next_points [{'alpha': 1.4547088319532528, 'batch_size': 30, 'beta_1': 0.9181036622682228, 'beta_2': 0.9614600485389323, 'epsilon': 2.9169330950127195e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 4.7139456168673504e-05, 'tol': 0.0002468230783372694, 'validation_fraction': 0.11130498239787077}]
function_evaluation time 4.873363 value 0.275440 suggestion {'alpha': 1.4547088319532528, 'batch_size': 30, 'beta_1': 0.9181036622682228, 'beta_2': 0.9614600485389323, 'epsilon': 2.9169330950127195e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 4.7139456168673504e-05, 'tol': 0.0002468230783372694, 'validation_fraction': 0.11130498239787077}
observation time 0.000006, current best 0.107850 at iter 9
suggestion time taken 9.280588 iter 10 next_points [{'alpha': 0.07807689139983896, 'batch_size': 15, 'beta_1': 0.987437711746539, 'beta_2': 0.9999915206953248, 'epsilon': 4.848800478082015e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0029487650725516876, 'tol': 0.01923321267613109, 'validation_fraction': 0.5254039967595587}]
function_evaluation time 0.921297 value 0.171669 suggestion {'alpha': 0.07807689139983896, 'batch_size': 15, 'beta_1': 0.987437711746539, 'beta_2': 0.9999915206953248, 'epsilon': 4.848800478082015e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0029487650725516876, 'tol': 0.01923321267613109, 'validation_fraction': 0.5254039967595587}
observation time 0.000006, current best 0.107850 at iter 10
suggestion time taken 9.318721 iter 11 next_points [{'alpha': 0.0013902464535531696, 'batch_size': 28, 'beta_1': 0.7402482936412552, 'beta_2': 0.9397188549830561, 'epsilon': 2.608931430904239e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 1.4096068425409819e-05, 'tol': 0.00013271431741536526, 'validation_fraction': 0.41043789414273407}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 6.466862 value 5.123960 suggestion {'alpha': 0.0013902464535531696, 'batch_size': 28, 'beta_1': 0.7402482936412552, 'beta_2': 0.9397188549830561, 'epsilon': 2.608931430904239e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 1.4096068425409819e-05, 'tol': 0.00013271431741536526, 'validation_fraction': 0.41043789414273407}
observation time 0.000005, current best 0.107850 at iter 11
suggestion time taken 9.207275 iter 12 next_points [{'alpha': 0.0004247382638539052, 'batch_size': 18, 'beta_1': 0.9720479688773179, 'beta_2': 0.9999913136559242, 'epsilon': 1.7696693337791688e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.04731802203059835, 'tol': 3.0197338447631292e-05, 'validation_fraction': 0.13903886222750336}]
function_evaluation time 3.442621 value 1.016293 suggestion {'alpha': 0.0004247382638539052, 'batch_size': 18, 'beta_1': 0.9720479688773179, 'beta_2': 0.9999913136559242, 'epsilon': 1.7696693337791688e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.04731802203059835, 'tol': 3.0197338447631292e-05, 'validation_fraction': 0.13903886222750336}
observation time 0.000005, current best 0.107850 at iter 12
suggestion time taken 9.183226 iter 13 next_points [{'alpha': 0.0002998761673582533, 'batch_size': 41, 'beta_1': 0.6972553663350837, 'beta_2': 0.9994399871594051, 'epsilon': 3.081784444846735e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.09383666180915011, 'tol': 3.293995692463912e-05, 'validation_fraction': 0.696157197342113}]
function_evaluation time 0.541155 value 1.597957 suggestion {'alpha': 0.0002998761673582533, 'batch_size': 41, 'beta_1': 0.6972553663350837, 'beta_2': 0.9994399871594051, 'epsilon': 3.081784444846735e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.09383666180915011, 'tol': 3.293995692463912e-05, 'validation_fraction': 0.696157197342113}
observation time 0.000005, current best 0.107850 at iter 13
suggestion time taken 9.155240 iter 14 next_points [{'alpha': 0.00018929556827357321, 'batch_size': 45, 'beta_1': 0.823754558956968, 'beta_2': 0.9998214192803575, 'epsilon': 1.0081068243695878e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.005384622539072265, 'tol': 0.0035792827153399093, 'validation_fraction': 0.6045573436486987}]
function_evaluation time 0.673573 value 0.185363 suggestion {'alpha': 0.00018929556827357321, 'batch_size': 45, 'beta_1': 0.823754558956968, 'beta_2': 0.9998214192803575, 'epsilon': 1.0081068243695878e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.005384622539072265, 'tol': 0.0035792827153399093, 'validation_fraction': 0.6045573436486987}
observation time 0.000006, current best 0.107850 at iter 14
saving meta data: {'args': {'--uuid': '27b0411335255eb5a537fa4b21217c27', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

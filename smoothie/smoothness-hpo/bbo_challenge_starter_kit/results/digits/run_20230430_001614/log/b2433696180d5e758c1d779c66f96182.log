running: {'--uuid': 'b2433696180d5e758c1d779c66f96182', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u b2433696180d5e758c1d779c66f96182 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002142 iter 0 next_points [{'alpha': 0.13000531877000931, 'batch_size': 118, 'beta_1': 0.9077381541300621, 'beta_2': 0.9997468029484434, 'epsilon': 2.2074736085245008e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.013247572455898821, 'tol': 0.0006735941897292482, 'validation_fraction': 0.20602980362592144}]
function_evaluation time 0.844977 value -0.962420 suggestion {'alpha': 0.13000531877000931, 'batch_size': 118, 'beta_1': 0.9077381541300621, 'beta_2': 0.9997468029484434, 'epsilon': 2.2074736085245008e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.013247572455898821, 'tol': 0.0006735941897292482, 'validation_fraction': 0.20602980362592144}
observation time 0.001382, current best -0.962420 at iter 0
suggestion time taken 0.001777 iter 1 next_points [{'alpha': 2.0287002592468907e-05, 'batch_size': 44, 'beta_1': 0.8935925582840163, 'beta_2': 0.9995118730537464, 'epsilon': 1.9798367971699347e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.004319203441420562, 'tol': 2.3161068003559493e-05, 'validation_fraction': 0.41609478375935377}]
function_evaluation time 1.332507 value -0.958251 suggestion {'alpha': 2.0287002592468907e-05, 'batch_size': 44, 'beta_1': 0.8935925582840163, 'beta_2': 0.9995118730537464, 'epsilon': 1.9798367971699347e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.004319203441420562, 'tol': 2.3161068003559493e-05, 'validation_fraction': 0.41609478375935377}
observation time 0.001358, current best -0.962420 at iter 1
suggestion time taken 0.001710 iter 2 next_points [{'alpha': 0.00035401111582286985, 'batch_size': 182, 'beta_1': 0.8535362131334897, 'beta_2': 0.999997912909438, 'epsilon': 4.3038160619988016e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.008725851627342485, 'tol': 0.0019350334396138363, 'validation_fraction': 0.6649019118732576}]
function_evaluation time 0.726101 value -0.947123 suggestion {'alpha': 0.00035401111582286985, 'batch_size': 182, 'beta_1': 0.8535362131334897, 'beta_2': 0.999997912909438, 'epsilon': 4.3038160619988016e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.008725851627342485, 'tol': 0.0019350334396138363, 'validation_fraction': 0.6649019118732576}
observation time 0.001601, current best -0.962420 at iter 2
suggestion time taken 0.001831 iter 3 next_points [{'alpha': 0.0006551623745288563, 'batch_size': 16, 'beta_1': 0.9810271032215243, 'beta_2': 0.9930034729018028, 'epsilon': 6.431802450494522e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 1.0139339317134183e-05, 'tol': 4.92086676974811e-05, 'validation_fraction': 0.13428047061670748}]
function_evaluation time 15.833640 value -0.920686 suggestion {'alpha': 0.0006551623745288563, 'batch_size': 16, 'beta_1': 0.9810271032215243, 'beta_2': 0.9930034729018028, 'epsilon': 6.431802450494522e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 1.0139339317134183e-05, 'tol': 4.92086676974811e-05, 'validation_fraction': 0.13428047061670748}
observation time 0.001363, current best -0.962420 at iter 3
suggestion time taken 0.001722 iter 4 next_points [{'alpha': 0.0014240055100801102, 'batch_size': 146, 'beta_1': 0.5184066450772603, 'beta_2': 0.9999986733971757, 'epsilon': 2.5815504494591795e-07, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.09053297756373921, 'tol': 0.0004261811005292904, 'validation_fraction': 0.11233555994843546}]
function_evaluation time 0.916543 value -0.629026 suggestion {'alpha': 0.0014240055100801102, 'batch_size': 146, 'beta_1': 0.5184066450772603, 'beta_2': 0.9999986733971757, 'epsilon': 2.5815504494591795e-07, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.09053297756373921, 'tol': 0.0004261811005292904, 'validation_fraction': 0.11233555994843546}
observation time 0.001649, current best -0.962420 at iter 4
suggestion time taken 0.001772 iter 5 next_points [{'alpha': 0.09093884456609991, 'batch_size': 102, 'beta_1': 0.9537204628914787, 'beta_2': 0.9655379369412707, 'epsilon': 1.2231081663002582e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0018785263634350394, 'tol': 3.9667514893802e-05, 'validation_fraction': 0.770293584332515}]
function_evaluation time 0.886198 value -0.911641 suggestion {'alpha': 0.09093884456609991, 'batch_size': 102, 'beta_1': 0.9537204628914787, 'beta_2': 0.9655379369412707, 'epsilon': 1.2231081663002582e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0018785263634350394, 'tol': 3.9667514893802e-05, 'validation_fraction': 0.770293584332515}
observation time 0.001410, current best -0.962420 at iter 5
suggestion time taken 0.001714 iter 6 next_points [{'alpha': 0.04618702284813983, 'batch_size': 164, 'beta_1': 0.9475498063586423, 'beta_2': 0.9999957274990018, 'epsilon': 5.823166516771986e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.01482872236503481, 'tol': 0.002364344342966363, 'validation_fraction': 0.8749893305553414}]
function_evaluation time 0.490258 value -0.881710 suggestion {'alpha': 0.04618702284813983, 'batch_size': 164, 'beta_1': 0.9475498063586423, 'beta_2': 0.9999957274990018, 'epsilon': 5.823166516771986e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.01482872236503481, 'tol': 0.002364344342966363, 'validation_fraction': 0.8749893305553414}
observation time 0.001363, current best -0.962420 at iter 6
suggestion time taken 0.001753 iter 7 next_points [{'alpha': 0.8726429367911654, 'batch_size': 243, 'beta_1': 0.6058025793526798, 'beta_2': 0.9843300655600581, 'epsilon': 8.435422285875965e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 1.771133726135127e-05, 'tol': 7.508053043218175e-05, 'validation_fraction': 0.7287259809018545}]
function_evaluation time 1.198483 value -0.160765 suggestion {'alpha': 0.8726429367911654, 'batch_size': 243, 'beta_1': 0.6058025793526798, 'beta_2': 0.9843300655600581, 'epsilon': 8.435422285875965e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 1.771133726135127e-05, 'tol': 7.508053043218175e-05, 'validation_fraction': 0.7287259809018545}
observation time 0.001536, current best -0.962420 at iter 7
suggestion time taken 0.001813 iter 8 next_points [{'alpha': 2.850394608675112e-05, 'batch_size': 236, 'beta_1': 0.7726122282226623, 'beta_2': 0.9953079780164068, 'epsilon': 2.935100214073801e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 5.158149829177574e-05, 'tol': 0.07980568874407039, 'validation_fraction': 0.6390090711526261}]
function_evaluation time 0.188971 value -0.099552 suggestion {'alpha': 2.850394608675112e-05, 'batch_size': 236, 'beta_1': 0.7726122282226623, 'beta_2': 0.9953079780164068, 'epsilon': 2.935100214073801e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 5.158149829177574e-05, 'tol': 0.07980568874407039, 'validation_fraction': 0.6390090711526261}
observation time 0.001354, current best -0.962420 at iter 8
suggestion time taken 0.001760 iter 9 next_points [{'alpha': 5.527011000819554, 'batch_size': 25, 'beta_1': 0.9846210850561457, 'beta_2': 0.9998381334902181, 'epsilon': 4.2630795217268316e-08, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.00047100497289177004, 'tol': 0.014505623801022315, 'validation_fraction': 0.8489847329498081}]
function_evaluation time 0.693267 value -0.862933 suggestion {'alpha': 5.527011000819554, 'batch_size': 25, 'beta_1': 0.9846210850561457, 'beta_2': 0.9998381334902181, 'epsilon': 4.2630795217268316e-08, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.00047100497289177004, 'tol': 0.014505623801022315, 'validation_fraction': 0.8489847329498081}
observation time 0.001353, current best -0.962420 at iter 9
suggestion time taken 0.001717 iter 10 next_points [{'alpha': 0.40960819938521065, 'batch_size': 52, 'beta_1': 0.9186781191767862, 'beta_2': 0.9271238478963424, 'epsilon': 1.3237974068566007e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 3.205272642416661e-05, 'tol': 0.007838003849128418, 'validation_fraction': 0.2967603489529888}]
function_evaluation time 3.696406 value -0.876817 suggestion {'alpha': 0.40960819938521065, 'batch_size': 52, 'beta_1': 0.9186781191767862, 'beta_2': 0.9271238478963424, 'epsilon': 1.3237974068566007e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 3.205272642416661e-05, 'tol': 0.007838003849128418, 'validation_fraction': 0.2967603489529888}
observation time 0.001376, current best -0.962420 at iter 10
suggestion time taken 0.002018 iter 11 next_points [{'alpha': 2.3218670861643314, 'batch_size': 203, 'beta_1': 0.9674216553056576, 'beta_2': 0.9999762875438912, 'epsilon': 9.179430898984712e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.000783998155914702, 'tol': 0.003562819213574587, 'validation_fraction': 0.5533482327818319}]
function_evaluation time 0.917935 value -0.908825 suggestion {'alpha': 2.3218670861643314, 'batch_size': 203, 'beta_1': 0.9674216553056576, 'beta_2': 0.9999762875438912, 'epsilon': 9.179430898984712e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.000783998155914702, 'tol': 0.003562819213574587, 'validation_fraction': 0.5533482327818319}
observation time 0.001332, current best -0.962420 at iter 11
suggestion time taken 0.001661 iter 12 next_points [{'alpha': 9.447853905360886e-05, 'batch_size': 86, 'beta_1': 0.653526272479906, 'beta_2': 0.9999895852097762, 'epsilon': 1.722407154742183e-08, 'hidden_layer_sizes': 121, 'learning_rate_init': 8.133079802777083e-05, 'tol': 0.023543675393962217, 'validation_fraction': 0.48227268482978125}]
function_evaluation time 0.508543 value -0.244957 suggestion {'alpha': 9.447853905360886e-05, 'batch_size': 86, 'beta_1': 0.653526272479906, 'beta_2': 0.9999895852097762, 'epsilon': 1.722407154742183e-08, 'hidden_layer_sizes': 121, 'learning_rate_init': 8.133079802777083e-05, 'tol': 0.023543675393962217, 'validation_fraction': 0.48227268482978125}
observation time 0.001397, current best -0.962420 at iter 12
suggestion time taken 0.001706 iter 13 next_points [{'alpha': 0.014334856351578086, 'batch_size': 159, 'beta_1': 0.9596038732726245, 'beta_2': 0.9990973535172994, 'epsilon': 9.913871298004055e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.05515205396232695, 'tol': 0.010616714794196645, 'validation_fraction': 0.8820882862983471}]
function_evaluation time 0.210414 value -0.400779 suggestion {'alpha': 0.014334856351578086, 'batch_size': 159, 'beta_1': 0.9596038732726245, 'beta_2': 0.9990973535172994, 'epsilon': 9.913871298004055e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.05515205396232695, 'tol': 0.010616714794196645, 'validation_fraction': 0.8820882862983471}
observation time 0.001377, current best -0.962420 at iter 13
suggestion time taken 0.001698 iter 14 next_points [{'alpha': 3.3193400950022256, 'batch_size': 126, 'beta_1': 0.7394904006497458, 'beta_2': 0.9974680752501864, 'epsilon': 3.116807752289733e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.0008062872100487635, 'tol': 1.0354204721190119e-05, 'validation_fraction': 0.7940419030922176}]
function_evaluation time 1.588410 value -0.907457 suggestion {'alpha': 3.3193400950022256, 'batch_size': 126, 'beta_1': 0.7394904006497458, 'beta_2': 0.9974680752501864, 'epsilon': 3.116807752289733e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.0008062872100487635, 'tol': 1.0354204721190119e-05, 'validation_fraction': 0.7940419030922176}
observation time 0.001380, current best -0.962420 at iter 14
saving meta data: {'args': {'--uuid': 'b2433696180d5e758c1d779c66f96182', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

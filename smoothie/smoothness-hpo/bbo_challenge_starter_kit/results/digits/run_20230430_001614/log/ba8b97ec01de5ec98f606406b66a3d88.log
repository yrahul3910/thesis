running: {'--uuid': 'ba8b97ec01de5ec98f606406b66a3d88', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u ba8b97ec01de5ec98f606406b66a3d88 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002216 iter 0 next_points [{'alpha': 0.002814644045642308, 'batch_size': 176, 'beta_1': 0.8343609426198647, 'beta_2': 0.9999498604806619, 'epsilon': 1.1362522254775654e-07, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.001045166849985492, 'tol': 0.08650554547520892, 'validation_fraction': 0.3460996450506368}]
function_evaluation time 0.518220 value -0.935284 suggestion {'alpha': 0.002814644045642308, 'batch_size': 176, 'beta_1': 0.8343609426198647, 'beta_2': 0.9999498604806619, 'epsilon': 1.1362522254775654e-07, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.001045166849985492, 'tol': 0.08650554547520892, 'validation_fraction': 0.3460996450506368}
observation time 0.001722, current best -0.935284 at iter 0
suggestion time taken 0.001811 iter 1 next_points [{'alpha': 4.68353357537628, 'batch_size': 210, 'beta_1': 0.9832483627425318, 'beta_2': 0.9980344305920102, 'epsilon': 5.595866634969162e-08, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.00027356042088423594, 'tol': 0.0005545609709995986, 'validation_fraction': 0.10044956950756688}]
function_evaluation time 1.562086 value -0.885893 suggestion {'alpha': 4.68353357537628, 'batch_size': 210, 'beta_1': 0.9832483627425318, 'beta_2': 0.9980344305920102, 'epsilon': 5.595866634969162e-08, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.00027356042088423594, 'tol': 0.0005545609709995986, 'validation_fraction': 0.10044956950756688}
observation time 0.001410, current best -0.935284 at iter 1
suggestion time taken 0.001774 iter 2 next_points [{'alpha': 0.000316052954508051, 'batch_size': 221, 'beta_1': 0.657290417862485, 'beta_2': 0.9655035491031855, 'epsilon': 4.426058642971844e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.002670787915127686, 'tol': 1.1664160825760868e-05, 'validation_fraction': 0.3614371821969646}]
function_evaluation time 1.364303 value -0.964520 suggestion {'alpha': 0.000316052954508051, 'batch_size': 221, 'beta_1': 0.657290417862485, 'beta_2': 0.9655035491031855, 'epsilon': 4.426058642971844e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.002670787915127686, 'tol': 1.1664160825760868e-05, 'validation_fraction': 0.3614371821969646}
observation time 0.001380, current best -0.964520 at iter 2
suggestion time taken 0.001713 iter 3 next_points [{'alpha': 9.040372782228502, 'batch_size': 60, 'beta_1': 0.5132688522315358, 'beta_2': 0.9999621373264644, 'epsilon': 2.968780077782222e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.021335960668140235, 'tol': 0.00940993452635118, 'validation_fraction': 0.19530561563196983}]
function_evaluation time 1.106546 value -0.926261 suggestion {'alpha': 9.040372782228502, 'batch_size': 60, 'beta_1': 0.5132688522315358, 'beta_2': 0.9999621373264644, 'epsilon': 2.968780077782222e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.021335960668140235, 'tol': 0.00940993452635118, 'validation_fraction': 0.19530561563196983}
observation time 0.001416, current best -0.964520 at iter 3
suggestion time taken 0.001869 iter 4 next_points [{'alpha': 0.33943621446950323, 'batch_size': 236, 'beta_1': 0.9782482906548744, 'beta_2': 0.9781047151130774, 'epsilon': 1.647963900826667e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.06545630448644957, 'tol': 0.00015937150307761798, 'validation_fraction': 0.17773747988611918}]
function_evaluation time 0.876739 value -0.908800 suggestion {'alpha': 0.33943621446950323, 'batch_size': 236, 'beta_1': 0.9782482906548744, 'beta_2': 0.9781047151130774, 'epsilon': 1.647963900826667e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.06545630448644957, 'tol': 0.00015937150307761798, 'validation_fraction': 0.17773747988611918}
observation time 0.001416, current best -0.964520 at iter 4
suggestion time taken 0.001777 iter 5 next_points [{'alpha': 9.796455867835052e-05, 'batch_size': 116, 'beta_1': 0.9858269723328441, 'beta_2': 0.9998337068925608, 'epsilon': 1.9073449143512353e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.003866142799101401, 'tol': 0.02114010191793041, 'validation_fraction': 0.8979562386832276}]
function_evaluation time 0.327482 value -0.676423 suggestion {'alpha': 9.796455867835052e-05, 'batch_size': 116, 'beta_1': 0.9858269723328441, 'beta_2': 0.9998337068925608, 'epsilon': 1.9073449143512353e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.003866142799101401, 'tol': 0.02114010191793041, 'validation_fraction': 0.8979562386832276}
observation time 0.001361, current best -0.964520 at iter 5
suggestion time taken 0.001748 iter 6 next_points [{'alpha': 6.611439294201924e-05, 'batch_size': 191, 'beta_1': 0.7191992457111421, 'beta_2': 0.9999982424056381, 'epsilon': 3.5587708380609255e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.00043022444827819234, 'tol': 0.03174765464717932, 'validation_fraction': 0.562753880881453}]
function_evaluation time 0.576654 value -0.860112 suggestion {'alpha': 6.611439294201924e-05, 'batch_size': 191, 'beta_1': 0.7191992457111421, 'beta_2': 0.9999982424056381, 'epsilon': 3.5587708380609255e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.00043022444827819234, 'tol': 0.03174765464717932, 'validation_fraction': 0.562753880881453}
observation time 0.001378, current best -0.964520 at iter 6
suggestion time taken 0.001740 iter 7 next_points [{'alpha': 0.0014396763216033915, 'batch_size': 239, 'beta_1': 0.7264650118402022, 'beta_2': 0.9999945597882558, 'epsilon': 2.7745286750406815e-09, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.00013147877441527716, 'tol': 6.91176305421595e-05, 'validation_fraction': 0.4814309273053894}]
function_evaluation time 3.506642 value -0.906756 suggestion {'alpha': 0.0014396763216033915, 'batch_size': 239, 'beta_1': 0.7264650118402022, 'beta_2': 0.9999945597882558, 'epsilon': 2.7745286750406815e-09, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.00013147877441527716, 'tol': 6.91176305421595e-05, 'validation_fraction': 0.4814309273053894}
observation time 0.001362, current best -0.964520 at iter 7
suggestion time taken 0.001757 iter 8 next_points [{'alpha': 2.4251340529027152e-05, 'batch_size': 19, 'beta_1': 0.7833214026404987, 'beta_2': 0.9965697329245474, 'epsilon': 1.3688721755262087e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 3.466593101790598e-05, 'tol': 0.0004238267210239422, 'validation_fraction': 0.8572968333568952}]
function_evaluation time 5.907786 value -0.855263 suggestion {'alpha': 2.4251340529027152e-05, 'batch_size': 19, 'beta_1': 0.7833214026404987, 'beta_2': 0.9965697329245474, 'epsilon': 1.3688721755262087e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 3.466593101790598e-05, 'tol': 0.0004238267210239422, 'validation_fraction': 0.8572968333568952}
observation time 0.001381, current best -0.964520 at iter 8
suggestion time taken 0.001749 iter 9 next_points [{'alpha': 0.004758997475311409, 'batch_size': 65, 'beta_1': 0.9521457967959441, 'beta_2': 0.999478086903017, 'epsilon': 1.0701459771460944e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.04432150319843843, 'tol': 0.0009983648792449746, 'validation_fraction': 0.29689565160790604}]
function_evaluation time 1.227734 value -0.896303 suggestion {'alpha': 0.004758997475311409, 'batch_size': 65, 'beta_1': 0.9521457967959441, 'beta_2': 0.999478086903017, 'epsilon': 1.0701459771460944e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.04432150319843843, 'tol': 0.0009983648792449746, 'validation_fraction': 0.29689565160790604}
observation time 0.001352, current best -0.964520 at iter 9
suggestion time taken 0.001755 iter 10 next_points [{'alpha': 0.0532871994962933, 'batch_size': 137, 'beta_1': 0.9371689352157127, 'beta_2': 0.9259816528883605, 'epsilon': 7.407307507196803e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 1.1548255362597618e-05, 'tol': 0.006078044747265191, 'validation_fraction': 0.7809719724715705}]
function_evaluation time 0.193971 value -0.113451 suggestion {'alpha': 0.0532871994962933, 'batch_size': 137, 'beta_1': 0.9371689352157127, 'beta_2': 0.9259816528883605, 'epsilon': 7.407307507196803e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 1.1548255362597618e-05, 'tol': 0.006078044747265191, 'validation_fraction': 0.7809719724715705}
observation time 0.001358, current best -0.964520 at iter 10
suggestion time taken 0.002032 iter 11 next_points [{'alpha': 1.037808073086783e-05, 'batch_size': 92, 'beta_1': 0.9897312925905076, 'beta_2': 0.9999903932196743, 'epsilon': 4.931863704487142e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.02354871936882569, 'tol': 2.543358915190129e-05, 'validation_fraction': 0.7173961059518983}]
function_evaluation time 0.923846 value -0.900508 suggestion {'alpha': 1.037808073086783e-05, 'batch_size': 92, 'beta_1': 0.9897312925905076, 'beta_2': 0.9999903932196743, 'epsilon': 4.931863704487142e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.02354871936882569, 'tol': 2.543358915190129e-05, 'validation_fraction': 0.7173961059518983}
observation time 0.001362, current best -0.964520 at iter 11
suggestion time taken 0.002007 iter 12 next_points [{'alpha': 0.0005634577260625857, 'batch_size': 24, 'beta_1': 0.9611571340868271, 'beta_2': 0.999900574983386, 'epsilon': 9.828059675876061e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.8108810979299025e-05, 'tol': 2.6448891986933312e-05, 'validation_fraction': 0.22701836027120392}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 11.099708 value -0.693431 suggestion {'alpha': 0.0005634577260625857, 'batch_size': 24, 'beta_1': 0.9611571340868271, 'beta_2': 0.999900574983386, 'epsilon': 9.828059675876061e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.8108810979299025e-05, 'tol': 2.6448891986933312e-05, 'validation_fraction': 0.22701836027120392}
observation time 0.001359, current best -0.964520 at iter 12
suggestion time taken 0.001729 iter 13 next_points [{'alpha': 0.11490647896945462, 'batch_size': 149, 'beta_1': 0.8661070187229207, 'beta_2': 0.9999979029870455, 'epsilon': 2.293540756282058e-08, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.005563122452748948, 'tol': 0.0032612719340864124, 'validation_fraction': 0.42311452821081624}]
function_evaluation time 0.625006 value -0.954082 suggestion {'alpha': 0.11490647896945462, 'batch_size': 149, 'beta_1': 0.8661070187229207, 'beta_2': 0.9999979029870455, 'epsilon': 2.293540756282058e-08, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.005563122452748948, 'tol': 0.0032612719340864124, 'validation_fraction': 0.42311452821081624}
observation time 0.001349, current best -0.964520 at iter 13
suggestion time taken 0.001683 iter 14 next_points [{'alpha': 0.6601286212774352, 'batch_size': 39, 'beta_1': 0.9687558083096158, 'beta_2': 0.9999865705991452, 'epsilon': 8.155179251298164e-08, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0005642789945204663, 'tol': 0.001858986193580966, 'validation_fraction': 0.8444145864976014}]
function_evaluation time 1.211926 value -0.878201 suggestion {'alpha': 0.6601286212774352, 'batch_size': 39, 'beta_1': 0.9687558083096158, 'beta_2': 0.9999865705991452, 'epsilon': 8.155179251298164e-08, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0005642789945204663, 'tol': 0.001858986193580966, 'validation_fraction': 0.8444145864976014}
observation time 0.001346, current best -0.964520 at iter 14
saving meta data: {'args': {'--uuid': 'ba8b97ec01de5ec98f606406b66a3d88', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

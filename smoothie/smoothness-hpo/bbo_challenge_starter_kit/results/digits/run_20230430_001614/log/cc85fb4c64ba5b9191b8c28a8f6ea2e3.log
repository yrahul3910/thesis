running: {'--uuid': 'cc85fb4c64ba5b9191b8c28a8f6ea2e3', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u cc85fb4c64ba5b9191b8c28a8f6ea2e3 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002420 iter 0 next_points [{'alpha': 1.3703102903545882e-05, 'batch_size': 172, 'beta_1': 0.9750552504625829, 'beta_2': 0.9155758619860163, 'epsilon': 2.2974604251673922e-07, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.024163950907345917, 'tol': 0.0002806710743099566, 'validation_fraction': 0.35070979509103123}]
function_evaluation time 1.095129 value -0.929728 suggestion {'alpha': 1.3703102903545882e-05, 'batch_size': 172, 'beta_1': 0.9750552504625829, 'beta_2': 0.9155758619860163, 'epsilon': 2.2974604251673922e-07, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.024163950907345917, 'tol': 0.0002806710743099566, 'validation_fraction': 0.35070979509103123}
observation time 0.000065, current best -0.929728 at iter 0
suggestion time taken 0.002594 iter 1 next_points [{'alpha': 0.11297690245451536, 'batch_size': 185, 'beta_1': 0.881299862946666, 'beta_2': 0.9301549739192778, 'epsilon': 1.9967982814295974e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.00037638508886029333, 'tol': 0.0018242049949896142, 'validation_fraction': 0.18847391641707276}]
function_evaluation time 1.412534 value -0.932506 suggestion {'alpha': 0.11297690245451536, 'batch_size': 185, 'beta_1': 0.881299862946666, 'beta_2': 0.9301549739192778, 'epsilon': 1.9967982814295974e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.00037638508886029333, 'tol': 0.0018242049949896142, 'validation_fraction': 0.18847391641707276}
observation time 0.000070, current best -0.932506 at iter 1
suggestion time taken 0.002141 iter 2 next_points [{'alpha': 0.21023010947311752, 'batch_size': 25, 'beta_1': 0.7526982465101474, 'beta_2': 0.9713999554642182, 'epsilon': 2.379468291494697e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.009950181721349337, 'tol': 0.016027849963742142, 'validation_fraction': 0.5240891807604956}]
function_evaluation time 0.831893 value -0.940159 suggestion {'alpha': 0.21023010947311752, 'batch_size': 25, 'beta_1': 0.7526982465101474, 'beta_2': 0.9713999554642182, 'epsilon': 2.379468291494697e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.009950181721349337, 'tol': 0.016027849963742142, 'validation_fraction': 0.5240891807604956}
observation time 0.000072, current best -0.940159 at iter 2
suggestion time taken 0.002400 iter 3 next_points [{'alpha': 0.8648773508228927, 'batch_size': 104, 'beta_1': 0.7649874954699801, 'beta_2': 0.9387326398570814, 'epsilon': 3.7275035516759173e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 2.8966161124792084e-05, 'tol': 0.0004036002439230695, 'validation_fraction': 0.7589353017877065}]
function_evaluation time 0.925346 value -0.243765 suggestion {'alpha': 0.8648773508228927, 'batch_size': 104, 'beta_1': 0.7649874954699801, 'beta_2': 0.9387326398570814, 'epsilon': 3.7275035516759173e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 2.8966161124792084e-05, 'tol': 0.0004036002439230695, 'validation_fraction': 0.7589353017877065}
observation time 0.000067, current best -0.940159 at iter 3
suggestion time taken 0.002120 iter 4 next_points [{'alpha': 0.6265590552086533, 'batch_size': 34, 'beta_1': 0.8509548181664166, 'beta_2': 0.9704426053989776, 'epsilon': 4.579395866076495e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0016197253789301971, 'tol': 0.009744370166244635, 'validation_fraction': 0.5784222062468402}]
function_evaluation time 0.725178 value -0.944331 suggestion {'alpha': 0.6265590552086533, 'batch_size': 34, 'beta_1': 0.8509548181664166, 'beta_2': 0.9704426053989776, 'epsilon': 4.579395866076495e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0016197253789301971, 'tol': 0.009744370166244635, 'validation_fraction': 0.5784222062468402}
observation time 0.000071, current best -0.944331 at iter 4
suggestion time taken 0.002129 iter 5 next_points [{'alpha': 0.00029350645841667725, 'batch_size': 101, 'beta_1': 0.9044787470621317, 'beta_2': 0.9996732833784543, 'epsilon': 7.250639142603267e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.05760347996815702, 'tol': 0.010296924316030657, 'validation_fraction': 0.1571073887221023}]
function_evaluation time 1.015421 value -0.883077 suggestion {'alpha': 0.00029350645841667725, 'batch_size': 101, 'beta_1': 0.9044787470621317, 'beta_2': 0.9996732833784543, 'epsilon': 7.250639142603267e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.05760347996815702, 'tol': 0.010296924316030657, 'validation_fraction': 0.1571073887221023}
observation time 0.000069, current best -0.944331 at iter 5
suggestion time taken 0.002397 iter 6 next_points [{'alpha': 1.2931409077788149e-05, 'batch_size': 74, 'beta_1': 0.6889535333477723, 'beta_2': 0.9064930618183392, 'epsilon': 2.129758378916979e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0829232138229748, 'tol': 0.00016735394425520327, 'validation_fraction': 0.5983473962343456}]
function_evaluation time 0.661692 value -0.563749 suggestion {'alpha': 1.2931409077788149e-05, 'batch_size': 74, 'beta_1': 0.6889535333477723, 'beta_2': 0.9064930618183392, 'epsilon': 2.129758378916979e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0829232138229748, 'tol': 0.00016735394425520327, 'validation_fraction': 0.5983473962343456}
observation time 0.000072, current best -0.944331 at iter 6
suggestion time taken 0.002199 iter 7 next_points [{'alpha': 0.6831384165622326, 'batch_size': 91, 'beta_1': 0.6192429752106268, 'beta_2': 0.9616193077597364, 'epsilon': 3.708672353679451e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.013330616626915662, 'tol': 0.00017695668281757888, 'validation_fraction': 0.4652200300858767}]
function_evaluation time 0.985026 value -0.965912 suggestion {'alpha': 0.6831384165622326, 'batch_size': 91, 'beta_1': 0.6192429752106268, 'beta_2': 0.9616193077597364, 'epsilon': 3.708672353679451e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.013330616626915662, 'tol': 0.00017695668281757888, 'validation_fraction': 0.4652200300858767}
observation time 0.000076, current best -0.965912 at iter 7
suggestion time taken 0.002148 iter 8 next_points [{'alpha': 0.0287604780805992, 'batch_size': 17, 'beta_1': 0.5816102271496448, 'beta_2': 0.918279862872571, 'epsilon': 6.425348674811813e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 2.6077159019283355e-05, 'tol': 0.0032671375871971197, 'validation_fraction': 0.26507356229313694}]
function_evaluation time 10.898880 value -0.935279 suggestion {'alpha': 0.0287604780805992, 'batch_size': 17, 'beta_1': 0.5816102271496448, 'beta_2': 0.918279862872571, 'epsilon': 6.425348674811813e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 2.6077159019283355e-05, 'tol': 0.0032671375871971197, 'validation_fraction': 0.26507356229313694}
observation time 0.000072, current best -0.965912 at iter 8
suggestion time taken 0.002125 iter 9 next_points [{'alpha': 0.0003340624672653641, 'batch_size': 136, 'beta_1': 0.7954041443388585, 'beta_2': 0.9497691586367554, 'epsilon': 4.0642259948868683e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.01004082010407041, 'tol': 1.7539037298990874e-05, 'validation_fraction': 0.5476239837167663}]
function_evaluation time 1.288312 value -0.959647 suggestion {'alpha': 0.0003340624672653641, 'batch_size': 136, 'beta_1': 0.7954041443388585, 'beta_2': 0.9497691586367554, 'epsilon': 4.0642259948868683e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.01004082010407041, 'tol': 1.7539037298990874e-05, 'validation_fraction': 0.5476239837167663}
observation time 0.000071, current best -0.965912 at iter 9
suggestion time taken 0.002148 iter 10 next_points [{'alpha': 0.10638349364002526, 'batch_size': 153, 'beta_1': 0.534799455451564, 'beta_2': 0.9299609954651147, 'epsilon': 2.9659346318781034e-08, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0011625644189569154, 'tol': 0.00027633623995013676, 'validation_fraction': 0.14721358400526285}]
function_evaluation time 1.346638 value -0.963811 suggestion {'alpha': 0.10638349364002526, 'batch_size': 153, 'beta_1': 0.534799455451564, 'beta_2': 0.9299609954651147, 'epsilon': 2.9659346318781034e-08, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0011625644189569154, 'tol': 0.00027633623995013676, 'validation_fraction': 0.14721358400526285}
observation time 0.000079, current best -0.965912 at iter 10
suggestion time taken 0.002106 iter 11 next_points [{'alpha': 0.0002953664769197858, 'batch_size': 238, 'beta_1': 0.6259275971923706, 'beta_2': 0.9796920828362213, 'epsilon': 3.852174249047089e-08, 'hidden_layer_sizes': 72, 'learning_rate_init': 2.5905301507639473e-05, 'tol': 8.326432691054481e-05, 'validation_fraction': 0.4635415107293658}]
function_evaluation time 1.243347 value -0.195683 suggestion {'alpha': 0.0002953664769197858, 'batch_size': 238, 'beta_1': 0.6259275971923706, 'beta_2': 0.9796920828362213, 'epsilon': 3.852174249047089e-08, 'hidden_layer_sizes': 72, 'learning_rate_init': 2.5905301507639473e-05, 'tol': 8.326432691054481e-05, 'validation_fraction': 0.4635415107293658}
observation time 0.000072, current best -0.965912 at iter 11
suggestion time taken 0.002133 iter 12 next_points [{'alpha': 0.23611096900776868, 'batch_size': 211, 'beta_1': 0.5772903176422323, 'beta_2': 0.9347700608121101, 'epsilon': 3.887999552553552e-08, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.003738335864515401, 'tol': 0.00013040356780227969, 'validation_fraction': 0.6217285151917956}]
function_evaluation time 0.888770 value -0.947123 suggestion {'alpha': 0.23611096900776868, 'batch_size': 211, 'beta_1': 0.5772903176422323, 'beta_2': 0.9347700608121101, 'epsilon': 3.887999552553552e-08, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.003738335864515401, 'tol': 0.00013040356780227969, 'validation_fraction': 0.6217285151917956}
observation time 0.000075, current best -0.965912 at iter 12
suggestion time taken 0.002218 iter 13 next_points [{'alpha': 0.0001739440923377274, 'batch_size': 38, 'beta_1': 0.6558689960638127, 'beta_2': 0.9930700565778976, 'epsilon': 4.70428888879353e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.03979252995722977, 'tol': 0.020755420385692187, 'validation_fraction': 0.1865326066109338}]
function_evaluation time 0.916738 value -0.934606 suggestion {'alpha': 0.0001739440923377274, 'batch_size': 38, 'beta_1': 0.6558689960638127, 'beta_2': 0.9930700565778976, 'epsilon': 4.70428888879353e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.03979252995722977, 'tol': 0.020755420385692187, 'validation_fraction': 0.1865326066109338}
observation time 0.000070, current best -0.965912 at iter 13
suggestion time taken 0.002155 iter 14 next_points [{'alpha': 0.0007286863050363109, 'batch_size': 46, 'beta_1': 0.6778827619465371, 'beta_2': 0.9420463230291017, 'epsilon': 1.1158061830177578e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.00011495131752790717, 'tol': 0.0009073236336138449, 'validation_fraction': 0.6764955433819657}]
function_evaluation time 4.585917 value -0.943631 suggestion {'alpha': 0.0007286863050363109, 'batch_size': 46, 'beta_1': 0.6778827619465371, 'beta_2': 0.9420463230291017, 'epsilon': 1.1158061830177578e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.00011495131752790717, 'tol': 0.0009073236336138449, 'validation_fraction': 0.6764955433819657}
observation time 0.000076, current best -0.965912 at iter 14
saving meta data: {'args': {'--uuid': 'cc85fb4c64ba5b9191b8c28a8f6ea2e3', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

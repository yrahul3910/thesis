running: {'--uuid': '4f896c1181b95368810d47c4e84818b2', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u 4f896c1181b95368810d47c4e84818b2 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study smoothness MLP-adam digits acc 15 1
with data root: None
suggestion time taken 9.497978 iter 0 next_points [{'alpha': 0.04106469628599189, 'batch_size': 11, 'beta_1': 0.5700488561161527, 'beta_2': 0.9922267783444491, 'epsilon': 1.253582597359401e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.00044881176357144373, 'tol': 0.0003002680944356427, 'validation_fraction': 0.15149370216813196}]
function_evaluation time 3.374808 value -0.956170 suggestion {'alpha': 0.04106469628599189, 'batch_size': 11, 'beta_1': 0.5700488561161527, 'beta_2': 0.9922267783444491, 'epsilon': 1.253582597359401e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.00044881176357144373, 'tol': 0.0003002680944356427, 'validation_fraction': 0.15149370216813196}
observation time 0.000010, current best -0.956170 at iter 0
suggestion time taken 9.240366 iter 1 next_points [{'alpha': 0.1847592601594048, 'batch_size': 36, 'beta_1': 0.9722337227552399, 'beta_2': 0.9983931193747858, 'epsilon': 4.1971683782281754e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.0015727802281158695, 'tol': 0.0025154249178003054, 'validation_fraction': 0.2269687874045671}]
function_evaluation time 1.693257 value -0.961723 suggestion {'alpha': 0.1847592601594048, 'batch_size': 36, 'beta_1': 0.9722337227552399, 'beta_2': 0.9983931193747858, 'epsilon': 4.1971683782281754e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.0015727802281158695, 'tol': 0.0025154249178003054, 'validation_fraction': 0.2269687874045671}
observation time 0.000006, current best -0.961723 at iter 1
suggestion time taken 9.189345 iter 2 next_points [{'alpha': 1.5153600153630718e-05, 'batch_size': 38, 'beta_1': 0.9893172291757985, 'beta_2': 0.9796539978625821, 'epsilon': 7.53420238052741e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.0005215138183287721, 'tol': 0.031854533205834784, 'validation_fraction': 0.4357664340924907}]
function_evaluation time 0.903697 value -0.936677 suggestion {'alpha': 1.5153600153630718e-05, 'batch_size': 38, 'beta_1': 0.9893172291757985, 'beta_2': 0.9796539978625821, 'epsilon': 7.53420238052741e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.0005215138183287721, 'tol': 0.031854533205834784, 'validation_fraction': 0.4357664340924907}
observation time 0.000006, current best -0.961723 at iter 2
suggestion time taken 9.529405 iter 3 next_points [{'alpha': 1.319498000181371, 'batch_size': 21, 'beta_1': 0.5780384932432338, 'beta_2': 0.9966592083137571, 'epsilon': 9.550911666538915e-09, 'hidden_layer_sizes': 110, 'learning_rate_init': 4.896767717562022e-05, 'tol': 0.0020434845555636436, 'validation_fraction': 0.6792450799228918}]
function_evaluation time 6.220573 value -0.906064 suggestion {'alpha': 1.319498000181371, 'batch_size': 21, 'beta_1': 0.5780384932432338, 'beta_2': 0.9966592083137571, 'epsilon': 9.550911666538915e-09, 'hidden_layer_sizes': 110, 'learning_rate_init': 4.896767717562022e-05, 'tol': 0.0020434845555636436, 'validation_fraction': 0.6792450799228918}
observation time 0.000005, current best -0.961723 at iter 3
suggestion time taken 9.259437 iter 4 next_points [{'alpha': 0.05192385905583103, 'batch_size': 25, 'beta_1': 0.9660794479310219, 'beta_2': 0.9999967136651082, 'epsilon': 3.604248242926855e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 6.448731011164094e-05, 'tol': 2.0542259131709587e-05, 'validation_fraction': 0.5281401667269712}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 7.587914 value -0.900518 suggestion {'alpha': 0.05192385905583103, 'batch_size': 25, 'beta_1': 0.9660794479310219, 'beta_2': 0.9999967136651082, 'epsilon': 3.604248242926855e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 6.448731011164094e-05, 'tol': 2.0542259131709587e-05, 'validation_fraction': 0.5281401667269712}
observation time 0.000006, current best -0.961723 at iter 4
suggestion time taken 9.205921 iter 5 next_points [{'alpha': 6.435256164605574, 'batch_size': 14, 'beta_1': 0.8976849461445672, 'beta_2': 0.9965264765027674, 'epsilon': 6.977688421200459e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 3.1028132277702485e-05, 'tol': 4.778089875719943e-05, 'validation_fraction': 0.8686747737889172}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.356836 value -0.460025 suggestion {'alpha': 6.435256164605574, 'batch_size': 14, 'beta_1': 0.8976849461445672, 'beta_2': 0.9965264765027674, 'epsilon': 6.977688421200459e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 3.1028132277702485e-05, 'tol': 4.778089875719943e-05, 'validation_fraction': 0.8686747737889172}
observation time 0.000006, current best -0.961723 at iter 5
suggestion time taken 9.186804 iter 6 next_points [{'alpha': 1.58929230848669e-05, 'batch_size': 54, 'beta_1': 0.8579572148174016, 'beta_2': 0.9999627520408398, 'epsilon': 2.6906268999441044e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0028997064796541755, 'tol': 0.017022464236961753, 'validation_fraction': 0.1584522640918631}]
function_evaluation time 0.808533 value -0.966609 suggestion {'alpha': 1.58929230848669e-05, 'batch_size': 54, 'beta_1': 0.8579572148174016, 'beta_2': 0.9999627520408398, 'epsilon': 2.6906268999441044e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0028997064796541755, 'tol': 0.017022464236961753, 'validation_fraction': 0.1584522640918631}
observation time 0.000005, current best -0.966609 at iter 6
suggestion time taken 9.207620 iter 7 next_points [{'alpha': 0.00039183876651151467, 'batch_size': 22, 'beta_1': 0.5142560229759655, 'beta_2': 0.999996124348333, 'epsilon': 1.1425901186621991e-09, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.09787265081075668, 'tol': 0.0001225166796559726, 'validation_fraction': 0.13324136278090581}]
function_evaluation time 1.317139 value -0.339612 suggestion {'alpha': 0.00039183876651151467, 'batch_size': 22, 'beta_1': 0.5142560229759655, 'beta_2': 0.999996124348333, 'epsilon': 1.1425901186621991e-09, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.09787265081075668, 'tol': 0.0001225166796559726, 'validation_fraction': 0.13324136278090581}
observation time 0.000005, current best -0.966609 at iter 7
suggestion time taken 9.299816 iter 8 next_points [{'alpha': 6.496032593309136, 'batch_size': 24, 'beta_1': 0.9738422870813972, 'beta_2': 0.9897197609776653, 'epsilon': 5.976383615227253e-08, 'hidden_layer_sizes': 88, 'learning_rate_init': 4.3691871638385844e-05, 'tol': 3.848284502787086e-05, 'validation_fraction': 0.7137355289665916}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 5.679109 value -0.746489 suggestion {'alpha': 6.496032593309136, 'batch_size': 24, 'beta_1': 0.9738422870813972, 'beta_2': 0.9897197609776653, 'epsilon': 5.976383615227253e-08, 'hidden_layer_sizes': 88, 'learning_rate_init': 4.3691871638385844e-05, 'tol': 3.848284502787086e-05, 'validation_fraction': 0.7137355289665916}
observation time 0.000006, current best -0.966609 at iter 8
suggestion time taken 9.237521 iter 9 next_points [{'alpha': 0.00011863460456334003, 'batch_size': 30, 'beta_1': 0.7254620169195801, 'beta_2': 0.9999984634974727, 'epsilon': 2.1637175883061099e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.010847688599754261, 'tol': 0.02362141105165655, 'validation_fraction': 0.21074155847680323}]
function_evaluation time 0.891234 value -0.963819 suggestion {'alpha': 0.00011863460456334003, 'batch_size': 30, 'beta_1': 0.7254620169195801, 'beta_2': 0.9999984634974727, 'epsilon': 2.1637175883061099e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.010847688599754261, 'tol': 0.02362141105165655, 'validation_fraction': 0.21074155847680323}
observation time 0.000004, current best -0.966609 at iter 9
suggestion time taken 9.262911 iter 10 next_points [{'alpha': 1.9704561612378242, 'batch_size': 22, 'beta_1': 0.9575837835639617, 'beta_2': 0.9995937662942402, 'epsilon': 6.26311173973847e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.015431829580229928, 'tol': 0.06892931496725384, 'validation_fraction': 0.29885987398607866}]
function_evaluation time 0.999023 value -0.938773 suggestion {'alpha': 1.9704561612378242, 'batch_size': 22, 'beta_1': 0.9575837835639617, 'beta_2': 0.9995937662942402, 'epsilon': 6.26311173973847e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.015431829580229928, 'tol': 0.06892931496725384, 'validation_fraction': 0.29885987398607866}
observation time 0.000006, current best -0.966609 at iter 10
suggestion time taken 9.275711 iter 11 next_points [{'alpha': 0.0001318933795014838, 'batch_size': 11, 'beta_1': 0.9340356327997521, 'beta_2': 0.9999959291261393, 'epsilon': 2.6090258630624536e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 1.0083500209685707e-05, 'tol': 0.022077126723192054, 'validation_fraction': 0.5712696903679019}]
function_evaluation time 0.865578 value -0.097425 suggestion {'alpha': 0.0001318933795014838, 'batch_size': 11, 'beta_1': 0.9340356327997521, 'beta_2': 0.9999959291261393, 'epsilon': 2.6090258630624536e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 1.0083500209685707e-05, 'tol': 0.022077126723192054, 'validation_fraction': 0.5712696903679019}
observation time 0.000005, current best -0.966609 at iter 11
suggestion time taken 9.190913 iter 12 next_points [{'alpha': 0.08500367601610648, 'batch_size': 30, 'beta_1': 0.8835805577085939, 'beta_2': 0.9999382006186558, 'epsilon': 9.206665947968624e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.08790529378192206, 'tol': 1.832081716439682e-05, 'validation_fraction': 0.16981324087835123}]
function_evaluation time 0.928605 value -0.313942 suggestion {'alpha': 0.08500367601610648, 'batch_size': 30, 'beta_1': 0.8835805577085939, 'beta_2': 0.9999382006186558, 'epsilon': 9.206665947968624e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.08790529378192206, 'tol': 1.832081716439682e-05, 'validation_fraction': 0.16981324087835123}
observation time 0.000006, current best -0.966609 at iter 12
suggestion time taken 9.252393 iter 13 next_points [{'alpha': 0.3622510597396205, 'batch_size': 12, 'beta_1': 0.9768461929537948, 'beta_2': 0.9999228784217467, 'epsilon': 4.198060446643109e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0011784259143830017, 'tol': 0.00038044404314431025, 'validation_fraction': 0.11142075614530315}]
function_evaluation time 2.919355 value -0.970095 suggestion {'alpha': 0.3622510597396205, 'batch_size': 12, 'beta_1': 0.9768461929537948, 'beta_2': 0.9999228784217467, 'epsilon': 4.198060446643109e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0011784259143830017, 'tol': 0.00038044404314431025, 'validation_fraction': 0.11142075614530315}
observation time 0.000005, current best -0.970095 at iter 13
suggestion time taken 9.330732 iter 14 next_points [{'alpha': 2.4353870078289262e-05, 'batch_size': 10, 'beta_1': 0.9788887452166687, 'beta_2': 0.986216209360486, 'epsilon': 4.650379993268152e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.037903674968312026, 'tol': 0.07917795068258582, 'validation_fraction': 0.5510583156631613}]
function_evaluation time 1.062751 value -0.578971 suggestion {'alpha': 2.4353870078289262e-05, 'batch_size': 10, 'beta_1': 0.9788887452166687, 'beta_2': 0.986216209360486, 'epsilon': 4.650379993268152e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.037903674968312026, 'tol': 0.07917795068258582, 'validation_fraction': 0.5510583156631613}
observation time 0.000005, current best -0.970095 at iter 14
saving meta data: {'args': {'--uuid': '4f896c1181b95368810d47c4e84818b2', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

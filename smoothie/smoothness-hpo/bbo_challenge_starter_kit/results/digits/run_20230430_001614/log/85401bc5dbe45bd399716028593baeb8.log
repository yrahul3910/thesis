running: {'--uuid': '85401bc5dbe45bd399716028593baeb8', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u 85401bc5dbe45bd399716028593baeb8 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study smoothness MLP-adam digits acc 15 1
with data root: None
suggestion time taken 9.568507 iter 0 next_points [{'alpha': 0.000769358018668908, 'batch_size': 13, 'beta_1': 0.791247833851063, 'beta_2': 0.9999917515227573, 'epsilon': 3.222481527292909e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.000718104518223539, 'tol': 0.0011048679999324852, 'validation_fraction': 0.11990613062238366}]
function_evaluation time 3.514529 value -0.963833 suggestion {'alpha': 0.000769358018668908, 'batch_size': 13, 'beta_1': 0.791247833851063, 'beta_2': 0.9999917515227573, 'epsilon': 3.222481527292909e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.000718104518223539, 'tol': 0.0011048679999324852, 'validation_fraction': 0.11990613062238366}
observation time 0.000006, current best -0.963833 at iter 0
suggestion time taken 9.223795 iter 1 next_points [{'alpha': 0.004146468222608709, 'batch_size': 14, 'beta_1': 0.5284566808010299, 'beta_2': 0.9999852803291575, 'epsilon': 1.290373472707511e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.03973012764746805, 'tol': 0.0014604512000891906, 'validation_fraction': 0.7945439902698237}]
function_evaluation time 0.894257 value -0.880335 suggestion {'alpha': 0.004146468222608709, 'batch_size': 14, 'beta_1': 0.5284566808010299, 'beta_2': 0.9999852803291575, 'epsilon': 1.290373472707511e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.03973012764746805, 'tol': 0.0014604512000891906, 'validation_fraction': 0.7945439902698237}
observation time 0.000006, current best -0.963833 at iter 1
suggestion time taken 9.248540 iter 2 next_points [{'alpha': 0.018819318980383925, 'batch_size': 30, 'beta_1': 0.7669818442838213, 'beta_2': 0.9705724881802488, 'epsilon': 4.955769890121023e-07, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.01019131933862628, 'tol': 0.0002577801810562193, 'validation_fraction': 0.8377728446244525}]
function_evaluation time 0.783590 value -0.918598 suggestion {'alpha': 0.018819318980383925, 'batch_size': 30, 'beta_1': 0.7669818442838213, 'beta_2': 0.9705724881802488, 'epsilon': 4.955769890121023e-07, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.01019131933862628, 'tol': 0.0002577801810562193, 'validation_fraction': 0.8377728446244525}
observation time 0.000006, current best -0.963833 at iter 2
suggestion time taken 9.530329 iter 3 next_points [{'alpha': 0.00019809738534790972, 'batch_size': 28, 'beta_1': 0.9897494560329089, 'beta_2': 0.9550498669653273, 'epsilon': 8.264003747183246e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.004787859515882456, 'tol': 0.02430796089506772, 'validation_fraction': 0.7997477473390803}]
function_evaluation time 0.411248 value -0.899081 suggestion {'alpha': 0.00019809738534790972, 'batch_size': 28, 'beta_1': 0.9897494560329089, 'beta_2': 0.9550498669653273, 'epsilon': 8.264003747183246e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.004787859515882456, 'tol': 0.02430796089506772, 'validation_fraction': 0.7997477473390803}
observation time 0.000006, current best -0.963833 at iter 3
suggestion time taken 9.269382 iter 4 next_points [{'alpha': 0.004229514595021538, 'batch_size': 23, 'beta_1': 0.8266061472558043, 'beta_2': 0.9904369868584745, 'epsilon': 3.2287880325352603e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0035736021074997586, 'tol': 0.08221065929736598, 'validation_fraction': 0.11471972115097728}]
function_evaluation time 0.875823 value -0.959647 suggestion {'alpha': 0.004229514595021538, 'batch_size': 23, 'beta_1': 0.8266061472558043, 'beta_2': 0.9904369868584745, 'epsilon': 3.2287880325352603e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0035736021074997586, 'tol': 0.08221065929736598, 'validation_fraction': 0.11471972115097728}
observation time 0.000006, current best -0.963833 at iter 4
suggestion time taken 9.241707 iter 5 next_points [{'alpha': 6.7906290102445, 'batch_size': 18, 'beta_1': 0.8931439020806449, 'beta_2': 0.9945166927823421, 'epsilon': 2.1367961572178202e-07, 'hidden_layer_sizes': 108, 'learning_rate_init': 8.641882373673884e-05, 'tol': 0.0002809330389260407, 'validation_fraction': 0.8326557027398104}]
function_evaluation time 5.028826 value -0.901895 suggestion {'alpha': 6.7906290102445, 'batch_size': 18, 'beta_1': 0.8931439020806449, 'beta_2': 0.9945166927823421, 'epsilon': 2.1367961572178202e-07, 'hidden_layer_sizes': 108, 'learning_rate_init': 8.641882373673884e-05, 'tol': 0.0002809330389260407, 'validation_fraction': 0.8326557027398104}
observation time 0.000006, current best -0.963833 at iter 5
suggestion time taken 9.207905 iter 6 next_points [{'alpha': 7.654260804693645, 'batch_size': 38, 'beta_1': 0.702554997800189, 'beta_2': 0.9999168310755986, 'epsilon': 2.958656334744096e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.00018305029328049126, 'tol': 0.0006363211559634727, 'validation_fraction': 0.2880036652065957}]
function_evaluation time 4.582794 value -0.945030 suggestion {'alpha': 7.654260804693645, 'batch_size': 38, 'beta_1': 0.702554997800189, 'beta_2': 0.9999168310755986, 'epsilon': 2.958656334744096e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.00018305029328049126, 'tol': 0.0006363211559634727, 'validation_fraction': 0.2880036652065957}
observation time 0.000006, current best -0.963833 at iter 6
suggestion time taken 9.216896 iter 7 next_points [{'alpha': 0.03785149542021198, 'batch_size': 16, 'beta_1': 0.5844702530941798, 'beta_2': 0.9999305374121266, 'epsilon': 3.846736421356564e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0022844572743132277, 'tol': 7.140986544325255e-05, 'validation_fraction': 0.20934435018873293}]
function_evaluation time 2.397202 value -0.962432 suggestion {'alpha': 0.03785149542021198, 'batch_size': 16, 'beta_1': 0.5844702530941798, 'beta_2': 0.9999305374121266, 'epsilon': 3.846736421356564e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0022844572743132277, 'tol': 7.140986544325255e-05, 'validation_fraction': 0.20934435018873293}
observation time 0.000006, current best -0.963833 at iter 7
suggestion time taken 9.221009 iter 8 next_points [{'alpha': 0.002387098622876834, 'batch_size': 19, 'beta_1': 0.6428122171898006, 'beta_2': 0.9999803596134533, 'epsilon': 1.0016163505668197e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.034619846995845804, 'tol': 0.013921448154380036, 'validation_fraction': 0.16839253823229502}]
function_evaluation time 1.432181 value -0.941541 suggestion {'alpha': 0.002387098622876834, 'batch_size': 19, 'beta_1': 0.6428122171898006, 'beta_2': 0.9999803596134533, 'epsilon': 1.0016163505668197e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.034619846995845804, 'tol': 0.013921448154380036, 'validation_fraction': 0.16839253823229502}
observation time 0.000005, current best -0.963833 at iter 8
suggestion time taken 9.162461 iter 9 next_points [{'alpha': 3.676361684790166, 'batch_size': 27, 'beta_1': 0.9751222701795036, 'beta_2': 0.9982374631496971, 'epsilon': 3.66057515769131e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.007411740168090318, 'tol': 0.01227249615750505, 'validation_fraction': 0.7009030644872013}]
function_evaluation time 0.776360 value -0.937362 suggestion {'alpha': 3.676361684790166, 'batch_size': 27, 'beta_1': 0.9751222701795036, 'beta_2': 0.9982374631496971, 'epsilon': 3.66057515769131e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.007411740168090318, 'tol': 0.01227249615750505, 'validation_fraction': 0.7009030644872013}
observation time 0.000006, current best -0.963833 at iter 9
suggestion time taken 9.208227 iter 10 next_points [{'alpha': 0.0214702814369926, 'batch_size': 31, 'beta_1': 0.8841590786168564, 'beta_2': 0.9595612039969085, 'epsilon': 8.618827573151618e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.0002161961315441081, 'tol': 2.161144614496747e-05, 'validation_fraction': 0.38674029710864755}]
function_evaluation time 3.444400 value -0.956165 suggestion {'alpha': 0.0214702814369926, 'batch_size': 31, 'beta_1': 0.8841590786168564, 'beta_2': 0.9595612039969085, 'epsilon': 8.618827573151618e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.0002161961315441081, 'tol': 2.161144614496747e-05, 'validation_fraction': 0.38674029710864755}
observation time 0.000005, current best -0.963833 at iter 10
suggestion time taken 9.287094 iter 11 next_points [{'alpha': 2.8287671878183283e-05, 'batch_size': 10, 'beta_1': 0.9851596250843555, 'beta_2': 0.9982553325851766, 'epsilon': 3.4007581626328836e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.014991950269790943, 'tol': 0.07742897065608462, 'validation_fraction': 0.6636453817685233}]
function_evaluation time 0.862145 value -0.931807 suggestion {'alpha': 2.8287671878183283e-05, 'batch_size': 10, 'beta_1': 0.9851596250843555, 'beta_2': 0.9982553325851766, 'epsilon': 3.4007581626328836e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.014991950269790943, 'tol': 0.07742897065608462, 'validation_fraction': 0.6636453817685233}
observation time 0.000006, current best -0.963833 at iter 11
suggestion time taken 9.219018 iter 12 next_points [{'alpha': 0.010305179942620214, 'batch_size': 16, 'beta_1': 0.9809731737452169, 'beta_2': 0.9798685826131075, 'epsilon': 1.4980568976802084e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 1.3984306981164906e-05, 'tol': 0.008872182373054455, 'validation_fraction': 0.5912417721100512}]
function_evaluation time 0.780210 value -0.105737 suggestion {'alpha': 0.010305179942620214, 'batch_size': 16, 'beta_1': 0.9809731737452169, 'beta_2': 0.9798685826131075, 'epsilon': 1.4980568976802084e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 1.3984306981164906e-05, 'tol': 0.008872182373054455, 'validation_fraction': 0.5912417721100512}
observation time 0.000005, current best -0.963833 at iter 12
suggestion time taken 9.206582 iter 13 next_points [{'alpha': 0.0011244725212147936, 'batch_size': 24, 'beta_1': 0.5707383178625228, 'beta_2': 0.9993372193127928, 'epsilon': 3.875426879378045e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.009012057606380606, 'tol': 0.000945210347955556, 'validation_fraction': 0.5051689431055124}]
function_evaluation time 1.459042 value -0.963831 suggestion {'alpha': 0.0011244725212147936, 'batch_size': 24, 'beta_1': 0.5707383178625228, 'beta_2': 0.9993372193127928, 'epsilon': 3.875426879378045e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.009012057606380606, 'tol': 0.000945210347955556, 'validation_fraction': 0.5051689431055124}
observation time 0.000006, current best -0.963833 at iter 13
suggestion time taken 9.183380 iter 14 next_points [{'alpha': 0.6147463329503693, 'batch_size': 23, 'beta_1': 0.8759157314983321, 'beta_2': 0.9422198479627218, 'epsilon': 9.752290761251665e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 1.1108796617469165e-05, 'tol': 0.002273257807085139, 'validation_fraction': 0.7827139103811767}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.587471 value -0.152398 suggestion {'alpha': 0.6147463329503693, 'batch_size': 23, 'beta_1': 0.8759157314983321, 'beta_2': 0.9422198479627218, 'epsilon': 9.752290761251665e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 1.1108796617469165e-05, 'tol': 0.002273257807085139, 'validation_fraction': 0.7827139103811767}
observation time 0.000005, current best -0.963833 at iter 14
saving meta data: {'args': {'--uuid': '85401bc5dbe45bd399716028593baeb8', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

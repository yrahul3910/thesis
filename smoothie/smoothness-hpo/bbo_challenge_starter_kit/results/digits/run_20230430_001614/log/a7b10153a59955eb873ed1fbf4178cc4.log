running: {'--uuid': 'a7b10153a59955eb873ed1fbf4178cc4', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u a7b10153a59955eb873ed1fbf4178cc4 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002396 iter 0 next_points [{'alpha': 4.1429189327256264e-05, 'batch_size': 116, 'beta_1': 0.5894655720711258, 'beta_2': 0.9083544040344523, 'epsilon': 3.3669496378557706e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 1.881423057737666e-05, 'tol': 1.7824539221163442e-05, 'validation_fraction': 0.5939266157784945}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.887785 value -0.165558 suggestion {'alpha': 4.1429189327256264e-05, 'batch_size': 116, 'beta_1': 0.5894655720711258, 'beta_2': 0.9083544040344523, 'epsilon': 3.3669496378557706e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 1.881423057737666e-05, 'tol': 1.7824539221163442e-05, 'validation_fraction': 0.5939266157784945}
observation time 0.000077, current best -0.165558 at iter 0
suggestion time taken 0.002363 iter 1 next_points [{'alpha': 2.1163570237522884, 'batch_size': 232, 'beta_1': 0.9385039787391569, 'beta_2': 0.9208293054947768, 'epsilon': 1.6941645787441508e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.00023900488926328965, 'tol': 0.008981909116991585, 'validation_fraction': 0.5335502296777082}]
function_evaluation time 1.046964 value -0.897726 suggestion {'alpha': 2.1163570237522884, 'batch_size': 232, 'beta_1': 0.9385039787391569, 'beta_2': 0.9208293054947768, 'epsilon': 1.6941645787441508e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.00023900488926328965, 'tol': 0.008981909116991585, 'validation_fraction': 0.5335502296777082}
observation time 0.000087, current best -0.897726 at iter 1
suggestion time taken 0.002120 iter 2 next_points [{'alpha': 0.013520735592750391, 'batch_size': 96, 'beta_1': 0.5933251046271103, 'beta_2': 0.9796893813544827, 'epsilon': 4.5282336443955094e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.001711535092504724, 'tol': 0.00019209283778470122, 'validation_fraction': 0.13336526053145448}]
function_evaluation time 1.349285 value -0.967988 suggestion {'alpha': 0.013520735592750391, 'batch_size': 96, 'beta_1': 0.5933251046271103, 'beta_2': 0.9796893813544827, 'epsilon': 4.5282336443955094e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.001711535092504724, 'tol': 0.00019209283778470122, 'validation_fraction': 0.13336526053145448}
observation time 0.000069, current best -0.967988 at iter 2
suggestion time taken 0.002335 iter 3 next_points [{'alpha': 0.1863289298437109, 'batch_size': 192, 'beta_1': 0.9845132350005714, 'beta_2': 0.9382903895594085, 'epsilon': 1.2405851291635213e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.014765483488441377, 'tol': 0.05150065770668761, 'validation_fraction': 0.17388750513499152}]
function_evaluation time 0.417659 value -0.923471 suggestion {'alpha': 0.1863289298437109, 'batch_size': 192, 'beta_1': 0.9845132350005714, 'beta_2': 0.9382903895594085, 'epsilon': 1.2405851291635213e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.014765483488441377, 'tol': 0.05150065770668761, 'validation_fraction': 0.17388750513499152}
observation time 0.000067, current best -0.967988 at iter 3
suggestion time taken 0.002149 iter 4 next_points [{'alpha': 2.9725231948144546, 'batch_size': 130, 'beta_1': 0.8585966045752562, 'beta_2': 0.9112354797672949, 'epsilon': 2.688724726243232e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.09176861874298277, 'tol': 0.014298434972375089, 'validation_fraction': 0.47764635703990144}]
function_evaluation time 0.829145 value -0.922764 suggestion {'alpha': 2.9725231948144546, 'batch_size': 130, 'beta_1': 0.8585966045752562, 'beta_2': 0.9112354797672949, 'epsilon': 2.688724726243232e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.09176861874298277, 'tol': 0.014298434972375089, 'validation_fraction': 0.47764635703990144}
observation time 0.000073, current best -0.967988 at iter 4
suggestion time taken 0.002146 iter 5 next_points [{'alpha': 0.008351138573829563, 'batch_size': 225, 'beta_1': 0.7886112390429799, 'beta_2': 0.9850801557666705, 'epsilon': 5.6820126341104146e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.009336364876983498, 'tol': 0.009757107531495604, 'validation_fraction': 0.10641160736546647}]
function_evaluation time 0.298044 value -0.953373 suggestion {'alpha': 0.008351138573829563, 'batch_size': 225, 'beta_1': 0.7886112390429799, 'beta_2': 0.9850801557666705, 'epsilon': 5.6820126341104146e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.009336364876983498, 'tol': 0.009757107531495604, 'validation_fraction': 0.10641160736546647}
observation time 0.000070, current best -0.967988 at iter 5
suggestion time taken 0.002152 iter 6 next_points [{'alpha': 0.02242343370118252, 'batch_size': 247, 'beta_1': 0.622924148351807, 'beta_2': 0.9653736237726755, 'epsilon': 7.336249465639243e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 2.769819245710849e-05, 'tol': 0.06274807322519795, 'validation_fraction': 0.8449866718271697}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.131457 value -0.107813 suggestion {'alpha': 0.02242343370118252, 'batch_size': 247, 'beta_1': 0.622924148351807, 'beta_2': 0.9653736237726755, 'epsilon': 7.336249465639243e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 2.769819245710849e-05, 'tol': 0.06274807322519795, 'validation_fraction': 0.8449866718271697}
observation time 0.000071, current best -0.967988 at iter 6
suggestion time taken 0.002200 iter 7 next_points [{'alpha': 0.0003117420420378644, 'batch_size': 31, 'beta_1': 0.6295408148907192, 'beta_2': 0.9125708329834203, 'epsilon': 6.214167028113849e-08, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.00016124374413955885, 'tol': 0.006924987566360411, 'validation_fraction': 0.5468957613716108}]
function_evaluation time 1.484180 value -0.924845 suggestion {'alpha': 0.0003117420420378644, 'batch_size': 31, 'beta_1': 0.6295408148907192, 'beta_2': 0.9125708329834203, 'epsilon': 6.214167028113849e-08, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.00016124374413955885, 'tol': 0.006924987566360411, 'validation_fraction': 0.5468957613716108}
observation time 0.000073, current best -0.967988 at iter 7
suggestion time taken 0.002135 iter 8 next_points [{'alpha': 0.17003170138984505, 'batch_size': 12, 'beta_1': 0.6812014025949823, 'beta_2': 0.9011932407763055, 'epsilon': 1.0797413148895508e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 1.1769385475866752e-05, 'tol': 0.0005001429699994445, 'validation_fraction': 0.16111064783218337}]
function_evaluation time 18.326920 value -0.885881 suggestion {'alpha': 0.17003170138984505, 'batch_size': 12, 'beta_1': 0.6812014025949823, 'beta_2': 0.9011932407763055, 'epsilon': 1.0797413148895508e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 1.1769385475866752e-05, 'tol': 0.0005001429699994445, 'validation_fraction': 0.16111064783218337}
observation time 0.000072, current best -0.967988 at iter 8
suggestion time taken 0.002396 iter 9 next_points [{'alpha': 2.1885686995001273e-05, 'batch_size': 197, 'beta_1': 0.6816694442128391, 'beta_2': 0.9104292356267123, 'epsilon': 1.8616165503186228e-08, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.023248140776861975, 'tol': 0.0004614880871337189, 'validation_fraction': 0.4148159255656246}]
function_evaluation time 0.536030 value -0.951977 suggestion {'alpha': 2.1885686995001273e-05, 'batch_size': 197, 'beta_1': 0.6816694442128391, 'beta_2': 0.9104292356267123, 'epsilon': 1.8616165503186228e-08, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.023248140776861975, 'tol': 0.0004614880871337189, 'validation_fraction': 0.4148159255656246}
observation time 0.000070, current best -0.967988 at iter 9
suggestion time taken 0.002136 iter 10 next_points [{'alpha': 0.1675071367478559, 'batch_size': 13, 'beta_1': 0.5802444371066705, 'beta_2': 0.9463160928265321, 'epsilon': 3.0820999886981134e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 1.3811522567803276e-05, 'tol': 0.04613938924554328, 'validation_fraction': 0.6111260129136421}]
function_evaluation time 0.758085 value -0.099504 suggestion {'alpha': 0.1675071367478559, 'batch_size': 13, 'beta_1': 0.5802444371066705, 'beta_2': 0.9463160928265321, 'epsilon': 3.0820999886981134e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 1.3811522567803276e-05, 'tol': 0.04613938924554328, 'validation_fraction': 0.6111260129136421}
observation time 0.000081, current best -0.967988 at iter 10
suggestion time taken 0.002147 iter 11 next_points [{'alpha': 7.479157478236081e-05, 'batch_size': 245, 'beta_1': 0.5579409522950147, 'beta_2': 0.9527063968834447, 'epsilon': 6.481699626999047e-08, 'hidden_layer_sizes': 143, 'learning_rate_init': 2.600015833914386e-05, 'tol': 0.0009946564993411355, 'validation_fraction': 0.3935232570789947}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.840982 value -0.229856 suggestion {'alpha': 7.479157478236081e-05, 'batch_size': 245, 'beta_1': 0.5579409522950147, 'beta_2': 0.9527063968834447, 'epsilon': 6.481699626999047e-08, 'hidden_layer_sizes': 143, 'learning_rate_init': 2.600015833914386e-05, 'tol': 0.0009946564993411355, 'validation_fraction': 0.3935232570789947}
observation time 0.000071, current best -0.967988 at iter 11
suggestion time taken 0.002146 iter 12 next_points [{'alpha': 0.0002545608371065637, 'batch_size': 147, 'beta_1': 0.5451123007474159, 'beta_2': 0.9749783570062607, 'epsilon': 2.326910463252211e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.015240227902938814, 'tol': 9.599218283697074e-05, 'validation_fraction': 0.11434685244789268}]
function_evaluation time 0.690111 value -0.965203 suggestion {'alpha': 0.0002545608371065637, 'batch_size': 147, 'beta_1': 0.5451123007474159, 'beta_2': 0.9749783570062607, 'epsilon': 2.326910463252211e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.015240227902938814, 'tol': 9.599218283697074e-05, 'validation_fraction': 0.11434685244789268}
observation time 0.000076, current best -0.967988 at iter 12
suggestion time taken 0.002164 iter 13 next_points [{'alpha': 0.0002912146253772902, 'batch_size': 186, 'beta_1': 0.643554113913802, 'beta_2': 0.9587972555905416, 'epsilon': 2.0423762961093013e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.046432314366661606, 'tol': 0.0002638540971765941, 'validation_fraction': 0.2369469807018235}]
function_evaluation time 0.709102 value -0.949898 suggestion {'alpha': 0.0002912146253772902, 'batch_size': 186, 'beta_1': 0.643554113913802, 'beta_2': 0.9587972555905416, 'epsilon': 2.0423762961093013e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.046432314366661606, 'tol': 0.0002638540971765941, 'validation_fraction': 0.2369469807018235}
observation time 0.000077, current best -0.967988 at iter 13
suggestion time taken 0.002123 iter 14 next_points [{'alpha': 0.030983678615177982, 'batch_size': 70, 'beta_1': 0.5446602310179478, 'beta_2': 0.9697020550379453, 'epsilon': 1.2024302252648459e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00019723055772011595, 'tol': 0.015210983517910863, 'validation_fraction': 0.1045206719602052}]
function_evaluation time 1.516335 value -0.941553 suggestion {'alpha': 0.030983678615177982, 'batch_size': 70, 'beta_1': 0.5446602310179478, 'beta_2': 0.9697020550379453, 'epsilon': 1.2024302252648459e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00019723055772011595, 'tol': 0.015210983517910863, 'validation_fraction': 0.1045206719602052}
observation time 0.000075, current best -0.967988 at iter 14
saving meta data: {'args': {'--uuid': 'a7b10153a59955eb873ed1fbf4178cc4', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

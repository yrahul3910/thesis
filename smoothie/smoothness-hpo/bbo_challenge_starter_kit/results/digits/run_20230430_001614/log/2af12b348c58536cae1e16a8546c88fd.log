running: {'--uuid': '2af12b348c58536cae1e16a8546c88fd', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d digits -o random-search -u 2af12b348c58536cae1e16a8546c88fd -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study random-search MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002840 iter 0 next_points [{'alpha': 1.386417579704251, 'batch_size': 140, 'beta_1': 0.9860856024763942, 'beta_2': 0.972880030166554, 'epsilon': 2.407958608674338e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.013643970799331457, 'tol': 0.0007803433241332743, 'validation_fraction': 0.26805057683380423}]
function_evaluation time 0.881084 value 0.298429 suggestion {'alpha': 1.386417579704251, 'batch_size': 140, 'beta_1': 0.9860856024763942, 'beta_2': 0.972880030166554, 'epsilon': 2.407958608674338e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.013643970799331457, 'tol': 0.0007803433241332743, 'validation_fraction': 0.26805057683380423}
observation time 0.000006, current best 0.298429 at iter 0
suggestion time taken 0.002553 iter 1 next_points [{'alpha': 0.000584703238071576, 'batch_size': 184, 'beta_1': 0.8457677022157786, 'beta_2': 0.9302597578159428, 'epsilon': 5.0499422640950834e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.018970512474685855, 'tol': 2.2197328002660248e-05, 'validation_fraction': 0.7196454514345351}]
function_evaluation time 0.646170 value 0.255414 suggestion {'alpha': 0.000584703238071576, 'batch_size': 184, 'beta_1': 0.8457677022157786, 'beta_2': 0.9302597578159428, 'epsilon': 5.0499422640950834e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.018970512474685855, 'tol': 2.2197328002660248e-05, 'validation_fraction': 0.7196454514345351}
observation time 0.000004, current best 0.255414 at iter 1
suggestion time taken 0.002461 iter 2 next_points [{'alpha': 0.022367460931723083, 'batch_size': 144, 'beta_1': 0.9747233662828216, 'beta_2': 0.996964449282939, 'epsilon': 6.849874680185644e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.0701264942632283, 'tol': 0.017151710322242185, 'validation_fraction': 0.7478668261218542}]
function_evaluation time 0.587159 value 1.310165 suggestion {'alpha': 0.022367460931723083, 'batch_size': 144, 'beta_1': 0.9747233662828216, 'beta_2': 0.996964449282939, 'epsilon': 6.849874680185644e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.0701264942632283, 'tol': 0.017151710322242185, 'validation_fraction': 0.7478668261218542}
observation time 0.000004, current best 0.255414 at iter 2
suggestion time taken 0.002450 iter 3 next_points [{'alpha': 0.00060079989591125, 'batch_size': 138, 'beta_1': 0.9520905703512429, 'beta_2': 0.9999585517161926, 'epsilon': 9.491930850767683e-09, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.008913079809731652, 'tol': 0.0015398811785434202, 'validation_fraction': 0.2127976789520054}]
function_evaluation time 1.030249 value 0.133668 suggestion {'alpha': 0.00060079989591125, 'batch_size': 138, 'beta_1': 0.9520905703512429, 'beta_2': 0.9999585517161926, 'epsilon': 9.491930850767683e-09, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.008913079809731652, 'tol': 0.0015398811785434202, 'validation_fraction': 0.2127976789520054}
observation time 0.000005, current best 0.133668 at iter 3
suggestion time taken 0.002500 iter 4 next_points [{'alpha': 2.1123089752549054, 'batch_size': 218, 'beta_1': 0.9289208833452126, 'beta_2': 0.9983158246919284, 'epsilon': 8.88647042084256e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 3.704933658559207e-05, 'tol': 0.004135509911134207, 'validation_fraction': 0.8172617857668628}]
function_evaluation time 0.175959 value 13.282053 suggestion {'alpha': 2.1123089752549054, 'batch_size': 218, 'beta_1': 0.9289208833452126, 'beta_2': 0.9983158246919284, 'epsilon': 8.88647042084256e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 3.704933658559207e-05, 'tol': 0.004135509911134207, 'validation_fraction': 0.8172617857668628}
observation time 0.000004, current best 0.133668 at iter 4
suggestion time taken 0.002471 iter 5 next_points [{'alpha': 0.1932004370796098, 'batch_size': 159, 'beta_1': 0.9378962439477658, 'beta_2': 0.9999896773223751, 'epsilon': 2.971660977637663e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 4.069641603640825e-05, 'tol': 0.07600869561484361, 'validation_fraction': 0.39444427622313805}]
function_evaluation time 0.334382 value 5.834328 suggestion {'alpha': 0.1932004370796098, 'batch_size': 159, 'beta_1': 0.9378962439477658, 'beta_2': 0.9999896773223751, 'epsilon': 2.971660977637663e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 4.069641603640825e-05, 'tol': 0.07600869561484361, 'validation_fraction': 0.39444427622313805}
observation time 0.000004, current best 0.133668 at iter 5
suggestion time taken 0.002438 iter 6 next_points [{'alpha': 1.769417726366306e-05, 'batch_size': 230, 'beta_1': 0.9416859998468197, 'beta_2': 0.9775962029621068, 'epsilon': 8.083538861621284e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 5.974185473834847e-05, 'tol': 0.05358754801308734, 'validation_fraction': 0.10056632025042243}]
function_evaluation time 0.270950 value 8.930248 suggestion {'alpha': 1.769417726366306e-05, 'batch_size': 230, 'beta_1': 0.9416859998468197, 'beta_2': 0.9775962029621068, 'epsilon': 8.083538861621284e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 5.974185473834847e-05, 'tol': 0.05358754801308734, 'validation_fraction': 0.10056632025042243}
observation time 0.000005, current best 0.133668 at iter 6
suggestion time taken 0.002460 iter 7 next_points [{'alpha': 0.0006809380429182538, 'batch_size': 210, 'beta_1': 0.9875711691891966, 'beta_2': 0.9999987558918807, 'epsilon': 7.594063616841176e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 1.0877654873582617e-05, 'tol': 0.00011948249262589936, 'validation_fraction': 0.8876759192788412}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.370481 value 7.232284 suggestion {'alpha': 0.0006809380429182538, 'batch_size': 210, 'beta_1': 0.9875711691891966, 'beta_2': 0.9999987558918807, 'epsilon': 7.594063616841176e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 1.0877654873582617e-05, 'tol': 0.00011948249262589936, 'validation_fraction': 0.8876759192788412}
observation time 0.000003, current best 0.133668 at iter 7
suggestion time taken 0.002447 iter 8 next_points [{'alpha': 0.00030488576131916436, 'batch_size': 91, 'beta_1': 0.9771693422931138, 'beta_2': 0.9951547283680816, 'epsilon': 4.419219462537538e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.08813151148917105, 'tol': 0.014778522808301638, 'validation_fraction': 0.7847252310982574}]
function_evaluation time 0.362222 value 1.776239 suggestion {'alpha': 0.00030488576131916436, 'batch_size': 91, 'beta_1': 0.9771693422931138, 'beta_2': 0.9951547283680816, 'epsilon': 4.419219462537538e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.08813151148917105, 'tol': 0.014778522808301638, 'validation_fraction': 0.7847252310982574}
observation time 0.000005, current best 0.133668 at iter 8
suggestion time taken 0.002482 iter 9 next_points [{'alpha': 1.3503032069325447, 'batch_size': 162, 'beta_1': 0.8927066587616702, 'beta_2': 0.9999580033957964, 'epsilon': 1.1717487835006035e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 3.884965336884679e-05, 'tol': 0.03304024584568758, 'validation_fraction': 0.22637182020592891}]
function_evaluation time 0.359512 value 7.397683 suggestion {'alpha': 1.3503032069325447, 'batch_size': 162, 'beta_1': 0.8927066587616702, 'beta_2': 0.9999580033957964, 'epsilon': 1.1717487835006035e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 3.884965336884679e-05, 'tol': 0.03304024584568758, 'validation_fraction': 0.22637182020592891}
observation time 0.000005, current best 0.133668 at iter 9
suggestion time taken 0.002422 iter 10 next_points [{'alpha': 0.26875368251065396, 'batch_size': 76, 'beta_1': 0.9730579474624593, 'beta_2': 0.9981933337563316, 'epsilon': 1.861243516397138e-08, 'hidden_layer_sizes': 169, 'learning_rate_init': 8.669964843259237e-05, 'tol': 0.08142013318491018, 'validation_fraction': 0.2773110826985454}]
function_evaluation time 0.625637 value 1.914769 suggestion {'alpha': 0.26875368251065396, 'batch_size': 76, 'beta_1': 0.9730579474624593, 'beta_2': 0.9981933337563316, 'epsilon': 1.861243516397138e-08, 'hidden_layer_sizes': 169, 'learning_rate_init': 8.669964843259237e-05, 'tol': 0.08142013318491018, 'validation_fraction': 0.2773110826985454}
observation time 0.000005, current best 0.133668 at iter 10
suggestion time taken 0.002525 iter 11 next_points [{'alpha': 0.6041019078189119, 'batch_size': 68, 'beta_1': 0.5278435184369371, 'beta_2': 0.9999985696305793, 'epsilon': 4.2433235654165566e-07, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.0003339152563692389, 'tol': 0.0004659729921564491, 'validation_fraction': 0.19032042952576644}]
function_evaluation time 2.279732 value 0.176040 suggestion {'alpha': 0.6041019078189119, 'batch_size': 68, 'beta_1': 0.5278435184369371, 'beta_2': 0.9999985696305793, 'epsilon': 4.2433235654165566e-07, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.0003339152563692389, 'tol': 0.0004659729921564491, 'validation_fraction': 0.19032042952576644}
observation time 0.000005, current best 0.133668 at iter 11
suggestion time taken 0.002472 iter 12 next_points [{'alpha': 0.17989037531518534, 'batch_size': 40, 'beta_1': 0.9615475826437037, 'beta_2': 0.9999963845220603, 'epsilon': 6.353799129173562e-08, 'hidden_layer_sizes': 127, 'learning_rate_init': 4.4718418233236144e-05, 'tol': 0.017038037707714403, 'validation_fraction': 0.37106764763299}]
function_evaluation time 2.359514 value 0.798612 suggestion {'alpha': 0.17989037531518534, 'batch_size': 40, 'beta_1': 0.9615475826437037, 'beta_2': 0.9999963845220603, 'epsilon': 6.353799129173562e-08, 'hidden_layer_sizes': 127, 'learning_rate_init': 4.4718418233236144e-05, 'tol': 0.017038037707714403, 'validation_fraction': 0.37106764763299}
observation time 0.000004, current best 0.133668 at iter 12
suggestion time taken 0.002465 iter 13 next_points [{'alpha': 0.21762063907942272, 'batch_size': 47, 'beta_1': 0.957293754895506, 'beta_2': 0.9979773072507874, 'epsilon': 8.433414295316352e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.0017631668961345223, 'tol': 0.001415861901360571, 'validation_fraction': 0.6863204403004167}]
function_evaluation time 0.964262 value 0.215010 suggestion {'alpha': 0.21762063907942272, 'batch_size': 47, 'beta_1': 0.957293754895506, 'beta_2': 0.9979773072507874, 'epsilon': 8.433414295316352e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.0017631668961345223, 'tol': 0.001415861901360571, 'validation_fraction': 0.6863204403004167}
observation time 0.000004, current best 0.133668 at iter 13
suggestion time taken 0.002453 iter 14 next_points [{'alpha': 0.7628187649264051, 'batch_size': 99, 'beta_1': 0.9896835257945253, 'beta_2': 0.9732802344160438, 'epsilon': 5.234585123498532e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 1.660114066228937e-05, 'tol': 0.0002663365314969643, 'validation_fraction': 0.10919451367434}]
function_evaluation time 3.452291 value 5.147951 suggestion {'alpha': 0.7628187649264051, 'batch_size': 99, 'beta_1': 0.9896835257945253, 'beta_2': 0.9732802344160438, 'epsilon': 5.234585123498532e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 1.660114066228937e-05, 'tol': 0.0002663365314969643, 'validation_fraction': 0.10919451367434}
observation time 0.000004, current best 0.133668 at iter 14
saving meta data: {'args': {'--uuid': '2af12b348c58536cae1e16a8546c88fd', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

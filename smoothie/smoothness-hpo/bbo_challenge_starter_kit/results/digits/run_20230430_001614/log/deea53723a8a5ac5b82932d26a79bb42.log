running: {'--uuid': 'deea53723a8a5ac5b82932d26a79bb42', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d digits -o random-search -u deea53723a8a5ac5b82932d26a79bb42 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study random-search MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002494 iter 0 next_points [{'alpha': 0.18602641104808226, 'batch_size': 66, 'beta_1': 0.5971970032009457, 'beta_2': 0.9999777371305811, 'epsilon': 9.134460159398896e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.0001356230630190979, 'tol': 0.00037641425915899395, 'validation_fraction': 0.1442476340515698}]
function_evaluation time 2.590375 value 0.295392 suggestion {'alpha': 0.18602641104808226, 'batch_size': 66, 'beta_1': 0.5971970032009457, 'beta_2': 0.9999777371305811, 'epsilon': 9.134460159398896e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.0001356230630190979, 'tol': 0.00037641425915899395, 'validation_fraction': 0.1442476340515698}
observation time 0.000007, current best 0.295392 at iter 0
suggestion time taken 0.002448 iter 1 next_points [{'alpha': 0.00034340105081731055, 'batch_size': 139, 'beta_1': 0.5967103618598465, 'beta_2': 0.9980905347419925, 'epsilon': 3.0490617310005273e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.034306411086373, 'tol': 0.00840382171996008, 'validation_fraction': 0.5028630610447092}]
function_evaluation time 0.631249 value 0.160621 suggestion {'alpha': 0.00034340105081731055, 'batch_size': 139, 'beta_1': 0.5967103618598465, 'beta_2': 0.9980905347419925, 'epsilon': 3.0490617310005273e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.034306411086373, 'tol': 0.00840382171996008, 'validation_fraction': 0.5028630610447092}
observation time 0.000005, current best 0.160621 at iter 1
suggestion time taken 0.002437 iter 2 next_points [{'alpha': 0.49345112291698295, 'batch_size': 16, 'beta_1': 0.9888203562060507, 'beta_2': 0.9985659091178565, 'epsilon': 1.6196155482108846e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.0008875291958411356, 'tol': 0.0007471621248496763, 'validation_fraction': 0.11234730348015608}]
function_evaluation time 2.732406 value 0.157869 suggestion {'alpha': 0.49345112291698295, 'batch_size': 16, 'beta_1': 0.9888203562060507, 'beta_2': 0.9985659091178565, 'epsilon': 1.6196155482108846e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.0008875291958411356, 'tol': 0.0007471621248496763, 'validation_fraction': 0.11234730348015608}
observation time 0.000005, current best 0.157869 at iter 2
suggestion time taken 0.002422 iter 3 next_points [{'alpha': 0.0006938669724554306, 'batch_size': 155, 'beta_1': 0.8880698113851431, 'beta_2': 0.9947715370496865, 'epsilon': 1.1512977934229931e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.013822353141477799, 'tol': 0.019820719499364727, 'validation_fraction': 0.3517739055766761}]
function_evaluation time 0.428711 value 0.151543 suggestion {'alpha': 0.0006938669724554306, 'batch_size': 155, 'beta_1': 0.8880698113851431, 'beta_2': 0.9947715370496865, 'epsilon': 1.1512977934229931e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.013822353141477799, 'tol': 0.019820719499364727, 'validation_fraction': 0.3517739055766761}
observation time 0.000005, current best 0.151543 at iter 3
suggestion time taken 0.002488 iter 4 next_points [{'alpha': 0.00012259319009178216, 'batch_size': 198, 'beta_1': 0.8715556472689362, 'beta_2': 0.9999876119249216, 'epsilon': 9.950778138265435e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.0014306465222229784, 'tol': 0.040954002797575766, 'validation_fraction': 0.8516801067934973}]
function_evaluation time 0.287957 value 0.633998 suggestion {'alpha': 0.00012259319009178216, 'batch_size': 198, 'beta_1': 0.8715556472689362, 'beta_2': 0.9999876119249216, 'epsilon': 9.950778138265435e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.0014306465222229784, 'tol': 0.040954002797575766, 'validation_fraction': 0.8516801067934973}
observation time 0.000005, current best 0.151543 at iter 4
suggestion time taken 0.002401 iter 5 next_points [{'alpha': 0.0054846143353070856, 'batch_size': 115, 'beta_1': 0.8752058144867464, 'beta_2': 0.9703035390857625, 'epsilon': 2.661600652395685e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.06775905139437119, 'tol': 2.198770878083775e-05, 'validation_fraction': 0.40360455985961}]
function_evaluation time 1.166859 value 1.011993 suggestion {'alpha': 0.0054846143353070856, 'batch_size': 115, 'beta_1': 0.8752058144867464, 'beta_2': 0.9703035390857625, 'epsilon': 2.661600652395685e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.06775905139437119, 'tol': 2.198770878083775e-05, 'validation_fraction': 0.40360455985961}
observation time 0.000005, current best 0.151543 at iter 5
suggestion time taken 0.002453 iter 6 next_points [{'alpha': 0.04295240156416628, 'batch_size': 45, 'beta_1': 0.981427192411211, 'beta_2': 0.9991587235275722, 'epsilon': 6.161358290613545e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.0009614226163601052, 'tol': 1.8677481104541596e-05, 'validation_fraction': 0.8720587289373974}]
function_evaluation time 1.232993 value 0.481668 suggestion {'alpha': 0.04295240156416628, 'batch_size': 45, 'beta_1': 0.981427192411211, 'beta_2': 0.9991587235275722, 'epsilon': 6.161358290613545e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.0009614226163601052, 'tol': 1.8677481104541596e-05, 'validation_fraction': 0.8720587289373974}
observation time 0.000004, current best 0.151543 at iter 6
suggestion time taken 0.002396 iter 7 next_points [{'alpha': 4.341441277570576, 'batch_size': 226, 'beta_1': 0.9807284092789326, 'beta_2': 0.9752234036561325, 'epsilon': 4.804245310205016e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.00015773540624745472, 'tol': 0.0011651814815782332, 'validation_fraction': 0.3588350505595226}]
function_evaluation time 3.046717 value 0.192983 suggestion {'alpha': 4.341441277570576, 'batch_size': 226, 'beta_1': 0.9807284092789326, 'beta_2': 0.9752234036561325, 'epsilon': 4.804245310205016e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.00015773540624745472, 'tol': 0.0011651814815782332, 'validation_fraction': 0.3588350505595226}
observation time 0.000005, current best 0.151543 at iter 7
suggestion time taken 0.002395 iter 8 next_points [{'alpha': 0.2607297073058332, 'batch_size': 191, 'beta_1': 0.5892236453950233, 'beta_2': 0.997412384733703, 'epsilon': 4.8015553891171e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0005047640514310259, 'tol': 0.006273167671398204, 'validation_fraction': 0.8734285228503736}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.799221 value 0.841232 suggestion {'alpha': 0.2607297073058332, 'batch_size': 191, 'beta_1': 0.5892236453950233, 'beta_2': 0.997412384733703, 'epsilon': 4.8015553891171e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0005047640514310259, 'tol': 0.006273167671398204, 'validation_fraction': 0.8734285228503736}
observation time 0.000004, current best 0.151543 at iter 8
suggestion time taken 0.002786 iter 9 next_points [{'alpha': 0.004611984011078312, 'batch_size': 217, 'beta_1': 0.9470948844795887, 'beta_2': 0.9999810144738739, 'epsilon': 1.1959200637850113e-08, 'hidden_layer_sizes': 200, 'learning_rate_init': 5.272102256967279e-05, 'tol': 0.0071032572214946976, 'validation_fraction': 0.4387223122218767}]
function_evaluation time 1.829300 value 2.407916 suggestion {'alpha': 0.004611984011078312, 'batch_size': 217, 'beta_1': 0.9470948844795887, 'beta_2': 0.9999810144738739, 'epsilon': 1.1959200637850113e-08, 'hidden_layer_sizes': 200, 'learning_rate_init': 5.272102256967279e-05, 'tol': 0.0071032572214946976, 'validation_fraction': 0.4387223122218767}
observation time 0.000004, current best 0.151543 at iter 9
suggestion time taken 0.002466 iter 10 next_points [{'alpha': 1.5944409197317718e-05, 'batch_size': 148, 'beta_1': 0.9648660366232088, 'beta_2': 0.9980032875091628, 'epsilon': 5.3577217376186824e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.01720154952741468, 'tol': 0.009829586998917611, 'validation_fraction': 0.7539867339441285}]
function_evaluation time 0.501200 value 0.323834 suggestion {'alpha': 1.5944409197317718e-05, 'batch_size': 148, 'beta_1': 0.9648660366232088, 'beta_2': 0.9980032875091628, 'epsilon': 5.3577217376186824e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.01720154952741468, 'tol': 0.009829586998917611, 'validation_fraction': 0.7539867339441285}
observation time 0.000005, current best 0.151543 at iter 10
suggestion time taken 0.002445 iter 11 next_points [{'alpha': 0.0013391592154689423, 'batch_size': 34, 'beta_1': 0.8826311102990756, 'beta_2': 0.999931825618582, 'epsilon': 8.103294379864704e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0005157224723641527, 'tol': 0.001903911995300767, 'validation_fraction': 0.17765514462733642}]
function_evaluation time 2.541904 value 0.115047 suggestion {'alpha': 0.0013391592154689423, 'batch_size': 34, 'beta_1': 0.8826311102990756, 'beta_2': 0.999931825618582, 'epsilon': 8.103294379864704e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0005157224723641527, 'tol': 0.001903911995300767, 'validation_fraction': 0.17765514462733642}
observation time 0.000005, current best 0.115047 at iter 11
suggestion time taken 0.002465 iter 12 next_points [{'alpha': 0.033928787967298604, 'batch_size': 192, 'beta_1': 0.6900957021073801, 'beta_2': 0.9990584765617977, 'epsilon': 9.812605258099817e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.019297694089414428, 'tol': 1.1222138138356568e-05, 'validation_fraction': 0.8112919506920602}]
function_evaluation time 0.579995 value 0.292540 suggestion {'alpha': 0.033928787967298604, 'batch_size': 192, 'beta_1': 0.6900957021073801, 'beta_2': 0.9990584765617977, 'epsilon': 9.812605258099817e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.019297694089414428, 'tol': 1.1222138138356568e-05, 'validation_fraction': 0.8112919506920602}
observation time 0.000004, current best 0.115047 at iter 12
suggestion time taken 0.002449 iter 13 next_points [{'alpha': 2.7864416832932855, 'batch_size': 223, 'beta_1': 0.9678589933357815, 'beta_2': 0.956975236149647, 'epsilon': 2.2775667173833452e-07, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.00329763075405502, 'tol': 0.0006071507575403901, 'validation_fraction': 0.7683030567276631}]
function_evaluation time 0.632385 value 0.312764 suggestion {'alpha': 2.7864416832932855, 'batch_size': 223, 'beta_1': 0.9678589933357815, 'beta_2': 0.956975236149647, 'epsilon': 2.2775667173833452e-07, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.00329763075405502, 'tol': 0.0006071507575403901, 'validation_fraction': 0.7683030567276631}
observation time 0.000005, current best 0.115047 at iter 13
suggestion time taken 0.002421 iter 14 next_points [{'alpha': 0.009572872428026237, 'batch_size': 148, 'beta_1': 0.9748210068951276, 'beta_2': 0.9933207688080479, 'epsilon': 1.5042666536184634e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.010979238232632518, 'tol': 0.00038036157544594205, 'validation_fraction': 0.8296319948625782}]
function_evaluation time 0.489957 value 0.453502 suggestion {'alpha': 0.009572872428026237, 'batch_size': 148, 'beta_1': 0.9748210068951276, 'beta_2': 0.9933207688080479, 'epsilon': 1.5042666536184634e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.010979238232632518, 'tol': 0.00038036157544594205, 'validation_fraction': 0.8296319948625782}
observation time 0.000004, current best 0.115047 at iter 14
saving meta data: {'args': {'--uuid': 'deea53723a8a5ac5b82932d26a79bb42', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

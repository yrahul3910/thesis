running: {'--uuid': '01fb3757100057b3a33a839f24bd977f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 01fb3757100057b3a33a839f24bd977f -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study hyperopt MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002389 iter 0 next_points [{'alpha': 0.007776543210703064, 'batch_size': 225, 'beta_1': 0.9344292360600099, 'beta_2': 0.9665414994221677, 'epsilon': 9.868912132023108e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0006288078328488307, 'tol': 0.015606853868640266, 'validation_fraction': 0.7883518925371367}]
function_evaluation time 0.538160 value 0.693259 suggestion {'alpha': 0.007776543210703064, 'batch_size': 225, 'beta_1': 0.9344292360600099, 'beta_2': 0.9665414994221677, 'epsilon': 9.868912132023108e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0006288078328488307, 'tol': 0.015606853868640266, 'validation_fraction': 0.7883518925371367}
observation time 0.000075, current best 0.693259 at iter 0
suggestion time taken 0.002368 iter 1 next_points [{'alpha': 4.252258433236154e-05, 'batch_size': 135, 'beta_1': 0.8787180320230173, 'beta_2': 0.9280077045685062, 'epsilon': 7.077021162358536e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.07881181290252343, 'tol': 5.782723880221108e-05, 'validation_fraction': 0.17197197015704008}]
function_evaluation time 1.085390 value 2.309600 suggestion {'alpha': 4.252258433236154e-05, 'batch_size': 135, 'beta_1': 0.8787180320230173, 'beta_2': 0.9280077045685062, 'epsilon': 7.077021162358536e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.07881181290252343, 'tol': 5.782723880221108e-05, 'validation_fraction': 0.17197197015704008}
observation time 0.000068, current best 0.693259 at iter 1
suggestion time taken 0.002096 iter 2 next_points [{'alpha': 0.0008606995959899203, 'batch_size': 213, 'beta_1': 0.5824100856143135, 'beta_2': 0.9108984854268162, 'epsilon': 9.077832721952569e-08, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0036060213150744327, 'tol': 0.0005221595764776113, 'validation_fraction': 0.5201485380458485}]
function_evaluation time 0.946367 value 0.130056 suggestion {'alpha': 0.0008606995959899203, 'batch_size': 213, 'beta_1': 0.5824100856143135, 'beta_2': 0.9108984854268162, 'epsilon': 9.077832721952569e-08, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0036060213150744327, 'tol': 0.0005221595764776113, 'validation_fraction': 0.5201485380458485}
observation time 0.000064, current best 0.130056 at iter 2
suggestion time taken 0.002101 iter 3 next_points [{'alpha': 0.017865514143945556, 'batch_size': 98, 'beta_1': 0.9295094608108274, 'beta_2': 0.968363759150031, 'epsilon': 6.37096335770728e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0013599591114430393, 'tol': 0.00026472757228077526, 'validation_fraction': 0.20851426864447634}]
function_evaluation time 1.021893 value 0.135791 suggestion {'alpha': 0.017865514143945556, 'batch_size': 98, 'beta_1': 0.9295094608108274, 'beta_2': 0.968363759150031, 'epsilon': 6.37096335770728e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0013599591114430393, 'tol': 0.00026472757228077526, 'validation_fraction': 0.20851426864447634}
observation time 0.000078, current best 0.130056 at iter 3
suggestion time taken 0.002129 iter 4 next_points [{'alpha': 2.4621061932836857e-05, 'batch_size': 232, 'beta_1': 0.7320279732277912, 'beta_2': 0.9169938690443805, 'epsilon': 5.081904280679877e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.007531236656290616, 'tol': 0.013225650921604014, 'validation_fraction': 0.21292286554374065}]
function_evaluation time 0.384189 value 0.151707 suggestion {'alpha': 2.4621061932836857e-05, 'batch_size': 232, 'beta_1': 0.7320279732277912, 'beta_2': 0.9169938690443805, 'epsilon': 5.081904280679877e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.007531236656290616, 'tol': 0.013225650921604014, 'validation_fraction': 0.21292286554374065}
observation time 0.000066, current best 0.130056 at iter 4
suggestion time taken 0.002110 iter 5 next_points [{'alpha': 0.011016001409669367, 'batch_size': 135, 'beta_1': 0.5691579502476848, 'beta_2': 0.9870432242092575, 'epsilon': 1.58521738622327e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 5.447309045657257e-05, 'tol': 0.05965796535538165, 'validation_fraction': 0.7048554184493501}]
function_evaluation time 0.260035 value 6.388672 suggestion {'alpha': 0.011016001409669367, 'batch_size': 135, 'beta_1': 0.5691579502476848, 'beta_2': 0.9870432242092575, 'epsilon': 1.58521738622327e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 5.447309045657257e-05, 'tol': 0.05965796535538165, 'validation_fraction': 0.7048554184493501}
observation time 0.000069, current best 0.130056 at iter 5
suggestion time taken 0.002154 iter 6 next_points [{'alpha': 0.0014678547444253371, 'batch_size': 167, 'beta_1': 0.5452794679877037, 'beta_2': 0.9755929505249206, 'epsilon': 2.6315346656780692e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0006434706255090072, 'tol': 0.0004957986092659959, 'validation_fraction': 0.4373291661944306}]
function_evaluation time 1.804302 value 0.160021 suggestion {'alpha': 0.0014678547444253371, 'batch_size': 167, 'beta_1': 0.5452794679877037, 'beta_2': 0.9755929505249206, 'epsilon': 2.6315346656780692e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0006434706255090072, 'tol': 0.0004957986092659959, 'validation_fraction': 0.4373291661944306}
observation time 0.000070, current best 0.130056 at iter 6
suggestion time taken 0.002234 iter 7 next_points [{'alpha': 3.0016756063071752, 'batch_size': 27, 'beta_1': 0.5746850913677426, 'beta_2': 0.952851792699065, 'epsilon': 2.0057692310775023e-08, 'hidden_layer_sizes': 196, 'learning_rate_init': 2.3439871567081707e-05, 'tol': 0.018950512489338416, 'validation_fraction': 0.28862429086576846}]
function_evaluation time 3.478758 value 0.599527 suggestion {'alpha': 3.0016756063071752, 'batch_size': 27, 'beta_1': 0.5746850913677426, 'beta_2': 0.952851792699065, 'epsilon': 2.0057692310775023e-08, 'hidden_layer_sizes': 196, 'learning_rate_init': 2.3439871567081707e-05, 'tol': 0.018950512489338416, 'validation_fraction': 0.28862429086576846}
observation time 0.000064, current best 0.130056 at iter 7
suggestion time taken 0.002424 iter 8 next_points [{'alpha': 0.011335303679934768, 'batch_size': 113, 'beta_1': 0.7951769224355342, 'beta_2': 0.9587240482398576, 'epsilon': 1.7184938555132273e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.0004650549270541529, 'tol': 0.048837317007658095, 'validation_fraction': 0.11196301606264165}]
function_evaluation time 0.537148 value 0.391970 suggestion {'alpha': 0.011335303679934768, 'batch_size': 113, 'beta_1': 0.7951769224355342, 'beta_2': 0.9587240482398576, 'epsilon': 1.7184938555132273e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.0004650549270541529, 'tol': 0.048837317007658095, 'validation_fraction': 0.11196301606264165}
observation time 0.000071, current best 0.130056 at iter 8
suggestion time taken 0.002109 iter 9 next_points [{'alpha': 7.584886426379103, 'batch_size': 28, 'beta_1': 0.9564623877892222, 'beta_2': 0.9553985610338057, 'epsilon': 3.6525002640118295e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 1.8663949173218888e-05, 'tol': 0.09245544588547011, 'validation_fraction': 0.8219942079300603}]
function_evaluation time 0.382780 value 6.507029 suggestion {'alpha': 7.584886426379103, 'batch_size': 28, 'beta_1': 0.9564623877892222, 'beta_2': 0.9553985610338057, 'epsilon': 3.6525002640118295e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 1.8663949173218888e-05, 'tol': 0.09245544588547011, 'validation_fraction': 0.8219942079300603}
observation time 0.000063, current best 0.130056 at iter 9
suggestion time taken 0.002121 iter 10 next_points [{'alpha': 0.06821566232734133, 'batch_size': 155, 'beta_1': 0.784963840857908, 'beta_2': 0.9241483980606101, 'epsilon': 5.6205114134249265e-08, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.0027809059032804133, 'tol': 0.01133030435056697, 'validation_fraction': 0.1172627680352855}]
function_evaluation time 0.669250 value 0.118166 suggestion {'alpha': 0.06821566232734133, 'batch_size': 155, 'beta_1': 0.784963840857908, 'beta_2': 0.9241483980606101, 'epsilon': 5.6205114134249265e-08, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.0027809059032804133, 'tol': 0.01133030435056697, 'validation_fraction': 0.1172627680352855}
observation time 0.000075, current best 0.118166 at iter 10
suggestion time taken 0.002127 iter 11 next_points [{'alpha': 0.002011198046694378, 'batch_size': 127, 'beta_1': 0.6457045939181387, 'beta_2': 0.9946124778506337, 'epsilon': 3.2400977620753382e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.004540462879377646, 'tol': 2.470338310766494e-05, 'validation_fraction': 0.11929597094307537}]
function_evaluation time 0.848226 value 0.123587 suggestion {'alpha': 0.002011198046694378, 'batch_size': 127, 'beta_1': 0.6457045939181387, 'beta_2': 0.9946124778506337, 'epsilon': 3.2400977620753382e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.004540462879377646, 'tol': 2.470338310766494e-05, 'validation_fraction': 0.11929597094307537}
observation time 0.000069, current best 0.118166 at iter 11
suggestion time taken 0.002122 iter 12 next_points [{'alpha': 0.8499780421494432, 'batch_size': 34, 'beta_1': 0.5113120060828346, 'beta_2': 0.9509884965502101, 'epsilon': 3.377597103820622e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.01640603056301373, 'tol': 0.009442337500651236, 'validation_fraction': 0.4641449364671807}]
function_evaluation time 0.892890 value 0.199312 suggestion {'alpha': 0.8499780421494432, 'batch_size': 34, 'beta_1': 0.5113120060828346, 'beta_2': 0.9509884965502101, 'epsilon': 3.377597103820622e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.01640603056301373, 'tol': 0.009442337500651236, 'validation_fraction': 0.4641449364671807}
observation time 0.000073, current best 0.118166 at iter 12
suggestion time taken 0.002171 iter 13 next_points [{'alpha': 2.123272276353432e-05, 'batch_size': 160, 'beta_1': 0.9236343504581433, 'beta_2': 0.9412592251026496, 'epsilon': 4.027112034162028e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.0005616538195252169, 'tol': 4.93001286674726e-05, 'validation_fraction': 0.12631426462669199}]
function_evaluation time 1.329428 value 0.150936 suggestion {'alpha': 2.123272276353432e-05, 'batch_size': 160, 'beta_1': 0.9236343504581433, 'beta_2': 0.9412592251026496, 'epsilon': 4.027112034162028e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.0005616538195252169, 'tol': 4.93001286674726e-05, 'validation_fraction': 0.12631426462669199}
observation time 0.000073, current best 0.118166 at iter 13
suggestion time taken 0.002114 iter 14 next_points [{'alpha': 1.022749553342836e-05, 'batch_size': 201, 'beta_1': 0.6864671878296251, 'beta_2': 0.9170137405208901, 'epsilon': 1.1491682449000195e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.06623436306748788, 'tol': 0.09281715294032292, 'validation_fraction': 0.10022374341938894}]
function_evaluation time 0.509982 value 0.465049 suggestion {'alpha': 1.022749553342836e-05, 'batch_size': 201, 'beta_1': 0.6864671878296251, 'beta_2': 0.9170137405208901, 'epsilon': 1.1491682449000195e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.06623436306748788, 'tol': 0.09281715294032292, 'validation_fraction': 0.10022374341938894}
observation time 0.000075, current best 0.118166 at iter 14
saving meta data: {'args': {'--uuid': '01fb3757100057b3a33a839f24bd977f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

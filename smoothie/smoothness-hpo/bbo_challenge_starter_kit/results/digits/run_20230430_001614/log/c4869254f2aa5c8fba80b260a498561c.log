running: {'--uuid': 'c4869254f2aa5c8fba80b260a498561c', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u c4869254f2aa5c8fba80b260a498561c -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002374 iter 0 next_points [{'alpha': 0.00040465146213476894, 'batch_size': 93, 'beta_1': 0.96485059494166, 'beta_2': 0.9015878354492621, 'epsilon': 2.0061171389636387e-07, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.023819525522536744, 'tol': 0.01732787685069634, 'validation_fraction': 0.24935298737000516}]
function_evaluation time 0.733460 value -0.938064 suggestion {'alpha': 0.00040465146213476894, 'batch_size': 93, 'beta_1': 0.96485059494166, 'beta_2': 0.9015878354492621, 'epsilon': 2.0061171389636387e-07, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.023819525522536744, 'tol': 0.01732787685069634, 'validation_fraction': 0.24935298737000516}
observation time 0.000066, current best -0.938064 at iter 0
suggestion time taken 0.002367 iter 1 next_points [{'alpha': 6.36721809058493e-05, 'batch_size': 210, 'beta_1': 0.5591007951602708, 'beta_2': 0.984554361045622, 'epsilon': 9.796071419829102e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 7.015142135770097e-05, 'tol': 0.00029443378339769505, 'validation_fraction': 0.36152805489968987}]
function_evaluation time 4.350589 value -0.916509 suggestion {'alpha': 6.36721809058493e-05, 'batch_size': 210, 'beta_1': 0.5591007951602708, 'beta_2': 0.984554361045622, 'epsilon': 9.796071419829102e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 7.015142135770097e-05, 'tol': 0.00029443378339769505, 'validation_fraction': 0.36152805489968987}
observation time 0.000064, current best -0.938064 at iter 1
suggestion time taken 0.002091 iter 2 next_points [{'alpha': 0.00020926179523161773, 'batch_size': 168, 'beta_1': 0.5538057051467264, 'beta_2': 0.9568090971117315, 'epsilon': 3.712155691814031e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.001696055324757258, 'tol': 0.03704138311702684, 'validation_fraction': 0.6655883544065837}]
function_evaluation time 0.319556 value -0.849025 suggestion {'alpha': 0.00020926179523161773, 'batch_size': 168, 'beta_1': 0.5538057051467264, 'beta_2': 0.9568090971117315, 'epsilon': 3.712155691814031e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.001696055324757258, 'tol': 0.03704138311702684, 'validation_fraction': 0.6655883544065837}
observation time 0.000068, current best -0.938064 at iter 2
suggestion time taken 0.002118 iter 3 next_points [{'alpha': 1.4468377079782825e-05, 'batch_size': 37, 'beta_1': 0.839146977335714, 'beta_2': 0.9070617933105461, 'epsilon': 1.933271198995517e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.013546682150123786, 'tol': 0.0016888182231396861, 'validation_fraction': 0.14530952911952127}]
function_evaluation time 1.655164 value -0.954767 suggestion {'alpha': 1.4468377079782825e-05, 'batch_size': 37, 'beta_1': 0.839146977335714, 'beta_2': 0.9070617933105461, 'epsilon': 1.933271198995517e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.013546682150123786, 'tol': 0.0016888182231396861, 'validation_fraction': 0.14530952911952127}
observation time 0.000069, current best -0.954767 at iter 3
suggestion time taken 0.002084 iter 4 next_points [{'alpha': 6.392646106078197e-05, 'batch_size': 13, 'beta_1': 0.9180493512892848, 'beta_2': 0.919649730360965, 'epsilon': 3.102552424291559e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 3.88747167081026e-05, 'tol': 0.011749473253878947, 'validation_fraction': 0.1300640454086398}]
function_evaluation time 4.128686 value -0.888703 suggestion {'alpha': 6.392646106078197e-05, 'batch_size': 13, 'beta_1': 0.9180493512892848, 'beta_2': 0.919649730360965, 'epsilon': 3.102552424291559e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 3.88747167081026e-05, 'tol': 0.011749473253878947, 'validation_fraction': 0.1300640454086398}
observation time 0.000068, current best -0.954767 at iter 4
suggestion time taken 0.002125 iter 5 next_points [{'alpha': 2.4085419365585627e-05, 'batch_size': 246, 'beta_1': 0.7367759364348718, 'beta_2': 0.9354237466855174, 'epsilon': 7.268008432660342e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 2.3941989473416745e-05, 'tol': 0.09448679674651297, 'validation_fraction': 0.7342846009152747}]
function_evaluation time 0.220745 value -0.097413 suggestion {'alpha': 2.4085419365585627e-05, 'batch_size': 246, 'beta_1': 0.7367759364348718, 'beta_2': 0.9354237466855174, 'epsilon': 7.268008432660342e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 2.3941989473416745e-05, 'tol': 0.09448679674651297, 'validation_fraction': 0.7342846009152747}
observation time 0.000070, current best -0.954767 at iter 5
suggestion time taken 0.002105 iter 6 next_points [{'alpha': 3.9687545533449833, 'batch_size': 60, 'beta_1': 0.703301777242026, 'beta_2': 0.9183404547073422, 'epsilon': 7.581628384328065e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 6.427155013169253e-05, 'tol': 0.005864872095779069, 'validation_fraction': 0.14864189311175746}]
function_evaluation time 2.146526 value -0.875433 suggestion {'alpha': 3.9687545533449833, 'batch_size': 60, 'beta_1': 0.703301777242026, 'beta_2': 0.9183404547073422, 'epsilon': 7.581628384328065e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 6.427155013169253e-05, 'tol': 0.005864872095779069, 'validation_fraction': 0.14864189311175746}
observation time 0.000071, current best -0.954767 at iter 6
suggestion time taken 0.002196 iter 7 next_points [{'alpha': 0.030104282350341783, 'batch_size': 228, 'beta_1': 0.8449835659218236, 'beta_2': 0.95756662568369, 'epsilon': 1.0159119123447715e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.002084127612293434, 'tol': 0.00014530358170219683, 'validation_fraction': 0.29039520275105857}]
function_evaluation time 1.137816 value -0.962437 suggestion {'alpha': 0.030104282350341783, 'batch_size': 228, 'beta_1': 0.8449835659218236, 'beta_2': 0.95756662568369, 'epsilon': 1.0159119123447715e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.002084127612293434, 'tol': 0.00014530358170219683, 'validation_fraction': 0.29039520275105857}
observation time 0.000074, current best -0.962437 at iter 7
suggestion time taken 0.002141 iter 8 next_points [{'alpha': 0.0152784296595254, 'batch_size': 137, 'beta_1': 0.7176904181842685, 'beta_2': 0.9439651861478072, 'epsilon': 5.00975485545205e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 2.831348045997137e-05, 'tol': 0.0008455248339919212, 'validation_fraction': 0.43684931357959894}]
function_evaluation time 0.912773 value -0.202606 suggestion {'alpha': 0.0152784296595254, 'batch_size': 137, 'beta_1': 0.7176904181842685, 'beta_2': 0.9439651861478072, 'epsilon': 5.00975485545205e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 2.831348045997137e-05, 'tol': 0.0008455248339919212, 'validation_fraction': 0.43684931357959894}
observation time 0.000071, current best -0.962437 at iter 8
suggestion time taken 0.002143 iter 9 next_points [{'alpha': 4.258668750625095, 'batch_size': 43, 'beta_1': 0.7643109605481008, 'beta_2': 0.980800296813399, 'epsilon': 1.406034019959762e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0001456832264171028, 'tol': 0.00014914501755642956, 'validation_fraction': 0.6473697755049674}]
function_evaluation time 3.860425 value -0.948514 suggestion {'alpha': 4.258668750625095, 'batch_size': 43, 'beta_1': 0.7643109605481008, 'beta_2': 0.980800296813399, 'epsilon': 1.406034019959762e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0001456832264171028, 'tol': 0.00014914501755642956, 'validation_fraction': 0.6473697755049674}
observation time 0.000070, current best -0.962437 at iter 9
suggestion time taken 0.002148 iter 10 next_points [{'alpha': 7.711307586899552, 'batch_size': 15, 'beta_1': 0.9740453568499902, 'beta_2': 0.9890772818682, 'epsilon': 4.991172790678665e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.00132979817785731, 'tol': 0.0006619669579329895, 'validation_fraction': 0.2258421780785062}]
function_evaluation time 1.675683 value -0.935301 suggestion {'alpha': 7.711307586899552, 'batch_size': 15, 'beta_1': 0.9740453568499902, 'beta_2': 0.9890772818682, 'epsilon': 4.991172790678665e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.00132979817785731, 'tol': 0.0006619669579329895, 'validation_fraction': 0.2258421780785062}
observation time 0.000070, current best -0.962437 at iter 10
suggestion time taken 0.002110 iter 11 next_points [{'alpha': 0.23572294388518353, 'batch_size': 170, 'beta_1': 0.7314201245518877, 'beta_2': 0.9219568083592535, 'epsilon': 1.5598525607693321e-09, 'hidden_layer_sizes': 160, 'learning_rate_init': 5.214573275264172e-05, 'tol': 0.01614057666950987, 'validation_fraction': 0.18897599517530606}]
function_evaluation time 1.500229 value -0.698974 suggestion {'alpha': 0.23572294388518353, 'batch_size': 170, 'beta_1': 0.7314201245518877, 'beta_2': 0.9219568083592535, 'epsilon': 1.5598525607693321e-09, 'hidden_layer_sizes': 160, 'learning_rate_init': 5.214573275264172e-05, 'tol': 0.01614057666950987, 'validation_fraction': 0.18897599517530606}
observation time 0.000075, current best -0.962437 at iter 11
suggestion time taken 0.002103 iter 12 next_points [{'alpha': 0.022071785988392024, 'batch_size': 172, 'beta_1': 0.6245334466914638, 'beta_2': 0.9320473328592883, 'epsilon': 2.3735595177956965e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0005777111129688242, 'tol': 7.347184600355844e-05, 'validation_fraction': 0.22668683405221698}]
function_evaluation time 1.574744 value -0.963814 suggestion {'alpha': 0.022071785988392024, 'batch_size': 172, 'beta_1': 0.6245334466914638, 'beta_2': 0.9320473328592883, 'epsilon': 2.3735595177956965e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0005777111129688242, 'tol': 7.347184600355844e-05, 'validation_fraction': 0.22668683405221698}
observation time 0.000073, current best -0.963814 at iter 12
suggestion time taken 0.002178 iter 13 next_points [{'alpha': 0.02966107940491866, 'batch_size': 194, 'beta_1': 0.8489883811358387, 'beta_2': 0.9770207513610651, 'epsilon': 1.4505157565795645e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.02363508635816647, 'tol': 0.02905286363361639, 'validation_fraction': 0.8329485936738281}]
function_evaluation time 0.456243 value -0.894210 suggestion {'alpha': 0.02966107940491866, 'batch_size': 194, 'beta_1': 0.8489883811358387, 'beta_2': 0.9770207513610651, 'epsilon': 1.4505157565795645e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.02363508635816647, 'tol': 0.02905286363361639, 'validation_fraction': 0.8329485936738281}
observation time 0.000075, current best -0.963814 at iter 13
suggestion time taken 0.002154 iter 14 next_points [{'alpha': 0.007850192478791871, 'batch_size': 69, 'beta_1': 0.5533401628189965, 'beta_2': 0.9817001155591113, 'epsilon': 1.883274735408632e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.002655298411989916, 'tol': 5.044544599430314e-05, 'validation_fraction': 0.13299408933608906}]
function_evaluation time 1.537054 value -0.974942 suggestion {'alpha': 0.007850192478791871, 'batch_size': 69, 'beta_1': 0.5533401628189965, 'beta_2': 0.9817001155591113, 'epsilon': 1.883274735408632e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.002655298411989916, 'tol': 5.044544599430314e-05, 'validation_fraction': 0.13299408933608906}
observation time 0.000075, current best -0.974942 at iter 14
saving meta data: {'args': {'--uuid': 'c4869254f2aa5c8fba80b260a498561c', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

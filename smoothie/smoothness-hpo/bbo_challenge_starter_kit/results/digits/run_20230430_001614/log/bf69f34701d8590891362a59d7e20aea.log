running: {'--uuid': 'bf69f34701d8590891362a59d7e20aea', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d digits -o random-search -u bf69f34701d8590891362a59d7e20aea -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230430_001614
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study random-search MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002539 iter 0 next_points [{'alpha': 0.00014820323861605803, 'batch_size': 93, 'beta_1': 0.6818704500844592, 'beta_2': 0.9999794347135806, 'epsilon': 1.1877555937812547e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 5.067759944504541e-05, 'tol': 1.2866463634644115e-05, 'validation_fraction': 0.3515909109158671}]
function_evaluation time 6.462637 value -0.853891 suggestion {'alpha': 0.00014820323861605803, 'batch_size': 93, 'beta_1': 0.6818704500844592, 'beta_2': 0.9999794347135806, 'epsilon': 1.1877555937812547e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 5.067759944504541e-05, 'tol': 1.2866463634644115e-05, 'validation_fraction': 0.3515909109158671}
observation time 0.000006, current best -0.853891 at iter 0
suggestion time taken 0.002859 iter 1 next_points [{'alpha': 6.318190861166441e-05, 'batch_size': 209, 'beta_1': 0.8850221037001492, 'beta_2': 0.9996755483745658, 'epsilon': 6.782092505037472e-09, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.037905742132702806, 'tol': 0.011818952840629874, 'validation_fraction': 0.12617145589459663}]
function_evaluation time 0.369112 value -0.934601 suggestion {'alpha': 6.318190861166441e-05, 'batch_size': 209, 'beta_1': 0.8850221037001492, 'beta_2': 0.9996755483745658, 'epsilon': 6.782092505037472e-09, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.037905742132702806, 'tol': 0.011818952840629874, 'validation_fraction': 0.12617145589459663}
observation time 0.000004, current best -0.934601 at iter 1
suggestion time taken 0.002535 iter 2 next_points [{'alpha': 0.007550950688262801, 'batch_size': 138, 'beta_1': 0.7565904122661842, 'beta_2': 0.9999973758211832, 'epsilon': 3.99695521513088e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0036827651187799557, 'tol': 0.022492140743903103, 'validation_fraction': 0.15305118130093517}]
function_evaluation time 0.625532 value -0.963811 suggestion {'alpha': 0.007550950688262801, 'batch_size': 138, 'beta_1': 0.7565904122661842, 'beta_2': 0.9999973758211832, 'epsilon': 3.99695521513088e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0036827651187799557, 'tol': 0.022492140743903103, 'validation_fraction': 0.15305118130093517}
observation time 0.000005, current best -0.963811 at iter 2
suggestion time taken 0.002506 iter 3 next_points [{'alpha': 1.919188710866033e-05, 'batch_size': 105, 'beta_1': 0.7316845122938492, 'beta_2': 0.9984353112452065, 'epsilon': 2.1919202252289924e-07, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.05615256431538862, 'tol': 0.0009276512918170569, 'validation_fraction': 0.6665097073898735}]
function_evaluation time 1.102242 value -0.808629 suggestion {'alpha': 1.919188710866033e-05, 'batch_size': 105, 'beta_1': 0.7316845122938492, 'beta_2': 0.9984353112452065, 'epsilon': 2.1919202252289924e-07, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.05615256431538862, 'tol': 0.0009276512918170569, 'validation_fraction': 0.6665097073898735}
observation time 0.000005, current best -0.963811 at iter 3
suggestion time taken 0.002499 iter 4 next_points [{'alpha': 0.811614899952301, 'batch_size': 82, 'beta_1': 0.9492699882012112, 'beta_2': 0.9999750364856601, 'epsilon': 3.8545563920730493e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.048122340309816866, 'tol': 0.002751532854366423, 'validation_fraction': 0.2669431374694004}]
function_evaluation time 0.986268 value -0.945710 suggestion {'alpha': 0.811614899952301, 'batch_size': 82, 'beta_1': 0.9492699882012112, 'beta_2': 0.9999750364856601, 'epsilon': 3.8545563920730493e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.048122340309816866, 'tol': 0.002751532854366423, 'validation_fraction': 0.2669431374694004}
observation time 0.000004, current best -0.963811 at iter 4
suggestion time taken 0.002476 iter 5 next_points [{'alpha': 0.00896827919370571, 'batch_size': 69, 'beta_1': 0.7109843184625856, 'beta_2': 0.9995272693238532, 'epsilon': 3.94121281361888e-08, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.010019307580340777, 'tol': 2.314613150785093e-05, 'validation_fraction': 0.29683200114594027}]
function_evaluation time 1.181319 value -0.970083 suggestion {'alpha': 0.00896827919370571, 'batch_size': 69, 'beta_1': 0.7109843184625856, 'beta_2': 0.9995272693238532, 'epsilon': 3.94121281361888e-08, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.010019307580340777, 'tol': 2.314613150785093e-05, 'validation_fraction': 0.29683200114594027}
observation time 0.000005, current best -0.970083 at iter 5
suggestion time taken 0.002448 iter 6 next_points [{'alpha': 0.8385054439206444, 'batch_size': 234, 'beta_1': 0.9722324528951396, 'beta_2': 0.9993388912424589, 'epsilon': 3.183665449684335e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 3.3946704491078047e-05, 'tol': 0.007899060400000588, 'validation_fraction': 0.37360686797511633}]
function_evaluation time 0.800600 value -0.126655 suggestion {'alpha': 0.8385054439206444, 'batch_size': 234, 'beta_1': 0.9722324528951396, 'beta_2': 0.9993388912424589, 'epsilon': 3.183665449684335e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 3.3946704491078047e-05, 'tol': 0.007899060400000588, 'validation_fraction': 0.37360686797511633}
observation time 0.000004, current best -0.970083 at iter 6
suggestion time taken 0.002458 iter 7 next_points [{'alpha': 0.0006114971895005815, 'batch_size': 131, 'beta_1': 0.8502594128863937, 'beta_2': 0.9982931608413718, 'epsilon': 1.917587079614691e-08, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.014686452206574281, 'tol': 0.02167352468383905, 'validation_fraction': 0.15114171322332062}]
function_evaluation time 0.541698 value -0.968697 suggestion {'alpha': 0.0006114971895005815, 'batch_size': 131, 'beta_1': 0.8502594128863937, 'beta_2': 0.9982931608413718, 'epsilon': 1.917587079614691e-08, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.014686452206574281, 'tol': 0.02167352468383905, 'validation_fraction': 0.15114171322332062}
observation time 0.000005, current best -0.970083 at iter 7
suggestion time taken 0.002461 iter 8 next_points [{'alpha': 8.041634487199287, 'batch_size': 111, 'beta_1': 0.6793339446789574, 'beta_2': 0.9902904202383684, 'epsilon': 5.236686368650859e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.00773005830304175, 'tol': 0.0009099428218533001, 'validation_fraction': 0.8093621220354835}]
function_evaluation time 0.913720 value -0.925542 suggestion {'alpha': 8.041634487199287, 'batch_size': 111, 'beta_1': 0.6793339446789574, 'beta_2': 0.9902904202383684, 'epsilon': 5.236686368650859e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.00773005830304175, 'tol': 0.0009099428218533001, 'validation_fraction': 0.8093621220354835}
observation time 0.000004, current best -0.970083 at iter 8
suggestion time taken 0.002466 iter 9 next_points [{'alpha': 0.021317103381364572, 'batch_size': 45, 'beta_1': 0.7734784495562415, 'beta_2': 0.9999792664148249, 'epsilon': 8.807817562091684e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00036601703524858, 'tol': 0.04151867185601644, 'validation_fraction': 0.18099262394461277}]
function_evaluation time 1.135444 value -0.942952 suggestion {'alpha': 0.021317103381364572, 'batch_size': 45, 'beta_1': 0.7734784495562415, 'beta_2': 0.9999792664148249, 'epsilon': 8.807817562091684e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00036601703524858, 'tol': 0.04151867185601644, 'validation_fraction': 0.18099262394461277}
observation time 0.000004, current best -0.970083 at iter 9
suggestion time taken 0.002508 iter 10 next_points [{'alpha': 0.011069103212706146, 'batch_size': 41, 'beta_1': 0.9874080965176656, 'beta_2': 0.9993750516875647, 'epsilon': 8.716750963119062e-09, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.06672414061229738, 'tol': 0.0008102558565328112, 'validation_fraction': 0.11124023181057931}]
function_evaluation time 2.403705 value -0.757000 suggestion {'alpha': 0.011069103212706146, 'batch_size': 41, 'beta_1': 0.9874080965176656, 'beta_2': 0.9993750516875647, 'epsilon': 8.716750963119062e-09, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.06672414061229738, 'tol': 0.0008102558565328112, 'validation_fraction': 0.11124023181057931}
observation time 0.000005, current best -0.970083 at iter 10
suggestion time taken 0.002819 iter 11 next_points [{'alpha': 1.8909331640389756e-05, 'batch_size': 126, 'beta_1': 0.5768976707607298, 'beta_2': 0.9999975344606331, 'epsilon': 7.827187035518444e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 2.0010080670729333e-05, 'tol': 0.00045078633426966924, 'validation_fraction': 0.14325407362807713}]
function_evaluation time 4.641730 value -0.491887 suggestion {'alpha': 1.8909331640389756e-05, 'batch_size': 126, 'beta_1': 0.5768976707607298, 'beta_2': 0.9999975344606331, 'epsilon': 7.827187035518444e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 2.0010080670729333e-05, 'tol': 0.00045078633426966924, 'validation_fraction': 0.14325407362807713}
observation time 0.000005, current best -0.970083 at iter 11
suggestion time taken 0.002495 iter 12 next_points [{'alpha': 3.9914222636540138, 'batch_size': 135, 'beta_1': 0.9862783438854793, 'beta_2': 0.9999332372872729, 'epsilon': 1.4929239010410567e-07, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0004027780224705928, 'tol': 5.668780881049564e-05, 'validation_fraction': 0.5284281401213187}]
function_evaluation time 2.239182 value -0.916502 suggestion {'alpha': 3.9914222636540138, 'batch_size': 135, 'beta_1': 0.9862783438854793, 'beta_2': 0.9999332372872729, 'epsilon': 1.4929239010410567e-07, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0004027780224705928, 'tol': 5.668780881049564e-05, 'validation_fraction': 0.5284281401213187}
observation time 0.000005, current best -0.970083 at iter 12
suggestion time taken 0.002461 iter 13 next_points [{'alpha': 0.12554568184702747, 'batch_size': 167, 'beta_1': 0.9685948001344351, 'beta_2': 0.9965326048432224, 'epsilon': 8.581835237505333e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.004646272726487957, 'tol': 0.001301511084921802, 'validation_fraction': 0.3975331676894406}]
function_evaluation time 1.003871 value -0.950595 suggestion {'alpha': 0.12554568184702747, 'batch_size': 167, 'beta_1': 0.9685948001344351, 'beta_2': 0.9965326048432224, 'epsilon': 8.581835237505333e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.004646272726487957, 'tol': 0.001301511084921802, 'validation_fraction': 0.3975331676894406}
observation time 0.000005, current best -0.970083 at iter 13
suggestion time taken 0.002802 iter 14 next_points [{'alpha': 0.002760904131105357, 'batch_size': 109, 'beta_1': 0.8970829525781235, 'beta_2': 0.9953711755207598, 'epsilon': 2.8437667283086226e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 1.612594982357971e-05, 'tol': 0.0019598846590460008, 'validation_fraction': 0.8465170552658547}]
function_evaluation time 0.478487 value -0.138427 suggestion {'alpha': 0.002760904131105357, 'batch_size': 109, 'beta_1': 0.8970829525781235, 'beta_2': 0.9953711755207598, 'epsilon': 2.8437667283086226e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 1.612594982357971e-05, 'tol': 0.0019598846590460008, 'validation_fraction': 0.8465170552658547}
observation time 0.000005, current best -0.970083 at iter 14
saving meta data: {'args': {'--uuid': 'bf69f34701d8590891362a59d7e20aea', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230430_001614', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

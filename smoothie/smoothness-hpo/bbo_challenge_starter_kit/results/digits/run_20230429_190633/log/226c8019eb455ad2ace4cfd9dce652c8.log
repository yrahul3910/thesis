running: {'--uuid': '226c8019eb455ad2ace4cfd9dce652c8', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u 226c8019eb455ad2ace4cfd9dce652c8 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study smoothness MLP-adam digits nll 15 1
with data root: None
suggestion time taken 9.518538 iter 0 next_points [{'alpha': 0.05804913828986578, 'batch_size': 20, 'beta_1': 0.6782898649611998, 'beta_2': 0.9822340998474152, 'epsilon': 4.577293806039392e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.01571656386033134, 'tol': 1.4342567062136101e-05, 'validation_fraction': 0.3653926929551509}]
function_evaluation time 1.795703 value 0.213508 suggestion {'alpha': 0.05804913828986578, 'batch_size': 20, 'beta_1': 0.6782898649611998, 'beta_2': 0.9822340998474152, 'epsilon': 4.577293806039392e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.01571656386033134, 'tol': 1.4342567062136101e-05, 'validation_fraction': 0.3653926929551509}
observation time 0.000008, current best 0.213508 at iter 0
suggestion time taken 9.326970 iter 1 next_points [{'alpha': 0.0002950139943257465, 'batch_size': 19, 'beta_1': 0.9887164756327022, 'beta_2': 0.9999973308116793, 'epsilon': 7.982244765028884e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.0028686772411359203, 'tol': 3.181394374118347e-05, 'validation_fraction': 0.8382794512070958}]
function_evaluation time 0.939701 value 0.395188 suggestion {'alpha': 0.0002950139943257465, 'batch_size': 19, 'beta_1': 0.9887164756327022, 'beta_2': 0.9999973308116793, 'epsilon': 7.982244765028884e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.0028686772411359203, 'tol': 3.181394374118347e-05, 'validation_fraction': 0.8382794512070958}
observation time 0.000007, current best 0.213508 at iter 1
suggestion time taken 9.501829 iter 2 next_points [{'alpha': 1.8778154974821586e-05, 'batch_size': 13, 'beta_1': 0.8317831193114015, 'beta_2': 0.9999505383750857, 'epsilon': 2.4385993526821885e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0009533585602655115, 'tol': 5.5722729628500304e-05, 'validation_fraction': 0.83780410249055}]
function_evaluation time 2.389050 value 0.492128 suggestion {'alpha': 1.8778154974821586e-05, 'batch_size': 13, 'beta_1': 0.8317831193114015, 'beta_2': 0.9999505383750857, 'epsilon': 2.4385993526821885e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0009533585602655115, 'tol': 5.5722729628500304e-05, 'validation_fraction': 0.83780410249055}
observation time 0.000006, current best 0.213508 at iter 2
suggestion time taken 9.708649 iter 3 next_points [{'alpha': 0.25750094261500356, 'batch_size': 26, 'beta_1': 0.9708293936621638, 'beta_2': 0.9999698116226696, 'epsilon': 5.519515716955857e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.042333630951703095, 'tol': 8.321778473766195e-05, 'validation_fraction': 0.10206714060143313}]
function_evaluation time 1.635420 value 0.325994 suggestion {'alpha': 0.25750094261500356, 'batch_size': 26, 'beta_1': 0.9708293936621638, 'beta_2': 0.9999698116226696, 'epsilon': 5.519515716955857e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.042333630951703095, 'tol': 8.321778473766195e-05, 'validation_fraction': 0.10206714060143313}
observation time 0.000005, current best 0.213508 at iter 3
suggestion time taken 9.668175 iter 4 next_points [{'alpha': 0.8055514459531133, 'batch_size': 19, 'beta_1': 0.6216278622714735, 'beta_2': 0.9999224610901913, 'epsilon': 4.7330122621210145e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.002214000374710179, 'tol': 0.002083856275303351, 'validation_fraction': 0.7255764132499427}]
function_evaluation time 2.639101 value 0.186895 suggestion {'alpha': 0.8055514459531133, 'batch_size': 19, 'beta_1': 0.6216278622714735, 'beta_2': 0.9999224610901913, 'epsilon': 4.7330122621210145e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.002214000374710179, 'tol': 0.002083856275303351, 'validation_fraction': 0.7255764132499427}
observation time 0.000004, current best 0.186895 at iter 4
suggestion time taken 9.703632 iter 5 next_points [{'alpha': 0.0008809800796670889, 'batch_size': 37, 'beta_1': 0.7825776092684206, 'beta_2': 0.9756381048664846, 'epsilon': 1.2814989203130375e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.07436738052713901, 'tol': 3.579896223705464e-05, 'validation_fraction': 0.2538204995959348}]
function_evaluation time 1.837463 value 1.522382 suggestion {'alpha': 0.0008809800796670889, 'batch_size': 37, 'beta_1': 0.7825776092684206, 'beta_2': 0.9756381048664846, 'epsilon': 1.2814989203130375e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.07436738052713901, 'tol': 3.579896223705464e-05, 'validation_fraction': 0.2538204995959348}
observation time 0.000005, current best 0.186895 at iter 5
suggestion time taken 9.687845 iter 6 next_points [{'alpha': 2.1250588312583276, 'batch_size': 24, 'beta_1': 0.8394158305443701, 'beta_2': 0.9943690893661369, 'epsilon': 2.015273261145514e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.06178857107604605, 'tol': 0.016779747809084773, 'validation_fraction': 0.21591986785512554}]
function_evaluation time 2.080951 value 0.557271 suggestion {'alpha': 2.1250588312583276, 'batch_size': 24, 'beta_1': 0.8394158305443701, 'beta_2': 0.9943690893661369, 'epsilon': 2.015273261145514e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.06178857107604605, 'tol': 0.016779747809084773, 'validation_fraction': 0.21591986785512554}
observation time 0.000005, current best 0.186895 at iter 6
suggestion time taken 9.749518 iter 7 next_points [{'alpha': 0.0035994121186326013, 'batch_size': 48, 'beta_1': 0.9884444717576971, 'beta_2': 0.9999449599983535, 'epsilon': 3.5258725165495313e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 4.8924865480409394e-05, 'tol': 0.00032051354123783696, 'validation_fraction': 0.5745254374100973}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 7.441836 value 2.889772 suggestion {'alpha': 0.0035994121186326013, 'batch_size': 48, 'beta_1': 0.9884444717576971, 'beta_2': 0.9999449599983535, 'epsilon': 3.5258725165495313e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 4.8924865480409394e-05, 'tol': 0.00032051354123783696, 'validation_fraction': 0.5745254374100973}
observation time 0.000005, current best 0.186895 at iter 7
suggestion time taken 9.792842 iter 8 next_points [{'alpha': 0.0006057112385799548, 'batch_size': 17, 'beta_1': 0.6605019833526102, 'beta_2': 0.9995764743869758, 'epsilon': 5.284993111699913e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 1.3052497147973724e-05, 'tol': 4.2355088370045734e-05, 'validation_fraction': 0.7283205537702125}]
function_evaluation time 4.407517 value 7.011174 suggestion {'alpha': 0.0006057112385799548, 'batch_size': 17, 'beta_1': 0.6605019833526102, 'beta_2': 0.9995764743869758, 'epsilon': 5.284993111699913e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 1.3052497147973724e-05, 'tol': 4.2355088370045734e-05, 'validation_fraction': 0.7283205537702125}
observation time 0.000005, current best 0.186895 at iter 8
suggestion time taken 9.767030 iter 9 next_points [{'alpha': 3.2932200298439356, 'batch_size': 19, 'beta_1': 0.9711129141803967, 'beta_2': 0.9999966946775766, 'epsilon': 6.028905237561137e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.0011524755716145133, 'tol': 2.974893534136964e-05, 'validation_fraction': 0.7066696300912737}]
function_evaluation time 3.291540 value 0.259238 suggestion {'alpha': 3.2932200298439356, 'batch_size': 19, 'beta_1': 0.9711129141803967, 'beta_2': 0.9999966946775766, 'epsilon': 6.028905237561137e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.0011524755716145133, 'tol': 2.974893534136964e-05, 'validation_fraction': 0.7066696300912737}
observation time 0.000005, current best 0.186895 at iter 9
suggestion time taken 9.820379 iter 10 next_points [{'alpha': 1.7144962034107556e-05, 'batch_size': 24, 'beta_1': 0.7237003802935246, 'beta_2': 0.9114340536313073, 'epsilon': 4.457059065528483e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.0031523764927249096, 'tol': 0.002908124451111149, 'validation_fraction': 0.8861114791515082}]
function_evaluation time 1.283864 value 0.391690 suggestion {'alpha': 1.7144962034107556e-05, 'batch_size': 24, 'beta_1': 0.7237003802935246, 'beta_2': 0.9114340536313073, 'epsilon': 4.457059065528483e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.0031523764927249096, 'tol': 0.002908124451111149, 'validation_fraction': 0.8861114791515082}
observation time 0.000005, current best 0.186895 at iter 10
suggestion time taken 9.812097 iter 11 next_points [{'alpha': 0.007937302833576798, 'batch_size': 35, 'beta_1': 0.9648044358343046, 'beta_2': 0.9998626761922511, 'epsilon': 3.3495032072119224e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 9.513429310571304e-05, 'tol': 4.5665701900410255e-05, 'validation_fraction': 0.2615446614262701}]
function_evaluation time 7.022507 value 0.277879 suggestion {'alpha': 0.007937302833576798, 'batch_size': 35, 'beta_1': 0.9648044358343046, 'beta_2': 0.9998626761922511, 'epsilon': 3.3495032072119224e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 9.513429310571304e-05, 'tol': 4.5665701900410255e-05, 'validation_fraction': 0.2615446614262701}
observation time 0.000005, current best 0.186895 at iter 11
suggestion time taken 9.854827 iter 12 next_points [{'alpha': 0.002766133649321629, 'batch_size': 27, 'beta_1': 0.8947123451506425, 'beta_2': 0.9992246712116875, 'epsilon': 4.954213305525195e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.09736298403871232, 'tol': 0.04583144554106882, 'validation_fraction': 0.13932836190351788}]
function_evaluation time 0.913284 value 1.888707 suggestion {'alpha': 0.002766133649321629, 'batch_size': 27, 'beta_1': 0.8947123451506425, 'beta_2': 0.9992246712116875, 'epsilon': 4.954213305525195e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.09736298403871232, 'tol': 0.04583144554106882, 'validation_fraction': 0.13932836190351788}
observation time 0.000005, current best 0.186895 at iter 12
suggestion time taken 9.838391 iter 13 next_points [{'alpha': 0.003748575672951373, 'batch_size': 29, 'beta_1': 0.9854502208171645, 'beta_2': 0.9997193092573313, 'epsilon': 3.562647771574399e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 6.717794886826193e-05, 'tol': 0.0006448947118905305, 'validation_fraction': 0.18859884019947695}]
function_evaluation time 7.470567 value 0.282666 suggestion {'alpha': 0.003748575672951373, 'batch_size': 29, 'beta_1': 0.9854502208171645, 'beta_2': 0.9997193092573313, 'epsilon': 3.562647771574399e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 6.717794886826193e-05, 'tol': 0.0006448947118905305, 'validation_fraction': 0.18859884019947695}
observation time 0.000006, current best 0.186895 at iter 13
suggestion time taken 9.921705 iter 14 next_points [{'alpha': 1.3287874143183856e-05, 'batch_size': 51, 'beta_1': 0.8476252808243273, 'beta_2': 0.9999909485202532, 'epsilon': 5.014917393360395e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0028249615893553115, 'tol': 7.170215135899864e-05, 'validation_fraction': 0.17094276131629135}]
function_evaluation time 1.115095 value 0.122036 suggestion {'alpha': 1.3287874143183856e-05, 'batch_size': 51, 'beta_1': 0.8476252808243273, 'beta_2': 0.9999909485202532, 'epsilon': 5.014917393360395e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0028249615893553115, 'tol': 7.170215135899864e-05, 'validation_fraction': 0.17094276131629135}
observation time 0.000005, current best 0.122036 at iter 14
saving meta data: {'args': {'--uuid': '226c8019eb455ad2ace4cfd9dce652c8', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '6cf76d8981d25347a58bc13c3f345cdc', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 6cf76d8981d25347a58bc13c3f345cdc -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002438 iter 0 next_points [{'alpha': 5.167794334116915, 'batch_size': 24, 'beta_1': 0.5443399747783912, 'beta_2': 0.9707411979425625, 'epsilon': 2.5169218716618664e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 2.0231392843284785e-05, 'tol': 2.1066476749392888e-05, 'validation_fraction': 0.8412627089720857}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.348917 value -0.276253 suggestion {'alpha': 5.167794334116915, 'batch_size': 24, 'beta_1': 0.5443399747783912, 'beta_2': 0.9707411979425625, 'epsilon': 2.5169218716618664e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 2.0231392843284785e-05, 'tol': 2.1066476749392888e-05, 'validation_fraction': 0.8412627089720857}
observation time 0.000074, current best -0.276253 at iter 0
suggestion time taken 0.002400 iter 1 next_points [{'alpha': 0.6318487823394692, 'batch_size': 216, 'beta_1': 0.6931024631153359, 'beta_2': 0.952556983052025, 'epsilon': 8.426300528783239e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.025635860849002084, 'tol': 0.006722081742813828, 'validation_fraction': 0.4379208342480501}]
function_evaluation time 0.373125 value -0.943658 suggestion {'alpha': 0.6318487823394692, 'batch_size': 216, 'beta_1': 0.6931024631153359, 'beta_2': 0.952556983052025, 'epsilon': 8.426300528783239e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.025635860849002084, 'tol': 0.006722081742813828, 'validation_fraction': 0.4379208342480501}
observation time 0.000071, current best -0.943658 at iter 1
suggestion time taken 0.002107 iter 2 next_points [{'alpha': 1.1819354842169528e-05, 'batch_size': 218, 'beta_1': 0.851438474047292, 'beta_2': 0.9836439400678303, 'epsilon': 1.0252470504367468e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 6.0362000175131674e-05, 'tol': 2.398977718728834e-05, 'validation_fraction': 0.5542365169125012}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.753659 value -0.737955 suggestion {'alpha': 1.1819354842169528e-05, 'batch_size': 218, 'beta_1': 0.851438474047292, 'beta_2': 0.9836439400678303, 'epsilon': 1.0252470504367468e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 6.0362000175131674e-05, 'tol': 2.398977718728834e-05, 'validation_fraction': 0.5542365169125012}
observation time 0.000072, current best -0.943658 at iter 2
suggestion time taken 0.002121 iter 3 next_points [{'alpha': 0.5168959858647018, 'batch_size': 187, 'beta_1': 0.654370514948461, 'beta_2': 0.940330217044996, 'epsilon': 2.1777647657837804e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.04050348779443125, 'tol': 0.00024335945181814286, 'validation_fraction': 0.18055316576292607}]
function_evaluation time 0.626450 value -0.945756 suggestion {'alpha': 0.5168959858647018, 'batch_size': 187, 'beta_1': 0.654370514948461, 'beta_2': 0.940330217044996, 'epsilon': 2.1777647657837804e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.04050348779443125, 'tol': 0.00024335945181814286, 'validation_fraction': 0.18055316576292607}
observation time 0.000073, current best -0.945756 at iter 3
suggestion time taken 0.002102 iter 4 next_points [{'alpha': 0.06413273652509487, 'batch_size': 166, 'beta_1': 0.5738592831685415, 'beta_2': 0.9787765255614962, 'epsilon': 2.4287837347102412e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 4.5637310895391934e-05, 'tol': 0.001417499028938832, 'validation_fraction': 0.30701587348183146}]
function_evaluation time 4.039299 value -0.740793 suggestion {'alpha': 0.06413273652509487, 'batch_size': 166, 'beta_1': 0.5738592831685415, 'beta_2': 0.9787765255614962, 'epsilon': 2.4287837347102412e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 4.5637310895391934e-05, 'tol': 0.001417499028938832, 'validation_fraction': 0.30701587348183146}
observation time 0.000068, current best -0.945756 at iter 4
suggestion time taken 0.002152 iter 5 next_points [{'alpha': 1.5703264204653231, 'batch_size': 164, 'beta_1': 0.7315551230738615, 'beta_2': 0.915615146320784, 'epsilon': 2.0398230536353073e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0002560886314837481, 'tol': 0.0004770290069866061, 'validation_fraction': 0.7594278628936344}]
function_evaluation time 2.117565 value -0.921368 suggestion {'alpha': 1.5703264204653231, 'batch_size': 164, 'beta_1': 0.7315551230738615, 'beta_2': 0.915615146320784, 'epsilon': 2.0398230536353073e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0002560886314837481, 'tol': 0.0004770290069866061, 'validation_fraction': 0.7594278628936344}
observation time 0.000071, current best -0.945756 at iter 5
suggestion time taken 0.002186 iter 6 next_points [{'alpha': 0.0022357195769390653, 'batch_size': 130, 'beta_1': 0.5724475316275449, 'beta_2': 0.9720779128309264, 'epsilon': 9.762435849753798e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.009865659403905162, 'tol': 0.0005760629766392944, 'validation_fraction': 0.1275710903992299}]
function_evaluation time 0.783998 value -0.959647 suggestion {'alpha': 0.0022357195769390653, 'batch_size': 130, 'beta_1': 0.5724475316275449, 'beta_2': 0.9720779128309264, 'epsilon': 9.762435849753798e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.009865659403905162, 'tol': 0.0005760629766392944, 'validation_fraction': 0.1275710903992299}
observation time 0.000071, current best -0.959647 at iter 6
suggestion time taken 0.002208 iter 7 next_points [{'alpha': 0.2418244576799111, 'batch_size': 175, 'beta_1': 0.918249702907235, 'beta_2': 0.9201070472044091, 'epsilon': 1.1627272249899226e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.005847903635893704, 'tol': 5.312622305813764e-05, 'validation_fraction': 0.564343047156946}]
function_evaluation time 0.686047 value -0.951270 suggestion {'alpha': 0.2418244576799111, 'batch_size': 175, 'beta_1': 0.918249702907235, 'beta_2': 0.9201070472044091, 'epsilon': 1.1627272249899226e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.005847903635893704, 'tol': 5.312622305813764e-05, 'validation_fraction': 0.564343047156946}
observation time 0.000074, current best -0.959647 at iter 7
suggestion time taken 0.002134 iter 8 next_points [{'alpha': 0.0008402101663290339, 'batch_size': 227, 'beta_1': 0.9825431353630153, 'beta_2': 0.996995330251374, 'epsilon': 5.342991998367245e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 3.570893846459024e-05, 'tol': 0.0102601859232481, 'validation_fraction': 0.21701188613367733}]
function_evaluation time 0.212805 value -0.176028 suggestion {'alpha': 0.0008402101663290339, 'batch_size': 227, 'beta_1': 0.9825431353630153, 'beta_2': 0.996995330251374, 'epsilon': 5.342991998367245e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 3.570893846459024e-05, 'tol': 0.0102601859232481, 'validation_fraction': 0.21701188613367733}
observation time 0.000078, current best -0.959647 at iter 8
suggestion time taken 0.002172 iter 9 next_points [{'alpha': 1.678573439296922e-05, 'batch_size': 125, 'beta_1': 0.6917141215463581, 'beta_2': 0.9267960366000131, 'epsilon': 2.985976657179182e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.0001336845561834378, 'tol': 0.001903458403596412, 'validation_fraction': 0.34355115072378867}]
function_evaluation time 3.095690 value -0.915113 suggestion {'alpha': 1.678573439296922e-05, 'batch_size': 125, 'beta_1': 0.6917141215463581, 'beta_2': 0.9267960366000131, 'epsilon': 2.985976657179182e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.0001336845561834378, 'tol': 0.001903458403596412, 'validation_fraction': 0.34355115072378867}
observation time 0.000065, current best -0.959647 at iter 9
suggestion time taken 0.002385 iter 10 next_points [{'alpha': 0.00024119471117173093, 'batch_size': 115, 'beta_1': 0.9602865256468263, 'beta_2': 0.989640039988602, 'epsilon': 6.344652687402885e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.06350969038500837, 'tol': 0.0009039679738077896, 'validation_fraction': 0.13657636185953145}]
function_evaluation time 1.968859 value -0.622967 suggestion {'alpha': 0.00024119471117173093, 'batch_size': 115, 'beta_1': 0.9602865256468263, 'beta_2': 0.989640039988602, 'epsilon': 6.344652687402885e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.06350969038500837, 'tol': 0.0009039679738077896, 'validation_fraction': 0.13657636185953145}
observation time 0.000071, current best -0.959647 at iter 10
suggestion time taken 0.002151 iter 11 next_points [{'alpha': 0.03171328204226471, 'batch_size': 145, 'beta_1': 0.75272812728514, 'beta_2': 0.9840364739096612, 'epsilon': 2.0774295985902388e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 1.9565903264643545e-05, 'tol': 0.018007820575609877, 'validation_fraction': 0.27223587905829016}]
function_evaluation time 0.321203 value -0.095342 suggestion {'alpha': 0.03171328204226471, 'batch_size': 145, 'beta_1': 0.75272812728514, 'beta_2': 0.9840364739096612, 'epsilon': 2.0774295985902388e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 1.9565903264643545e-05, 'tol': 0.018007820575609877, 'validation_fraction': 0.27223587905829016}
observation time 0.000072, current best -0.959647 at iter 11
suggestion time taken 0.002371 iter 12 next_points [{'alpha': 0.02221323373336355, 'batch_size': 249, 'beta_1': 0.9033660766563588, 'beta_2': 0.9768266399696053, 'epsilon': 7.4028888876536274e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 9.799238897532942e-05, 'tol': 0.0066923534943017695, 'validation_fraction': 0.8676719722761445}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.139282 value -0.132866 suggestion {'alpha': 0.02221323373336355, 'batch_size': 249, 'beta_1': 0.9033660766563588, 'beta_2': 0.9768266399696053, 'epsilon': 7.4028888876536274e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 9.799238897532942e-05, 'tol': 0.0066923534943017695, 'validation_fraction': 0.8676719722761445}
observation time 0.000074, current best -0.959647 at iter 12
suggestion time taken 0.002234 iter 13 next_points [{'alpha': 0.0668481085622403, 'batch_size': 42, 'beta_1': 0.6581960977465686, 'beta_2': 0.94914225069583, 'epsilon': 3.551844327512542e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0031149140733523002, 'tol': 0.0004601333938692994, 'validation_fraction': 0.2305106387809377}]
function_evaluation time 1.491019 value -0.966604 suggestion {'alpha': 0.0668481085622403, 'batch_size': 42, 'beta_1': 0.6581960977465686, 'beta_2': 0.94914225069583, 'epsilon': 3.551844327512542e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0031149140733523002, 'tol': 0.0004601333938692994, 'validation_fraction': 0.2305106387809377}
observation time 0.000079, current best -0.966604 at iter 13
suggestion time taken 0.002166 iter 14 next_points [{'alpha': 0.018385758509581115, 'batch_size': 154, 'beta_1': 0.5692876017218234, 'beta_2': 0.9438522081668257, 'epsilon': 1.0577874289500974e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0022580239147164294, 'tol': 0.004190382164536455, 'validation_fraction': 0.11904974511465397}]
function_evaluation time 1.084110 value -0.965914 suggestion {'alpha': 0.018385758509581115, 'batch_size': 154, 'beta_1': 0.5692876017218234, 'beta_2': 0.9438522081668257, 'epsilon': 1.0577874289500974e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0022580239147164294, 'tol': 0.004190382164536455, 'validation_fraction': 0.11904974511465397}
observation time 0.000076, current best -0.966604 at iter 14
saving meta data: {'args': {'--uuid': '6cf76d8981d25347a58bc13c3f345cdc', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

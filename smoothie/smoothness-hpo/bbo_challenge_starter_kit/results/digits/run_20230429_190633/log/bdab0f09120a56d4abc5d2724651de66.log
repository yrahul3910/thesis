running: {'--uuid': 'bdab0f09120a56d4abc5d2724651de66', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u bdab0f09120a56d4abc5d2724651de66 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study smoothness MLP-adam digits nll 15 1
with data root: None
suggestion time taken 9.522417 iter 0 next_points [{'alpha': 0.0020024477307092714, 'batch_size': 28, 'beta_1': 0.828264909501712, 'beta_2': 0.9999853127533793, 'epsilon': 3.50930655656982e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.011253151927343743, 'tol': 0.02466297891131981, 'validation_fraction': 0.10243634594719887}]
function_evaluation time 0.902794 value 0.119923 suggestion {'alpha': 0.0020024477307092714, 'batch_size': 28, 'beta_1': 0.828264909501712, 'beta_2': 0.9999853127533793, 'epsilon': 3.50930655656982e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.011253151927343743, 'tol': 0.02466297891131981, 'validation_fraction': 0.10243634594719887}
observation time 0.000007, current best 0.119923 at iter 0
suggestion time taken 9.333970 iter 1 next_points [{'alpha': 0.07435162546871792, 'batch_size': 26, 'beta_1': 0.669049901369557, 'beta_2': 0.9359449721919818, 'epsilon': 3.6741993941456534e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.0015919483390103573, 'tol': 0.0009536155388107475, 'validation_fraction': 0.10456853742756621}]
function_evaluation time 1.348469 value 0.118295 suggestion {'alpha': 0.07435162546871792, 'batch_size': 26, 'beta_1': 0.669049901369557, 'beta_2': 0.9359449721919818, 'epsilon': 3.6741993941456534e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.0015919483390103573, 'tol': 0.0009536155388107475, 'validation_fraction': 0.10456853742756621}
observation time 0.000005, current best 0.118295 at iter 1
suggestion time taken 9.379115 iter 2 next_points [{'alpha': 2.096845973993603e-05, 'batch_size': 24, 'beta_1': 0.8119957900933291, 'beta_2': 0.9999978640785716, 'epsilon': 3.501286516904903e-07, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0017522737726173533, 'tol': 0.006358914722220759, 'validation_fraction': 0.5304282009038801}]
function_evaluation time 1.201094 value 0.137063 suggestion {'alpha': 2.096845973993603e-05, 'batch_size': 24, 'beta_1': 0.8119957900933291, 'beta_2': 0.9999978640785716, 'epsilon': 3.501286516904903e-07, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0017522737726173533, 'tol': 0.006358914722220759, 'validation_fraction': 0.5304282009038801}
observation time 0.000006, current best 0.118295 at iter 2
suggestion time taken 9.542920 iter 3 next_points [{'alpha': 0.08564091759028815, 'batch_size': 18, 'beta_1': 0.8833611440887035, 'beta_2': 0.9998190906366806, 'epsilon': 3.6225888542567898e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 2.260732348114836e-05, 'tol': 0.0004571063550947745, 'validation_fraction': 0.8280086605751708}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.524296 value 5.060785 suggestion {'alpha': 0.08564091759028815, 'batch_size': 18, 'beta_1': 0.8833611440887035, 'beta_2': 0.9998190906366806, 'epsilon': 3.6225888542567898e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 2.260732348114836e-05, 'tol': 0.0004571063550947745, 'validation_fraction': 0.8280086605751708}
observation time 0.000007, current best 0.118295 at iter 3
suggestion time taken 9.301587 iter 4 next_points [{'alpha': 0.0033519853030835062, 'batch_size': 34, 'beta_1': 0.829044914817248, 'beta_2': 0.9999983578854506, 'epsilon': 2.231952411407478e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.002165377475867727, 'tol': 2.2876774588640827e-05, 'validation_fraction': 0.24973359674717682}]
function_evaluation time 1.978162 value 0.138030 suggestion {'alpha': 0.0033519853030835062, 'batch_size': 34, 'beta_1': 0.829044914817248, 'beta_2': 0.9999983578854506, 'epsilon': 2.231952411407478e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.002165377475867727, 'tol': 2.2876774588640827e-05, 'validation_fraction': 0.24973359674717682}
observation time 0.000006, current best 0.118295 at iter 4
suggestion time taken 9.339778 iter 5 next_points [{'alpha': 0.5196271687493761, 'batch_size': 19, 'beta_1': 0.9800420852984175, 'beta_2': 0.9999936982793222, 'epsilon': 2.2036724640568768e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.00021698070180241146, 'tol': 1.5014771947433287e-05, 'validation_fraction': 0.7004730971947709}]
function_evaluation time 3.803164 value 0.244364 suggestion {'alpha': 0.5196271687493761, 'batch_size': 19, 'beta_1': 0.9800420852984175, 'beta_2': 0.9999936982793222, 'epsilon': 2.2036724640568768e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.00021698070180241146, 'tol': 1.5014771947433287e-05, 'validation_fraction': 0.7004730971947709}
observation time 0.000005, current best 0.118295 at iter 5
suggestion time taken 9.294890 iter 6 next_points [{'alpha': 6.450009558822718e-05, 'batch_size': 49, 'beta_1': 0.7168235029963584, 'beta_2': 0.9916811240169122, 'epsilon': 4.521442117007707e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 5.0401164137350895e-05, 'tol': 5.210028209326846e-05, 'validation_fraction': 0.32919369609799076}]
function_evaluation time 6.061798 value 0.310953 suggestion {'alpha': 6.450009558822718e-05, 'batch_size': 49, 'beta_1': 0.7168235029963584, 'beta_2': 0.9916811240169122, 'epsilon': 4.521442117007707e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 5.0401164137350895e-05, 'tol': 5.210028209326846e-05, 'validation_fraction': 0.32919369609799076}
observation time 0.000006, current best 0.118295 at iter 6
suggestion time taken 9.297861 iter 7 next_points [{'alpha': 1.0194510519270803, 'batch_size': 39, 'beta_1': 0.5150115531642152, 'beta_2': 0.9627288537352193, 'epsilon': 2.2295722493675618e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.0590440738530789, 'tol': 7.729252005443923e-05, 'validation_fraction': 0.6792995188468212}]
function_evaluation time 0.848869 value 0.633769 suggestion {'alpha': 1.0194510519270803, 'batch_size': 39, 'beta_1': 0.5150115531642152, 'beta_2': 0.9627288537352193, 'epsilon': 2.2295722493675618e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.0590440738530789, 'tol': 7.729252005443923e-05, 'validation_fraction': 0.6792995188468212}
observation time 0.000006, current best 0.118295 at iter 7
suggestion time taken 9.343462 iter 8 next_points [{'alpha': 0.001037870057733438, 'batch_size': 33, 'beta_1': 0.8776897347228264, 'beta_2': 0.9887882876234967, 'epsilon': 1.7856758407261933e-09, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.0031190344882963475, 'tol': 5.832038705287775e-05, 'validation_fraction': 0.24951525414177025}]
function_evaluation time 1.710297 value 0.145081 suggestion {'alpha': 0.001037870057733438, 'batch_size': 33, 'beta_1': 0.8776897347228264, 'beta_2': 0.9887882876234967, 'epsilon': 1.7856758407261933e-09, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.0031190344882963475, 'tol': 5.832038705287775e-05, 'validation_fraction': 0.24951525414177025}
observation time 0.000006, current best 0.118295 at iter 8
suggestion time taken 9.319050 iter 9 next_points [{'alpha': 0.004205219700187116, 'batch_size': 10, 'beta_1': 0.9047743568211728, 'beta_2': 0.9999965436443892, 'epsilon': 9.36332873953153e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0021151312681193715, 'tol': 0.0004904037775399413, 'validation_fraction': 0.11147607724456152}]
function_evaluation time 2.201416 value 0.151223 suggestion {'alpha': 0.004205219700187116, 'batch_size': 10, 'beta_1': 0.9047743568211728, 'beta_2': 0.9999965436443892, 'epsilon': 9.36332873953153e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0021151312681193715, 'tol': 0.0004904037775399413, 'validation_fraction': 0.11147607724456152}
observation time 0.000006, current best 0.118295 at iter 9
suggestion time taken 9.411568 iter 10 next_points [{'alpha': 4.267002026247607e-05, 'batch_size': 21, 'beta_1': 0.7526142022393415, 'beta_2': 0.9999989449445739, 'epsilon': 2.9151379489324077e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.001095650428821857, 'tol': 0.0041003449534311115, 'validation_fraction': 0.5288147050604867}]
function_evaluation time 1.425040 value 0.205754 suggestion {'alpha': 4.267002026247607e-05, 'batch_size': 21, 'beta_1': 0.7526142022393415, 'beta_2': 0.9999989449445739, 'epsilon': 2.9151379489324077e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.001095650428821857, 'tol': 0.0041003449534311115, 'validation_fraction': 0.5288147050604867}
observation time 0.000006, current best 0.118295 at iter 10
suggestion time taken 9.318856 iter 11 next_points [{'alpha': 0.0006096649534766599, 'batch_size': 16, 'beta_1': 0.7975018203825651, 'beta_2': 0.9997444822502635, 'epsilon': 3.0194168983889687e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0007742718974013687, 'tol': 0.0169800104730043, 'validation_fraction': 0.10972637346979448}]
function_evaluation time 1.519973 value 0.181949 suggestion {'alpha': 0.0006096649534766599, 'batch_size': 16, 'beta_1': 0.7975018203825651, 'beta_2': 0.9997444822502635, 'epsilon': 3.0194168983889687e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0007742718974013687, 'tol': 0.0169800104730043, 'validation_fraction': 0.10972637346979448}
observation time 0.000007, current best 0.118295 at iter 11
suggestion time taken 9.371112 iter 12 next_points [{'alpha': 0.01221493644391932, 'batch_size': 20, 'beta_1': 0.9816235856521834, 'beta_2': 0.9999802074755468, 'epsilon': 1.0926056694643259e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.01641021936655854, 'tol': 3.9428182627470305e-05, 'validation_fraction': 0.6212603308053647}]
function_evaluation time 1.486048 value 0.352524 suggestion {'alpha': 0.01221493644391932, 'batch_size': 20, 'beta_1': 0.9816235856521834, 'beta_2': 0.9999802074755468, 'epsilon': 1.0926056694643259e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.01641021936655854, 'tol': 3.9428182627470305e-05, 'validation_fraction': 0.6212603308053647}
observation time 0.000006, current best 0.118295 at iter 12
suggestion time taken 9.309414 iter 13 next_points [{'alpha': 2.466167076865114, 'batch_size': 42, 'beta_1': 0.9708293447182306, 'beta_2': 0.9999488466590216, 'epsilon': 8.189106018230541e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 1.5483980213502198e-05, 'tol': 0.03731923263921701, 'validation_fraction': 0.4419911734754322}]
function_evaluation time 0.649980 value 6.390367 suggestion {'alpha': 2.466167076865114, 'batch_size': 42, 'beta_1': 0.9708293447182306, 'beta_2': 0.9999488466590216, 'epsilon': 8.189106018230541e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 1.5483980213502198e-05, 'tol': 0.03731923263921701, 'validation_fraction': 0.4419911734754322}
observation time 0.000006, current best 0.118295 at iter 13
suggestion time taken 9.374187 iter 14 next_points [{'alpha': 7.814300715969219e-05, 'batch_size': 28, 'beta_1': 0.5111865338882229, 'beta_2': 0.9999439305461062, 'epsilon': 3.0974074523627616e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 7.036436748052125e-05, 'tol': 0.08693036431349696, 'validation_fraction': 0.3022959621114149}]
function_evaluation time 0.708145 value 2.731094 suggestion {'alpha': 7.814300715969219e-05, 'batch_size': 28, 'beta_1': 0.5111865338882229, 'beta_2': 0.9999439305461062, 'epsilon': 3.0974074523627616e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 7.036436748052125e-05, 'tol': 0.08693036431349696, 'validation_fraction': 0.3022959621114149}
observation time 0.000005, current best 0.118295 at iter 14
saving meta data: {'args': {'--uuid': 'bdab0f09120a56d4abc5d2724651de66', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

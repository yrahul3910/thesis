running: {'--uuid': 'da32b168b7db57648499e3679da6ed11', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d digits -o random-search -u da32b168b7db57648499e3679da6ed11 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study random-search MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002688 iter 0 next_points [{'alpha': 0.00022515990436286254, 'batch_size': 98, 'beta_1': 0.6123614546126083, 'beta_2': 0.9960813523806515, 'epsilon': 1.6221485333173265e-08, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.00028060905987024073, 'tol': 0.019016734087926677, 'validation_fraction': 0.524127666423568}]
function_evaluation time 0.840421 value 0.453469 suggestion {'alpha': 0.00022515990436286254, 'batch_size': 98, 'beta_1': 0.6123614546126083, 'beta_2': 0.9960813523806515, 'epsilon': 1.6221485333173265e-08, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.00028060905987024073, 'tol': 0.019016734087926677, 'validation_fraction': 0.524127666423568}
observation time 0.000007, current best 0.453469 at iter 0
suggestion time taken 0.002529 iter 1 next_points [{'alpha': 2.553539089419829, 'batch_size': 189, 'beta_1': 0.9791124329755035, 'beta_2': 0.9996812959872308, 'epsilon': 6.527682688964075e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.01797474708641736, 'tol': 7.31494645182968e-05, 'validation_fraction': 0.4651695187402262}]
function_evaluation time 0.823134 value 0.199399 suggestion {'alpha': 2.553539089419829, 'batch_size': 189, 'beta_1': 0.9791124329755035, 'beta_2': 0.9996812959872308, 'epsilon': 6.527682688964075e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.01797474708641736, 'tol': 7.31494645182968e-05, 'validation_fraction': 0.4651695187402262}
observation time 0.000005, current best 0.199399 at iter 1
suggestion time taken 0.002627 iter 2 next_points [{'alpha': 0.0036647647662844283, 'batch_size': 93, 'beta_1': 0.8245546344523895, 'beta_2': 0.9953495387110991, 'epsilon': 1.424042350045258e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 4.510075813800354e-05, 'tol': 0.017885131543095015, 'validation_fraction': 0.7901548156785437}]
function_evaluation time 0.232373 value 8.522610 suggestion {'alpha': 0.0036647647662844283, 'batch_size': 93, 'beta_1': 0.8245546344523895, 'beta_2': 0.9953495387110991, 'epsilon': 1.424042350045258e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 4.510075813800354e-05, 'tol': 0.017885131543095015, 'validation_fraction': 0.7901548156785437}
observation time 0.000005, current best 0.199399 at iter 2
suggestion time taken 0.002836 iter 3 next_points [{'alpha': 0.00010257327880274746, 'batch_size': 216, 'beta_1': 0.9877197671517413, 'beta_2': 0.9452041179956393, 'epsilon': 8.411112635511977e-09, 'hidden_layer_sizes': 183, 'learning_rate_init': 1.3465173565427024e-05, 'tol': 0.0001451937501006977, 'validation_fraction': 0.35732022339090225}]
function_evaluation time 0.572777 value 8.006384 suggestion {'alpha': 0.00010257327880274746, 'batch_size': 216, 'beta_1': 0.9877197671517413, 'beta_2': 0.9452041179956393, 'epsilon': 8.411112635511977e-09, 'hidden_layer_sizes': 183, 'learning_rate_init': 1.3465173565427024e-05, 'tol': 0.0001451937501006977, 'validation_fraction': 0.35732022339090225}
observation time 0.000005, current best 0.199399 at iter 3
suggestion time taken 0.002516 iter 4 next_points [{'alpha': 0.00021909059966860347, 'batch_size': 219, 'beta_1': 0.9673597934352659, 'beta_2': 0.9999874839921039, 'epsilon': 1.0818750665193086e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.0016800199173286799, 'tol': 0.023536449957862648, 'validation_fraction': 0.6057957870667151}]
function_evaluation time 0.480031 value 0.282254 suggestion {'alpha': 0.00021909059966860347, 'batch_size': 219, 'beta_1': 0.9673597934352659, 'beta_2': 0.9999874839921039, 'epsilon': 1.0818750665193086e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.0016800199173286799, 'tol': 0.023536449957862648, 'validation_fraction': 0.6057957870667151}
observation time 0.000005, current best 0.199399 at iter 4
suggestion time taken 0.002585 iter 5 next_points [{'alpha': 8.218301325343978e-05, 'batch_size': 36, 'beta_1': 0.5267644455813457, 'beta_2': 0.9573125296532755, 'epsilon': 3.4556236482711373e-07, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.025291506634062468, 'tol': 1.5638821417610886e-05, 'validation_fraction': 0.1005506031109408}]
function_evaluation time 1.365663 value 0.232410 suggestion {'alpha': 8.218301325343978e-05, 'batch_size': 36, 'beta_1': 0.5267644455813457, 'beta_2': 0.9573125296532755, 'epsilon': 3.4556236482711373e-07, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.025291506634062468, 'tol': 1.5638821417610886e-05, 'validation_fraction': 0.1005506031109408}
observation time 0.000003, current best 0.199399 at iter 5
suggestion time taken 0.002916 iter 6 next_points [{'alpha': 0.001475872481898453, 'batch_size': 42, 'beta_1': 0.7525083827596077, 'beta_2': 0.999906633577967, 'epsilon': 1.437834343683715e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00012090795518006727, 'tol': 0.0017474723791237178, 'validation_fraction': 0.6664987087239435}]
function_evaluation time 3.453001 value 0.352547 suggestion {'alpha': 0.001475872481898453, 'batch_size': 42, 'beta_1': 0.7525083827596077, 'beta_2': 0.999906633577967, 'epsilon': 1.437834343683715e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00012090795518006727, 'tol': 0.0017474723791237178, 'validation_fraction': 0.6664987087239435}
observation time 0.000005, current best 0.199399 at iter 6
suggestion time taken 0.002860 iter 7 next_points [{'alpha': 2.0354331307290327e-05, 'batch_size': 97, 'beta_1': 0.7311667275490829, 'beta_2': 0.9990043073023102, 'epsilon': 7.629805196406137e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.0007275813833171668, 'tol': 0.0010322537847001875, 'validation_fraction': 0.720215411264504}]
function_evaluation time 1.979146 value 0.293008 suggestion {'alpha': 2.0354331307290327e-05, 'batch_size': 97, 'beta_1': 0.7311667275490829, 'beta_2': 0.9990043073023102, 'epsilon': 7.629805196406137e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.0007275813833171668, 'tol': 0.0010322537847001875, 'validation_fraction': 0.720215411264504}
observation time 0.000005, current best 0.199399 at iter 7
suggestion time taken 0.002816 iter 8 next_points [{'alpha': 0.02985494789799425, 'batch_size': 236, 'beta_1': 0.9618090021621948, 'beta_2': 0.99995853697474, 'epsilon': 5.931086139883624e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 2.394623877685527e-05, 'tol': 0.01702771027499358, 'validation_fraction': 0.819026985688283}]
function_evaluation time 0.143515 value 10.153765 suggestion {'alpha': 0.02985494789799425, 'batch_size': 236, 'beta_1': 0.9618090021621948, 'beta_2': 0.99995853697474, 'epsilon': 5.931086139883624e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 2.394623877685527e-05, 'tol': 0.01702771027499358, 'validation_fraction': 0.819026985688283}
observation time 0.000004, current best 0.199399 at iter 8
suggestion time taken 0.002553 iter 9 next_points [{'alpha': 0.9113717361446849, 'batch_size': 207, 'beta_1': 0.9821816056038886, 'beta_2': 0.9999237327759624, 'epsilon': 1.0430501312146093e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.018966736034812727, 'tol': 0.0003689837028893359, 'validation_fraction': 0.4234635775304909}]
function_evaluation time 1.163586 value 0.175288 suggestion {'alpha': 0.9113717361446849, 'batch_size': 207, 'beta_1': 0.9821816056038886, 'beta_2': 0.9999237327759624, 'epsilon': 1.0430501312146093e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.018966736034812727, 'tol': 0.0003689837028893359, 'validation_fraction': 0.4234635775304909}
observation time 0.000005, current best 0.175288 at iter 9
suggestion time taken 0.002551 iter 10 next_points [{'alpha': 0.4493259452730403, 'batch_size': 225, 'beta_1': 0.8909075786729088, 'beta_2': 0.9340324836807806, 'epsilon': 6.527131566487023e-08, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.00037570592164119185, 'tol': 0.061382187578583686, 'validation_fraction': 0.877045520756356}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.180139 value 4.266917 suggestion {'alpha': 0.4493259452730403, 'batch_size': 225, 'beta_1': 0.8909075786729088, 'beta_2': 0.9340324836807806, 'epsilon': 6.527131566487023e-08, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.00037570592164119185, 'tol': 0.061382187578583686, 'validation_fraction': 0.877045520756356}
observation time 0.000004, current best 0.175288 at iter 10
suggestion time taken 0.002551 iter 11 next_points [{'alpha': 0.0012226350132761572, 'batch_size': 96, 'beta_1': 0.9742720003474405, 'beta_2': 0.9959200851023718, 'epsilon': 8.734223982897206e-09, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0011631885685882617, 'tol': 1.0930833284070538e-05, 'validation_fraction': 0.13563525073889862}]
function_evaluation time 1.413412 value 0.128519 suggestion {'alpha': 0.0012226350132761572, 'batch_size': 96, 'beta_1': 0.9742720003474405, 'beta_2': 0.9959200851023718, 'epsilon': 8.734223982897206e-09, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0011631885685882617, 'tol': 1.0930833284070538e-05, 'validation_fraction': 0.13563525073889862}
observation time 0.000005, current best 0.128519 at iter 11
suggestion time taken 0.002587 iter 12 next_points [{'alpha': 3.8344114571037266e-05, 'batch_size': 104, 'beta_1': 0.8982201485529553, 'beta_2': 0.9999167428835821, 'epsilon': 5.8234974360836466e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.06493284486265676, 'tol': 0.006557589554784585, 'validation_fraction': 0.7590845073548658}]
function_evaluation time 0.779058 value 0.790441 suggestion {'alpha': 3.8344114571037266e-05, 'batch_size': 104, 'beta_1': 0.8982201485529553, 'beta_2': 0.9999167428835821, 'epsilon': 5.8234974360836466e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.06493284486265676, 'tol': 0.006557589554784585, 'validation_fraction': 0.7590845073548658}
observation time 0.000005, current best 0.128519 at iter 12
suggestion time taken 0.002520 iter 13 next_points [{'alpha': 0.7635027585221653, 'batch_size': 208, 'beta_1': 0.9474751985468677, 'beta_2': 0.9679524572739537, 'epsilon': 2.9309167218149514e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 4.44360232414686e-05, 'tol': 0.0012191153207500752, 'validation_fraction': 0.12280943025620815}]
function_evaluation time 3.055899 value 1.627529 suggestion {'alpha': 0.7635027585221653, 'batch_size': 208, 'beta_1': 0.9474751985468677, 'beta_2': 0.9679524572739537, 'epsilon': 2.9309167218149514e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 4.44360232414686e-05, 'tol': 0.0012191153207500752, 'validation_fraction': 0.12280943025620815}
observation time 0.000005, current best 0.128519 at iter 13
suggestion time taken 0.002517 iter 14 next_points [{'alpha': 0.08971474502696712, 'batch_size': 180, 'beta_1': 0.7836235911230679, 'beta_2': 0.999855864247921, 'epsilon': 1.2643401498420864e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.001282858623955664, 'tol': 1.9946221782169752e-05, 'validation_fraction': 0.1625325928216327}]
function_evaluation time 1.324508 value 0.131872 suggestion {'alpha': 0.08971474502696712, 'batch_size': 180, 'beta_1': 0.7836235911230679, 'beta_2': 0.999855864247921, 'epsilon': 1.2643401498420864e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.001282858623955664, 'tol': 1.9946221782169752e-05, 'validation_fraction': 0.1625325928216327}
observation time 0.000005, current best 0.128519 at iter 14
saving meta data: {'args': {'--uuid': 'da32b168b7db57648499e3679da6ed11', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'random-search', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

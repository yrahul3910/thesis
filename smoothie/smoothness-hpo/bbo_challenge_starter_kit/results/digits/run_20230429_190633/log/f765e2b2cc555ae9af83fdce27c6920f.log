running: {'--uuid': 'f765e2b2cc555ae9af83fdce27c6920f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u f765e2b2cc555ae9af83fdce27c6920f -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002420 iter 0 next_points [{'alpha': 0.002587914567888513, 'batch_size': 199, 'beta_1': 0.6323911643356442, 'beta_2': 0.9742018116477099, 'epsilon': 1.5078507121143013e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.046663071613357664, 'tol': 0.00019230927747546835, 'validation_fraction': 0.4563164551509812}]
function_evaluation time 0.703657 value -0.940846 suggestion {'alpha': 0.002587914567888513, 'batch_size': 199, 'beta_1': 0.6323911643356442, 'beta_2': 0.9742018116477099, 'epsilon': 1.5078507121143013e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.046663071613357664, 'tol': 0.00019230927747546835, 'validation_fraction': 0.4563164551509812}
observation time 0.000071, current best -0.940846 at iter 0
suggestion time taken 0.002395 iter 1 next_points [{'alpha': 0.0021905793709409505, 'batch_size': 97, 'beta_1': 0.6325117808211143, 'beta_2': 0.9621342211634143, 'epsilon': 1.7213909991421179e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.0005796948062895452, 'tol': 0.0007314418226392339, 'validation_fraction': 0.143428442652748}]
function_evaluation time 1.764945 value -0.967305 suggestion {'alpha': 0.0021905793709409505, 'batch_size': 97, 'beta_1': 0.6325117808211143, 'beta_2': 0.9621342211634143, 'epsilon': 1.7213909991421179e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.0005796948062895452, 'tol': 0.0007314418226392339, 'validation_fraction': 0.143428442652748}
observation time 0.000068, current best -0.967305 at iter 1
suggestion time taken 0.002303 iter 2 next_points [{'alpha': 0.0535256137505562, 'batch_size': 205, 'beta_1': 0.9092053110699853, 'beta_2': 0.9978309337753973, 'epsilon': 1.223720841671709e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.0015419717960010498, 'tol': 0.023981612996747167, 'validation_fraction': 0.4130893156508712}]
function_evaluation time 0.420956 value -0.917199 suggestion {'alpha': 0.0535256137505562, 'batch_size': 205, 'beta_1': 0.9092053110699853, 'beta_2': 0.9978309337753973, 'epsilon': 1.223720841671709e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.0015419717960010498, 'tol': 0.023981612996747167, 'validation_fraction': 0.4130893156508712}
observation time 0.000072, current best -0.967305 at iter 2
suggestion time taken 0.002166 iter 3 next_points [{'alpha': 0.007109666581079878, 'batch_size': 28, 'beta_1': 0.651971133149139, 'beta_2': 0.9175107435982496, 'epsilon': 9.661747299857484e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0001451091875287391, 'tol': 2.1134416563327528e-05, 'validation_fraction': 0.5076612240540427}]
function_evaluation time 4.578222 value -0.958943 suggestion {'alpha': 0.007109666581079878, 'batch_size': 28, 'beta_1': 0.651971133149139, 'beta_2': 0.9175107435982496, 'epsilon': 9.661747299857484e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0001451091875287391, 'tol': 2.1134416563327528e-05, 'validation_fraction': 0.5076612240540427}
observation time 0.000080, current best -0.967305 at iter 3
suggestion time taken 0.002176 iter 4 next_points [{'alpha': 3.300361650649201, 'batch_size': 143, 'beta_1': 0.5106136548559711, 'beta_2': 0.9240813887550128, 'epsilon': 2.4668271355363844e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.027248805763376054, 'tol': 3.353697289529684e-05, 'validation_fraction': 0.1213464164586057}]
function_evaluation time 0.734919 value -0.937369 suggestion {'alpha': 3.300361650649201, 'batch_size': 143, 'beta_1': 0.5106136548559711, 'beta_2': 0.9240813887550128, 'epsilon': 2.4668271355363844e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.027248805763376054, 'tol': 3.353697289529684e-05, 'validation_fraction': 0.1213464164586057}
observation time 0.000072, current best -0.967305 at iter 4
suggestion time taken 0.002184 iter 5 next_points [{'alpha': 8.299789579076637e-05, 'batch_size': 142, 'beta_1': 0.7866605801772264, 'beta_2': 0.967293189437107, 'epsilon': 7.357541567447639e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.026400884532297473, 'tol': 3.900461848881801e-05, 'validation_fraction': 0.2604748995920645}]
function_evaluation time 0.670544 value -0.959625 suggestion {'alpha': 8.299789579076637e-05, 'batch_size': 142, 'beta_1': 0.7866605801772264, 'beta_2': 0.967293189437107, 'epsilon': 7.357541567447639e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.026400884532297473, 'tol': 3.900461848881801e-05, 'validation_fraction': 0.2604748995920645}
observation time 0.000076, current best -0.967305 at iter 5
suggestion time taken 0.002155 iter 6 next_points [{'alpha': 0.004468921982104053, 'batch_size': 153, 'beta_1': 0.6395766415793482, 'beta_2': 0.9589689418813082, 'epsilon': 5.393175583275991e-09, 'hidden_layer_sizes': 178, 'learning_rate_init': 6.237719915167036e-05, 'tol': 0.0009950042738276544, 'validation_fraction': 0.12312349519885435}]
function_evaluation time 3.487401 value -0.915067 suggestion {'alpha': 0.004468921982104053, 'batch_size': 153, 'beta_1': 0.6395766415793482, 'beta_2': 0.9589689418813082, 'epsilon': 5.393175583275991e-09, 'hidden_layer_sizes': 178, 'learning_rate_init': 6.237719915167036e-05, 'tol': 0.0009950042738276544, 'validation_fraction': 0.12312349519885435}
observation time 0.000077, current best -0.967305 at iter 6
suggestion time taken 0.002412 iter 7 next_points [{'alpha': 0.8884044588978468, 'batch_size': 167, 'beta_1': 0.7040513235955275, 'beta_2': 0.9951566360432099, 'epsilon': 1.0775154186205577e-08, 'hidden_layer_sizes': 119, 'learning_rate_init': 1.5203563973718395e-05, 'tol': 0.005836333859988356, 'validation_fraction': 0.8177696605553828}]
function_evaluation time 0.187868 value -0.080735 suggestion {'alpha': 0.8884044588978468, 'batch_size': 167, 'beta_1': 0.7040513235955275, 'beta_2': 0.9951566360432099, 'epsilon': 1.0775154186205577e-08, 'hidden_layer_sizes': 119, 'learning_rate_init': 1.5203563973718395e-05, 'tol': 0.005836333859988356, 'validation_fraction': 0.8177696605553828}
observation time 0.000078, current best -0.967305 at iter 7
suggestion time taken 0.002165 iter 8 next_points [{'alpha': 0.02639678259191318, 'batch_size': 54, 'beta_1': 0.6055663885955691, 'beta_2': 0.9333612235062702, 'epsilon': 2.740487089656104e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0005323237220130711, 'tol': 0.005122217777812509, 'validation_fraction': 0.4690114912310109}]
function_evaluation time 1.259574 value -0.954082 suggestion {'alpha': 0.02639678259191318, 'batch_size': 54, 'beta_1': 0.6055663885955691, 'beta_2': 0.9333612235062702, 'epsilon': 2.740487089656104e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0005323237220130711, 'tol': 0.005122217777812509, 'validation_fraction': 0.4690114912310109}
observation time 0.000092, current best -0.967305 at iter 8
suggestion time taken 0.002158 iter 9 next_points [{'alpha': 0.007976232817675379, 'batch_size': 75, 'beta_1': 0.7881681316044435, 'beta_2': 0.9919884850734975, 'epsilon': 1.7658257469744672e-07, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.00037718920596078136, 'tol': 0.007967877868019635, 'validation_fraction': 0.7312831202260934}]
function_evaluation time 1.048903 value -0.894928 suggestion {'alpha': 0.007976232817675379, 'batch_size': 75, 'beta_1': 0.7881681316044435, 'beta_2': 0.9919884850734975, 'epsilon': 1.7658257469744672e-07, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.00037718920596078136, 'tol': 0.007967877868019635, 'validation_fraction': 0.7312831202260934}
observation time 0.000070, current best -0.967305 at iter 9
suggestion time taken 0.002163 iter 10 next_points [{'alpha': 3.809523840146712e-05, 'batch_size': 96, 'beta_1': 0.6830840149491424, 'beta_2': 0.9981837592115723, 'epsilon': 2.212306287104511e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.0004869064382343595, 'tol': 0.0005140709940648611, 'validation_fraction': 0.16794782092854396}]
function_evaluation time 1.845375 value -0.961726 suggestion {'alpha': 3.809523840146712e-05, 'batch_size': 96, 'beta_1': 0.6830840149491424, 'beta_2': 0.9981837592115723, 'epsilon': 2.212306287104511e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.0004869064382343595, 'tol': 0.0005140709940648611, 'validation_fraction': 0.16794782092854396}
observation time 0.000076, current best -0.967305 at iter 10
suggestion time taken 0.002417 iter 11 next_points [{'alpha': 2.028163044555976e-05, 'batch_size': 236, 'beta_1': 0.6203333998192064, 'beta_2': 0.9623975047681171, 'epsilon': 1.7025101919553526e-09, 'hidden_layer_sizes': 144, 'learning_rate_init': 2.2039207606126955e-05, 'tol': 0.07333763757805262, 'validation_fraction': 0.10778558117771535}]
function_evaluation time 0.399512 value -0.130181 suggestion {'alpha': 2.028163044555976e-05, 'batch_size': 236, 'beta_1': 0.6203333998192064, 'beta_2': 0.9623975047681171, 'epsilon': 1.7025101919553526e-09, 'hidden_layer_sizes': 144, 'learning_rate_init': 2.2039207606126955e-05, 'tol': 0.07333763757805262, 'validation_fraction': 0.10778558117771535}
observation time 0.000077, current best -0.967305 at iter 11
suggestion time taken 0.002199 iter 12 next_points [{'alpha': 1.7639905811601375, 'batch_size': 123, 'beta_1': 0.7506713322435107, 'beta_2': 0.9720153835367651, 'epsilon': 9.717765676673716e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.0007711695890281288, 'tol': 2.332409870778424e-05, 'validation_fraction': 0.12347697343447969}]
function_evaluation time 1.117720 value -0.959647 suggestion {'alpha': 1.7639905811601375, 'batch_size': 123, 'beta_1': 0.7506713322435107, 'beta_2': 0.9720153835367651, 'epsilon': 9.717765676673716e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.0007711695890281288, 'tol': 2.332409870778424e-05, 'validation_fraction': 0.12347697343447969}
observation time 0.000080, current best -0.967305 at iter 12
suggestion time taken 0.002283 iter 13 next_points [{'alpha': 0.05306691423504043, 'batch_size': 100, 'beta_1': 0.7378960731318558, 'beta_2': 0.9387812891811846, 'epsilon': 3.045798527993176e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0022121703246764284, 'tol': 0.0007563907551107118, 'validation_fraction': 0.7273702434459345}]
function_evaluation time 1.177390 value -0.950607 suggestion {'alpha': 0.05306691423504043, 'batch_size': 100, 'beta_1': 0.7378960731318558, 'beta_2': 0.9387812891811846, 'epsilon': 3.045798527993176e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0022121703246764284, 'tol': 0.0007563907551107118, 'validation_fraction': 0.7273702434459345}
observation time 0.000076, current best -0.967305 at iter 13
suggestion time taken 0.002404 iter 14 next_points [{'alpha': 2.9943559585345927e-05, 'batch_size': 205, 'beta_1': 0.8807318228125681, 'beta_2': 0.9098576827189605, 'epsilon': 2.6305530650127162e-08, 'hidden_layer_sizes': 141, 'learning_rate_init': 1.1791319487864586e-05, 'tol': 2.0704099087292923e-05, 'validation_fraction': 0.12516304802670844}]
function_evaluation time 0.563267 value -0.096005 suggestion {'alpha': 2.9943559585345927e-05, 'batch_size': 205, 'beta_1': 0.8807318228125681, 'beta_2': 0.9098576827189605, 'epsilon': 2.6305530650127162e-08, 'hidden_layer_sizes': 141, 'learning_rate_init': 1.1791319487864586e-05, 'tol': 2.0704099087292923e-05, 'validation_fraction': 0.12516304802670844}
observation time 0.000079, current best -0.967305 at iter 14
saving meta data: {'args': {'--uuid': 'f765e2b2cc555ae9af83fdce27c6920f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '54564fb75266544a99ea3adf0ca2fb06', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u 54564fb75266544a99ea3adf0ca2fb06 -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study turbo MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002158 iter 0 next_points [{'alpha': 9.53977432378065, 'batch_size': 228, 'beta_1': 0.9757248173077967, 'beta_2': 0.9999937615027867, 'epsilon': 6.58768487380644e-09, 'hidden_layer_sizes': 107, 'learning_rate_init': 1.7328356768744102e-05, 'tol': 0.04494015498139426, 'validation_fraction': 0.10855081333174198}]
function_evaluation time 0.502353 value 11.815532 suggestion {'alpha': 9.53977432378065, 'batch_size': 228, 'beta_1': 0.9757248173077967, 'beta_2': 0.9999937615027867, 'epsilon': 6.58768487380644e-09, 'hidden_layer_sizes': 107, 'learning_rate_init': 1.7328356768744102e-05, 'tol': 0.04494015498139426, 'validation_fraction': 0.10855081333174198}
observation time 0.001326, current best 11.815532 at iter 0
suggestion time taken 0.001755 iter 1 next_points [{'alpha': 0.0013379572574197913, 'batch_size': 127, 'beta_1': 0.655709311905496, 'beta_2': 0.9995209604994281, 'epsilon': 2.614740975903564e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.000529592559242784, 'tol': 1.7645421433620912e-05, 'validation_fraction': 0.837563962952338}]
function_evaluation time 3.346022 value 0.420309 suggestion {'alpha': 0.0013379572574197913, 'batch_size': 127, 'beta_1': 0.655709311905496, 'beta_2': 0.9995209604994281, 'epsilon': 2.614740975903564e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.000529592559242784, 'tol': 1.7645421433620912e-05, 'validation_fraction': 0.837563962952338}
observation time 0.001325, current best 0.420309 at iter 1
suggestion time taken 0.001775 iter 2 next_points [{'alpha': 5.689891227917087e-05, 'batch_size': 210, 'beta_1': 0.9417230827345476, 'beta_2': 0.9999781998586341, 'epsilon': 1.4817086626199163e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.0003781570613273887, 'tol': 0.016231184160510045, 'validation_fraction': 0.5904414847467364}]
function_evaluation time 1.389534 value 0.447552 suggestion {'alpha': 5.689891227917087e-05, 'batch_size': 210, 'beta_1': 0.9417230827345476, 'beta_2': 0.9999781998586341, 'epsilon': 1.4817086626199163e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.0003781570613273887, 'tol': 0.016231184160510045, 'validation_fraction': 0.5904414847467364}
observation time 0.001351, current best 0.420309 at iter 2
suggestion time taken 0.001754 iter 3 next_points [{'alpha': 1.9542695757805268, 'batch_size': 16, 'beta_1': 0.8978398919876268, 'beta_2': 0.9700649328021488, 'epsilon': 3.235218330722137e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.005441127688441141, 'tol': 0.08914032263760091, 'validation_fraction': 0.297652208828261}]
function_evaluation time 1.360575 value 0.215928 suggestion {'alpha': 1.9542695757805268, 'batch_size': 16, 'beta_1': 0.8978398919876268, 'beta_2': 0.9700649328021488, 'epsilon': 3.235218330722137e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.005441127688441141, 'tol': 0.08914032263760091, 'validation_fraction': 0.297652208828261}
observation time 0.001359, current best 0.215928 at iter 3
suggestion time taken 0.001764 iter 4 next_points [{'alpha': 0.5734448890469959, 'batch_size': 161, 'beta_1': 0.9683230140562106, 'beta_2': 0.9976472846102477, 'epsilon': 5.272028187272205e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 9.597566865142449e-05, 'tol': 0.0005746342397352264, 'validation_fraction': 0.20069773609807215}]
function_evaluation time 6.549880 value 0.273843 suggestion {'alpha': 0.5734448890469959, 'batch_size': 161, 'beta_1': 0.9683230140562106, 'beta_2': 0.9976472846102477, 'epsilon': 5.272028187272205e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 9.597566865142449e-05, 'tol': 0.0005746342397352264, 'validation_fraction': 0.20069773609807215}
observation time 0.001332, current best 0.215928 at iter 4
suggestion time taken 0.001976 iter 5 next_points [{'alpha': 0.0034005164174717687, 'batch_size': 93, 'beta_1': 0.9529609365782418, 'beta_2': 0.9997080447746812, 'epsilon': 9.77455940606011e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.02396383483347537, 'tol': 0.00010418367990472942, 'validation_fraction': 0.6971676560324841}]
function_evaluation time 1.182029 value 0.392017 suggestion {'alpha': 0.0034005164174717687, 'batch_size': 93, 'beta_1': 0.9529609365782418, 'beta_2': 0.9997080447746812, 'epsilon': 9.77455940606011e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.02396383483347537, 'tol': 0.00010418367990472942, 'validation_fraction': 0.6971676560324841}
observation time 0.001333, current best 0.215928 at iter 5
suggestion time taken 0.001710 iter 6 next_points [{'alpha': 0.05844973516249544, 'batch_size': 36, 'beta_1': 0.9165610626503746, 'beta_2': 0.9999868314047999, 'epsilon': 1.9849652632034976e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.00018243200863448837, 'tol': 1.3083786782086472e-05, 'validation_fraction': 0.17591139802015093}]
function_evaluation time 5.801287 value 0.167634 suggestion {'alpha': 0.05844973516249544, 'batch_size': 36, 'beta_1': 0.9165610626503746, 'beta_2': 0.9999868314047999, 'epsilon': 1.9849652632034976e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.00018243200863448837, 'tol': 1.3083786782086472e-05, 'validation_fraction': 0.17591139802015093}
observation time 0.001314, current best 0.167634 at iter 6
suggestion time taken 0.001746 iter 7 next_points [{'alpha': 2.9059438023956313e-05, 'batch_size': 77, 'beta_1': 0.548385035946208, 'beta_2': 0.9999986443720955, 'epsilon': 3.726101989865664e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.002098231780305026, 'tol': 0.0031666933875171294, 'validation_fraction': 0.758104129247484}]
function_evaluation time 0.936969 value 0.203948 suggestion {'alpha': 2.9059438023956313e-05, 'batch_size': 77, 'beta_1': 0.548385035946208, 'beta_2': 0.9999986443720955, 'epsilon': 3.726101989865664e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.002098231780305026, 'tol': 0.0031666933875171294, 'validation_fraction': 0.758104129247484}
observation time 0.001362, current best 0.167634 at iter 7
suggestion time taken 0.001895 iter 8 next_points [{'alpha': 0.0018356463495973348, 'batch_size': 246, 'beta_1': 0.7182486488553806, 'beta_2': 0.9945846654563212, 'epsilon': 4.009558363505725e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.0010129969194571284, 'tol': 0.008527203113922506, 'validation_fraction': 0.8717585672989746}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.887752 value 0.885025 suggestion {'alpha': 0.0018356463495973348, 'batch_size': 246, 'beta_1': 0.7182486488553806, 'beta_2': 0.9945846654563212, 'epsilon': 4.009558363505725e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.0010129969194571284, 'tol': 0.008527203113922506, 'validation_fraction': 0.8717585672989746}
observation time 0.001339, current best 0.167634 at iter 8
suggestion time taken 0.001734 iter 9 next_points [{'alpha': 0.3845970846894359, 'batch_size': 196, 'beta_1': 0.7613976369179523, 'beta_2': 0.9997890220761829, 'epsilon': 7.076540596533548e-08, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.007361562252840118, 'tol': 5.085210855570074e-05, 'validation_fraction': 0.8974954001091906}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 1.008175 value 0.475099 suggestion {'alpha': 0.3845970846894359, 'batch_size': 196, 'beta_1': 0.7613976369179523, 'beta_2': 0.9997890220761829, 'epsilon': 7.076540596533548e-08, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.007361562252840118, 'tol': 5.085210855570074e-05, 'validation_fraction': 0.8974954001091906}
observation time 0.001322, current best 0.167634 at iter 9
suggestion time taken 0.001740 iter 10 next_points [{'alpha': 0.014369372687577365, 'batch_size': 24, 'beta_1': 0.9836345693912288, 'beta_2': 0.9999932312795136, 'epsilon': 5.966427695510018e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.0013422334954015563, 'tol': 0.0018626580736653643, 'validation_fraction': 0.6627771451215204}]
function_evaluation time 1.805101 value 0.198547 suggestion {'alpha': 0.014369372687577365, 'batch_size': 24, 'beta_1': 0.9836345693912288, 'beta_2': 0.9999932312795136, 'epsilon': 5.966427695510018e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.0013422334954015563, 'tol': 0.0018626580736653643, 'validation_fraction': 0.6627771451215204}
observation time 0.001420, current best 0.167634 at iter 10
suggestion time taken 0.001708 iter 11 next_points [{'alpha': 0.016867529082989823, 'batch_size': 117, 'beta_1': 0.9846088321875, 'beta_2': 0.9961321599748475, 'epsilon': 5.392910886855442e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.013275731878822899, 'tol': 0.0003820231082079035, 'validation_fraction': 0.5475872650568949}]
function_evaluation time 1.667536 value 0.286699 suggestion {'alpha': 0.016867529082989823, 'batch_size': 117, 'beta_1': 0.9846088321875, 'beta_2': 0.9961321599748475, 'epsilon': 5.392910886855442e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.013275731878822899, 'tol': 0.0003820231082079035, 'validation_fraction': 0.5475872650568949}
observation time 0.001400, current best 0.167634 at iter 11
suggestion time taken 0.001754 iter 12 next_points [{'alpha': 0.00042205302521493553, 'batch_size': 58, 'beta_1': 0.7971396195061528, 'beta_2': 0.9853914431561628, 'epsilon': 1.919266957278499e-08, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.03937992149512075, 'tol': 0.00016554551076493988, 'validation_fraction': 0.22785025667066366}]
function_evaluation time 1.236674 value 0.247699 suggestion {'alpha': 0.00042205302521493553, 'batch_size': 58, 'beta_1': 0.7971396195061528, 'beta_2': 0.9853914431561628, 'epsilon': 1.919266957278499e-08, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.03937992149512075, 'tol': 0.00016554551076493988, 'validation_fraction': 0.22785025667066366}
observation time 0.001335, current best 0.167634 at iter 12
suggestion time taken 0.001717 iter 13 next_points [{'alpha': 0.08352535263890495, 'batch_size': 186, 'beta_1': 0.9240205515188836, 'beta_2': 0.9999981460874938, 'epsilon': 1.486755471279848e-07, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.016928375221968647, 'tol': 0.0008464857004513307, 'validation_fraction': 0.4678451649958045}]
function_evaluation time 1.332598 value 0.152936 suggestion {'alpha': 0.08352535263890495, 'batch_size': 186, 'beta_1': 0.9240205515188836, 'beta_2': 0.9999981460874938, 'epsilon': 1.486755471279848e-07, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.016928375221968647, 'tol': 0.0008464857004513307, 'validation_fraction': 0.4678451649958045}
observation time 0.001327, current best 0.152936 at iter 13
suggestion time taken 0.001699 iter 14 next_points [{'alpha': 0.00020071631503543153, 'batch_size': 164, 'beta_1': 0.9891424194412558, 'beta_2': 0.9163577378264874, 'epsilon': 1.0595309124480403e-07, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.06577842188063211, 'tol': 0.01179070899462205, 'validation_fraction': 0.48310788181446185}]
function_evaluation time 0.646425 value 4.044566 suggestion {'alpha': 0.00020071631503543153, 'batch_size': 164, 'beta_1': 0.9891424194412558, 'beta_2': 0.9163577378264874, 'epsilon': 1.0595309124480403e-07, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.06577842188063211, 'tol': 0.01179070899462205, 'validation_fraction': 0.48310788181446185}
observation time 0.001374, current best 0.152936 at iter 14
saving meta data: {'args': {'--uuid': '54564fb75266544a99ea3adf0ca2fb06', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

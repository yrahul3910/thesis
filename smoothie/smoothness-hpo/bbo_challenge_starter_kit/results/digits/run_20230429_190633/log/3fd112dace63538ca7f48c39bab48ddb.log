running: {'--uuid': '3fd112dace63538ca7f48c39bab48ddb', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 3fd112dace63538ca7f48c39bab48ddb -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002349 iter 0 next_points [{'alpha': 0.004277881463409698, 'batch_size': 231, 'beta_1': 0.6847873763874712, 'beta_2': 0.918405425670106, 'epsilon': 2.2910584349754223e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.04061390810684365, 'tol': 0.00010698783149497835, 'validation_fraction': 0.13707210629152516}]
function_evaluation time 0.849016 value -0.938064 suggestion {'alpha': 0.004277881463409698, 'batch_size': 231, 'beta_1': 0.6847873763874712, 'beta_2': 0.918405425670106, 'epsilon': 2.2910584349754223e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.04061390810684365, 'tol': 0.00010698783149497835, 'validation_fraction': 0.13707210629152516}
observation time 0.000078, current best -0.938064 at iter 0
suggestion time taken 0.002383 iter 1 next_points [{'alpha': 0.016488427955150844, 'batch_size': 145, 'beta_1': 0.5496308968676514, 'beta_2': 0.9718508601251048, 'epsilon': 2.1291560823962567e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 1.4148140949099129e-05, 'tol': 0.00011244974678110865, 'validation_fraction': 0.5988808878834693}]
function_evaluation time 1.045970 value -0.130118 suggestion {'alpha': 0.016488427955150844, 'batch_size': 145, 'beta_1': 0.5496308968676514, 'beta_2': 0.9718508601251048, 'epsilon': 2.1291560823962567e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 1.4148140949099129e-05, 'tol': 0.00011244974678110865, 'validation_fraction': 0.5988808878834693}
observation time 0.000071, current best -0.938064 at iter 1
suggestion time taken 0.002151 iter 2 next_points [{'alpha': 4.248429801492378, 'batch_size': 163, 'beta_1': 0.9098808764850075, 'beta_2': 0.9841811601532483, 'epsilon': 5.078193671929932e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 2.301772150956069e-05, 'tol': 0.03784218019205396, 'validation_fraction': 0.3016840006752596}]
function_evaluation time 0.260984 value -0.086958 suggestion {'alpha': 4.248429801492378, 'batch_size': 163, 'beta_1': 0.9098808764850075, 'beta_2': 0.9841811601532483, 'epsilon': 5.078193671929932e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 2.301772150956069e-05, 'tol': 0.03784218019205396, 'validation_fraction': 0.3016840006752596}
observation time 0.000069, current best -0.938064 at iter 2
suggestion time taken 0.002142 iter 3 next_points [{'alpha': 0.0006709200526337511, 'batch_size': 178, 'beta_1': 0.9853300356063814, 'beta_2': 0.9325706051340091, 'epsilon': 1.8242654751038924e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.006585492311320043, 'tol': 2.234416842224623e-05, 'validation_fraction': 0.8705658882865311}]
function_evaluation time 0.457260 value -0.854561 suggestion {'alpha': 0.0006709200526337511, 'batch_size': 178, 'beta_1': 0.9853300356063814, 'beta_2': 0.9325706051340091, 'epsilon': 1.8242654751038924e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.006585492311320043, 'tol': 2.234416842224623e-05, 'validation_fraction': 0.8705658882865311}
observation time 0.000072, current best -0.938064 at iter 3
suggestion time taken 0.002125 iter 4 next_points [{'alpha': 0.0020388140387918685, 'batch_size': 68, 'beta_1': 0.6183829267172547, 'beta_2': 0.9473680895127006, 'epsilon': 9.582735038146088e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.022807337787211876, 'tol': 0.00042842014504545497, 'validation_fraction': 0.5830444782535407}]
function_evaluation time 0.893967 value -0.933203 suggestion {'alpha': 0.0020388140387918685, 'batch_size': 68, 'beta_1': 0.6183829267172547, 'beta_2': 0.9473680895127006, 'epsilon': 9.582735038146088e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.022807337787211876, 'tol': 0.00042842014504545497, 'validation_fraction': 0.5830444782535407}
observation time 0.000074, current best -0.938064 at iter 4
suggestion time taken 0.002222 iter 5 next_points [{'alpha': 0.00017732140364253493, 'batch_size': 68, 'beta_1': 0.5365237418463157, 'beta_2': 0.9659130409392872, 'epsilon': 1.599740740604883e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.014196664928144604, 'tol': 0.008519786877474157, 'validation_fraction': 0.24929975928663864}]
function_evaluation time 0.608946 value -0.954764 suggestion {'alpha': 0.00017732140364253493, 'batch_size': 68, 'beta_1': 0.5365237418463157, 'beta_2': 0.9659130409392872, 'epsilon': 1.599740740604883e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.014196664928144604, 'tol': 0.008519786877474157, 'validation_fraction': 0.24929975928663864}
observation time 0.000072, current best -0.954764 at iter 5
suggestion time taken 0.002143 iter 6 next_points [{'alpha': 1.2570166519728052e-05, 'batch_size': 136, 'beta_1': 0.524327496766912, 'beta_2': 0.9050179904559308, 'epsilon': 8.721797372583471e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0007327355443505662, 'tol': 0.08851880387481824, 'validation_fraction': 0.8022268458857479}]
function_evaluation time 0.155344 value -0.252497 suggestion {'alpha': 1.2570166519728052e-05, 'batch_size': 136, 'beta_1': 0.524327496766912, 'beta_2': 0.9050179904559308, 'epsilon': 8.721797372583471e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0007327355443505662, 'tol': 0.08851880387481824, 'validation_fraction': 0.8022268458857479}
observation time 0.000073, current best -0.954764 at iter 6
suggestion time taken 0.002209 iter 7 next_points [{'alpha': 0.1660884501510933, 'batch_size': 182, 'beta_1': 0.7153499311732968, 'beta_2': 0.9368214349471107, 'epsilon': 2.1874301905892355e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0010305154217336875, 'tol': 0.01672397328418603, 'validation_fraction': 0.29177468664603873}]
function_evaluation time 0.552636 value -0.942927 suggestion {'alpha': 0.1660884501510933, 'batch_size': 182, 'beta_1': 0.7153499311732968, 'beta_2': 0.9368214349471107, 'epsilon': 2.1874301905892355e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0010305154217336875, 'tol': 0.01672397328418603, 'validation_fraction': 0.29177468664603873}
observation time 0.000072, current best -0.954764 at iter 7
suggestion time taken 0.002130 iter 8 next_points [{'alpha': 1.4716302572721636e-05, 'batch_size': 120, 'beta_1': 0.5428916900640551, 'beta_2': 0.9404593277239911, 'epsilon': 2.5529114746459337e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.06029390122939472, 'tol': 2.748249411156146e-05, 'validation_fraction': 0.8789484032231208}]
function_evaluation time 0.572212 value -0.823214 suggestion {'alpha': 1.4716302572721636e-05, 'batch_size': 120, 'beta_1': 0.5428916900640551, 'beta_2': 0.9404593277239911, 'epsilon': 2.5529114746459337e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.06029390122939472, 'tol': 2.748249411156146e-05, 'validation_fraction': 0.8789484032231208}
observation time 0.000080, current best -0.954764 at iter 8
suggestion time taken 0.002205 iter 9 next_points [{'alpha': 4.713635664748615, 'batch_size': 190, 'beta_1': 0.6460116761422474, 'beta_2': 0.9330222156503676, 'epsilon': 1.4721282871703988e-08, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.005906390380966214, 'tol': 0.0194778444126029, 'validation_fraction': 0.27500694127092173}]
function_evaluation time 0.516727 value -0.951287 suggestion {'alpha': 4.713635664748615, 'batch_size': 190, 'beta_1': 0.6460116761422474, 'beta_2': 0.9330222156503676, 'epsilon': 1.4721282871703988e-08, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.005906390380966214, 'tol': 0.0194778444126029, 'validation_fraction': 0.27500694127092173}
observation time 0.000075, current best -0.954764 at iter 9
suggestion time taken 0.002137 iter 10 next_points [{'alpha': 0.10780793944551727, 'batch_size': 108, 'beta_1': 0.5295695055380842, 'beta_2': 0.9175861395816204, 'epsilon': 4.523590337311134e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 3.268713597455821e-05, 'tol': 0.0029009985488866316, 'validation_fraction': 0.24586515872919246}]
function_evaluation time 3.935181 value -0.570582 suggestion {'alpha': 0.10780793944551727, 'batch_size': 108, 'beta_1': 0.5295695055380842, 'beta_2': 0.9175861395816204, 'epsilon': 4.523590337311134e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 3.268713597455821e-05, 'tol': 0.0029009985488866316, 'validation_fraction': 0.24586515872919246}
observation time 0.000073, current best -0.954764 at iter 10
suggestion time taken 0.002144 iter 11 next_points [{'alpha': 0.119629995557064, 'batch_size': 97, 'beta_1': 0.911423574637328, 'beta_2': 0.9023480180605676, 'epsilon': 3.066384333677562e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 6.205750031780519e-05, 'tol': 5.3254443140700725e-05, 'validation_fraction': 0.6171049733889384}]
function_evaluation time 4.893445 value -0.933200 suggestion {'alpha': 0.119629995557064, 'batch_size': 97, 'beta_1': 0.911423574637328, 'beta_2': 0.9023480180605676, 'epsilon': 3.066384333677562e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 6.205750031780519e-05, 'tol': 5.3254443140700725e-05, 'validation_fraction': 0.6171049733889384}
observation time 0.000073, current best -0.954764 at iter 11
suggestion time taken 0.002146 iter 12 next_points [{'alpha': 0.783540107656321, 'batch_size': 155, 'beta_1': 0.5463875790279821, 'beta_2': 0.9790424199572669, 'epsilon': 1.7410735356582763e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.0007191770993988257, 'tol': 7.603583245095794e-05, 'validation_fraction': 0.7878085047881129}]
function_evaluation time 2.145785 value -0.924855 suggestion {'alpha': 0.783540107656321, 'batch_size': 155, 'beta_1': 0.5463875790279821, 'beta_2': 0.9790424199572669, 'epsilon': 1.7410735356582763e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.0007191770993988257, 'tol': 7.603583245095794e-05, 'validation_fraction': 0.7878085047881129}
observation time 0.000073, current best -0.954764 at iter 12
suggestion time taken 0.002172 iter 13 next_points [{'alpha': 0.00029519184570436015, 'batch_size': 127, 'beta_1': 0.8459580789823263, 'beta_2': 0.9114296240846879, 'epsilon': 1.7482962470005883e-07, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.01576698344160703, 'tol': 1.3058347581098424e-05, 'validation_fraction': 0.10185908673829044}]
function_evaluation time 0.943913 value -0.954075 suggestion {'alpha': 0.00029519184570436015, 'batch_size': 127, 'beta_1': 0.8459580789823263, 'beta_2': 0.9114296240846879, 'epsilon': 1.7482962470005883e-07, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.01576698344160703, 'tol': 1.3058347581098424e-05, 'validation_fraction': 0.10185908673829044}
observation time 0.000074, current best -0.954764 at iter 13
suggestion time taken 0.002103 iter 14 next_points [{'alpha': 0.4219779596161181, 'batch_size': 120, 'beta_1': 0.6078057362042208, 'beta_2': 0.9657660559358475, 'epsilon': 4.795927464206492e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.001749746008728292, 'tol': 0.0005502860959472629, 'validation_fraction': 0.2961366968381755}]
function_evaluation time 1.568429 value -0.974247 suggestion {'alpha': 0.4219779596161181, 'batch_size': 120, 'beta_1': 0.6078057362042208, 'beta_2': 0.9657660559358475, 'epsilon': 4.795927464206492e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.001749746008728292, 'tol': 0.0005502860959472629, 'validation_fraction': 0.2961366968381755}
observation time 0.000077, current best -0.974247 at iter 14
saving meta data: {'args': {'--uuid': '3fd112dace63538ca7f48c39bab48ddb', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

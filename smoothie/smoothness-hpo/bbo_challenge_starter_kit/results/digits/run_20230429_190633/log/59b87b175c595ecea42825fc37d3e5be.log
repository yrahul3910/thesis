running: {'--uuid': '59b87b175c595ecea42825fc37d3e5be', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u 59b87b175c595ecea42825fc37d3e5be -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study smoothness MLP-adam digits acc 15 1
with data root: None
suggestion time taken 9.479067 iter 0 next_points [{'alpha': 0.459811227137814, 'batch_size': 29, 'beta_1': 0.7112769609855604, 'beta_2': 0.9999730231510207, 'epsilon': 3.7887569458369715e-09, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.0015520082128481249, 'tol': 0.0011690388280449896, 'validation_fraction': 0.8975083146578181}]
function_evaluation time 1.245848 value -0.886595 suggestion {'alpha': 0.459811227137814, 'batch_size': 29, 'beta_1': 0.7112769609855604, 'beta_2': 0.9999730231510207, 'epsilon': 3.7887569458369715e-09, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.0015520082128481249, 'tol': 0.0011690388280449896, 'validation_fraction': 0.8975083146578181}
observation time 0.000007, current best -0.886595 at iter 0
suggestion time taken 9.358874 iter 1 next_points [{'alpha': 0.07379919270651636, 'batch_size': 27, 'beta_1': 0.8537215891894422, 'beta_2': 0.9931893861902856, 'epsilon': 1.5978879766243066e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.000665920540228567, 'tol': 4.1581950941431665e-05, 'validation_fraction': 0.8448381134325156}]
function_evaluation time 2.491557 value -0.922070 suggestion {'alpha': 0.07379919270651636, 'batch_size': 27, 'beta_1': 0.8537215891894422, 'beta_2': 0.9931893861902856, 'epsilon': 1.5978879766243066e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.000665920540228567, 'tol': 4.1581950941431665e-05, 'validation_fraction': 0.8448381134325156}
observation time 0.000006, current best -0.922070 at iter 1
suggestion time taken 9.375169 iter 2 next_points [{'alpha': 0.20280108613293893, 'batch_size': 35, 'beta_1': 0.707683800552612, 'beta_2': 0.984947402782699, 'epsilon': 2.523265616917468e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0015102550267466494, 'tol': 0.00399627706864505, 'validation_fraction': 0.2676991900236772}]
function_evaluation time 1.588927 value -0.972868 suggestion {'alpha': 0.20280108613293893, 'batch_size': 35, 'beta_1': 0.707683800552612, 'beta_2': 0.984947402782699, 'epsilon': 2.523265616917468e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0015102550267466494, 'tol': 0.00399627706864505, 'validation_fraction': 0.2676991900236772}
observation time 0.000006, current best -0.972868 at iter 2
suggestion time taken 9.582098 iter 3 next_points [{'alpha': 0.0004032726288799803, 'batch_size': 33, 'beta_1': 0.9495496572298496, 'beta_2': 0.998554424254586, 'epsilon': 6.063267447761495e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0003301015447668617, 'tol': 1.9901759950955227e-05, 'validation_fraction': 0.39611271646274027}]
function_evaluation time 3.581517 value -0.948502 suggestion {'alpha': 0.0004032726288799803, 'batch_size': 33, 'beta_1': 0.9495496572298496, 'beta_2': 0.998554424254586, 'epsilon': 6.063267447761495e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0003301015447668617, 'tol': 1.9901759950955227e-05, 'validation_fraction': 0.39611271646274027}
observation time 0.000005, current best -0.972868 at iter 3
suggestion time taken 9.348546 iter 4 next_points [{'alpha': 0.0001816483739584051, 'batch_size': 23, 'beta_1': 0.8920529464117808, 'beta_2': 0.9995087315920551, 'epsilon': 1.4564464225886018e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.000612318112130463, 'tol': 0.00044842158270838605, 'validation_fraction': 0.8983933441588215}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.357058 value -0.790595 suggestion {'alpha': 0.0001816483739584051, 'batch_size': 23, 'beta_1': 0.8920529464117808, 'beta_2': 0.9995087315920551, 'epsilon': 1.4564464225886018e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.000612318112130463, 'tol': 0.00044842158270838605, 'validation_fraction': 0.8983933441588215}
observation time 0.000005, current best -0.972868 at iter 4
suggestion time taken 9.333702 iter 5 next_points [{'alpha': 0.000809420933195036, 'batch_size': 45, 'beta_1': 0.9519476339911412, 'beta_2': 0.9132999195343101, 'epsilon': 7.283036911785119e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.00013292809339553326, 'tol': 0.00016395994297130028, 'validation_fraction': 0.5242852658214113}]
function_evaluation time 3.881996 value -0.956170 suggestion {'alpha': 0.000809420933195036, 'batch_size': 45, 'beta_1': 0.9519476339911412, 'beta_2': 0.9132999195343101, 'epsilon': 7.283036911785119e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.00013292809339553326, 'tol': 0.00016395994297130028, 'validation_fraction': 0.5242852658214113}
observation time 0.000006, current best -0.972868 at iter 5
suggestion time taken 9.311065 iter 6 next_points [{'alpha': 0.09799185081254057, 'batch_size': 51, 'beta_1': 0.5276594913516216, 'beta_2': 0.991212747797173, 'epsilon': 6.819731584541561e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 9.390428570898937e-05, 'tol': 4.80448042414732e-05, 'validation_fraction': 0.8567932383251562}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.689333 value -0.653291 suggestion {'alpha': 0.09799185081254057, 'batch_size': 51, 'beta_1': 0.5276594913516216, 'beta_2': 0.991212747797173, 'epsilon': 6.819731584541561e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 9.390428570898937e-05, 'tol': 4.80448042414732e-05, 'validation_fraction': 0.8567932383251562}
observation time 0.000006, current best -0.972868 at iter 6
suggestion time taken 9.320833 iter 7 next_points [{'alpha': 0.22703205016319306, 'batch_size': 45, 'beta_1': 0.7418444019110692, 'beta_2': 0.9993839144257538, 'epsilon': 8.989501453790713e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0007782747658560484, 'tol': 0.010819011141440469, 'validation_fraction': 0.2962164966923713}]
function_evaluation time 1.008699 value -0.942952 suggestion {'alpha': 0.22703205016319306, 'batch_size': 45, 'beta_1': 0.7418444019110692, 'beta_2': 0.9993839144257538, 'epsilon': 8.989501453790713e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0007782747658560484, 'tol': 0.010819011141440469, 'validation_fraction': 0.2962164966923713}
observation time 0.000006, current best -0.972868 at iter 7
suggestion time taken 9.318770 iter 8 next_points [{'alpha': 6.268147231095235, 'batch_size': 22, 'beta_1': 0.8603955382959887, 'beta_2': 0.9401953861914164, 'epsilon': 1.9762200016245463e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.02588913246061922, 'tol': 0.0674032130922817, 'validation_fraction': 0.5432756686214046}]
function_evaluation time 0.663945 value -0.911617 suggestion {'alpha': 6.268147231095235, 'batch_size': 22, 'beta_1': 0.8603955382959887, 'beta_2': 0.9401953861914164, 'epsilon': 1.9762200016245463e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.02588913246061922, 'tol': 0.0674032130922817, 'validation_fraction': 0.5432756686214046}
observation time 0.000005, current best -0.972868 at iter 8
suggestion time taken 9.317849 iter 9 next_points [{'alpha': 0.0003234593116531946, 'batch_size': 34, 'beta_1': 0.965937242150817, 'beta_2': 0.9999769595550344, 'epsilon': 1.0206608602444974e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 9.495733240638969e-05, 'tol': 0.0010344617559707953, 'validation_fraction': 0.4440460503492455}]
function_evaluation time 5.597667 value -0.922757 suggestion {'alpha': 0.0003234593116531946, 'batch_size': 34, 'beta_1': 0.965937242150817, 'beta_2': 0.9999769595550344, 'epsilon': 1.0206608602444974e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 9.495733240638969e-05, 'tol': 0.0010344617559707953, 'validation_fraction': 0.4440460503492455}
observation time 0.000005, current best -0.972868 at iter 9
suggestion time taken 9.358318 iter 10 next_points [{'alpha': 2.537649679519222e-05, 'batch_size': 22, 'beta_1': 0.7568939045161642, 'beta_2': 0.9980696637756314, 'epsilon': 6.626972621274332e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 4.5737103692338515e-05, 'tol': 0.020221989778285803, 'validation_fraction': 0.1548776556374457}]
function_evaluation time 2.400521 value -0.759219 suggestion {'alpha': 2.537649679519222e-05, 'batch_size': 22, 'beta_1': 0.7568939045161642, 'beta_2': 0.9980696637756314, 'epsilon': 6.626972621274332e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 4.5737103692338515e-05, 'tol': 0.020221989778285803, 'validation_fraction': 0.1548776556374457}

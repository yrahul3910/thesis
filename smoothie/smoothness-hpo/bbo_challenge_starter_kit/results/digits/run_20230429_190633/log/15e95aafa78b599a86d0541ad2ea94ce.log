running: {'--uuid': '15e95aafa78b599a86d0541ad2ea94ce', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d digits -o turbo -u 15e95aafa78b599a86d0541ad2ea94ce -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study turbo MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002115 iter 0 next_points [{'alpha': 0.0017020631447048516, 'batch_size': 244, 'beta_1': 0.9511690823598961, 'beta_2': 0.9913725050604064, 'epsilon': 2.483042442731878e-08, 'hidden_layer_sizes': 78, 'learning_rate_init': 3.591919540427872e-05, 'tol': 1.1889575700083948e-05, 'validation_fraction': 0.45241721073604807}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.975661 value -0.306124 suggestion {'alpha': 0.0017020631447048516, 'batch_size': 244, 'beta_1': 0.9511690823598961, 'beta_2': 0.9913725050604064, 'epsilon': 2.483042442731878e-08, 'hidden_layer_sizes': 78, 'learning_rate_init': 3.591919540427872e-05, 'tol': 1.1889575700083948e-05, 'validation_fraction': 0.45241721073604807}
observation time 0.001380, current best -0.306124 at iter 0
suggestion time taken 0.002077 iter 1 next_points [{'alpha': 0.26331055555250416, 'batch_size': 43, 'beta_1': 0.9855826332563525, 'beta_2': 0.9970183192648367, 'epsilon': 6.22735333872489e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0018587298183287077, 'tol': 3.5828250186208125e-05, 'validation_fraction': 0.2233585481525054}]
function_evaluation time 1.644221 value -0.960337 suggestion {'alpha': 0.26331055555250416, 'batch_size': 43, 'beta_1': 0.9855826332563525, 'beta_2': 0.9970183192648367, 'epsilon': 6.22735333872489e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0018587298183287077, 'tol': 3.5828250186208125e-05, 'validation_fraction': 0.2233585481525054}
observation time 0.001415, current best -0.960337 at iter 1
suggestion time taken 0.002043 iter 2 next_points [{'alpha': 4.011802579093077e-05, 'batch_size': 177, 'beta_1': 0.6478270442859474, 'beta_2': 0.9997941843880729, 'epsilon': 4.039734429288104e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.017720094305456947, 'tol': 0.007900781365933697, 'validation_fraction': 0.477734880939874}]
function_evaluation time 0.544371 value -0.959645 suggestion {'alpha': 4.011802579093077e-05, 'batch_size': 177, 'beta_1': 0.6478270442859474, 'beta_2': 0.9997941843880729, 'epsilon': 4.039734429288104e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.017720094305456947, 'tol': 0.007900781365933697, 'validation_fraction': 0.477734880939874}
observation time 0.001385, current best -0.960337 at iter 2
suggestion time taken 0.001729 iter 3 next_points [{'alpha': 3.8753330368204963, 'batch_size': 14, 'beta_1': 0.9821335365741395, 'beta_2': 0.9999983280723403, 'epsilon': 3.767834415246946e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 4.319950215800678e-05, 'tol': 0.031000036874783286, 'validation_fraction': 0.7817895180801302}]
function_evaluation time 0.784674 value -0.384023 suggestion {'alpha': 3.8753330368204963, 'batch_size': 14, 'beta_1': 0.9821335365741395, 'beta_2': 0.9999983280723403, 'epsilon': 3.767834415246946e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 4.319950215800678e-05, 'tol': 0.031000036874783286, 'validation_fraction': 0.7817895180801302}
observation time 0.001369, current best -0.960337 at iter 3
suggestion time taken 0.001740 iter 4 next_points [{'alpha': 0.4186491543895183, 'batch_size': 76, 'beta_1': 0.8154064585444731, 'beta_2': 0.9982688477205156, 'epsilon': 1.9383349957341963e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0023988041201537928, 'tol': 0.050465485563131456, 'validation_fraction': 0.6781332082350666}]
function_evaluation time 0.368901 value -0.922060 suggestion {'alpha': 0.4186491543895183, 'batch_size': 76, 'beta_1': 0.8154064585444731, 'beta_2': 0.9982688477205156, 'epsilon': 1.9383349957341963e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0023988041201537928, 'tol': 0.050465485563131456, 'validation_fraction': 0.6781332082350666}
observation time 0.001400, current best -0.960337 at iter 4
suggestion time taken 0.002036 iter 5 next_points [{'alpha': 0.02552884625178008, 'batch_size': 202, 'beta_1': 0.9476826642839068, 'beta_2': 0.9999313043517327, 'epsilon': 5.510852889849292e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0009906935999142363, 'tol': 7.263808973101768e-05, 'validation_fraction': 0.8826180188921531}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 1.207134 value -0.846160 suggestion {'alpha': 0.02552884625178008, 'batch_size': 202, 'beta_1': 0.9476826642839068, 'beta_2': 0.9999313043517327, 'epsilon': 5.510852889849292e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0009906935999142363, 'tol': 7.263808973101768e-05, 'validation_fraction': 0.8826180188921531}
observation time 0.001405, current best -0.960337 at iter 5
suggestion time taken 0.001700 iter 6 next_points [{'alpha': 0.0006416977941427674, 'batch_size': 172, 'beta_1': 0.5091801257415732, 'beta_2': 0.9408359974138316, 'epsilon': 6.020560899288204e-07, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.07199203380235858, 'tol': 0.004249674462678655, 'validation_fraction': 0.180807699085764}]
function_evaluation time 1.188511 value -0.910944 suggestion {'alpha': 0.0006416977941427674, 'batch_size': 172, 'beta_1': 0.5091801257415732, 'beta_2': 0.9408359974138316, 'epsilon': 6.020560899288204e-07, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.07199203380235858, 'tol': 0.004249674462678655, 'validation_fraction': 0.180807699085764}
observation time 0.001362, current best -0.960337 at iter 6
suggestion time taken 0.001750 iter 7 next_points [{'alpha': 9.1290718313418, 'batch_size': 115, 'beta_1': 0.8842517232453008, 'beta_2': 0.9777659096674096, 'epsilon': 3.981218241604942e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.000567275570688037, 'tol': 0.0004040791340205647, 'validation_fraction': 0.618050905980887}]
function_evaluation time 1.973012 value -0.947130 suggestion {'alpha': 9.1290718313418, 'batch_size': 115, 'beta_1': 0.8842517232453008, 'beta_2': 0.9777659096674096, 'epsilon': 3.981218241604942e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.000567275570688037, 'tol': 0.0004040791340205647, 'validation_fraction': 0.618050905980887}
observation time 0.001379, current best -0.960337 at iter 7
suggestion time taken 0.001739 iter 8 next_points [{'alpha': 1.8456184837133135e-05, 'batch_size': 187, 'beta_1': 0.7830837262855004, 'beta_2': 0.964592691950916, 'epsilon': 3.8387107791415607e-07, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.046437468692202805, 'tol': 2.018977973616902e-05, 'validation_fraction': 0.2840303993012797}]
function_evaluation time 0.830575 value -0.940147 suggestion {'alpha': 1.8456184837133135e-05, 'batch_size': 187, 'beta_1': 0.7830837262855004, 'beta_2': 0.964592691950916, 'epsilon': 3.8387107791415607e-07, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.046437468692202805, 'tol': 2.018977973616902e-05, 'validation_fraction': 0.2840303993012797}
observation time 0.001369, current best -0.960337 at iter 8
suggestion time taken 0.001979 iter 9 next_points [{'alpha': 0.003584639327913395, 'batch_size': 86, 'beta_1': 0.9610621445322978, 'beta_2': 0.9999803876337715, 'epsilon': 1.6809155646800283e-07, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.00035596861916133236, 'tol': 0.0026147760105858365, 'validation_fraction': 0.829200199075364}]
function_evaluation time 1.359109 value -0.877565 suggestion {'alpha': 0.003584639327913395, 'batch_size': 86, 'beta_1': 0.9610621445322978, 'beta_2': 0.9999803876337715, 'epsilon': 1.6809155646800283e-07, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.00035596861916133236, 'tol': 0.0026147760105858365, 'validation_fraction': 0.829200199075364}
observation time 0.001389, current best -0.960337 at iter 9
suggestion time taken 0.001694 iter 10 next_points [{'alpha': 0.9228736738693649, 'batch_size': 59, 'beta_1': 0.616388766573668, 'beta_2': 0.9896920194515716, 'epsilon': 1.3384496661640572e-08, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.0055956568746992575, 'tol': 0.0007821164090878371, 'validation_fraction': 0.14768731308484115}]
function_evaluation time 1.293084 value -0.965909 suggestion {'alpha': 0.9228736738693649, 'batch_size': 59, 'beta_1': 0.616388766573668, 'beta_2': 0.9896920194515716, 'epsilon': 1.3384496661640572e-08, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.0055956568746992575, 'tol': 0.0007821164090878371, 'validation_fraction': 0.14768731308484115}
observation time 0.001386, current best -0.965909 at iter 10
suggestion time taken 0.001693 iter 11 next_points [{'alpha': 9.489768195478455e-05, 'batch_size': 66, 'beta_1': 0.906802310133075, 'beta_2': 0.999617366124901, 'epsilon': 1.2302712750058768e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.012109429714803532, 'tol': 4.8426259044081975e-05, 'validation_fraction': 0.6956772703426274}]
function_evaluation time 0.842099 value -0.951282 suggestion {'alpha': 9.489768195478455e-05, 'batch_size': 66, 'beta_1': 0.906802310133075, 'beta_2': 0.999617366124901, 'epsilon': 1.2302712750058768e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.012109429714803532, 'tol': 4.8426259044081975e-05, 'validation_fraction': 0.6956772703426274}
observation time 0.001334, current best -0.965909 at iter 11
suggestion time taken 0.001957 iter 12 next_points [{'alpha': 1.5117140526186417, 'batch_size': 153, 'beta_1': 0.9674985869687969, 'beta_2': 0.9999978904262298, 'epsilon': 1.2285776613358064e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 1.583996360949985e-05, 'tol': 0.0015045781028232865, 'validation_fraction': 0.855167576879036}]
function_evaluation time 0.160542 value -0.102308 suggestion {'alpha': 1.5117140526186417, 'batch_size': 153, 'beta_1': 0.9674985869687969, 'beta_2': 0.9999978904262298, 'epsilon': 1.2285776613358064e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 1.583996360949985e-05, 'tol': 0.0015045781028232865, 'validation_fraction': 0.855167576879036}
observation time 0.001358, current best -0.965909 at iter 12
suggestion time taken 0.001663 iter 13 next_points [{'alpha': 0.011838749099799973, 'batch_size': 221, 'beta_1': 0.8719076722304655, 'beta_2': 0.9999617313254531, 'epsilon': 6.830176844011121e-09, 'hidden_layer_sizes': 196, 'learning_rate_init': 9.698101600639136e-05, 'tol': 0.013612754995277448, 'validation_fraction': 0.3724428748336388}]
function_evaluation time 1.391957 value -0.676672 suggestion {'alpha': 0.011838749099799973, 'batch_size': 221, 'beta_1': 0.8719076722304655, 'beta_2': 0.9999617313254531, 'epsilon': 6.830176844011121e-09, 'hidden_layer_sizes': 196, 'learning_rate_init': 9.698101600639136e-05, 'tol': 0.013612754995277448, 'validation_fraction': 0.3724428748336388}
observation time 0.001363, current best -0.965909 at iter 13
suggestion time taken 0.001740 iter 14 next_points [{'alpha': 0.05621533361296581, 'batch_size': 34, 'beta_1': 0.9197179672384367, 'beta_2': 0.9999891719814601, 'epsilon': 9.421933416424747e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.00011728459023169164, 'tol': 0.020604353426933467, 'validation_fraction': 0.3214583046446796}]
function_evaluation time 1.572104 value -0.869846 suggestion {'alpha': 0.05621533361296581, 'batch_size': 34, 'beta_1': 0.9197179672384367, 'beta_2': 0.9999891719814601, 'epsilon': 9.421933416424747e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.00011728459023169164, 'tol': 0.020604353426933467, 'validation_fraction': 0.3214583046446796}
observation time 0.001338, current best -0.965909 at iter 14
saving meta data: {'args': {'--uuid': '15e95aafa78b599a86d0541ad2ea94ce', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'turbo', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

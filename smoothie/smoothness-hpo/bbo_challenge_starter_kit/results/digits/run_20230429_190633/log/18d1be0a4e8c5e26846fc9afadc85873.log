running: {'--uuid': '18d1be0a4e8c5e26846fc9afadc85873', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d digits -o smoothness -u 18d1be0a4e8c5e26846fc9afadc85873 -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study smoothness MLP-adam digits acc 15 1
with data root: None
suggestion time taken 9.454795 iter 0 next_points [{'alpha': 0.5322401244634217, 'batch_size': 24, 'beta_1': 0.6953047603867347, 'beta_2': 0.9999768800669754, 'epsilon': 1.2349010745407173e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.02933496634710139, 'tol': 0.018900962494069678, 'validation_fraction': 0.7975679427864757}]
function_evaluation time 0.387566 value -0.916488 suggestion {'alpha': 0.5322401244634217, 'batch_size': 24, 'beta_1': 0.6953047603867347, 'beta_2': 0.9999768800669754, 'epsilon': 1.2349010745407173e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.02933496634710139, 'tol': 0.018900962494069678, 'validation_fraction': 0.7975679427864757}
observation time 0.000006, current best -0.916488 at iter 0
suggestion time taken 9.387748 iter 1 next_points [{'alpha': 0.20274480105635023, 'batch_size': 13, 'beta_1': 0.6236172066326757, 'beta_2': 0.9999232429146583, 'epsilon': 6.109500748607667e-07, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0004064044034868221, 'tol': 0.03378659226016606, 'validation_fraction': 0.18073897862359112}]
function_evaluation time 1.981149 value -0.956869 suggestion {'alpha': 0.20274480105635023, 'batch_size': 13, 'beta_1': 0.6236172066326757, 'beta_2': 0.9999232429146583, 'epsilon': 6.109500748607667e-07, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0004064044034868221, 'tol': 0.03378659226016606, 'validation_fraction': 0.18073897862359112}
observation time 0.000006, current best -0.956869 at iter 1
suggestion time taken 9.242648 iter 2 next_points [{'alpha': 2.269192146938752e-05, 'batch_size': 50, 'beta_1': 0.94471969207236, 'beta_2': 0.9981609051546694, 'epsilon': 3.2823644666808e-09, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.0017159365897416847, 'tol': 0.00259487632022551, 'validation_fraction': 0.1938753052936612}]
function_evaluation time 1.372601 value -0.965909 suggestion {'alpha': 2.269192146938752e-05, 'batch_size': 50, 'beta_1': 0.94471969207236, 'beta_2': 0.9981609051546694, 'epsilon': 3.2823644666808e-09, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.0017159365897416847, 'tol': 0.00259487632022551, 'validation_fraction': 0.1938753052936612}
observation time 0.000006, current best -0.965909 at iter 2
suggestion time taken 9.544330 iter 3 next_points [{'alpha': 4.69865502612529, 'batch_size': 13, 'beta_1': 0.989075378439565, 'beta_2': 0.9728784519573754, 'epsilon': 8.262156458084235e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 6.725083005767843e-05, 'tol': 0.012515122115844015, 'validation_fraction': 0.8284270257318279}]
function_evaluation time 1.903874 value -0.784292 suggestion {'alpha': 4.69865502612529, 'batch_size': 13, 'beta_1': 0.989075378439565, 'beta_2': 0.9728784519573754, 'epsilon': 8.262156458084235e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 6.725083005767843e-05, 'tol': 0.012515122115844015, 'validation_fraction': 0.8284270257318279}
observation time 0.000006, current best -0.965909 at iter 3
suggestion time taken 9.373050 iter 4 next_points [{'alpha': 0.27457269340519275, 'batch_size': 22, 'beta_1': 0.8277019758091273, 'beta_2': 0.9995122587050875, 'epsilon': 5.737907715882713e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.0050887345323005935, 'tol': 0.0001285098749597783, 'validation_fraction': 0.3121457168999956}]
function_evaluation time 1.833887 value -0.969384 suggestion {'alpha': 0.27457269340519275, 'batch_size': 22, 'beta_1': 0.8277019758091273, 'beta_2': 0.9995122587050875, 'epsilon': 5.737907715882713e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.0050887345323005935, 'tol': 0.0001285098749597783, 'validation_fraction': 0.3121457168999956}
observation time 0.000006, current best -0.969384 at iter 4
suggestion time taken 9.317340 iter 5 next_points [{'alpha': 0.00034100236387359594, 'batch_size': 28, 'beta_1': 0.9876088733340125, 'beta_2': 0.9230855952012473, 'epsilon': 5.842170036726321e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.021297574685424706, 'tol': 2.2856949189161094e-05, 'validation_fraction': 0.4162345285913481}]
function_evaluation time 0.850502 value -0.898367 suggestion {'alpha': 0.00034100236387359594, 'batch_size': 28, 'beta_1': 0.9876088733340125, 'beta_2': 0.9230855952012473, 'epsilon': 5.842170036726321e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.021297574685424706, 'tol': 2.2856949189161094e-05, 'validation_fraction': 0.4162345285913481}
observation time 0.000005, current best -0.969384 at iter 5
suggestion time taken 9.283425 iter 6 next_points [{'alpha': 0.07237165197148498, 'batch_size': 18, 'beta_1': 0.847384873181131, 'beta_2': 0.9997334722685289, 'epsilon': 1.545021013292488e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 1.630462094217052e-05, 'tol': 0.0001404040641005726, 'validation_fraction': 0.3972796115197661}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 14.215901 value -0.875455 suggestion {'alpha': 0.07237165197148498, 'batch_size': 18, 'beta_1': 0.847384873181131, 'beta_2': 0.9997334722685289, 'epsilon': 1.545021013292488e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 1.630462094217052e-05, 'tol': 0.0001404040641005726, 'validation_fraction': 0.3972796115197661}
observation time 0.000006, current best -0.969384 at iter 6
suggestion time taken 9.288808 iter 7 next_points [{'alpha': 8.632373558322996, 'batch_size': 20, 'beta_1': 0.9776962895525084, 'beta_2': 0.9999909164758545, 'epsilon': 3.7571289837690033e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.02137459708858386, 'tol': 0.013341093185989195, 'validation_fraction': 0.15060735231330735}]
function_evaluation time 2.423568 value -0.908157 suggestion {'alpha': 8.632373558322996, 'batch_size': 20, 'beta_1': 0.9776962895525084, 'beta_2': 0.9999909164758545, 'epsilon': 3.7571289837690033e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.02137459708858386, 'tol': 0.013341093185989195, 'validation_fraction': 0.15060735231330735}
observation time 0.000006, current best -0.969384 at iter 7
suggestion time taken 9.286714 iter 8 next_points [{'alpha': 0.00043320736620563945, 'batch_size': 25, 'beta_1': 0.7114120019673392, 'beta_2': 0.9999927561364491, 'epsilon': 1.0055950296858165e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.00015250843730259774, 'tol': 0.0030620434742449003, 'validation_fraction': 0.2933251341313095}]
function_evaluation time 3.048129 value -0.925566 suggestion {'alpha': 0.00043320736620563945, 'batch_size': 25, 'beta_1': 0.7114120019673392, 'beta_2': 0.9999927561364491, 'epsilon': 1.0055950296858165e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.00015250843730259774, 'tol': 0.0030620434742449003, 'validation_fraction': 0.2933251341313095}
observation time 0.000005, current best -0.969384 at iter 8
suggestion time taken 9.328842 iter 9 next_points [{'alpha': 4.081017354161858, 'batch_size': 24, 'beta_1': 0.8545695351971451, 'beta_2': 0.9986460697847286, 'epsilon': 1.74189367735462e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.009278071237516835, 'tol': 0.0010076674958061432, 'validation_fraction': 0.12140830533247722}]
function_evaluation time 1.777965 value -0.935296 suggestion {'alpha': 4.081017354161858, 'batch_size': 24, 'beta_1': 0.8545695351971451, 'beta_2': 0.9986460697847286, 'epsilon': 1.74189367735462e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.009278071237516835, 'tol': 0.0010076674958061432, 'validation_fraction': 0.12140830533247722}
observation time 0.000006, current best -0.969384 at iter 9
suggestion time taken 9.342461 iter 10 next_points [{'alpha': 2.8977289334171538e-05, 'batch_size': 22, 'beta_1': 0.9863197819562878, 'beta_2': 0.9999908077141884, 'epsilon': 5.549747385697933e-08, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.00014961774838045806, 'tol': 1.1253992279565356e-05, 'validation_fraction': 0.16858537849014513}]
function_evaluation time 5.391369 value -0.955456 suggestion {'alpha': 2.8977289334171538e-05, 'batch_size': 22, 'beta_1': 0.9863197819562878, 'beta_2': 0.9999908077141884, 'epsilon': 5.549747385697933e-08, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.00014961774838045806, 'tol': 1.1253992279565356e-05, 'validation_fraction': 0.16858537849014513}
observation time 0.000005, current best -0.969384 at iter 10
suggestion time taken 9.301761 iter 11 next_points [{'alpha': 0.09775762193306196, 'batch_size': 14, 'beta_1': 0.6294231483502366, 'beta_2': 0.9999123982606752, 'epsilon': 2.3980071569164103e-09, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0012770772155615599, 'tol': 0.03145437891331537, 'validation_fraction': 0.3001247164975393}]
function_evaluation time 1.410239 value -0.954769 suggestion {'alpha': 0.09775762193306196, 'batch_size': 14, 'beta_1': 0.6294231483502366, 'beta_2': 0.9999123982606752, 'epsilon': 2.3980071569164103e-09, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0012770772155615599, 'tol': 0.03145437891331537, 'validation_fraction': 0.3001247164975393}
observation time 0.000006, current best -0.969384 at iter 11
suggestion time taken 9.299337 iter 12 next_points [{'alpha': 0.001391577044773232, 'batch_size': 27, 'beta_1': 0.7185639449024298, 'beta_2': 0.9997975903418878, 'epsilon': 1.756299234964558e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.06366607285530348, 'tol': 0.00017367229063135607, 'validation_fraction': 0.8655502056967642}]
function_evaluation time 0.720767 value -0.727391 suggestion {'alpha': 0.001391577044773232, 'batch_size': 27, 'beta_1': 0.7185639449024298, 'beta_2': 0.9997975903418878, 'epsilon': 1.756299234964558e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.06366607285530348, 'tol': 0.00017367229063135607, 'validation_fraction': 0.8655502056967642}
observation time 0.000005, current best -0.969384 at iter 12
suggestion time taken 9.298260 iter 13 next_points [{'alpha': 0.02007903542770431, 'batch_size': 33, 'beta_1': 0.6358275758127881, 'beta_2': 0.9999961323911091, 'epsilon': 6.023732439562743e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.3144695875661291e-05, 'tol': 0.018766388197066997, 'validation_fraction': 0.4673927305706864}]
function_evaluation time 0.504231 value -0.122513 suggestion {'alpha': 0.02007903542770431, 'batch_size': 33, 'beta_1': 0.6358275758127881, 'beta_2': 0.9999961323911091, 'epsilon': 6.023732439562743e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.3144695875661291e-05, 'tol': 0.018766388197066997, 'validation_fraction': 0.4673927305706864}
observation time 0.000006, current best -0.969384 at iter 13
suggestion time taken 9.244052 iter 14 next_points [{'alpha': 1.7951832235941245e-05, 'batch_size': 19, 'beta_1': 0.8702907309743715, 'beta_2': 0.9999410423546475, 'epsilon': 1.689454139682572e-09, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.01542759758411349, 'tol': 0.0031742792577457166, 'validation_fraction': 0.6474938751745241}]
function_evaluation time 1.171422 value -0.942252 suggestion {'alpha': 1.7951832235941245e-05, 'batch_size': 19, 'beta_1': 0.8702907309743715, 'beta_2': 0.9999410423546475, 'epsilon': 1.689454139682572e-09, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.01542759758411349, 'tol': 0.0031742792577457166, 'validation_fraction': 0.6474938751745241}
observation time 0.000005, current best -0.969384 at iter 14
saving meta data: {'args': {'--uuid': '18d1be0a4e8c5e26846fc9afadc85873', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'smoothness', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '08154a972ab15cd5bdc3844e042e93ec', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 08154a972ab15cd5bdc3844e042e93ec -m acc -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_acc betwen [-0.2181506  -0.12954897 -0.42701514 -0.94997127 -0.93320509] and [-0.21081107 -0.11575494 -0.27999177 -0.94225223 -0.93253861]
  warnings.warn(

Signature errors:
                           0         1         2         3         4       max
MLP-adam_digits_acc  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
max                  0.00734  0.013794  0.147023  0.007719  0.000666  0.147023
starting sklearn study hyperopt MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.002401 iter 0 next_points [{'alpha': 0.09851143474748537, 'batch_size': 145, 'beta_1': 0.858910162138455, 'beta_2': 0.9233773241925252, 'epsilon': 2.989014382337472e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0012021810186354366, 'tol': 1.3878342454002006e-05, 'validation_fraction': 0.18361672198897666}]
function_evaluation time 1.388133 value -0.974252 suggestion {'alpha': 0.09851143474748537, 'batch_size': 145, 'beta_1': 0.858910162138455, 'beta_2': 0.9233773241925252, 'epsilon': 2.989014382337472e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0012021810186354366, 'tol': 1.3878342454002006e-05, 'validation_fraction': 0.18361672198897666}
observation time 0.000072, current best -0.974252 at iter 0
suggestion time taken 0.002378 iter 1 next_points [{'alpha': 2.913692300466066, 'batch_size': 121, 'beta_1': 0.6857874297166032, 'beta_2': 0.9608113124012692, 'epsilon': 1.1368904835671896e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.003097194938271055, 'tol': 0.0051343671290489295, 'validation_fraction': 0.15610726885316}]
function_evaluation time 0.771091 value -0.934599 suggestion {'alpha': 2.913692300466066, 'batch_size': 121, 'beta_1': 0.6857874297166032, 'beta_2': 0.9608113124012692, 'epsilon': 1.1368904835671896e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.003097194938271055, 'tol': 0.0051343671290489295, 'validation_fraction': 0.15610726885316}
observation time 0.000072, current best -0.974252 at iter 1
suggestion time taken 0.002162 iter 2 next_points [{'alpha': 3.748164207642088e-05, 'batch_size': 100, 'beta_1': 0.5102444259678685, 'beta_2': 0.9074255867152101, 'epsilon': 3.5410589129799155e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.029240450787597044, 'tol': 0.0031371669480939135, 'validation_fraction': 0.1730524999244376}]
function_evaluation time 0.675853 value -0.938081 suggestion {'alpha': 3.748164207642088e-05, 'batch_size': 100, 'beta_1': 0.5102444259678685, 'beta_2': 0.9074255867152101, 'epsilon': 3.5410589129799155e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.029240450787597044, 'tol': 0.0031371669480939135, 'validation_fraction': 0.1730524999244376}
observation time 0.000075, current best -0.974252 at iter 2
suggestion time taken 0.002133 iter 3 next_points [{'alpha': 0.10123612574349689, 'batch_size': 171, 'beta_1': 0.6535345932640017, 'beta_2': 0.9396697526996176, 'epsilon': 5.1724403660308154e-08, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.00010375990313531722, 'tol': 0.004508231422698757, 'validation_fraction': 0.6857288477920135}]
function_evaluation time 1.202569 value -0.411186 suggestion {'alpha': 0.10123612574349689, 'batch_size': 171, 'beta_1': 0.6535345932640017, 'beta_2': 0.9396697526996176, 'epsilon': 5.1724403660308154e-08, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.00010375990313531722, 'tol': 0.004508231422698757, 'validation_fraction': 0.6857288477920135}
observation time 0.000073, current best -0.974252 at iter 3
suggestion time taken 0.002103 iter 4 next_points [{'alpha': 8.66641183315597e-05, 'batch_size': 69, 'beta_1': 0.8517317065898055, 'beta_2': 0.916128437445152, 'epsilon': 1.0131088110387156e-09, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.018339221958080694, 'tol': 0.00016107108256473306, 'validation_fraction': 0.5756600351905211}]
function_evaluation time 0.835645 value -0.949898 suggestion {'alpha': 8.66641183315597e-05, 'batch_size': 69, 'beta_1': 0.8517317065898055, 'beta_2': 0.916128437445152, 'epsilon': 1.0131088110387156e-09, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.018339221958080694, 'tol': 0.00016107108256473306, 'validation_fraction': 0.5756600351905211}
observation time 0.000074, current best -0.974252 at iter 4
suggestion time taken 0.002140 iter 5 next_points [{'alpha': 0.0029952693420300766, 'batch_size': 121, 'beta_1': 0.5584855336478234, 'beta_2': 0.9739384442980916, 'epsilon': 2.1151424857022747e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.007371636675785765, 'tol': 0.015135499576272542, 'validation_fraction': 0.14476640972652463}]
function_evaluation time 0.564674 value -0.969394 suggestion {'alpha': 0.0029952693420300766, 'batch_size': 121, 'beta_1': 0.5584855336478234, 'beta_2': 0.9739384442980916, 'epsilon': 2.1151424857022747e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.007371636675785765, 'tol': 0.015135499576272542, 'validation_fraction': 0.14476640972652463}
observation time 0.000075, current best -0.974252 at iter 5
suggestion time taken 0.002169 iter 6 next_points [{'alpha': 0.014315738925230375, 'batch_size': 58, 'beta_1': 0.5480822279723663, 'beta_2': 0.9724266572660472, 'epsilon': 8.044409677323006e-08, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.0008094142029665307, 'tol': 0.0003674982910557565, 'validation_fraction': 0.31219602672770014}]
function_evaluation time 2.178074 value -0.970773 suggestion {'alpha': 0.014315738925230375, 'batch_size': 58, 'beta_1': 0.5480822279723663, 'beta_2': 0.9724266572660472, 'epsilon': 8.044409677323006e-08, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.0008094142029665307, 'tol': 0.0003674982910557565, 'validation_fraction': 0.31219602672770014}
observation time 0.000072, current best -0.974252 at iter 6
suggestion time taken 0.002476 iter 7 next_points [{'alpha': 7.095961605405252e-05, 'batch_size': 211, 'beta_1': 0.5592834012406545, 'beta_2': 0.9161887261069356, 'epsilon': 6.3394199409105486e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 9.359816802675457e-05, 'tol': 0.0005951413437975223, 'validation_fraction': 0.39634204382298893}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.575678 value -0.571446 suggestion {'alpha': 7.095961605405252e-05, 'batch_size': 211, 'beta_1': 0.5592834012406545, 'beta_2': 0.9161887261069356, 'epsilon': 6.3394199409105486e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 9.359816802675457e-05, 'tol': 0.0005951413437975223, 'validation_fraction': 0.39634204382298893}
observation time 0.000075, current best -0.974252 at iter 7
suggestion time taken 0.002123 iter 8 next_points [{'alpha': 2.1169303531061554, 'batch_size': 16, 'beta_1': 0.6934302675350065, 'beta_2': 0.9417071662907412, 'epsilon': 1.2802747441752316e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.003376767089008693, 'tol': 0.0006146910731356074, 'validation_fraction': 0.6098989002844075}]
function_evaluation time 1.384689 value -0.948509 suggestion {'alpha': 2.1169303531061554, 'batch_size': 16, 'beta_1': 0.6934302675350065, 'beta_2': 0.9417071662907412, 'epsilon': 1.2802747441752316e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.003376767089008693, 'tol': 0.0006146910731356074, 'validation_fraction': 0.6098989002844075}
observation time 0.000071, current best -0.974252 at iter 8
suggestion time taken 0.002382 iter 9 next_points [{'alpha': 0.00363539504272627, 'batch_size': 199, 'beta_1': 0.7151466735493629, 'beta_2': 0.9578632516064817, 'epsilon': 1.5104910229428485e-08, 'hidden_layer_sizes': 187, 'learning_rate_init': 4.860887355857155e-05, 'tol': 0.00035002865203356186, 'validation_fraction': 0.7935090059492461}]
function_evaluation time 2.889212 value -0.798872 suggestion {'alpha': 0.00363539504272627, 'batch_size': 199, 'beta_1': 0.7151466735493629, 'beta_2': 0.9578632516064817, 'epsilon': 1.5104910229428485e-08, 'hidden_layer_sizes': 187, 'learning_rate_init': 4.860887355857155e-05, 'tol': 0.00035002865203356186, 'validation_fraction': 0.7935090059492461}
observation time 0.000078, current best -0.974252 at iter 9
suggestion time taken 0.002147 iter 10 next_points [{'alpha': 0.6054898756372151, 'batch_size': 205, 'beta_1': 0.5608537865268627, 'beta_2': 0.972657579831165, 'epsilon': 1.554103300179375e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00022147053268998818, 'tol': 0.02561139244082982, 'validation_fraction': 0.7605725012336777}]
function_evaluation time 0.160295 value -0.148214 suggestion {'alpha': 0.6054898756372151, 'batch_size': 205, 'beta_1': 0.5608537865268627, 'beta_2': 0.972657579831165, 'epsilon': 1.554103300179375e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00022147053268998818, 'tol': 0.02561139244082982, 'validation_fraction': 0.7605725012336777}
observation time 0.000076, current best -0.974252 at iter 10
suggestion time taken 0.002140 iter 11 next_points [{'alpha': 0.0011044208416425862, 'batch_size': 25, 'beta_1': 0.5131873877703752, 'beta_2': 0.9860700367629598, 'epsilon': 2.3362987960902581e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.00031723078426106565, 'tol': 1.964706502187124e-05, 'validation_fraction': 0.5168436815778362}]
function_evaluation time 3.975793 value -0.965909 suggestion {'alpha': 0.0011044208416425862, 'batch_size': 25, 'beta_1': 0.5131873877703752, 'beta_2': 0.9860700367629598, 'epsilon': 2.3362987960902581e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.00031723078426106565, 'tol': 1.964706502187124e-05, 'validation_fraction': 0.5168436815778362}
observation time 0.000078, current best -0.974252 at iter 11
suggestion time taken 0.002370 iter 12 next_points [{'alpha': 8.132451659219665, 'batch_size': 137, 'beta_1': 0.8999596616735138, 'beta_2': 0.9128346072425332, 'epsilon': 7.876756987321566e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.001679627182615555, 'tol': 4.510352657583772e-05, 'validation_fraction': 0.2915110065272547}]
function_evaluation time 1.089833 value -0.965912 suggestion {'alpha': 8.132451659219665, 'batch_size': 137, 'beta_1': 0.8999596616735138, 'beta_2': 0.9128346072425332, 'epsilon': 7.876756987321566e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.001679627182615555, 'tol': 4.510352657583772e-05, 'validation_fraction': 0.2915110065272547}
observation time 0.000076, current best -0.974252 at iter 12
suggestion time taken 0.002251 iter 13 next_points [{'alpha': 0.12263108888114166, 'batch_size': 72, 'beta_1': 0.9574143262172305, 'beta_2': 0.9229357079414654, 'epsilon': 1.8375320405836678e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.08199872030445467, 'tol': 0.006785297540450829, 'validation_fraction': 0.11585246117850033}]
function_evaluation time 1.251121 value -0.935286 suggestion {'alpha': 0.12263108888114166, 'batch_size': 72, 'beta_1': 0.9574143262172305, 'beta_2': 0.9229357079414654, 'epsilon': 1.8375320405836678e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.08199872030445467, 'tol': 0.006785297540450829, 'validation_fraction': 0.11585246117850033}
observation time 0.000079, current best -0.974252 at iter 13
suggestion time taken 0.002159 iter 14 next_points [{'alpha': 0.0018143342521778462, 'batch_size': 104, 'beta_1': 0.9114758959625711, 'beta_2': 0.9835512268324915, 'epsilon': 1.2093064243540385e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0007674877664317672, 'tol': 0.0022100516935307803, 'validation_fraction': 0.17417681491096337}]
function_evaluation time 1.758000 value -0.959640 suggestion {'alpha': 0.0018143342521778462, 'batch_size': 104, 'beta_1': 0.9114758959625711, 'beta_2': 0.9835512268324915, 'epsilon': 1.2093064243540385e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0007674877664317672, 'tol': 0.0022100516935307803, 'validation_fraction': 0.17417681491096337}
observation time 0.000085, current best -0.974252 at iter 14
saving meta data: {'args': {'--uuid': '08154a972ab15cd5bdc3844e042e93ec', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '29632d7946f1511b9be68ba0ae2dd9db', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d digits -o hyperopt -u 29632d7946f1511b9be68ba0ae2dd9db -m nll -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230429_190633
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])
/home/ryedida/.local/lib/python3.9/site-packages/bayesmark/signatures.py:85: RuntimeWarning: Signature diverged on MLP-adam_digits_nll betwen [4.71022664 9.71262277 5.92543888 0.18972466 0.25190217] and [ 4.87095228 10.02890359  5.95079183  0.19438427  0.26094505]
  warnings.warn(

Signature errors:
                            0         1         2        3         4       max
MLP-adam_digits_nll  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
max                  0.160726  0.316281  0.025353  0.00466  0.009043  0.316281
starting sklearn study hyperopt MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.002418 iter 0 next_points [{'alpha': 0.0001369646007560411, 'batch_size': 164, 'beta_1': 0.9463276880339996, 'beta_2': 0.9663537526693008, 'epsilon': 3.0371729614666583e-07, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.03969356949978331, 'tol': 0.004669126574190654, 'validation_fraction': 0.13887381521939143}]
function_evaluation time 1.178359 value 0.280421 suggestion {'alpha': 0.0001369646007560411, 'batch_size': 164, 'beta_1': 0.9463276880339996, 'beta_2': 0.9663537526693008, 'epsilon': 3.0371729614666583e-07, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.03969356949978331, 'tol': 0.004669126574190654, 'validation_fraction': 0.13887381521939143}
observation time 0.000082, current best 0.280421 at iter 0
suggestion time taken 0.002415 iter 1 next_points [{'alpha': 0.03147155026873489, 'batch_size': 43, 'beta_1': 0.9034296725714158, 'beta_2': 0.9490478803234296, 'epsilon': 8.710879609428523e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.001955389197612635, 'tol': 6.757469133538424e-05, 'validation_fraction': 0.6362866770685532}]
function_evaluation time 1.184475 value 0.199867 suggestion {'alpha': 0.03147155026873489, 'batch_size': 43, 'beta_1': 0.9034296725714158, 'beta_2': 0.9490478803234296, 'epsilon': 8.710879609428523e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.001955389197612635, 'tol': 6.757469133538424e-05, 'validation_fraction': 0.6362866770685532}
observation time 0.000072, current best 0.199867 at iter 1
suggestion time taken 0.002107 iter 2 next_points [{'alpha': 0.0002525399049473912, 'batch_size': 54, 'beta_1': 0.9362667878565295, 'beta_2': 0.973343383863207, 'epsilon': 1.0707846754932141e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 1.3922752520557742e-05, 'tol': 0.0008705750436593168, 'validation_fraction': 0.559989419649768}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.651026 value 8.182463 suggestion {'alpha': 0.0002525399049473912, 'batch_size': 54, 'beta_1': 0.9362667878565295, 'beta_2': 0.973343383863207, 'epsilon': 1.0707846754932141e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 1.3922752520557742e-05, 'tol': 0.0008705750436593168, 'validation_fraction': 0.559989419649768}
observation time 0.000071, current best 0.199867 at iter 2
suggestion time taken 0.002140 iter 3 next_points [{'alpha': 0.0007803612402674715, 'batch_size': 227, 'beta_1': 0.7260333897715585, 'beta_2': 0.9066283786622139, 'epsilon': 2.53131557251466e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 7.80238294012154e-05, 'tol': 0.00037921356580904116, 'validation_fraction': 0.7441143017109827}]
function_evaluation time 2.406527 value 0.549984 suggestion {'alpha': 0.0007803612402674715, 'batch_size': 227, 'beta_1': 0.7260333897715585, 'beta_2': 0.9066283786622139, 'epsilon': 2.53131557251466e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 7.80238294012154e-05, 'tol': 0.00037921356580904116, 'validation_fraction': 0.7441143017109827}
observation time 0.000071, current best 0.199867 at iter 3
suggestion time taken 0.002135 iter 4 next_points [{'alpha': 0.00468316448957247, 'batch_size': 207, 'beta_1': 0.9854129938219514, 'beta_2': 0.9808378624300951, 'epsilon': 3.3205933315968264e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.012355745388217368, 'tol': 0.006211639884297852, 'validation_fraction': 0.8333492209944264}]
function_evaluation time 0.346219 value 0.660908 suggestion {'alpha': 0.00468316448957247, 'batch_size': 207, 'beta_1': 0.9854129938219514, 'beta_2': 0.9808378624300951, 'epsilon': 3.3205933315968264e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.012355745388217368, 'tol': 0.006211639884297852, 'validation_fraction': 0.8333492209944264}
observation time 0.000073, current best 0.199867 at iter 4
suggestion time taken 0.002137 iter 5 next_points [{'alpha': 0.03040687239631034, 'batch_size': 173, 'beta_1': 0.689363846730428, 'beta_2': 0.9470350989741865, 'epsilon': 1.5699974254464553e-07, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.0011623487178173198, 'tol': 0.015741284800309917, 'validation_fraction': 0.2937744195375485}]
function_evaluation time 0.650692 value 0.157918 suggestion {'alpha': 0.03040687239631034, 'batch_size': 173, 'beta_1': 0.689363846730428, 'beta_2': 0.9470350989741865, 'epsilon': 1.5699974254464553e-07, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.0011623487178173198, 'tol': 0.015741284800309917, 'validation_fraction': 0.2937744195375485}
observation time 0.000073, current best 0.157918 at iter 5
suggestion time taken 0.002172 iter 6 next_points [{'alpha': 0.00015131479173849873, 'batch_size': 55, 'beta_1': 0.8613391845150257, 'beta_2': 0.9292733228915975, 'epsilon': 9.568922418115256e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.0001858954896584869, 'tol': 0.0005190759096079804, 'validation_fraction': 0.5457985781655014}]
function_evaluation time 3.120450 value 0.212757 suggestion {'alpha': 0.00015131479173849873, 'batch_size': 55, 'beta_1': 0.8613391845150257, 'beta_2': 0.9292733228915975, 'epsilon': 9.568922418115256e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.0001858954896584869, 'tol': 0.0005190759096079804, 'validation_fraction': 0.5457985781655014}
observation time 0.000072, current best 0.157918 at iter 6
suggestion time taken 0.002175 iter 7 next_points [{'alpha': 2.42938231861522, 'batch_size': 52, 'beta_1': 0.7916686099651994, 'beta_2': 0.9304360583737781, 'epsilon': 9.338014332425287e-09, 'hidden_layer_sizes': 146, 'learning_rate_init': 1.94661691638416e-05, 'tol': 0.00029578408713519576, 'validation_fraction': 0.4609405478808886}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 5.737907 value 4.531552 suggestion {'alpha': 2.42938231861522, 'batch_size': 52, 'beta_1': 0.7916686099651994, 'beta_2': 0.9304360583737781, 'epsilon': 9.338014332425287e-09, 'hidden_layer_sizes': 146, 'learning_rate_init': 1.94661691638416e-05, 'tol': 0.00029578408713519576, 'validation_fraction': 0.4609405478808886}
observation time 0.000085, current best 0.157918 at iter 7
suggestion time taken 0.002317 iter 8 next_points [{'alpha': 0.0008473873821142833, 'batch_size': 101, 'beta_1': 0.5438996387401122, 'beta_2': 0.9852853158366346, 'epsilon': 8.925021141373548e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0004786928277603087, 'tol': 0.00011077897235603978, 'validation_fraction': 0.7172233983452388}]
function_evaluation time 1.933640 value 0.300650 suggestion {'alpha': 0.0008473873821142833, 'batch_size': 101, 'beta_1': 0.5438996387401122, 'beta_2': 0.9852853158366346, 'epsilon': 8.925021141373548e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0004786928277603087, 'tol': 0.00011077897235603978, 'validation_fraction': 0.7172233983452388}
observation time 0.000076, current best 0.157918 at iter 8
suggestion time taken 0.002128 iter 9 next_points [{'alpha': 0.0015480519765888716, 'batch_size': 11, 'beta_1': 0.9149676376902702, 'beta_2': 0.9945205069435806, 'epsilon': 7.471281210018151e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 6.111054341064477e-05, 'tol': 0.00019952813776125987, 'validation_fraction': 0.18901091177230647}]
function_evaluation time 9.488384 value 0.135614 suggestion {'alpha': 0.0015480519765888716, 'batch_size': 11, 'beta_1': 0.9149676376902702, 'beta_2': 0.9945205069435806, 'epsilon': 7.471281210018151e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 6.111054341064477e-05, 'tol': 0.00019952813776125987, 'validation_fraction': 0.18901091177230647}
observation time 0.000076, current best 0.135614 at iter 9
suggestion time taken 0.002112 iter 10 next_points [{'alpha': 0.012216139074195265, 'batch_size': 237, 'beta_1': 0.6822190406371675, 'beta_2': 0.9747855697579073, 'epsilon': 2.0896426140706798e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 4.5505198055594974e-05, 'tol': 0.06998234108238192, 'validation_fraction': 0.6744259484363969}]
function_evaluation time 0.178736 value 11.198036 suggestion {'alpha': 0.012216139074195265, 'batch_size': 237, 'beta_1': 0.6822190406371675, 'beta_2': 0.9747855697579073, 'epsilon': 2.0896426140706798e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 4.5505198055594974e-05, 'tol': 0.06998234108238192, 'validation_fraction': 0.6744259484363969}
observation time 0.000076, current best 0.135614 at iter 10
suggestion time taken 0.002116 iter 11 next_points [{'alpha': 0.03996325775662967, 'batch_size': 156, 'beta_1': 0.9012665567068734, 'beta_2': 0.984712184647564, 'epsilon': 8.314504036695731e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.03275837210132988, 'tol': 0.00786688714631036, 'validation_fraction': 0.3072066831962704}]
function_evaluation time 0.755933 value 0.219292 suggestion {'alpha': 0.03996325775662967, 'batch_size': 156, 'beta_1': 0.9012665567068734, 'beta_2': 0.984712184647564, 'epsilon': 8.314504036695731e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.03275837210132988, 'tol': 0.00786688714631036, 'validation_fraction': 0.3072066831962704}
observation time 0.000073, current best 0.135614 at iter 11
suggestion time taken 0.002433 iter 12 next_points [{'alpha': 0.021087475682821075, 'batch_size': 142, 'beta_1': 0.5456293479320875, 'beta_2': 0.9053057031340221, 'epsilon': 1.6880787715341955e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.008796720715989553, 'tol': 0.0011167593451806557, 'validation_fraction': 0.13772639564183214}]
function_evaluation time 0.948973 value 0.108258 suggestion {'alpha': 0.021087475682821075, 'batch_size': 142, 'beta_1': 0.5456293479320875, 'beta_2': 0.9053057031340221, 'epsilon': 1.6880787715341955e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.008796720715989553, 'tol': 0.0011167593451806557, 'validation_fraction': 0.13772639564183214}
observation time 0.000076, current best 0.108258 at iter 12
suggestion time taken 0.002171 iter 13 next_points [{'alpha': 0.0004044337067843342, 'batch_size': 50, 'beta_1': 0.6549047924446669, 'beta_2': 0.9094933487564364, 'epsilon': 6.625652693796729e-09, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.00011171545562187485, 'tol': 0.0030542740247712597, 'validation_fraction': 0.370698862587434}]
function_evaluation time 2.589541 value 0.172278 suggestion {'alpha': 0.0004044337067843342, 'batch_size': 50, 'beta_1': 0.6549047924446669, 'beta_2': 0.9094933487564364, 'epsilon': 6.625652693796729e-09, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.00011171545562187485, 'tol': 0.0030542740247712597, 'validation_fraction': 0.370698862587434}
observation time 0.000072, current best 0.108258 at iter 13
suggestion time taken 0.002117 iter 14 next_points [{'alpha': 4.641156866548723, 'batch_size': 72, 'beta_1': 0.5839605174687472, 'beta_2': 0.9431766624651261, 'epsilon': 8.292780250644322e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 2.3153303283754952e-05, 'tol': 1.7390937942678116e-05, 'validation_fraction': 0.19704927178808776}]
function_evaluation time 6.639396 value 0.327775 suggestion {'alpha': 4.641156866548723, 'batch_size': 72, 'beta_1': 0.5839605174687472, 'beta_2': 0.9431766624651261, 'epsilon': 8.292780250644322e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 2.3153303283754952e-05, 'tol': 1.7390937942678116e-05, 'validation_fraction': 0.19704927178808776}
observation time 0.000074, current best 0.108258 at iter 14
saving meta data: {'args': {'--uuid': '29632d7946f1511b9be68ba0ae2dd9db', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230429_190633', '--opt': 'hyperopt', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.251902166999456])}
saving results
saving timing
saving suggest log
done

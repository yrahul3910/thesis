running: {'--uuid': 'b6a5275fa6445290a5dcc849498a3be1', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d diabetes -o opentuner -u b6a5275fa6445290a5dcc849498a3be1 -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230427_004608
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study opentuner MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.056154 iter 0 next_points [{'hidden_layer_sizes': 82, 'alpha': 1.5669212102540646, 'batch_size': 160, 'learning_rate_init': 0.06582722697340652, 'tol': 0.049947687887801066, 'validation_fraction': 0.2738623003364242, 'beta_1': 0.6485793133644654, 'beta_2': 0.9912552756261295, 'epsilon': 8.172664872912728e-07}]
function_evaluation time 0.128303 value 3309.398815 suggestion {'hidden_layer_sizes': 82, 'alpha': 1.5669212102540646, 'batch_size': 160, 'learning_rate_init': 0.06582722697340652, 'tol': 0.049947687887801066, 'validation_fraction': 0.2738623003364242, 'beta_1': 0.6485793133644654, 'beta_2': 0.9912552756261295, 'epsilon': 8.172664872912728e-07}
observation time 0.004385, current best 3309.398815 at iter 0
suggestion time taken 0.007554 iter 1 next_points [{'hidden_layer_sizes': 82, 'alpha': 1.5669212102540646, 'batch_size': 188, 'learning_rate_init': 0.06582722697340652, 'tol': 0.049947687887801066, 'validation_fraction': 0.2075610828368305, 'beta_1': 0.6485793133644654, 'beta_2': 0.9972624456951836, 'epsilon': 8.172664872912728e-07}]
function_evaluation time 0.132362 value 3370.382690 suggestion {'hidden_layer_sizes': 82, 'alpha': 1.5669212102540646, 'batch_size': 188, 'learning_rate_init': 0.06582722697340652, 'tol': 0.049947687887801066, 'validation_fraction': 0.2075610828368305, 'beta_1': 0.6485793133644654, 'beta_2': 0.9972624456951836, 'epsilon': 8.172664872912728e-07}
observation time 0.002096, current best 3309.398815 at iter 1
suggestion time taken 0.007179 iter 2 next_points [{'hidden_layer_sizes': 82, 'alpha': 3.9101553401722877, 'batch_size': 160, 'learning_rate_init': 0.06582722697340652, 'tol': 0.049947687887801066, 'validation_fraction': 0.2738623003364242, 'beta_1': 0.6485793133644654, 'beta_2': 0.9912552756261295, 'epsilon': 8.172664872912728e-07}]
function_evaluation time 0.126502 value 3365.962848 suggestion {'hidden_layer_sizes': 82, 'alpha': 3.9101553401722877, 'batch_size': 160, 'learning_rate_init': 0.06582722697340652, 'tol': 0.049947687887801066, 'validation_fraction': 0.2738623003364242, 'beta_1': 0.6485793133644654, 'beta_2': 0.9912552756261295, 'epsilon': 8.172664872912728e-07}
observation time 0.002031, current best 3309.398815 at iter 2
suggestion time taken 0.021340 iter 3 next_points [{'alpha': 1.7724020040779438, 'epsilon': 3.429530503201429e-07, 'beta_2': 0.9235087515279327, 'tol': 0.05524598133663499, 'batch_size': 183, 'validation_fraction': 0.5861155177925629, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.08324964335845657, 'beta_1': 0.9112375456186496}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.142453 value 4156.519486 suggestion {'alpha': 1.7724020040779438, 'epsilon': 3.429530503201429e-07, 'beta_2': 0.9235087515279327, 'tol': 0.05524598133663499, 'batch_size': 183, 'validation_fraction': 0.5861155177925629, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.08324964335845657, 'beta_1': 0.9112375456186496}
observation time 0.002035, current best 3309.398815 at iter 3
suggestion time taken 0.005124 iter 4 next_points [{'hidden_layer_sizes': 183, 'alpha': 0.36029749549217355, 'batch_size': 168, 'learning_rate_init': 0.09370336832505603, 'tol': 0.06838787475761492, 'validation_fraction': 0.221677172126462, 'beta_1': 0.8350387208731608, 'beta_2': 0.9366983872979135, 'epsilon': 4.185270886808136e-07}]
function_evaluation time 0.154137 value 3050.603352 suggestion {'hidden_layer_sizes': 183, 'alpha': 0.36029749549217355, 'batch_size': 168, 'learning_rate_init': 0.09370336832505603, 'tol': 0.06838787475761492, 'validation_fraction': 0.221677172126462, 'beta_1': 0.8350387208731608, 'beta_2': 0.9366983872979135, 'epsilon': 4.185270886808136e-07}
observation time 0.001849, current best 3050.603352 at iter 4
suggestion time taken 0.005082 iter 5 next_points [{'hidden_layer_sizes': 60, 'alpha': 0.8257658216136009, 'batch_size': 55, 'learning_rate_init': 0.03763253684942896, 'tol': 0.09561643442786998, 'validation_fraction': 0.3015205967980402, 'beta_1': 0.851624115399221, 'beta_2': 0.9521838884908426, 'epsilon': 7.105813092661274e-07}]
function_evaluation time 0.112335 value 3516.479969 suggestion {'hidden_layer_sizes': 60, 'alpha': 0.8257658216136009, 'batch_size': 55, 'learning_rate_init': 0.03763253684942896, 'tol': 0.09561643442786998, 'validation_fraction': 0.3015205967980402, 'beta_1': 0.851624115399221, 'beta_2': 0.9521838884908426, 'epsilon': 7.105813092661274e-07}
observation time 0.002143, current best 3050.603352 at iter 5
suggestion time taken 0.005208 iter 6 next_points [{'hidden_layer_sizes': 104, 'alpha': 7.3524472751356935, 'batch_size': 207, 'learning_rate_init': 0.08594356393625106, 'tol': 0.045957348414413283, 'validation_fraction': 0.3342652059950056, 'beta_1': 0.573926950470276, 'beta_2': 0.9971251873563918, 'epsilon': 3.835731635146067e-08}]
function_evaluation time 0.123873 value 3394.050575 suggestion {'hidden_layer_sizes': 104, 'alpha': 7.3524472751356935, 'batch_size': 207, 'learning_rate_init': 0.08594356393625106, 'tol': 0.045957348414413283, 'validation_fraction': 0.3342652059950056, 'beta_1': 0.573926950470276, 'beta_2': 0.9971251873563918, 'epsilon': 3.835731635146067e-08}
observation time 0.001980, current best 3050.603352 at iter 6
suggestion time taken 0.005036 iter 7 next_points [{'hidden_layer_sizes': 142, 'alpha': 9.009455411356345, 'batch_size': 141, 'learning_rate_init': 0.06328195414636954, 'tol': 0.09042222001854909, 'validation_fraction': 0.11406214571966977, 'beta_1': 0.6027033780193836, 'beta_2': 0.9223085542956244, 'epsilon': 1.5656946375561153e-07}]
function_evaluation time 0.142015 value 3242.446865 suggestion {'hidden_layer_sizes': 142, 'alpha': 9.009455411356345, 'batch_size': 141, 'learning_rate_init': 0.06328195414636954, 'tol': 0.09042222001854909, 'validation_fraction': 0.11406214571966977, 'beta_1': 0.6027033780193836, 'beta_2': 0.9223085542956244, 'epsilon': 1.5656946375561153e-07}
observation time 0.001864, current best 3050.603352 at iter 7
suggestion time taken 0.005104 iter 8 next_points [{'hidden_layer_sizes': 172, 'alpha': 0.8597408997660202, 'batch_size': 243, 'learning_rate_init': 0.04449008140751281, 'tol': 0.09036745477432888, 'validation_fraction': 0.49475507632651683, 'beta_1': 0.7393895215685153, 'beta_2': 0.9393403737223358, 'epsilon': 1.731892084471932e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.173357 value 3772.659485 suggestion {'hidden_layer_sizes': 172, 'alpha': 0.8597408997660202, 'batch_size': 243, 'learning_rate_init': 0.04449008140751281, 'tol': 0.09036745477432888, 'validation_fraction': 0.49475507632651683, 'beta_1': 0.7393895215685153, 'beta_2': 0.9393403737223358, 'epsilon': 1.731892084471932e-07}
observation time 0.001887, current best 3050.603352 at iter 8
suggestion time taken 0.005024 iter 9 next_points [{'hidden_layer_sizes': 155, 'alpha': 2.4086851019993647, 'batch_size': 24, 'learning_rate_init': 0.061994387036460034, 'tol': 0.005026617976382642, 'validation_fraction': 0.3326284439668099, 'beta_1': 0.5075146808147213, 'beta_2': 0.9226054850053865, 'epsilon': 1.1027152441693944e-08}]
function_evaluation time 0.295755 value 2917.691777 suggestion {'hidden_layer_sizes': 155, 'alpha': 2.4086851019993647, 'batch_size': 24, 'learning_rate_init': 0.061994387036460034, 'tol': 0.005026617976382642, 'validation_fraction': 0.3326284439668099, 'beta_1': 0.5075146808147213, 'beta_2': 0.9226054850053865, 'epsilon': 1.1027152441693944e-08}
observation time 0.001976, current best 2917.691777 at iter 9
suggestion time taken 0.005104 iter 10 next_points [{'hidden_layer_sizes': 121, 'alpha': 7.4030023870208534, 'batch_size': 247, 'learning_rate_init': 3.953990242460236e-05, 'tol': 0.0624904473276388, 'validation_fraction': 0.7923276334838074, 'beta_1': 0.573709839328674, 'beta_2': 0.9671805814024546, 'epsilon': 2.683086603177666e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.052128 value 29045.146341 suggestion {'hidden_layer_sizes': 121, 'alpha': 7.4030023870208534, 'batch_size': 247, 'learning_rate_init': 3.953990242460236e-05, 'tol': 0.0624904473276388, 'validation_fraction': 0.7923276334838074, 'beta_1': 0.573709839328674, 'beta_2': 0.9671805814024546, 'epsilon': 2.683086603177666e-07}
observation time 0.001864, current best 2917.691777 at iter 10
suggestion time taken 0.005099 iter 11 next_points [{'hidden_layer_sizes': 103, 'alpha': 6.959078021254443, 'batch_size': 18, 'learning_rate_init': 0.01639428004202308, 'tol': 0.03749784342253031, 'validation_fraction': 0.15593453000954885, 'beta_1': 0.8208815039826998, 'beta_2': 0.996673130960093, 'epsilon': 2.217241802665294e-07}]
function_evaluation time 0.208364 value 3473.873321 suggestion {'hidden_layer_sizes': 103, 'alpha': 6.959078021254443, 'batch_size': 18, 'learning_rate_init': 0.01639428004202308, 'tol': 0.03749784342253031, 'validation_fraction': 0.15593453000954885, 'beta_1': 0.8208815039826998, 'beta_2': 0.996673130960093, 'epsilon': 2.217241802665294e-07}
observation time 0.001864, current best 2917.691777 at iter 11
suggestion time taken 0.005111 iter 12 next_points [{'hidden_layer_sizes': 57, 'alpha': 0.01475969475867316, 'batch_size': 62, 'learning_rate_init': 0.003494464447647495, 'tol': 0.0781905049242985, 'validation_fraction': 0.5598638211226102, 'beta_1': 0.9740551837119028, 'beta_2': 0.9807398182802339, 'epsilon': 1.7284886003107635e-07}]
function_evaluation time 0.047495 value 28950.169026 suggestion {'hidden_layer_sizes': 57, 'alpha': 0.01475969475867316, 'batch_size': 62, 'learning_rate_init': 0.003494464447647495, 'tol': 0.0781905049242985, 'validation_fraction': 0.5598638211226102, 'beta_1': 0.9740551837119028, 'beta_2': 0.9807398182802339, 'epsilon': 1.7284886003107635e-07}
observation time 0.002748, current best 2917.691777 at iter 12
suggestion time taken 0.005045 iter 13 next_points [{'hidden_layer_sizes': 71, 'alpha': 2.4411064573797465, 'batch_size': 192, 'learning_rate_init': 0.0650787967678254, 'tol': 0.004304260871239963, 'validation_fraction': 0.5721044726460508, 'beta_1': 0.7820987777608895, 'beta_2': 0.959500708143391, 'epsilon': 1.3296789194758196e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.191869 value 3381.685874 suggestion {'hidden_layer_sizes': 71, 'alpha': 2.4411064573797465, 'batch_size': 192, 'learning_rate_init': 0.0650787967678254, 'tol': 0.004304260871239963, 'validation_fraction': 0.5721044726460508, 'beta_1': 0.7820987777608895, 'beta_2': 0.959500708143391, 'epsilon': 1.3296789194758196e-07}
observation time 0.002153, current best 2917.691777 at iter 13
suggestion time taken 0.005316 iter 14 next_points [{'hidden_layer_sizes': 196, 'alpha': 6.623120376334655, 'batch_size': 190, 'learning_rate_init': 0.07403236762983727, 'tol': 0.03376978684992687, 'validation_fraction': 0.7789429037412978, 'beta_1': 0.5330377473103912, 'beta_2': 0.9477507676059299, 'epsilon': 9.315924439928503e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.123336 value 3412.796696 suggestion {'hidden_layer_sizes': 196, 'alpha': 6.623120376334655, 'batch_size': 190, 'learning_rate_init': 0.07403236762983727, 'tol': 0.03376978684992687, 'validation_fraction': 0.7789429037412978, 'beta_1': 0.5330377473103912, 'beta_2': 0.9477507676059299, 'epsilon': 9.315924439928503e-07}
observation time 0.001901, current best 2917.691777 at iter 14
saving meta data: {'args': {'--uuid': 'b6a5275fa6445290a5dcc849498a3be1', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

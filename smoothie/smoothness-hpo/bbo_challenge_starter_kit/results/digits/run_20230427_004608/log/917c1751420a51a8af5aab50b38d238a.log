running: {'--uuid': '917c1751420a51a8af5aab50b38d238a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d diabetes -o random-search -u 917c1751420a51a8af5aab50b38d238a -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230427_004608
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study random-search MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002876 iter 0 next_points [{'alpha': 0.003917651023413784, 'batch_size': 211, 'beta_1': 0.814313526909902, 'beta_2': 0.99996675385854, 'epsilon': 1.1155409240725484e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 3.704549251835109e-05, 'tol': 0.04462667345112299, 'validation_fraction': 0.11820582318587286}]
function_evaluation time 0.073025 value 151.518492 suggestion {'alpha': 0.003917651023413784, 'batch_size': 211, 'beta_1': 0.814313526909902, 'beta_2': 0.99996675385854, 'epsilon': 1.1155409240725484e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 3.704549251835109e-05, 'tol': 0.04462667345112299, 'validation_fraction': 0.11820582318587286}
observation time 0.000006, current best 151.518492 at iter 0
suggestion time taken 0.002521 iter 1 next_points [{'alpha': 0.15123986186756957, 'batch_size': 204, 'beta_1': 0.9331652153034994, 'beta_2': 0.9999975751520386, 'epsilon': 2.272507419772352e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.004545574976763724, 'tol': 1.782178701362657e-05, 'validation_fraction': 0.558071776168704}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.955388 value 57.161293 suggestion {'alpha': 0.15123986186756957, 'batch_size': 204, 'beta_1': 0.9331652153034994, 'beta_2': 0.9999975751520386, 'epsilon': 2.272507419772352e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.004545574976763724, 'tol': 1.782178701362657e-05, 'validation_fraction': 0.558071776168704}
observation time 0.000004, current best 57.161293 at iter 1
suggestion time taken 0.002558 iter 2 next_points [{'alpha': 0.0010582372215698999, 'batch_size': 210, 'beta_1': 0.9019195310019872, 'beta_2': 0.9981721770439436, 'epsilon': 4.641299976991519e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.000791379131078242, 'tol': 0.05967584244768409, 'validation_fraction': 0.26421159782065423}]
function_evaluation time 0.053389 value 151.550390 suggestion {'alpha': 0.0010582372215698999, 'batch_size': 210, 'beta_1': 0.9019195310019872, 'beta_2': 0.9981721770439436, 'epsilon': 4.641299976991519e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.000791379131078242, 'tol': 0.05967584244768409, 'validation_fraction': 0.26421159782065423}
observation time 0.000005, current best 57.161293 at iter 2
suggestion time taken 0.002457 iter 3 next_points [{'alpha': 0.0011863626563369972, 'batch_size': 110, 'beta_1': 0.5960966627193506, 'beta_2': 0.9999986565241602, 'epsilon': 1.92632082546548e-09, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0001927219929602941, 'tol': 0.0044152065059338925, 'validation_fraction': 0.39813770308114527}]
function_evaluation time 0.083444 value 151.426935 suggestion {'alpha': 0.0011863626563369972, 'batch_size': 110, 'beta_1': 0.5960966627193506, 'beta_2': 0.9999986565241602, 'epsilon': 1.92632082546548e-09, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0001927219929602941, 'tol': 0.0044152065059338925, 'validation_fraction': 0.39813770308114527}
observation time 0.000005, current best 57.161293 at iter 3
suggestion time taken 0.002709 iter 4 next_points [{'alpha': 0.00266856202999515, 'batch_size': 137, 'beta_1': 0.6824119284026734, 'beta_2': 0.9993757631213571, 'epsilon': 2.0382225947672557e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 1.3132499010246463e-05, 'tol': 0.00011859203861432688, 'validation_fraction': 0.4635657989982036}]
function_evaluation time 0.046973 value 151.631067 suggestion {'alpha': 0.00266856202999515, 'batch_size': 137, 'beta_1': 0.6824119284026734, 'beta_2': 0.9993757631213571, 'epsilon': 2.0382225947672557e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 1.3132499010246463e-05, 'tol': 0.00011859203861432688, 'validation_fraction': 0.4635657989982036}
observation time 0.000004, current best 57.161293 at iter 4
suggestion time taken 0.002520 iter 5 next_points [{'alpha': 0.003772634382143577, 'batch_size': 191, 'beta_1': 0.9387701668396647, 'beta_2': 0.9999895180505874, 'epsilon': 1.0142249159512162e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.01729033328208663, 'tol': 0.00406766419767529, 'validation_fraction': 0.49240112445819734}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.419064 value 53.506574 suggestion {'alpha': 0.003772634382143577, 'batch_size': 191, 'beta_1': 0.9387701668396647, 'beta_2': 0.9999895180505874, 'epsilon': 1.0142249159512162e-08, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.01729033328208663, 'tol': 0.00406766419767529, 'validation_fraction': 0.49240112445819734}
observation time 0.000005, current best 53.506574 at iter 5
suggestion time taken 0.002461 iter 6 next_points [{'alpha': 1.0849825764920673, 'batch_size': 168, 'beta_1': 0.9870580345620853, 'beta_2': 0.9757587216303476, 'epsilon': 3.879382671213901e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 1.123939151048522e-05, 'tol': 2.2286762903245988e-05, 'validation_fraction': 0.3545061113487776}]
function_evaluation time 0.073654 value 151.647773 suggestion {'alpha': 1.0849825764920673, 'batch_size': 168, 'beta_1': 0.9870580345620853, 'beta_2': 0.9757587216303476, 'epsilon': 3.879382671213901e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 1.123939151048522e-05, 'tol': 2.2286762903245988e-05, 'validation_fraction': 0.3545061113487776}
observation time 0.000004, current best 53.506574 at iter 6
suggestion time taken 0.002519 iter 7 next_points [{'alpha': 0.3569273835223429, 'batch_size': 105, 'beta_1': 0.9627588492260308, 'beta_2': 0.9918391776060806, 'epsilon': 3.5896420825544365e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.021364753170977965, 'tol': 0.0008765581224448351, 'validation_fraction': 0.23555266376133124}]
function_evaluation time 0.348047 value 56.892972 suggestion {'alpha': 0.3569273835223429, 'batch_size': 105, 'beta_1': 0.9627588492260308, 'beta_2': 0.9918391776060806, 'epsilon': 3.5896420825544365e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.021364753170977965, 'tol': 0.0008765581224448351, 'validation_fraction': 0.23555266376133124}
observation time 0.000004, current best 53.506574 at iter 7
suggestion time taken 0.002750 iter 8 next_points [{'alpha': 5.714262166834522, 'batch_size': 240, 'beta_1': 0.929313580070436, 'beta_2': 0.9999578172775997, 'epsilon': 9.049922447282658e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 3.251042910936374e-05, 'tol': 0.0004554146592048259, 'validation_fraction': 0.6919811027320592}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.051571 value 151.511630 suggestion {'alpha': 5.714262166834522, 'batch_size': 240, 'beta_1': 0.929313580070436, 'beta_2': 0.9999578172775997, 'epsilon': 9.049922447282658e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 3.251042910936374e-05, 'tol': 0.0004554146592048259, 'validation_fraction': 0.6919811027320592}
observation time 0.000004, current best 53.506574 at iter 8
suggestion time taken 0.002462 iter 9 next_points [{'alpha': 1.0175637082121634e-05, 'batch_size': 189, 'beta_1': 0.7717474789748764, 'beta_2': 0.9643428439200924, 'epsilon': 1.9521043583262513e-07, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.0008815687925456513, 'tol': 0.012533888301753593, 'validation_fraction': 0.7426243860782943}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.058183 value 151.235168 suggestion {'alpha': 1.0175637082121634e-05, 'batch_size': 189, 'beta_1': 0.7717474789748764, 'beta_2': 0.9643428439200924, 'epsilon': 1.9521043583262513e-07, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.0008815687925456513, 'tol': 0.012533888301753593, 'validation_fraction': 0.7426243860782943}
observation time 0.000005, current best 53.506574 at iter 9
suggestion time taken 0.002474 iter 10 next_points [{'alpha': 0.00393547996995452, 'batch_size': 217, 'beta_1': 0.9420965238570608, 'beta_2': 0.9999977232911121, 'epsilon': 3.5207587308628495e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.00766176152177389, 'tol': 0.0037016615633699065, 'validation_fraction': 0.7686170899904784}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.406771 value 84.082540 suggestion {'alpha': 0.00393547996995452, 'batch_size': 217, 'beta_1': 0.9420965238570608, 'beta_2': 0.9999977232911121, 'epsilon': 3.5207587308628495e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.00766176152177389, 'tol': 0.0037016615633699065, 'validation_fraction': 0.7686170899904784}
observation time 0.000005, current best 53.506574 at iter 10
suggestion time taken 0.002403 iter 11 next_points [{'alpha': 8.36567286123741e-05, 'batch_size': 21, 'beta_1': 0.6434322030783622, 'beta_2': 0.9998653724658736, 'epsilon': 1.7398812560048213e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.01495099827227498, 'tol': 0.0006155194455098761, 'validation_fraction': 0.17116473922378256}]
function_evaluation time 0.598638 value 43.877014 suggestion {'alpha': 8.36567286123741e-05, 'batch_size': 21, 'beta_1': 0.6434322030783622, 'beta_2': 0.9998653724658736, 'epsilon': 1.7398812560048213e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.01495099827227498, 'tol': 0.0006155194455098761, 'validation_fraction': 0.17116473922378256}
observation time 0.000005, current best 43.877014 at iter 11
suggestion time taken 0.002501 iter 12 next_points [{'alpha': 3.652386201609304e-05, 'batch_size': 98, 'beta_1': 0.8634869873285278, 'beta_2': 0.9932425594180428, 'epsilon': 5.896311172908362e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.06249136451044409, 'tol': 0.0001080342433811558, 'validation_fraction': 0.3801996928972506}]
function_evaluation time 0.511582 value 44.960693 suggestion {'alpha': 3.652386201609304e-05, 'batch_size': 98, 'beta_1': 0.8634869873285278, 'beta_2': 0.9932425594180428, 'epsilon': 5.896311172908362e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.06249136451044409, 'tol': 0.0001080342433811558, 'validation_fraction': 0.3801996928972506}
observation time 0.000004, current best 43.877014 at iter 12
suggestion time taken 0.002507 iter 13 next_points [{'alpha': 0.0005590571619445187, 'batch_size': 210, 'beta_1': 0.9384211330695391, 'beta_2': 0.9999978009623972, 'epsilon': 7.608091658477779e-08, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.0009534502588688487, 'tol': 0.009923177385177423, 'validation_fraction': 0.2973983290021734}]
function_evaluation time 0.062615 value 151.483736 suggestion {'alpha': 0.0005590571619445187, 'batch_size': 210, 'beta_1': 0.9384211330695391, 'beta_2': 0.9999978009623972, 'epsilon': 7.608091658477779e-08, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.0009534502588688487, 'tol': 0.009923177385177423, 'validation_fraction': 0.2973983290021734}
observation time 0.000004, current best 43.877014 at iter 13
suggestion time taken 0.002477 iter 14 next_points [{'alpha': 1.922438051428889e-05, 'batch_size': 66, 'beta_1': 0.8634873565948993, 'beta_2': 0.9999793746934832, 'epsilon': 4.7049450681387564e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.011878336348641374, 'tol': 0.0958935499451412, 'validation_fraction': 0.7943302196777208}]
function_evaluation time 0.045172 value 150.047939 suggestion {'alpha': 1.922438051428889e-05, 'batch_size': 66, 'beta_1': 0.8634873565948993, 'beta_2': 0.9999793746934832, 'epsilon': 4.7049450681387564e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.011878336348641374, 'tol': 0.0958935499451412, 'validation_fraction': 0.7943302196777208}
observation time 0.000004, current best 43.877014 at iter 14
saving meta data: {'args': {'--uuid': '917c1751420a51a8af5aab50b38d238a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

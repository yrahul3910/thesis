running: {'--uuid': '1afd287eeaea5efbb316861509b4315b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d diabetes -o hyperopt -u 1afd287eeaea5efbb316861509b4315b -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230427_004608
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study hyperopt MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002433 iter 0 next_points [{'alpha': 4.9257456829458904e-05, 'batch_size': 241, 'beta_1': 0.8465387532809516, 'beta_2': 0.9644112342790545, 'epsilon': 5.463518958420968e-09, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.07784377852139944, 'tol': 1.3585858307429912e-05, 'validation_fraction': 0.43215964596751383}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.403745 value 44.931601 suggestion {'alpha': 4.9257456829458904e-05, 'batch_size': 241, 'beta_1': 0.8465387532809516, 'beta_2': 0.9644112342790545, 'epsilon': 5.463518958420968e-09, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.07784377852139944, 'tol': 1.3585858307429912e-05, 'validation_fraction': 0.43215964596751383}
observation time 0.000072, current best 44.931601 at iter 0
suggestion time taken 0.002421 iter 1 next_points [{'alpha': 4.503869405994578e-05, 'batch_size': 197, 'beta_1': 0.7853300373585184, 'beta_2': 0.9221377002072251, 'epsilon': 9.520132696413578e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 2.7495880237411315e-05, 'tol': 0.03648580960168438, 'validation_fraction': 0.19091822884640489}]
function_evaluation time 0.075339 value 151.624138 suggestion {'alpha': 4.503869405994578e-05, 'batch_size': 197, 'beta_1': 0.7853300373585184, 'beta_2': 0.9221377002072251, 'epsilon': 9.520132696413578e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 2.7495880237411315e-05, 'tol': 0.03648580960168438, 'validation_fraction': 0.19091822884640489}
observation time 0.000069, current best 44.931601 at iter 1
suggestion time taken 0.002110 iter 2 next_points [{'alpha': 0.0002985198583701203, 'batch_size': 53, 'beta_1': 0.7891893496514601, 'beta_2': 0.9513516203527252, 'epsilon': 1.3195253692239145e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.000800648756531976, 'tol': 0.0006691316110464082, 'validation_fraction': 0.10132798227744658}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.042540 value 129.276522 suggestion {'alpha': 0.0002985198583701203, 'batch_size': 53, 'beta_1': 0.7891893496514601, 'beta_2': 0.9513516203527252, 'epsilon': 1.3195253692239145e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.000800648756531976, 'tol': 0.0006691316110464082, 'validation_fraction': 0.10132798227744658}
observation time 0.000072, current best 44.931601 at iter 2
suggestion time taken 0.002138 iter 3 next_points [{'alpha': 6.126359971640504, 'batch_size': 102, 'beta_1': 0.533161879529835, 'beta_2': 0.9587189024951368, 'epsilon': 6.500442051223192e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 1.6715805412447373e-05, 'tol': 1.4246980330037233e-05, 'validation_fraction': 0.41928225004175346}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.685534 value 151.542949 suggestion {'alpha': 6.126359971640504, 'batch_size': 102, 'beta_1': 0.533161879529835, 'beta_2': 0.9587189024951368, 'epsilon': 6.500442051223192e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 1.6715805412447373e-05, 'tol': 1.4246980330037233e-05, 'validation_fraction': 0.41928225004175346}
observation time 0.000070, current best 44.931601 at iter 3
suggestion time taken 0.002160 iter 4 next_points [{'alpha': 0.7437297082194192, 'batch_size': 24, 'beta_1': 0.7527483122447864, 'beta_2': 0.9821262331532751, 'epsilon': 8.136166198723485e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.07936377975851171, 'tol': 0.002666703759918483, 'validation_fraction': 0.11017914712707556}]
function_evaluation time 0.337290 value 43.760182 suggestion {'alpha': 0.7437297082194192, 'batch_size': 24, 'beta_1': 0.7527483122447864, 'beta_2': 0.9821262331532751, 'epsilon': 8.136166198723485e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.07936377975851171, 'tol': 0.002666703759918483, 'validation_fraction': 0.11017914712707556}
observation time 0.000072, current best 43.760182 at iter 4
suggestion time taken 0.002143 iter 5 next_points [{'alpha': 5.448791572574246, 'batch_size': 233, 'beta_1': 0.7326557729621284, 'beta_2': 0.9792340465793867, 'epsilon': 6.410653477890423e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0001164817992477596, 'tol': 0.028702103279638784, 'validation_fraction': 0.35139366427744506}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.054748 value 151.574564 suggestion {'alpha': 5.448791572574246, 'batch_size': 233, 'beta_1': 0.7326557729621284, 'beta_2': 0.9792340465793867, 'epsilon': 6.410653477890423e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0001164817992477596, 'tol': 0.028702103279638784, 'validation_fraction': 0.35139366427744506}
observation time 0.000072, current best 43.760182 at iter 5
suggestion time taken 0.002406 iter 6 next_points [{'alpha': 0.06222862739981561, 'batch_size': 49, 'beta_1': 0.5118274525631171, 'beta_2': 0.952225539733038, 'epsilon': 2.1953482045089956e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.0006122201153387516, 'tol': 0.03574959860013495, 'validation_fraction': 0.8569335864685398}]
function_evaluation time 0.051906 value 151.333598 suggestion {'alpha': 0.06222862739981561, 'batch_size': 49, 'beta_1': 0.5118274525631171, 'beta_2': 0.952225539733038, 'epsilon': 2.1953482045089956e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.0006122201153387516, 'tol': 0.03574959860013495, 'validation_fraction': 0.8569335864685398}
observation time 0.000066, current best 43.760182 at iter 6
suggestion time taken 0.002398 iter 7 next_points [{'alpha': 0.0012307867864948673, 'batch_size': 203, 'beta_1': 0.5111804991487496, 'beta_2': 0.9265848572036078, 'epsilon': 2.433315561405675e-08, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0036291745678916627, 'tol': 0.0001760519810193815, 'validation_fraction': 0.764448966805041}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.572652 value 129.671689 suggestion {'alpha': 0.0012307867864948673, 'batch_size': 203, 'beta_1': 0.5111804991487496, 'beta_2': 0.9265848572036078, 'epsilon': 2.433315561405675e-08, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0036291745678916627, 'tol': 0.0001760519810193815, 'validation_fraction': 0.764448966805041}
observation time 0.000074, current best 43.760182 at iter 7
suggestion time taken 0.002161 iter 8 next_points [{'alpha': 0.00036982144744762246, 'batch_size': 25, 'beta_1': 0.7900567931011013, 'beta_2': 0.9818395226446889, 'epsilon': 1.0457470075571747e-08, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.026981817929519925, 'tol': 0.00010726627793530833, 'validation_fraction': 0.320979646881146}]
function_evaluation time 0.529384 value 43.919635 suggestion {'alpha': 0.00036982144744762246, 'batch_size': 25, 'beta_1': 0.7900567931011013, 'beta_2': 0.9818395226446889, 'epsilon': 1.0457470075571747e-08, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.026981817929519925, 'tol': 0.00010726627793530833, 'validation_fraction': 0.320979646881146}
observation time 0.000068, current best 43.760182 at iter 8
suggestion time taken 0.002145 iter 9 next_points [{'alpha': 0.0008015539107193607, 'batch_size': 142, 'beta_1': 0.8768667263317017, 'beta_2': 0.9688561407940052, 'epsilon': 1.4458662900968796e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0706662825535628, 'tol': 0.0018813123352912774, 'validation_fraction': 0.17661309126625832}]
function_evaluation time 0.254771 value 45.806495 suggestion {'alpha': 0.0008015539107193607, 'batch_size': 142, 'beta_1': 0.8768667263317017, 'beta_2': 0.9688561407940052, 'epsilon': 1.4458662900968796e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0706662825535628, 'tol': 0.0018813123352912774, 'validation_fraction': 0.17661309126625832}
observation time 0.000074, current best 43.760182 at iter 9
suggestion time taken 0.002328 iter 10 next_points [{'alpha': 0.08672953932804056, 'batch_size': 225, 'beta_1': 0.7763496658357272, 'beta_2': 0.9026959828981456, 'epsilon': 3.135889956900629e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 2.2638899943561796e-05, 'tol': 0.01480644075076497, 'validation_fraction': 0.5487768481080085}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.055085 value 151.593443 suggestion {'alpha': 0.08672953932804056, 'batch_size': 225, 'beta_1': 0.7763496658357272, 'beta_2': 0.9026959828981456, 'epsilon': 3.135889956900629e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 2.2638899943561796e-05, 'tol': 0.01480644075076497, 'validation_fraction': 0.5487768481080085}
observation time 0.000062, current best 43.760182 at iter 10
suggestion time taken 0.002138 iter 11 next_points [{'alpha': 0.003931223636371555, 'batch_size': 13, 'beta_1': 0.5027340395496904, 'beta_2': 0.9165682175487422, 'epsilon': 1.4273601279855188e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.0003772045848149562, 'tol': 0.028275483585637855, 'validation_fraction': 0.13419622463379927}]
function_evaluation time 0.288364 value 149.879746 suggestion {'alpha': 0.003931223636371555, 'batch_size': 13, 'beta_1': 0.5027340395496904, 'beta_2': 0.9165682175487422, 'epsilon': 1.4273601279855188e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.0003772045848149562, 'tol': 0.028275483585637855, 'validation_fraction': 0.13419622463379927}
observation time 0.000076, current best 43.760182 at iter 11
suggestion time taken 0.002425 iter 12 next_points [{'alpha': 0.12380238274916977, 'batch_size': 94, 'beta_1': 0.767188814803749, 'beta_2': 0.9231180860447936, 'epsilon': 2.7562033629262074e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.0006823544549813851, 'tol': 0.0009196381295369092, 'validation_fraction': 0.7360218915317893}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.060520 value 151.400334 suggestion {'alpha': 0.12380238274916977, 'batch_size': 94, 'beta_1': 0.767188814803749, 'beta_2': 0.9231180860447936, 'epsilon': 2.7562033629262074e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.0006823544549813851, 'tol': 0.0009196381295369092, 'validation_fraction': 0.7360218915317893}
observation time 0.000070, current best 43.760182 at iter 12
suggestion time taken 0.002195 iter 13 next_points [{'alpha': 0.10426842251907628, 'batch_size': 12, 'beta_1': 0.925231162766565, 'beta_2': 0.9563860574012089, 'epsilon': 3.560903877729919e-09, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.0018998006669034566, 'tol': 0.00014985678193779028, 'validation_fraction': 0.6365598386589049}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 2.786904 value 46.731324 suggestion {'alpha': 0.10426842251907628, 'batch_size': 12, 'beta_1': 0.925231162766565, 'beta_2': 0.9563860574012089, 'epsilon': 3.560903877729919e-09, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.0018998006669034566, 'tol': 0.00014985678193779028, 'validation_fraction': 0.6365598386589049}
observation time 0.000069, current best 43.760182 at iter 13
suggestion time taken 0.002110 iter 14 next_points [{'alpha': 7.809170727951919, 'batch_size': 163, 'beta_1': 0.5149289154883466, 'beta_2': 0.9471778412930253, 'epsilon': 2.94965052052929e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.00019067933746611242, 'tol': 0.004028168801268444, 'validation_fraction': 0.5598136833329673}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.056383 value 151.491843 suggestion {'alpha': 7.809170727951919, 'batch_size': 163, 'beta_1': 0.5149289154883466, 'beta_2': 0.9471778412930253, 'epsilon': 2.94965052052929e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.00019067933746611242, 'tol': 0.004028168801268444, 'validation_fraction': 0.5598136833329673}
observation time 0.000076, current best 43.760182 at iter 14
saving meta data: {'args': {'--uuid': '1afd287eeaea5efbb316861509b4315b', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

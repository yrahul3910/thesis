running: {'--uuid': '5af24556f03151a2bdbf1cb455942e2a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python random-search/optimizer.py -c MLP-adam -d diabetes -o random-search -u 5af24556f03151a2bdbf1cb455942e2a -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230427_004608
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study random-search MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002513 iter 0 next_points [{'alpha': 0.06570428379197783, 'batch_size': 237, 'beta_1': 0.9734144150431334, 'beta_2': 0.9988462516477523, 'epsilon': 8.901149765447362e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0006003820145544948, 'tol': 6.978015162387472e-05, 'validation_fraction': 0.6869023045580099}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.852953 value 148.860607 suggestion {'alpha': 0.06570428379197783, 'batch_size': 237, 'beta_1': 0.9734144150431334, 'beta_2': 0.9988462516477523, 'epsilon': 8.901149765447362e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0006003820145544948, 'tol': 6.978015162387472e-05, 'validation_fraction': 0.6869023045580099}
observation time 0.000013, current best 148.860607 at iter 0
suggestion time taken 0.002504 iter 1 next_points [{'alpha': 0.05315657555276112, 'batch_size': 123, 'beta_1': 0.5757059843758027, 'beta_2': 0.9999387140647895, 'epsilon': 2.2030070084922804e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.03748921367671729, 'tol': 0.0018721747066810885, 'validation_fraction': 0.2048243321522455}]
function_evaluation time 0.225165 value 45.304834 suggestion {'alpha': 0.05315657555276112, 'batch_size': 123, 'beta_1': 0.5757059843758027, 'beta_2': 0.9999387140647895, 'epsilon': 2.2030070084922804e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.03748921367671729, 'tol': 0.0018721747066810885, 'validation_fraction': 0.2048243321522455}
observation time 0.000004, current best 45.304834 at iter 1
suggestion time taken 0.002774 iter 2 next_points [{'alpha': 0.06317425935109586, 'batch_size': 234, 'beta_1': 0.5598028142909287, 'beta_2': 0.9795621937431523, 'epsilon': 3.1460203429844173e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.009853719830528804, 'tol': 0.00015845001033212966, 'validation_fraction': 0.19594633166055866}]
function_evaluation time 1.067490 value 48.200712 suggestion {'alpha': 0.06317425935109586, 'batch_size': 234, 'beta_1': 0.5598028142909287, 'beta_2': 0.9795621937431523, 'epsilon': 3.1460203429844173e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.009853719830528804, 'tol': 0.00015845001033212966, 'validation_fraction': 0.19594633166055866}
observation time 0.000005, current best 45.304834 at iter 2
suggestion time taken 0.002490 iter 3 next_points [{'alpha': 0.04794170180218692, 'batch_size': 186, 'beta_1': 0.964920146606222, 'beta_2': 0.9570759731631784, 'epsilon': 2.1178751476872674e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.09576555801629864, 'tol': 0.000168734121771656, 'validation_fraction': 0.4800458909414519}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.134526 value 54.540559 suggestion {'alpha': 0.04794170180218692, 'batch_size': 186, 'beta_1': 0.964920146606222, 'beta_2': 0.9570759731631784, 'epsilon': 2.1178751476872674e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.09576555801629864, 'tol': 0.000168734121771656, 'validation_fraction': 0.4800458909414519}
observation time 0.000004, current best 45.304834 at iter 3
suggestion time taken 0.002475 iter 4 next_points [{'alpha': 0.9330787622745126, 'batch_size': 198, 'beta_1': 0.6383125173245856, 'beta_2': 0.9999308131753476, 'epsilon': 4.9922382358369515e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.0030671733014214797, 'tol': 0.0002621439685745534, 'validation_fraction': 0.10511033876906106}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.237060 value 52.907026 suggestion {'alpha': 0.9330787622745126, 'batch_size': 198, 'beta_1': 0.6383125173245856, 'beta_2': 0.9999308131753476, 'epsilon': 4.9922382358369515e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.0030671733014214797, 'tol': 0.0002621439685745534, 'validation_fraction': 0.10511033876906106}
observation time 0.000004, current best 45.304834 at iter 4
suggestion time taken 0.002781 iter 5 next_points [{'alpha': 0.06087947132405119, 'batch_size': 140, 'beta_1': 0.7869030262820812, 'beta_2': 0.9998640047675066, 'epsilon': 3.31833270074699e-07, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.04692233149711358, 'tol': 0.0024691218867775823, 'validation_fraction': 0.6337123160734671}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.281531 value 45.217535 suggestion {'alpha': 0.06087947132405119, 'batch_size': 140, 'beta_1': 0.7869030262820812, 'beta_2': 0.9998640047675066, 'epsilon': 3.31833270074699e-07, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.04692233149711358, 'tol': 0.0024691218867775823, 'validation_fraction': 0.6337123160734671}
observation time 0.000004, current best 45.217535 at iter 5
suggestion time taken 0.002736 iter 6 next_points [{'alpha': 3.2151935211681064e-05, 'batch_size': 90, 'beta_1': 0.8288382332729072, 'beta_2': 0.996322257038769, 'epsilon': 1.0831272434882218e-09, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.052873159286060345, 'tol': 0.0026270998431842984, 'validation_fraction': 0.5288150638351145}]
function_evaluation time 0.254407 value 44.604324 suggestion {'alpha': 3.2151935211681064e-05, 'batch_size': 90, 'beta_1': 0.8288382332729072, 'beta_2': 0.996322257038769, 'epsilon': 1.0831272434882218e-09, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.052873159286060345, 'tol': 0.0026270998431842984, 'validation_fraction': 0.5288150638351145}
observation time 0.000004, current best 44.604324 at iter 6
suggestion time taken 0.002505 iter 7 next_points [{'alpha': 0.005558959296926199, 'batch_size': 70, 'beta_1': 0.6779224546543567, 'beta_2': 0.9636083119151939, 'epsilon': 2.983340042936221e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.001806975502684223, 'tol': 6.160689355997296e-05, 'validation_fraction': 0.8311377797401877}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.731727 value 136.717877 suggestion {'alpha': 0.005558959296926199, 'batch_size': 70, 'beta_1': 0.6779224546543567, 'beta_2': 0.9636083119151939, 'epsilon': 2.983340042936221e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.001806975502684223, 'tol': 6.160689355997296e-05, 'validation_fraction': 0.8311377797401877}
observation time 0.000004, current best 44.604324 at iter 7
suggestion time taken 0.002728 iter 8 next_points [{'alpha': 0.000986939799190209, 'batch_size': 153, 'beta_1': 0.8717856702017667, 'beta_2': 0.9208282818789004, 'epsilon': 2.785624710967039e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 7.890516249138285e-05, 'tol': 0.00042500089120498874, 'validation_fraction': 0.6017605028936239}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.051387 value 151.615365 suggestion {'alpha': 0.000986939799190209, 'batch_size': 153, 'beta_1': 0.8717856702017667, 'beta_2': 0.9208282818789004, 'epsilon': 2.785624710967039e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 7.890516249138285e-05, 'tol': 0.00042500089120498874, 'validation_fraction': 0.6017605028936239}
observation time 0.000004, current best 44.604324 at iter 8
suggestion time taken 0.002505 iter 9 next_points [{'alpha': 7.303337435205584e-05, 'batch_size': 54, 'beta_1': 0.9899613372467405, 'beta_2': 0.9981604441183176, 'epsilon': 5.01934548950041e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 4.122467761582002e-05, 'tol': 0.00482179592127777, 'validation_fraction': 0.25915198551986174}]
function_evaluation time 0.120962 value 151.520697 suggestion {'alpha': 7.303337435205584e-05, 'batch_size': 54, 'beta_1': 0.9899613372467405, 'beta_2': 0.9981604441183176, 'epsilon': 5.01934548950041e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 4.122467761582002e-05, 'tol': 0.00482179592127777, 'validation_fraction': 0.25915198551986174}
observation time 0.000004, current best 44.604324 at iter 9
suggestion time taken 0.002450 iter 10 next_points [{'alpha': 0.37967607131201636, 'batch_size': 74, 'beta_1': 0.8162004927142144, 'beta_2': 0.9998758740699524, 'epsilon': 6.276035801458638e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.002514664806109217, 'tol': 0.002336577312857124, 'validation_fraction': 0.14521100177786267}]
function_evaluation time 1.198570 value 52.158930 suggestion {'alpha': 0.37967607131201636, 'batch_size': 74, 'beta_1': 0.8162004927142144, 'beta_2': 0.9998758740699524, 'epsilon': 6.276035801458638e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.002514664806109217, 'tol': 0.002336577312857124, 'validation_fraction': 0.14521100177786267}
observation time 0.000005, current best 44.604324 at iter 10
suggestion time taken 0.002724 iter 11 next_points [{'alpha': 0.0003775947412201756, 'batch_size': 162, 'beta_1': 0.7537922221061352, 'beta_2': 0.9364736665475442, 'epsilon': 4.1194067629956605e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.043585371936763935, 'tol': 0.0002497609482807944, 'validation_fraction': 0.2753231906988624}]
function_evaluation time 0.388563 value 44.330719 suggestion {'alpha': 0.0003775947412201756, 'batch_size': 162, 'beta_1': 0.7537922221061352, 'beta_2': 0.9364736665475442, 'epsilon': 4.1194067629956605e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.043585371936763935, 'tol': 0.0002497609482807944, 'validation_fraction': 0.2753231906988624}
observation time 0.000004, current best 44.330719 at iter 11
suggestion time taken 0.002457 iter 12 next_points [{'alpha': 0.4291845129056202, 'batch_size': 172, 'beta_1': 0.9862884985264092, 'beta_2': 0.9999743686408431, 'epsilon': 2.519408272807191e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 5.9737892639851935e-05, 'tol': 1.595253897954468e-05, 'validation_fraction': 0.15303574877196618}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.443310 value 151.203967 suggestion {'alpha': 0.4291845129056202, 'batch_size': 172, 'beta_1': 0.9862884985264092, 'beta_2': 0.9999743686408431, 'epsilon': 2.519408272807191e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 5.9737892639851935e-05, 'tol': 1.595253897954468e-05, 'validation_fraction': 0.15303574877196618}
observation time 0.000005, current best 44.330719 at iter 12
suggestion time taken 0.002485 iter 13 next_points [{'alpha': 0.0009612558446254162, 'batch_size': 100, 'beta_1': 0.6285265514500221, 'beta_2': 0.9999984250769759, 'epsilon': 9.256783847956179e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0011885305111544522, 'tol': 0.0028655167540996007, 'validation_fraction': 0.21307081398670719}]
function_evaluation time 0.051390 value 151.271972 suggestion {'alpha': 0.0009612558446254162, 'batch_size': 100, 'beta_1': 0.6285265514500221, 'beta_2': 0.9999984250769759, 'epsilon': 9.256783847956179e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0011885305111544522, 'tol': 0.0028655167540996007, 'validation_fraction': 0.21307081398670719}
observation time 0.000011, current best 44.330719 at iter 13
suggestion time taken 0.002459 iter 14 next_points [{'alpha': 3.656335397725178e-05, 'batch_size': 101, 'beta_1': 0.9247555122468293, 'beta_2': 0.9999817259070539, 'epsilon': 1.884676823677846e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 1.372479678873603e-05, 'tol': 0.0632348143784141, 'validation_fraction': 0.27549094826114345}]
function_evaluation time 0.087484 value 151.566687 suggestion {'alpha': 3.656335397725178e-05, 'batch_size': 101, 'beta_1': 0.9247555122468293, 'beta_2': 0.9999817259070539, 'epsilon': 1.884676823677846e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 1.372479678873603e-05, 'tol': 0.0632348143784141, 'validation_fraction': 0.27549094826114345}
observation time 0.000005, current best 44.330719 at iter 14
saving meta data: {'args': {'--uuid': '5af24556f03151a2bdbf1cb455942e2a', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230427_004608', '--opt': 'random-search', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

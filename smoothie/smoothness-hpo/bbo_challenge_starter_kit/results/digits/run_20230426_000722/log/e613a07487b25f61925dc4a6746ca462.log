running: {'--uuid': 'e613a07487b25f61925dc4a6746ca462', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d diabetes -o hyperopt -u e613a07487b25f61925dc4a6746ca462 -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_000722
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study hyperopt MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002398 iter 0 next_points [{'alpha': 2.1432176714357846e-05, 'batch_size': 189, 'beta_1': 0.6122276433215269, 'beta_2': 0.9035748648250144, 'epsilon': 5.228827491018282e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0005349994490273688, 'tol': 0.00013797069838658338, 'validation_fraction': 0.8661044390522948}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.768438 value 28382.852554 suggestion {'alpha': 2.1432176714357846e-05, 'batch_size': 189, 'beta_1': 0.6122276433215269, 'beta_2': 0.9035748648250144, 'epsilon': 5.228827491018282e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0005349994490273688, 'tol': 0.00013797069838658338, 'validation_fraction': 0.8661044390522948}
observation time 0.000073, current best 28382.852554 at iter 0
suggestion time taken 0.002455 iter 1 next_points [{'alpha': 0.00010857092142813915, 'batch_size': 60, 'beta_1': 0.7811390784645358, 'beta_2': 0.9322709642561631, 'epsilon': 3.076261894476102e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 9.885339878104756e-05, 'tol': 0.09680989354642311, 'validation_fraction': 0.13932309795947395}]
function_evaluation time 0.116434 value 29078.260170 suggestion {'alpha': 0.00010857092142813915, 'batch_size': 60, 'beta_1': 0.7811390784645358, 'beta_2': 0.9322709642561631, 'epsilon': 3.076261894476102e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 9.885339878104756e-05, 'tol': 0.09680989354642311, 'validation_fraction': 0.13932309795947395}
observation time 0.000070, current best 28382.852554 at iter 1
suggestion time taken 0.002150 iter 2 next_points [{'alpha': 0.001214846121224814, 'batch_size': 139, 'beta_1': 0.6556731701570577, 'beta_2': 0.9163351727366378, 'epsilon': 2.4079344834903524e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.038265600167846935, 'tol': 0.06882171528762925, 'validation_fraction': 0.18976306711355775}]
function_evaluation time 0.172891 value 3543.898962 suggestion {'alpha': 0.001214846121224814, 'batch_size': 139, 'beta_1': 0.6556731701570577, 'beta_2': 0.9163351727366378, 'epsilon': 2.4079344834903524e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.038265600167846935, 'tol': 0.06882171528762925, 'validation_fraction': 0.18976306711355775}
observation time 0.000066, current best 3543.898962 at iter 2
suggestion time taken 0.002379 iter 3 next_points [{'alpha': 1.6922843847634497e-05, 'batch_size': 171, 'beta_1': 0.5992876686012277, 'beta_2': 0.9073969146964804, 'epsilon': 2.338708419727082e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 1.6392667935475435e-05, 'tol': 0.0018671530173238265, 'validation_fraction': 0.5227545320454108}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.070184 value 29102.521491 suggestion {'alpha': 1.6922843847634497e-05, 'batch_size': 171, 'beta_1': 0.5992876686012277, 'beta_2': 0.9073969146964804, 'epsilon': 2.338708419727082e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 1.6392667935475435e-05, 'tol': 0.0018671530173238265, 'validation_fraction': 0.5227545320454108}
observation time 0.000071, current best 3543.898962 at iter 3
suggestion time taken 0.002161 iter 4 next_points [{'alpha': 0.06362763469887601, 'batch_size': 202, 'beta_1': 0.864955694989174, 'beta_2': 0.9920974681699686, 'epsilon': 2.7022742103203815e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 1.7011433174273266e-05, 'tol': 0.021007445316985073, 'validation_fraction': 0.2833231644352207}]
function_evaluation time 0.050526 value 29052.091926 suggestion {'alpha': 0.06362763469887601, 'batch_size': 202, 'beta_1': 0.864955694989174, 'beta_2': 0.9920974681699686, 'epsilon': 2.7022742103203815e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 1.7011433174273266e-05, 'tol': 0.021007445316985073, 'validation_fraction': 0.2833231644352207}
observation time 0.000071, current best 3543.898962 at iter 4
suggestion time taken 0.002158 iter 5 next_points [{'alpha': 0.0005205905841451969, 'batch_size': 183, 'beta_1': 0.6627977605933583, 'beta_2': 0.9304436936984747, 'epsilon': 1.7196191761432997e-09, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.0037496137244468837, 'tol': 1.2751558383898175e-05, 'validation_fraction': 0.8318308418458846}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.791016 value 12867.358999 suggestion {'alpha': 0.0005205905841451969, 'batch_size': 183, 'beta_1': 0.6627977605933583, 'beta_2': 0.9304436936984747, 'epsilon': 1.7196191761432997e-09, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.0037496137244468837, 'tol': 1.2751558383898175e-05, 'validation_fraction': 0.8318308418458846}
observation time 0.000070, current best 3543.898962 at iter 5
suggestion time taken 0.002369 iter 6 next_points [{'alpha': 0.0001875382191057287, 'batch_size': 86, 'beta_1': 0.9514156494984572, 'beta_2': 0.933804893394708, 'epsilon': 4.104921565418756e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.022024476500621698, 'tol': 0.00011837527473407661, 'validation_fraction': 0.21777253671909944}]
function_evaluation time 0.483422 value 3565.753867 suggestion {'alpha': 0.0001875382191057287, 'batch_size': 86, 'beta_1': 0.9514156494984572, 'beta_2': 0.933804893394708, 'epsilon': 4.104921565418756e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.022024476500621698, 'tol': 0.00011837527473407661, 'validation_fraction': 0.21777253671909944}
observation time 0.000066, current best 3543.898962 at iter 6
suggestion time taken 0.002171 iter 7 next_points [{'alpha': 7.336891175637539e-05, 'batch_size': 238, 'beta_1': 0.5666874563067014, 'beta_2': 0.9412653815868905, 'epsilon': 3.5676233031966696e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 1.86761108694587e-05, 'tol': 0.00041841145880702974, 'validation_fraction': 0.5800477768035524}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.053685 value 29129.525509 suggestion {'alpha': 7.336891175637539e-05, 'batch_size': 238, 'beta_1': 0.5666874563067014, 'beta_2': 0.9412653815868905, 'epsilon': 3.5676233031966696e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 1.86761108694587e-05, 'tol': 0.00041841145880702974, 'validation_fraction': 0.5800477768035524}
observation time 0.000069, current best 3543.898962 at iter 7
suggestion time taken 0.002294 iter 8 next_points [{'alpha': 0.019083931460280944, 'batch_size': 192, 'beta_1': 0.5239113829267609, 'beta_2': 0.9998916260641275, 'epsilon': 7.633825161951273e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.00017898326548828125, 'tol': 0.0040637508427987905, 'validation_fraction': 0.5463454137583217}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.054365 value 29104.240535 suggestion {'alpha': 0.019083931460280944, 'batch_size': 192, 'beta_1': 0.5239113829267609, 'beta_2': 0.9998916260641275, 'epsilon': 7.633825161951273e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.00017898326548828125, 'tol': 0.0040637508427987905, 'validation_fraction': 0.5463454137583217}
observation time 0.000072, current best 3543.898962 at iter 8
suggestion time taken 0.002118 iter 9 next_points [{'alpha': 0.004290583225668797, 'batch_size': 91, 'beta_1': 0.929930997782639, 'beta_2': 0.9770306835444412, 'epsilon': 6.605143896150205e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.007481967648418488, 'tol': 0.0012063800975584292, 'validation_fraction': 0.1544179359785236}]
function_evaluation time 0.676207 value 3572.949213 suggestion {'alpha': 0.004290583225668797, 'batch_size': 91, 'beta_1': 0.929930997782639, 'beta_2': 0.9770306835444412, 'epsilon': 6.605143896150205e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.007481967648418488, 'tol': 0.0012063800975584292, 'validation_fraction': 0.1544179359785236}
observation time 0.000070, current best 3543.898962 at iter 9
suggestion time taken 0.002364 iter 10 next_points [{'alpha': 0.01853301705837186, 'batch_size': 200, 'beta_1': 0.5190849682696914, 'beta_2': 0.9256900197467139, 'epsilon': 9.558412552060964e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 4.565105198923437e-05, 'tol': 0.00014461828943421762, 'validation_fraction': 0.23163425653948597}]
function_evaluation time 0.078087 value 29097.681506 suggestion {'alpha': 0.01853301705837186, 'batch_size': 200, 'beta_1': 0.5190849682696914, 'beta_2': 0.9256900197467139, 'epsilon': 9.558412552060964e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 4.565105198923437e-05, 'tol': 0.00014461828943421762, 'validation_fraction': 0.23163425653948597}
observation time 0.000068, current best 3543.898962 at iter 10
suggestion time taken 0.002120 iter 11 next_points [{'alpha': 0.0038574185586891896, 'batch_size': 20, 'beta_1': 0.5473151063787047, 'beta_2': 0.9649722251740155, 'epsilon': 1.3837226128080456e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.022243665919078216, 'tol': 0.026330726998183392, 'validation_fraction': 0.3245393487196841}]
function_evaluation time 0.191024 value 3335.531097 suggestion {'alpha': 0.0038574185586891896, 'batch_size': 20, 'beta_1': 0.5473151063787047, 'beta_2': 0.9649722251740155, 'epsilon': 1.3837226128080456e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.022243665919078216, 'tol': 0.026330726998183392, 'validation_fraction': 0.3245393487196841}
observation time 0.000078, current best 3335.531097 at iter 11
suggestion time taken 0.002142 iter 12 next_points [{'alpha': 0.0034575374608870136, 'batch_size': 129, 'beta_1': 0.772334710108822, 'beta_2': 0.9723354659042044, 'epsilon': 1.3793041020366726e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0020042853201952837, 'tol': 0.0007243070711700417, 'validation_fraction': 0.29336105814678587}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.223161 value 13611.666690 suggestion {'alpha': 0.0034575374608870136, 'batch_size': 129, 'beta_1': 0.772334710108822, 'beta_2': 0.9723354659042044, 'epsilon': 1.3793041020366726e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0020042853201952837, 'tol': 0.0007243070711700417, 'validation_fraction': 0.29336105814678587}
observation time 0.000075, current best 3335.531097 at iter 12
suggestion time taken 0.002215 iter 13 next_points [{'alpha': 0.0003392541195103336, 'batch_size': 98, 'beta_1': 0.7778294868408289, 'beta_2': 0.9817152861281936, 'epsilon': 1.2908731147236564e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 3.713397884485905e-05, 'tol': 0.0032366819923735695, 'validation_fraction': 0.30360977558524493}]
function_evaluation time 0.086790 value 29123.998108 suggestion {'alpha': 0.0003392541195103336, 'batch_size': 98, 'beta_1': 0.7778294868408289, 'beta_2': 0.9817152861281936, 'epsilon': 1.2908731147236564e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 3.713397884485905e-05, 'tol': 0.0032366819923735695, 'validation_fraction': 0.30360977558524493}
observation time 0.000078, current best 3335.531097 at iter 13
suggestion time taken 0.002146 iter 14 next_points [{'alpha': 0.0007513646008711772, 'batch_size': 174, 'beta_1': 0.8643628933765874, 'beta_2': 0.91919427884531, 'epsilon': 1.5986780419960696e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.008068174437517462, 'tol': 0.0367498184920659, 'validation_fraction': 0.15333909410911845}]
function_evaluation time 0.063039 value 28265.927203 suggestion {'alpha': 0.0007513646008711772, 'batch_size': 174, 'beta_1': 0.8643628933765874, 'beta_2': 0.91919427884531, 'epsilon': 1.5986780419960696e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.008068174437517462, 'tol': 0.0367498184920659, 'validation_fraction': 0.15333909410911845}
observation time 0.000072, current best 3335.531097 at iter 14
saving meta data: {'args': {'--uuid': 'e613a07487b25f61925dc4a6746ca462', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

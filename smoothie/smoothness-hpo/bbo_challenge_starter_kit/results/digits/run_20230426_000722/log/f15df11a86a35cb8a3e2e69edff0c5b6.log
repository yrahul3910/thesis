running: {'--uuid': 'f15df11a86a35cb8a3e2e69edff0c5b6', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'smoothness', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d diabetes -o smoothness -u f15df11a86a35cb8a3e2e69edff0c5b6 -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_000722
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study smoothness MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 11.889733 iter 0 next_points [{'alpha': 1.173025427977191, 'batch_size': 168, 'beta_1': 0.8512783536088704, 'beta_2': 0.9906890153355259, 'epsilon': 1.5263230279061704e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.001802582398654516, 'tol': 0.0001399901145259387, 'validation_fraction': 0.3305762929184669}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.270416 value 12964.104869 suggestion {'alpha': 1.173025427977191, 'batch_size': 168, 'beta_1': 0.8512783536088704, 'beta_2': 0.9906890153355259, 'epsilon': 1.5263230279061704e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.001802582398654516, 'tol': 0.0001399901145259387, 'validation_fraction': 0.3305762929184669}
observation time 0.000007, current best 12964.104869 at iter 0
suggestion time taken 11.582045 iter 1 next_points [{'alpha': 0.007082845776350915, 'batch_size': 233, 'beta_1': 0.9270212119233622, 'beta_2': 0.9890339805943018, 'epsilon': 5.729427892627552e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 3.228527832138422e-05, 'tol': 0.050406978612380964, 'validation_fraction': 0.741477885111501}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.046760 value 29077.234409 suggestion {'alpha': 0.007082845776350915, 'batch_size': 233, 'beta_1': 0.9270212119233622, 'beta_2': 0.9890339805943018, 'epsilon': 5.729427892627552e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 3.228527832138422e-05, 'tol': 0.050406978612380964, 'validation_fraction': 0.741477885111501}
observation time 0.000006, current best 12964.104869 at iter 1
suggestion time taken 11.634254 iter 2 next_points [{'alpha': 0.0023090786716061327, 'batch_size': 201, 'beta_1': 0.9640713587854071, 'beta_2': 0.9998853986934969, 'epsilon': 1.2177678191188546e-08, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.00548243554358222, 'tol': 0.029526916925373542, 'validation_fraction': 0.7834875996749537}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.051234 value 28808.866435 suggestion {'alpha': 0.0023090786716061327, 'batch_size': 201, 'beta_1': 0.9640713587854071, 'beta_2': 0.9998853986934969, 'epsilon': 1.2177678191188546e-08, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.00548243554358222, 'tol': 0.029526916925373542, 'validation_fraction': 0.7834875996749537}
observation time 0.000006, current best 12964.104869 at iter 2
suggestion time taken 11.925626 iter 3 next_points [{'alpha': 0.6543168047451213, 'batch_size': 83, 'beta_1': 0.9892467382180353, 'beta_2': 0.9999971672500751, 'epsilon': 3.0497856330514588e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.001112787886175332, 'tol': 0.09665500374012523, 'validation_fraction': 0.8861702771104507}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.048889 value 29045.540160 suggestion {'alpha': 0.6543168047451213, 'batch_size': 83, 'beta_1': 0.9892467382180353, 'beta_2': 0.9999971672500751, 'epsilon': 3.0497856330514588e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.001112787886175332, 'tol': 0.09665500374012523, 'validation_fraction': 0.8861702771104507}
observation time 0.000006, current best 12964.104869 at iter 3
suggestion time taken 11.710587 iter 4 next_points [{'alpha': 2.903938861830899, 'batch_size': 151, 'beta_1': 0.8769395731689993, 'beta_2': 0.9783103078042059, 'epsilon': 9.93815257918763e-07, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0006007150200019721, 'tol': 7.99662784350153e-05, 'validation_fraction': 0.31676457211135656}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.996860 value 27737.459847 suggestion {'alpha': 2.903938861830899, 'batch_size': 151, 'beta_1': 0.8769395731689993, 'beta_2': 0.9783103078042059, 'epsilon': 9.93815257918763e-07, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0006007150200019721, 'tol': 7.99662784350153e-05, 'validation_fraction': 0.31676457211135656}
observation time 0.000006, current best 12964.104869 at iter 4
suggestion time taken 12.061479 iter 5 next_points [{'alpha': 0.03594830278891422, 'batch_size': 159, 'beta_1': 0.5139317655935497, 'beta_2': 0.9775397807126779, 'epsilon': 3.155463821568209e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.00010463079866309683, 'tol': 0.0021603889685978244, 'validation_fraction': 0.8296027762663589}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.053019 value 29085.321038 suggestion {'alpha': 0.03594830278891422, 'batch_size': 159, 'beta_1': 0.5139317655935497, 'beta_2': 0.9775397807126779, 'epsilon': 3.155463821568209e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.00010463079866309683, 'tol': 0.0021603889685978244, 'validation_fraction': 0.8296027762663589}
observation time 0.000007, current best 12964.104869 at iter 5
suggestion time taken 11.842537 iter 6 next_points [{'alpha': 0.004534830310614515, 'batch_size': 214, 'beta_1': 0.7994123308636027, 'beta_2': 0.9999988502729114, 'epsilon': 2.6743494703774745e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 3.5601439501946386e-05, 'tol': 0.015199164170161528, 'validation_fraction': 0.49438170728763414}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.063009 value 29106.364955 suggestion {'alpha': 0.004534830310614515, 'batch_size': 214, 'beta_1': 0.7994123308636027, 'beta_2': 0.9999988502729114, 'epsilon': 2.6743494703774745e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 3.5601439501946386e-05, 'tol': 0.015199164170161528, 'validation_fraction': 0.49438170728763414}
observation time 0.000005, current best 12964.104869 at iter 6
suggestion time taken 12.201216 iter 7 next_points [{'alpha': 1.6832132143534417e-05, 'batch_size': 231, 'beta_1': 0.9605135174420768, 'beta_2': 0.9999945977392154, 'epsilon': 3.979662226497818e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.08152687930465231, 'tol': 1.9683708768626256e-05, 'validation_fraction': 0.6939377155047004}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.142477 value 4272.274505 suggestion {'alpha': 1.6832132143534417e-05, 'batch_size': 231, 'beta_1': 0.9605135174420768, 'beta_2': 0.9999945977392154, 'epsilon': 3.979662226497818e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.08152687930465231, 'tol': 1.9683708768626256e-05, 'validation_fraction': 0.6939377155047004}
observation time 0.000006, current best 4272.274505 at iter 7
suggestion time taken 12.012285 iter 8 next_points [{'alpha': 6.559915877480734, 'batch_size': 127, 'beta_1': 0.9783844360034474, 'beta_2': 0.9894828767424145, 'epsilon': 2.1718682380157162e-07, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0614665475229867, 'tol': 6.531487742510388e-05, 'validation_fraction': 0.22025848340502144}]
function_evaluation time 0.208419 value 3985.653827 suggestion {'alpha': 6.559915877480734, 'batch_size': 127, 'beta_1': 0.9783844360034474, 'beta_2': 0.9894828767424145, 'epsilon': 2.1718682380157162e-07, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0614665475229867, 'tol': 6.531487742510388e-05, 'validation_fraction': 0.22025848340502144}
observation time 0.000006, current best 3985.653827 at iter 8
suggestion time taken 12.020121 iter 9 next_points [{'alpha': 4.2860495993133405e-05, 'batch_size': 45, 'beta_1': 0.8114952444722118, 'beta_2': 0.9999257620856481, 'epsilon': 4.571793500453248e-08, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.02128238162680642, 'tol': 0.02681416564214537, 'validation_fraction': 0.727825463871663}]
function_evaluation time 0.210593 value 3579.475845 suggestion {'alpha': 4.2860495993133405e-05, 'batch_size': 45, 'beta_1': 0.8114952444722118, 'beta_2': 0.9999257620856481, 'epsilon': 4.571793500453248e-08, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.02128238162680642, 'tol': 0.02681416564214537, 'validation_fraction': 0.727825463871663}
observation time 0.000005, current best 3579.475845 at iter 9
suggestion time taken 12.316453 iter 10 next_points [{'alpha': 3.9572966745905784, 'batch_size': 24, 'beta_1': 0.8807117424708267, 'beta_2': 0.9995376393826377, 'epsilon': 1.0593172817860675e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.00015915067317363773, 'tol': 0.001964960790936257, 'validation_fraction': 0.7935668955717567}]
function_evaluation time 0.090508 value 29069.665609 suggestion {'alpha': 3.9572966745905784, 'batch_size': 24, 'beta_1': 0.8807117424708267, 'beta_2': 0.9995376393826377, 'epsilon': 1.0593172817860675e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.00015915067317363773, 'tol': 0.001964960790936257, 'validation_fraction': 0.7935668955717567}
observation time 0.000006, current best 3579.475845 at iter 10
suggestion time taken 12.055396 iter 11 next_points [{'alpha': 0.026096606544703034, 'batch_size': 28, 'beta_1': 0.9865229567229599, 'beta_2': 0.9985149692686257, 'epsilon': 1.4118116868451635e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.0005893783229107602, 'tol': 0.02480342243176054, 'validation_fraction': 0.18069891695358262}]
function_evaluation time 0.105963 value 28899.290510 suggestion {'alpha': 0.026096606544703034, 'batch_size': 28, 'beta_1': 0.9865229567229599, 'beta_2': 0.9985149692686257, 'epsilon': 1.4118116868451635e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.0005893783229107602, 'tol': 0.02480342243176054, 'validation_fraction': 0.18069891695358262}
observation time 0.000006, current best 3579.475845 at iter 11
suggestion time taken 11.993003 iter 12 next_points [{'alpha': 0.4323898252561725, 'batch_size': 176, 'beta_1': 0.8559331178123261, 'beta_2': 0.9999988156949616, 'epsilon': 9.640830853090167e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.006991630107323664, 'tol': 1.382406720761795e-05, 'validation_fraction': 0.7646213231190127}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.828925 value 3775.419357 suggestion {'alpha': 0.4323898252561725, 'batch_size': 176, 'beta_1': 0.8559331178123261, 'beta_2': 0.9999988156949616, 'epsilon': 9.640830853090167e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.006991630107323664, 'tol': 1.382406720761795e-05, 'validation_fraction': 0.7646213231190127}
observation time 0.000005, current best 3579.475845 at iter 12
suggestion time taken 12.310986 iter 13 next_points [{'alpha': 0.04399976208600937, 'batch_size': 248, 'beta_1': 0.9823886204071114, 'beta_2': 0.9795406471778182, 'epsilon': 9.228694794426791e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.00011902231026168336, 'tol': 4.23661276516845e-05, 'validation_fraction': 0.7031909908142115}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.879004 value 28962.771867 suggestion {'alpha': 0.04399976208600937, 'batch_size': 248, 'beta_1': 0.9823886204071114, 'beta_2': 0.9795406471778182, 'epsilon': 9.228694794426791e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.00011902231026168336, 'tol': 4.23661276516845e-05, 'validation_fraction': 0.7031909908142115}
observation time 0.000006, current best 3579.475845 at iter 13
suggestion time taken 12.144131 iter 14 next_points [{'alpha': 0.17285720000473218, 'batch_size': 184, 'beta_1': 0.9669384053869251, 'beta_2': 0.9992347112102682, 'epsilon': 1.905048666275172e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0014772353515566145, 'tol': 8.642007657328083e-05, 'validation_fraction': 0.8907512217441579}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.779409 value 25247.648404 suggestion {'alpha': 0.17285720000473218, 'batch_size': 184, 'beta_1': 0.9669384053869251, 'beta_2': 0.9992347112102682, 'epsilon': 1.905048666275172e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0014772353515566145, 'tol': 8.642007657328083e-05, 'validation_fraction': 0.8907512217441579}
observation time 0.000006, current best 3579.475845 at iter 14
saving meta data: {'args': {'--uuid': 'f15df11a86a35cb8a3e2e69edff0c5b6', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'smoothness', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': '37339ddda19f5650b2655bc195ca98d9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}
cmd: python opentuner/optimizer.py -c MLP-adam -d diabetes -o opentuner -u 37339ddda19f5650b2655bc195ca98d9 -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_000722
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study opentuner MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.030942 iter 0 next_points [{'hidden_layer_sizes': 183, 'alpha': 8.969006105798407, 'batch_size': 54, 'learning_rate_init': 0.05219933205576426, 'tol': 0.04089720777303734, 'validation_fraction': 0.4519976547677783, 'beta_1': 0.8355740297193959, 'beta_2': 0.9254091730879149, 'epsilon': 1.2525027962059687e-07}]
function_evaluation time 0.176097 value 3123.624660 suggestion {'hidden_layer_sizes': 183, 'alpha': 8.969006105798407, 'batch_size': 54, 'learning_rate_init': 0.05219933205576426, 'tol': 0.04089720777303734, 'validation_fraction': 0.4519976547677783, 'beta_1': 0.8355740297193959, 'beta_2': 0.9254091730879149, 'epsilon': 1.2525027962059687e-07}
observation time 0.004517, current best 3123.624660 at iter 0
suggestion time taken 0.007684 iter 1 next_points [{'hidden_layer_sizes': 183, 'alpha': 8.969006105798407, 'batch_size': 40, 'learning_rate_init': 0.05219933205576426, 'tol': 0.04089720777303734, 'validation_fraction': 0.4519976547677783, 'beta_1': 0.9277812222848385, 'beta_2': 0.9188220979337645, 'epsilon': 1.3627982659552118e-08}]
function_evaluation time 0.215866 value 2985.252323 suggestion {'hidden_layer_sizes': 183, 'alpha': 8.969006105798407, 'batch_size': 40, 'learning_rate_init': 0.05219933205576426, 'tol': 0.04089720777303734, 'validation_fraction': 0.4519976547677783, 'beta_1': 0.9277812222848385, 'beta_2': 0.9188220979337645, 'epsilon': 1.3627982659552118e-08}
observation time 0.001945, current best 2985.252323 at iter 1
suggestion time taken 0.046885 iter 2 next_points [{'beta_2': 0.947762663000752, 'learning_rate_init': 0.010734780770086983, 'validation_fraction': 0.25875583129798774, 'alpha': 1.3028866611253065, 'beta_1': 0.774581544848781, 'hidden_layer_sizes': 160, 'batch_size': 177, 'tol': 0.070944334646781, 'epsilon': 1.6098883107215533e-07}]
function_evaluation time 0.084190 value 26866.159431 suggestion {'beta_2': 0.947762663000752, 'learning_rate_init': 0.010734780770086983, 'validation_fraction': 0.25875583129798774, 'alpha': 1.3028866611253065, 'beta_1': 0.774581544848781, 'hidden_layer_sizes': 160, 'batch_size': 177, 'tol': 0.070944334646781, 'epsilon': 1.6098883107215533e-07}
observation time 0.001849, current best 2985.252323 at iter 2
suggestion time taken 0.006849 iter 3 next_points [{'hidden_layer_sizes': 183, 'alpha': 8.969006105798407, 'batch_size': 40, 'learning_rate_init': 0.06603121984175024, 'tol': 0.04089720777303734, 'validation_fraction': 0.4519976547677783, 'beta_1': 0.9277812222848385, 'beta_2': 0.9188220979337645, 'epsilon': 1.3627982659552118e-08}]
function_evaluation time 0.215021 value 3001.606418 suggestion {'hidden_layer_sizes': 183, 'alpha': 8.969006105798407, 'batch_size': 40, 'learning_rate_init': 0.06603121984175024, 'tol': 0.04089720777303734, 'validation_fraction': 0.4519976547677783, 'beta_1': 0.9277812222848385, 'beta_2': 0.9188220979337645, 'epsilon': 1.3627982659552118e-08}
observation time 0.002194, current best 2985.252323 at iter 3
suggestion time taken 0.006052 iter 4 next_points [{'hidden_layer_sizes': 167, 'alpha': 1.4593369287862488, 'batch_size': 148, 'learning_rate_init': 0.05032446010524832, 'tol': 0.08590593832492958, 'validation_fraction': 0.6734669429876159, 'beta_1': 0.939611400432488, 'beta_2': 0.9645706926560804, 'epsilon': 6.135500129350314e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.170253 value 4193.341081 suggestion {'hidden_layer_sizes': 167, 'alpha': 1.4593369287862488, 'batch_size': 148, 'learning_rate_init': 0.05032446010524832, 'tol': 0.08590593832492958, 'validation_fraction': 0.6734669429876159, 'beta_1': 0.939611400432488, 'beta_2': 0.9645706926560804, 'epsilon': 6.135500129350314e-07}
observation time 0.001842, current best 2985.252323 at iter 4
suggestion time taken 0.007051 iter 5 next_points [{'hidden_layer_sizes': 179, 'alpha': 5.686826634356062, 'batch_size': 69, 'learning_rate_init': 0.05219933205576426, 'tol': 0.04089720777303734, 'validation_fraction': 0.38976435210682536, 'beta_1': 0.830181399650969, 'beta_2': 0.9188220979337645, 'epsilon': 2.8771463795289718e-08}]
function_evaluation time 0.173396 value 3086.662330 suggestion {'hidden_layer_sizes': 179, 'alpha': 5.686826634356062, 'batch_size': 69, 'learning_rate_init': 0.05219933205576426, 'tol': 0.04089720777303734, 'validation_fraction': 0.38976435210682536, 'beta_1': 0.830181399650969, 'beta_2': 0.9188220979337645, 'epsilon': 2.8771463795289718e-08}
observation time 0.001994, current best 2985.252323 at iter 5
suggestion time taken 0.006981 iter 6 next_points [{'hidden_layer_sizes': 174, 'alpha': 8.969006105798407, 'batch_size': 23, 'learning_rate_init': 0.06712272779474053, 'tol': 0.04089720777303734, 'validation_fraction': 0.4519976547677783, 'beta_1': 0.9277812222848385, 'beta_2': 0.9188220979337645, 'epsilon': 1.24656390904614e-07}]
function_evaluation time 0.224767 value 3005.928798 suggestion {'hidden_layer_sizes': 174, 'alpha': 8.969006105798407, 'batch_size': 23, 'learning_rate_init': 0.06712272779474053, 'tol': 0.04089720777303734, 'validation_fraction': 0.4519976547677783, 'beta_1': 0.9277812222848385, 'beta_2': 0.9188220979337645, 'epsilon': 1.24656390904614e-07}
observation time 0.003409, current best 2985.252323 at iter 6
suggestion time taken 0.006389 iter 7 next_points [{'hidden_layer_sizes': 162, 'alpha': 0.5780127981250996, 'batch_size': 209, 'learning_rate_init': 0.026688218890450633, 'tol': 0.04384557518371184, 'validation_fraction': 0.8789262800404787, 'beta_1': 0.9069980229367207, 'beta_2': 0.9766819468611808, 'epsilon': 6.454449744957836e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.219632 value 4329.490411 suggestion {'hidden_layer_sizes': 162, 'alpha': 0.5780127981250996, 'batch_size': 209, 'learning_rate_init': 0.026688218890450633, 'tol': 0.04384557518371184, 'validation_fraction': 0.8789262800404787, 'beta_1': 0.9069980229367207, 'beta_2': 0.9766819468611808, 'epsilon': 6.454449744957836e-07}
observation time 0.002169, current best 2985.252323 at iter 7
suggestion time taken 0.006235 iter 8 next_points [{'hidden_layer_sizes': 105, 'alpha': 2.2966488125692157, 'batch_size': 221, 'learning_rate_init': 0.06883103713385334, 'tol': 0.04810470349502099, 'validation_fraction': 0.5377000005879501, 'beta_1': 0.8860121846759328, 'beta_2': 0.9128376590488563, 'epsilon': 7.303113046813459e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.154783 value 3969.146314 suggestion {'hidden_layer_sizes': 105, 'alpha': 2.2966488125692157, 'batch_size': 221, 'learning_rate_init': 0.06883103713385334, 'tol': 0.04810470349502099, 'validation_fraction': 0.5377000005879501, 'beta_1': 0.8860121846759328, 'beta_2': 0.9128376590488563, 'epsilon': 7.303113046813459e-07}
observation time 0.001826, current best 2985.252323 at iter 8
suggestion time taken 0.007549 iter 9 next_points [{'hidden_layer_sizes': 183, 'alpha': 8.969006105798407, 'batch_size': 40, 'learning_rate_init': 0.050407220417093716, 'tol': 0.04089720777303734, 'validation_fraction': 0.4519976547677783, 'beta_1': 0.9613213391220399, 'beta_2': 0.9239389904722781, 'epsilon': 1.0784219620138435e-07}]
function_evaluation time 0.246380 value 3102.047815 suggestion {'hidden_layer_sizes': 183, 'alpha': 8.969006105798407, 'batch_size': 40, 'learning_rate_init': 0.050407220417093716, 'tol': 0.04089720777303734, 'validation_fraction': 0.4519976547677783, 'beta_1': 0.9613213391220399, 'beta_2': 0.9239389904722781, 'epsilon': 1.0784219620138435e-07}
observation time 0.001816, current best 2985.252323 at iter 9
suggestion time taken 0.007186 iter 10 next_points [{'hidden_layer_sizes': 176, 'alpha': 8.293406315408404, 'batch_size': 74, 'learning_rate_init': 0.05219933205576426, 'tol': 0.05141795432343315, 'validation_fraction': 0.4519976547677783, 'beta_1': 0.9277812222848385, 'beta_2': 0.9211378409727938, 'epsilon': 1.3627982659552118e-08}]
function_evaluation time 0.208666 value 3457.666909 suggestion {'hidden_layer_sizes': 176, 'alpha': 8.293406315408404, 'batch_size': 74, 'learning_rate_init': 0.05219933205576426, 'tol': 0.05141795432343315, 'validation_fraction': 0.4519976547677783, 'beta_1': 0.9277812222848385, 'beta_2': 0.9211378409727938, 'epsilon': 1.3627982659552118e-08}
observation time 0.002913, current best 2985.252323 at iter 10
suggestion time taken 0.005863 iter 11 next_points [{'hidden_layer_sizes': 109, 'alpha': 0.4865151400263536, 'batch_size': 209, 'learning_rate_init': 0.04166222560485105, 'tol': 0.01691785392491123, 'validation_fraction': 0.4866854029665254, 'beta_1': 0.8646695508604054, 'beta_2': 0.9951923495046647, 'epsilon': 6.171730492504347e-07}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.201130 value 3837.734528 suggestion {'hidden_layer_sizes': 109, 'alpha': 0.4865151400263536, 'batch_size': 209, 'learning_rate_init': 0.04166222560485105, 'tol': 0.01691785392491123, 'validation_fraction': 0.4866854029665254, 'beta_1': 0.8646695508604054, 'beta_2': 0.9951923495046647, 'epsilon': 6.171730492504347e-07}
observation time 0.002118, current best 2985.252323 at iter 11
suggestion time taken 0.005181 iter 12 next_points [{'beta_2': 0.9143969515417768, 'learning_rate_init': 0.08399894132297463, 'validation_fraction': 0.28981392549499974, 'alpha': 0.8650310911484215, 'beta_1': 0.8363230242274693, 'hidden_layer_sizes': 168, 'batch_size': 213, 'tol': 0.017100330553524824, 'epsilon': 3.8613871350927755e-08}]
function_evaluation time 0.204528 value 3304.281156 suggestion {'beta_2': 0.9143969515417768, 'learning_rate_init': 0.08399894132297463, 'validation_fraction': 0.28981392549499974, 'alpha': 0.8650310911484215, 'beta_1': 0.8363230242274693, 'hidden_layer_sizes': 168, 'batch_size': 213, 'tol': 0.017100330553524824, 'epsilon': 3.8613871350927755e-08}
observation time 0.001853, current best 2985.252323 at iter 12
suggestion time taken 0.007132 iter 13 next_points [{'hidden_layer_sizes': 183, 'alpha': 8.969006105798407, 'batch_size': 40, 'learning_rate_init': 0.027712053288001238, 'tol': 0.026774189814010963, 'validation_fraction': 0.8588283558200777, 'beta_1': 0.8373619467908157, 'beta_2': 0.9726342826350876, 'epsilon': 1.3627982659552118e-08}]
function_evaluation time 0.209536 value 4075.674544 suggestion {'hidden_layer_sizes': 183, 'alpha': 8.969006105798407, 'batch_size': 40, 'learning_rate_init': 0.027712053288001238, 'tol': 0.026774189814010963, 'validation_fraction': 0.8588283558200777, 'beta_1': 0.8373619467908157, 'beta_2': 0.9726342826350876, 'epsilon': 1.3627982659552118e-08}
observation time 0.002070, current best 2985.252323 at iter 13
suggestion time taken 0.007197 iter 14 next_points [{'hidden_layer_sizes': 186, 'alpha': 8.560496362473875, 'batch_size': 40, 'learning_rate_init': 0.05219933205576426, 'tol': 0.06444932048241474, 'validation_fraction': 0.4519976547677783, 'beta_1': 0.9277812222848385, 'beta_2': 0.9064698569495924, 'epsilon': 1.3627982659552118e-08}]
function_evaluation time 0.205211 value 3086.397461 suggestion {'hidden_layer_sizes': 186, 'alpha': 8.560496362473875, 'batch_size': 40, 'learning_rate_init': 0.05219933205576426, 'tol': 0.06444932048241474, 'validation_fraction': 0.4519976547677783, 'beta_1': 0.9277812222848385, 'beta_2': 0.9064698569495924, 'epsilon': 1.3627982659552118e-08}
observation time 0.001869, current best 2985.252323 at iter 14
saving meta data: {'args': {'--uuid': '37339ddda19f5650b2655bc195ca98d9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'opentuner', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.8.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

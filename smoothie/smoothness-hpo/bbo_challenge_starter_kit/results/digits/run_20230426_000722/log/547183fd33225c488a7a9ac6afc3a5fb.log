running: {'--uuid': '547183fd33225c488a7a9ac6afc3a5fb', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}
cmd: python turbo/optimizer.py -c MLP-adam -d diabetes -o turbo -u 547183fd33225c488a7a9ac6afc3a5fb -m mse -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_000722
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])
Signature errors:
                              0         1         2         3         4       max
MLP-adam_diabetes_mse  0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
max                    0.000007  0.000008  0.000003  0.003558  0.004952  0.004952
starting sklearn study turbo MLP-adam diabetes mse 15 1
with data root: None
suggestion time taken 0.002105 iter 0 next_points [{'alpha': 2.6762391453278562, 'batch_size': 121, 'beta_1': 0.9747973072434082, 'beta_2': 0.9970184442386867, 'epsilon': 9.396426938726989e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.005615529967126126, 'tol': 0.03599465385394211, 'validation_fraction': 0.7726886424061428}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.058598 value 28724.059849 suggestion {'alpha': 2.6762391453278562, 'batch_size': 121, 'beta_1': 0.9747973072434082, 'beta_2': 0.9970184442386867, 'epsilon': 9.396426938726989e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.005615529967126126, 'tol': 0.03599465385394211, 'validation_fraction': 0.7726886424061428}
observation time 0.001380, current best 28724.059849 at iter 0
suggestion time taken 0.001736 iter 1 next_points [{'alpha': 0.00035943583299418905, 'batch_size': 92, 'beta_1': 0.7157892494132753, 'beta_2': 0.9592678304342638, 'epsilon': 1.1564486819581851e-08, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.06164332855537788, 'tol': 3.52993350025278e-05, 'validation_fraction': 0.8920111344508606}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.307647 value 3590.248221 suggestion {'alpha': 0.00035943583299418905, 'batch_size': 92, 'beta_1': 0.7157892494132753, 'beta_2': 0.9592678304342638, 'epsilon': 1.1564486819581851e-08, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.06164332855537788, 'tol': 3.52993350025278e-05, 'validation_fraction': 0.8920111344508606}
observation time 0.001369, current best 3590.248221 at iter 1
suggestion time taken 0.001768 iter 2 next_points [{'alpha': 8.407267299956185e-05, 'batch_size': 205, 'beta_1': 0.9665749589059146, 'beta_2': 0.9683322440165808, 'epsilon': 7.70887198536489e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0008505398264833821, 'tol': 0.00010099244438040235, 'validation_fraction': 0.1394621841365406}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.112582 value 26722.376025 suggestion {'alpha': 8.407267299956185e-05, 'batch_size': 205, 'beta_1': 0.9665749589059146, 'beta_2': 0.9683322440165808, 'epsilon': 7.70887198536489e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0008505398264833821, 'tol': 0.00010099244438040235, 'validation_fraction': 0.1394621841365406}
observation time 0.001422, current best 3590.248221 at iter 2
suggestion time taken 0.001752 iter 3 next_points [{'alpha': 0.029482346485564793, 'batch_size': 124, 'beta_1': 0.9892510585955624, 'beta_2': 0.9999975977127499, 'epsilon': 2.8917225560637856e-09, 'hidden_layer_sizes': 149, 'learning_rate_init': 7.744342180588862e-05, 'tol': 0.00036906670109916454, 'validation_fraction': 0.8329295260323556}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.054472 value 29137.858663 suggestion {'alpha': 0.029482346485564793, 'batch_size': 124, 'beta_1': 0.9892510585955624, 'beta_2': 0.9999975977127499, 'epsilon': 2.8917225560637856e-09, 'hidden_layer_sizes': 149, 'learning_rate_init': 7.744342180588862e-05, 'tol': 0.00036906670109916454, 'validation_fraction': 0.8329295260323556}
observation time 0.001364, current best 3590.248221 at iter 3
suggestion time taken 0.002005 iter 4 next_points [{'alpha': 0.7209069830853698, 'batch_size': 186, 'beta_1': 0.5032058794507318, 'beta_2': 0.999679941337758, 'epsilon': 1.3134363381317675e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.0025065437305176667, 'tol': 0.00014273128905429726, 'validation_fraction': 0.5808051970886348}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.790414 value 18915.147637 suggestion {'alpha': 0.7209069830853698, 'batch_size': 186, 'beta_1': 0.5032058794507318, 'beta_2': 0.999679941337758, 'epsilon': 1.3134363381317675e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.0025065437305176667, 'tol': 0.00014273128905429726, 'validation_fraction': 0.5808051970886348}
observation time 0.001412, current best 3590.248221 at iter 4
suggestion time taken 0.001724 iter 5 next_points [{'alpha': 0.06936569013290259, 'batch_size': 103, 'beta_1': 0.7988079840185549, 'beta_2': 0.9999086339981494, 'epsilon': 3.769038376261467e-08, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.0002977838866120919, 'tol': 1.759647349940186e-05, 'validation_fraction': 0.4444196952949875}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.102386 value 28151.881399 suggestion {'alpha': 0.06936569013290259, 'batch_size': 103, 'beta_1': 0.7988079840185549, 'beta_2': 0.9999086339981494, 'epsilon': 3.769038376261467e-08, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.0002977838866120919, 'tol': 1.759647349940186e-05, 'validation_fraction': 0.4444196952949875}
observation time 0.001404, current best 3590.248221 at iter 5
suggestion time taken 0.001736 iter 6 next_points [{'alpha': 0.009421352558645004, 'batch_size': 149, 'beta_1': 0.7323858545755954, 'beta_2': 0.9979271343542226, 'epsilon': 1.7349644995679827e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.010291981458828862, 'tol': 0.005235004906363349, 'validation_fraction': 0.7323116922044542}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.534732 value 3728.756650 suggestion {'alpha': 0.009421352558645004, 'batch_size': 149, 'beta_1': 0.7323858545755954, 'beta_2': 0.9979271343542226, 'epsilon': 1.7349644995679827e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.010291981458828862, 'tol': 0.005235004906363349, 'validation_fraction': 0.7323116922044542}
observation time 0.001359, current best 3590.248221 at iter 6
suggestion time taken 0.001760 iter 7 next_points [{'alpha': 1.0465119602575321e-05, 'batch_size': 239, 'beta_1': 0.8930043177676967, 'beta_2': 0.999850835779369, 'epsilon': 1.3666240016267182e-08, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.000491092287009322, 'tol': 0.005770932396624843, 'validation_fraction': 0.8730778810747197}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.043911 value 29122.946632 suggestion {'alpha': 1.0465119602575321e-05, 'batch_size': 239, 'beta_1': 0.8930043177676967, 'beta_2': 0.999850835779369, 'epsilon': 1.3666240016267182e-08, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.000491092287009322, 'tol': 0.005770932396624843, 'validation_fraction': 0.8730778810747197}
observation time 0.001406, current best 3590.248221 at iter 7
suggestion time taken 0.001720 iter 8 next_points [{'alpha': 0.0013361698274159727, 'batch_size': 153, 'beta_1': 0.9504872962473084, 'beta_2': 0.9999866292037314, 'epsilon': 3.206726056030099e-09, 'hidden_layer_sizes': 171, 'learning_rate_init': 3.60606361998675e-05, 'tol': 0.00025293720703922404, 'validation_fraction': 0.3804412568180049}]
function_evaluation time 0.084168 value 29046.180840 suggestion {'alpha': 0.0013361698274159727, 'batch_size': 153, 'beta_1': 0.9504872962473084, 'beta_2': 0.9999866292037314, 'epsilon': 3.206726056030099e-09, 'hidden_layer_sizes': 171, 'learning_rate_init': 3.60606361998675e-05, 'tol': 0.00025293720703922404, 'validation_fraction': 0.3804412568180049}
observation time 0.001397, current best 3590.248221 at iter 8
suggestion time taken 0.001761 iter 9 next_points [{'alpha': 5.475812689918403, 'batch_size': 47, 'beta_1': 0.9837424607700894, 'beta_2': 0.9999446737111296, 'epsilon': 2.5251604593275796e-07, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.02965129683241306, 'tol': 0.0005363123718010349, 'validation_fraction': 0.3198891931910525}]
function_evaluation time 0.402363 value 3502.193634 suggestion {'alpha': 5.475812689918403, 'batch_size': 47, 'beta_1': 0.9837424607700894, 'beta_2': 0.9999446737111296, 'epsilon': 2.5251604593275796e-07, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.02965129683241306, 'tol': 0.0005363123718010349, 'validation_fraction': 0.3198891931910525}
observation time 0.001371, current best 3502.193634 at iter 9
suggestion time taken 0.001719 iter 10 next_points [{'alpha': 0.5375789977751629, 'batch_size': 14, 'beta_1': 0.6537577232097502, 'beta_2': 0.9999986363732191, 'epsilon': 4.335782539170982e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.014895153622470483, 'tol': 0.0027223776083958313, 'validation_fraction': 0.6485220509028717}]
function_evaluation time 0.796355 value 3103.075959 suggestion {'alpha': 0.5375789977751629, 'batch_size': 14, 'beta_1': 0.6537577232097502, 'beta_2': 0.9999986363732191, 'epsilon': 4.335782539170982e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.014895153622470483, 'tol': 0.0027223776083958313, 'validation_fraction': 0.6485220509028717}
observation time 0.001363, current best 3103.075959 at iter 10
suggestion time taken 0.001750 iter 11 next_points [{'alpha': 2.072330203206625, 'batch_size': 83, 'beta_1': 0.8602177474622961, 'beta_2': 0.9111519575570871, 'epsilon': 3.9187325626459863e-08, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.0038631351494397503, 'tol': 0.012339667577996772, 'validation_fraction': 0.6113296435067882}]
function_evaluation time 0.065761 value 28692.901428 suggestion {'alpha': 2.072330203206625, 'batch_size': 83, 'beta_1': 0.8602177474622961, 'beta_2': 0.9111519575570871, 'epsilon': 3.9187325626459863e-08, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.0038631351494397503, 'tol': 0.012339667577996772, 'validation_fraction': 0.6113296435067882}
observation time 0.001352, current best 3103.075959 at iter 11
suggestion time taken 0.001751 iter 12 next_points [{'alpha': 0.005546752832708162, 'batch_size': 169, 'beta_1': 0.6177480137032699, 'beta_2': 0.9895028977911698, 'epsilon': 9.036972725041526e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 4.538719535092227e-05, 'tol': 0.001191809113057251, 'validation_fraction': 0.10972895902501202}]
function_evaluation time 0.044378 value 29059.513841 suggestion {'alpha': 0.005546752832708162, 'batch_size': 169, 'beta_1': 0.6177480137032699, 'beta_2': 0.9895028977911698, 'epsilon': 9.036972725041526e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 4.538719535092227e-05, 'tol': 0.001191809113057251, 'validation_fraction': 0.10972895902501202}
observation time 0.001388, current best 3103.075959 at iter 12
suggestion time taken 0.001712 iter 13 next_points [{'alpha': 0.16087493792971866, 'batch_size': 34, 'beta_1': 0.9711362071100275, 'beta_2': 0.999966850559673, 'epsilon': 7.667942325593715e-09, 'hidden_layer_sizes': 114, 'learning_rate_init': 1.2478024673834027e-05, 'tol': 0.015308284360760155, 'validation_fraction': 0.18727345779751725}]
function_evaluation time 0.093325 value 29087.166070 suggestion {'alpha': 0.16087493792971866, 'batch_size': 34, 'beta_1': 0.9711362071100275, 'beta_2': 0.999966850559673, 'epsilon': 7.667942325593715e-09, 'hidden_layer_sizes': 114, 'learning_rate_init': 1.2478024673834027e-05, 'tol': 0.015308284360760155, 'validation_fraction': 0.18727345779751725}
observation time 0.001364, current best 3103.075959 at iter 13
suggestion time taken 0.001761 iter 14 next_points [{'alpha': 0.03237311422065872, 'batch_size': 49, 'beta_1': 0.9453572983754255, 'beta_2': 0.9986168287382241, 'epsilon': 2.5869091350397847e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 1.7581299928984975e-05, 'tol': 0.001461319883634623, 'validation_fraction': 0.21952939977496425}]
function_evaluation time 0.071999 value 29147.080290 suggestion {'alpha': 0.03237311422065872, 'batch_size': 49, 'beta_1': 0.9453572983754255, 'beta_2': 0.9986168287382241, 'epsilon': 2.5869091350397847e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 1.7581299928984975e-05, 'tol': 0.001461319883634623, 'validation_fraction': 0.21952939977496425}
observation time 0.001577, current best 3103.075959 at iter 14
saving meta data: {'args': {'--uuid': '547183fd33225c488a7a9ac6afc3a5fb', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'turbo', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mse', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.1'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [29083.993548572587, 29062.423277324073, 29075.78987471409, 24626.32866834337, 9584.226858493177])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': 'e287d916bf6853c685da875bf704c2de', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}
cmd: python hyperopt/optimizer.py -c MLP-adam -d diabetes -o hyperopt -u e287d916bf6853c685da875bf704c2de -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_000722
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study hyperopt MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 0.002365 iter 0 next_points [{'alpha': 1.8967801911068e-05, 'batch_size': 128, 'beta_1': 0.7455768368067127, 'beta_2': 0.9177076452653662, 'epsilon': 1.5102416899905555e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.006114772534643336, 'tol': 0.004118522556867371, 'validation_fraction': 0.36168882686854437}]
function_evaluation time 0.752131 value 53.310066 suggestion {'alpha': 1.8967801911068e-05, 'batch_size': 128, 'beta_1': 0.7455768368067127, 'beta_2': 0.9177076452653662, 'epsilon': 1.5102416899905555e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.006114772534643336, 'tol': 0.004118522556867371, 'validation_fraction': 0.36168882686854437}
observation time 0.000071, current best 53.310066 at iter 0
suggestion time taken 0.002412 iter 1 next_points [{'alpha': 0.00017119430234936226, 'batch_size': 28, 'beta_1': 0.6040983954479546, 'beta_2': 0.9435043067078003, 'epsilon': 3.967477014100745e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 1.3970819136820975e-05, 'tol': 7.091166834722548e-05, 'validation_fraction': 0.48218490474685255}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.457557 value 151.704688 suggestion {'alpha': 0.00017119430234936226, 'batch_size': 28, 'beta_1': 0.6040983954479546, 'beta_2': 0.9435043067078003, 'epsilon': 3.967477014100745e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 1.3970819136820975e-05, 'tol': 7.091166834722548e-05, 'validation_fraction': 0.48218490474685255}
observation time 0.000067, current best 53.310066 at iter 1
suggestion time taken 0.002163 iter 2 next_points [{'alpha': 0.027916659973462238, 'batch_size': 84, 'beta_1': 0.519100321915687, 'beta_2': 0.9666160082319134, 'epsilon': 2.516828688825799e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 2.7597616124182015e-05, 'tol': 0.058189769484662125, 'validation_fraction': 0.2906033478635245}]
function_evaluation time 0.064207 value 151.628493 suggestion {'alpha': 0.027916659973462238, 'batch_size': 84, 'beta_1': 0.519100321915687, 'beta_2': 0.9666160082319134, 'epsilon': 2.516828688825799e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 2.7597616124182015e-05, 'tol': 0.058189769484662125, 'validation_fraction': 0.2906033478635245}
observation time 0.000069, current best 53.310066 at iter 2
suggestion time taken 0.002153 iter 3 next_points [{'alpha': 0.0038536072310041934, 'batch_size': 173, 'beta_1': 0.7820548894803657, 'beta_2': 0.909371218543043, 'epsilon': 1.588324504922389e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0003887614894197772, 'tol': 0.000437936477113037, 'validation_fraction': 0.19723193064710762}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.321926 value 147.923886 suggestion {'alpha': 0.0038536072310041934, 'batch_size': 173, 'beta_1': 0.7820548894803657, 'beta_2': 0.909371218543043, 'epsilon': 1.588324504922389e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0003887614894197772, 'tol': 0.000437936477113037, 'validation_fraction': 0.19723193064710762}
observation time 0.000078, current best 53.310066 at iter 3
suggestion time taken 0.002356 iter 4 next_points [{'alpha': 0.00018177881334648153, 'batch_size': 163, 'beta_1': 0.617566979160236, 'beta_2': 0.9732629518673888, 'epsilon': 2.2714793372527343e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.023350981450237854, 'tol': 5.6938760365169085e-05, 'validation_fraction': 0.15450587620289083}]
function_evaluation time 0.569555 value 44.447002 suggestion {'alpha': 0.00018177881334648153, 'batch_size': 163, 'beta_1': 0.617566979160236, 'beta_2': 0.9732629518673888, 'epsilon': 2.2714793372527343e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.023350981450237854, 'tol': 5.6938760365169085e-05, 'validation_fraction': 0.15450587620289083}
observation time 0.000069, current best 44.447002 at iter 4
suggestion time taken 0.002156 iter 5 next_points [{'alpha': 0.0023487945672252446, 'batch_size': 64, 'beta_1': 0.5806442392564155, 'beta_2': 0.9302527115057044, 'epsilon': 1.6231347690364244e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.00531908448347766, 'tol': 0.012643824986576681, 'validation_fraction': 0.3558723339953622}]
function_evaluation time 0.662881 value 53.324385 suggestion {'alpha': 0.0023487945672252446, 'batch_size': 64, 'beta_1': 0.5806442392564155, 'beta_2': 0.9302527115057044, 'epsilon': 1.6231347690364244e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.00531908448347766, 'tol': 0.012643824986576681, 'validation_fraction': 0.3558723339953622}
observation time 0.000067, current best 44.447002 at iter 5
suggestion time taken 0.002358 iter 6 next_points [{'alpha': 1.446822298069325e-05, 'batch_size': 27, 'beta_1': 0.7921988861226343, 'beta_2': 0.9804520616620515, 'epsilon': 1.443720142593001e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.002795426341481716, 'tol': 0.028445134983787465, 'validation_fraction': 0.2998129388312653}]
function_evaluation time 0.871463 value 55.311341 suggestion {'alpha': 1.446822298069325e-05, 'batch_size': 27, 'beta_1': 0.7921988861226343, 'beta_2': 0.9804520616620515, 'epsilon': 1.443720142593001e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.002795426341481716, 'tol': 0.028445134983787465, 'validation_fraction': 0.2998129388312653}
observation time 0.000072, current best 44.447002 at iter 6
suggestion time taken 0.002214 iter 7 next_points [{'alpha': 2.7147115891290616e-05, 'batch_size': 215, 'beta_1': 0.5465079987840153, 'beta_2': 0.9809317922763119, 'epsilon': 3.3217533510826756e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.04351722988313767, 'tol': 0.09091766459581944, 'validation_fraction': 0.39381882869356444}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.170690 value 50.949804 suggestion {'alpha': 2.7147115891290616e-05, 'batch_size': 215, 'beta_1': 0.5465079987840153, 'beta_2': 0.9809317922763119, 'epsilon': 3.3217533510826756e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.04351722988313767, 'tol': 0.09091766459581944, 'validation_fraction': 0.39381882869356444}
observation time 0.000068, current best 44.447002 at iter 7
suggestion time taken 0.002148 iter 8 next_points [{'alpha': 1.8484096267575592, 'batch_size': 169, 'beta_1': 0.7563146198574666, 'beta_2': 0.9114794841675785, 'epsilon': 1.8830342634513613e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.05736490526316684, 'tol': 0.001027290807541198, 'validation_fraction': 0.14313070822601787}]
function_evaluation time 0.324780 value 44.214378 suggestion {'alpha': 1.8484096267575592, 'batch_size': 169, 'beta_1': 0.7563146198574666, 'beta_2': 0.9114794841675785, 'epsilon': 1.8830342634513613e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.05736490526316684, 'tol': 0.001027290807541198, 'validation_fraction': 0.14313070822601787}
observation time 0.000064, current best 44.214378 at iter 8
suggestion time taken 0.002119 iter 9 next_points [{'alpha': 0.10571475026161951, 'batch_size': 142, 'beta_1': 0.6854027262103997, 'beta_2': 0.9072790279066335, 'epsilon': 3.265606594302545e-07, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.057518589391905545, 'tol': 0.00017995535617665767, 'validation_fraction': 0.21409067412965463}]
function_evaluation time 0.413334 value 43.908893 suggestion {'alpha': 0.10571475026161951, 'batch_size': 142, 'beta_1': 0.6854027262103997, 'beta_2': 0.9072790279066335, 'epsilon': 3.265606594302545e-07, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.057518589391905545, 'tol': 0.00017995535617665767, 'validation_fraction': 0.21409067412965463}
observation time 0.000075, current best 43.908893 at iter 9
suggestion time taken 0.002156 iter 10 next_points [{'alpha': 0.0015686627308347328, 'batch_size': 212, 'beta_1': 0.7100417478959797, 'beta_2': 0.9487846516240324, 'epsilon': 7.887661735586187e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.08840372937574434, 'tol': 0.08977688993416447, 'validation_fraction': 0.24806537240874876}]
function_evaluation time 0.128342 value 50.943638 suggestion {'alpha': 0.0015686627308347328, 'batch_size': 212, 'beta_1': 0.7100417478959797, 'beta_2': 0.9487846516240324, 'epsilon': 7.887661735586187e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.08840372937574434, 'tol': 0.08977688993416447, 'validation_fraction': 0.24806537240874876}
observation time 0.000067, current best 43.908893 at iter 10
suggestion time taken 0.002171 iter 11 next_points [{'alpha': 0.010600846989724263, 'batch_size': 123, 'beta_1': 0.5242440739910236, 'beta_2': 0.9597789324625079, 'epsilon': 1.1818992081393884e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.00023684870401831061, 'tol': 6.366617961457364e-05, 'validation_fraction': 0.20747651525250935}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.099179 value 150.103253 suggestion {'alpha': 0.010600846989724263, 'batch_size': 123, 'beta_1': 0.5242440739910236, 'beta_2': 0.9597789324625079, 'epsilon': 1.1818992081393884e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.00023684870401831061, 'tol': 6.366617961457364e-05, 'validation_fraction': 0.20747651525250935}
observation time 0.000073, current best 43.908893 at iter 11
suggestion time taken 0.002378 iter 12 next_points [{'alpha': 7.62530819151205, 'batch_size': 49, 'beta_1': 0.7356840194893307, 'beta_2': 0.9432986122011982, 'epsilon': 1.665869717805705e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0038878192025166214, 'tol': 0.0017299812756327952, 'validation_fraction': 0.8552909971076338}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 0.762964 value 102.009301 suggestion {'alpha': 7.62530819151205, 'batch_size': 49, 'beta_1': 0.7356840194893307, 'beta_2': 0.9432986122011982, 'epsilon': 1.665869717805705e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0038878192025166214, 'tol': 0.0017299812756327952, 'validation_fraction': 0.8552909971076338}
observation time 0.000072, current best 43.908893 at iter 12
suggestion time taken 0.002201 iter 13 next_points [{'alpha': 0.7865868511072419, 'batch_size': 122, 'beta_1': 0.7807746399489122, 'beta_2': 0.9148100335919214, 'epsilon': 5.435747941655719e-08, 'hidden_layer_sizes': 87, 'learning_rate_init': 1.0332898601340055e-05, 'tol': 3.14467182194596e-05, 'validation_fraction': 0.6855861791789952}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.048543 value 151.629997 suggestion {'alpha': 0.7865868511072419, 'batch_size': 122, 'beta_1': 0.7807746399489122, 'beta_2': 0.9148100335919214, 'epsilon': 5.435747941655719e-08, 'hidden_layer_sizes': 87, 'learning_rate_init': 1.0332898601340055e-05, 'tol': 3.14467182194596e-05, 'validation_fraction': 0.6855861791789952}
observation time 0.000074, current best 43.908893 at iter 13
suggestion time taken 0.002297 iter 14 next_points [{'alpha': 0.06160271503290135, 'batch_size': 191, 'beta_1': 0.9041160837971217, 'beta_2': 0.9084651763974868, 'epsilon': 3.8743171659591646e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 4.6220731727295754e-05, 'tol': 0.0029654955680661716, 'validation_fraction': 0.6135418392150479}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.052058 value 151.545204 suggestion {'alpha': 0.06160271503290135, 'batch_size': 191, 'beta_1': 0.9041160837971217, 'beta_2': 0.9084651763974868, 'epsilon': 3.8743171659591646e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 4.6220731727295754e-05, 'tol': 0.0029654955680661716, 'validation_fraction': 0.6135418392150479}
observation time 0.000066, current best 43.908893 at iter 14
saving meta data: {'args': {'--uuid': 'e287d916bf6853c685da875bf704c2de', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'hyperopt', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.2.7'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done

running: {'--uuid': 'f9e4832831105d1694dc4e2b783b4036', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'smoothness', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python smoothness/optimizer.py -c MLP-adam -d diabetes -o smoothness -u f9e4832831105d1694dc4e2b783b4036 -m mae -n 15 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20230426_000722
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])
Signature errors:
                                  0             1             2         3         4       max
MLP-adam_diabetes_mae  1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
max                    1.919244e-08  6.198704e-08  7.624578e-09  0.000007  0.000034  0.000034
starting sklearn study smoothness MLP-adam diabetes mae 15 1
with data root: None
suggestion time taken 11.717772 iter 0 next_points [{'alpha': 0.00015467737132382443, 'batch_size': 216, 'beta_1': 0.8404430233363014, 'beta_2': 0.9865828542680802, 'epsilon': 6.59156353450347e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.08296290292006317, 'tol': 2.454500977697898e-05, 'validation_fraction': 0.5631205803747654}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.300808 value 44.800242 suggestion {'alpha': 0.00015467737132382443, 'batch_size': 216, 'beta_1': 0.8404430233363014, 'beta_2': 0.9865828542680802, 'epsilon': 6.59156353450347e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.08296290292006317, 'tol': 2.454500977697898e-05, 'validation_fraction': 0.5631205803747654}
observation time 0.000006, current best 44.800242 at iter 0
suggestion time taken 11.527354 iter 1 next_points [{'alpha': 0.9320947877702244, 'batch_size': 167, 'beta_1': 0.581253996587911, 'beta_2': 0.9999692215515811, 'epsilon': 7.407062406452635e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0180294570428281, 'tol': 0.005147649898252901, 'validation_fraction': 0.19073226917088057}]
function_evaluation time 0.335445 value 50.241500 suggestion {'alpha': 0.9320947877702244, 'batch_size': 167, 'beta_1': 0.581253996587911, 'beta_2': 0.9999692215515811, 'epsilon': 7.407062406452635e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0180294570428281, 'tol': 0.005147649898252901, 'validation_fraction': 0.19073226917088057}
observation time 0.000005, current best 44.800242 at iter 1
suggestion time taken 11.460899 iter 2 next_points [{'alpha': 0.000355532663224794, 'batch_size': 231, 'beta_1': 0.6035085118058513, 'beta_2': 0.9997693150118734, 'epsilon': 6.121431387069573e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.00017371498013768304, 'tol': 0.00022626018303440268, 'validation_fraction': 0.6034545059357582}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.052879 value 151.394004 suggestion {'alpha': 0.000355532663224794, 'batch_size': 231, 'beta_1': 0.6035085118058513, 'beta_2': 0.9997693150118734, 'epsilon': 6.121431387069573e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.00017371498013768304, 'tol': 0.00022626018303440268, 'validation_fraction': 0.6034545059357582}
observation time 0.000006, current best 44.800242 at iter 2
suggestion time taken 11.749393 iter 3 next_points [{'alpha': 0.21149618475056048, 'batch_size': 121, 'beta_1': 0.6143099852194305, 'beta_2': 0.9999280876075174, 'epsilon': 1.3461346782798884e-08, 'hidden_layer_sizes': 106, 'learning_rate_init': 1.8954752406937364e-05, 'tol': 0.003401477473698969, 'validation_fraction': 0.3508660122711054}]
function_evaluation time 0.069744 value 151.590061 suggestion {'alpha': 0.21149618475056048, 'batch_size': 121, 'beta_1': 0.6143099852194305, 'beta_2': 0.9999280876075174, 'epsilon': 1.3461346782798884e-08, 'hidden_layer_sizes': 106, 'learning_rate_init': 1.8954752406937364e-05, 'tol': 0.003401477473698969, 'validation_fraction': 0.3508660122711054}
observation time 0.000006, current best 44.800242 at iter 3
suggestion time taken 11.556449 iter 4 next_points [{'alpha': 2.6613799272089137e-05, 'batch_size': 87, 'beta_1': 0.9834915045332722, 'beta_2': 0.9999965676298828, 'epsilon': 8.295879259612247e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.0927427576466779, 'tol': 0.00017562888303152024, 'validation_fraction': 0.1306631137148196}]
function_evaluation time 0.125265 value 47.870278 suggestion {'alpha': 2.6613799272089137e-05, 'batch_size': 87, 'beta_1': 0.9834915045332722, 'beta_2': 0.9999965676298828, 'epsilon': 8.295879259612247e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.0927427576466779, 'tol': 0.00017562888303152024, 'validation_fraction': 0.1306631137148196}
observation time 0.000006, current best 44.800242 at iter 4
suggestion time taken 11.946612 iter 5 next_points [{'alpha': 0.1508139521262731, 'batch_size': 207, 'beta_1': 0.5540284937195739, 'beta_2': 0.9999986676414473, 'epsilon': 7.605640706712589e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.043801730780306074, 'tol': 0.0005581355096207912, 'validation_fraction': 0.6221920701025601}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:605: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.419824 value 46.523695 suggestion {'alpha': 0.1508139521262731, 'batch_size': 207, 'beta_1': 0.5540284937195739, 'beta_2': 0.9999986676414473, 'epsilon': 7.605640706712589e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.043801730780306074, 'tol': 0.0005581355096207912, 'validation_fraction': 0.6221920701025601}
observation time 0.000006, current best 44.800242 at iter 5
suggestion time taken 11.742182 iter 6 next_points [{'alpha': 0.00016542342996817773, 'batch_size': 127, 'beta_1': 0.9876439179167907, 'beta_2': 0.9990372245218018, 'epsilon': 2.930757277605313e-07, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.000776813671654124, 'tol': 0.005818657461586264, 'validation_fraction': 0.1534142713696528}]
function_evaluation time 0.091530 value 151.406878 suggestion {'alpha': 0.00016542342996817773, 'batch_size': 127, 'beta_1': 0.9876439179167907, 'beta_2': 0.9990372245218018, 'epsilon': 2.930757277605313e-07, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.000776813671654124, 'tol': 0.005818657461586264, 'validation_fraction': 0.1534142713696528}
observation time 0.000006, current best 44.800242 at iter 6
suggestion time taken 12.107922 iter 7 next_points [{'alpha': 0.00022887525888091125, 'batch_size': 99, 'beta_1': 0.9897087140834635, 'beta_2': 0.9801530935453685, 'epsilon': 4.987342954781635e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.0252421152460433, 'tol': 0.012912491052148272, 'validation_fraction': 0.3729213061576947}]
function_evaluation time 0.185318 value 55.180488 suggestion {'alpha': 0.00022887525888091125, 'batch_size': 99, 'beta_1': 0.9897087140834635, 'beta_2': 0.9801530935453685, 'epsilon': 4.987342954781635e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.0252421152460433, 'tol': 0.012912491052148272, 'validation_fraction': 0.3729213061576947}
observation time 0.000005, current best 44.800242 at iter 7
suggestion time taken 11.971425 iter 8 next_points [{'alpha': 1.5931277221002813, 'batch_size': 96, 'beta_1': 0.9841927132362873, 'beta_2': 0.992822828377291, 'epsilon': 1.3756565978930612e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.002763680048217018, 'tol': 0.0011891201282430738, 'validation_fraction': 0.6483945237368173}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.029029 value 79.692940 suggestion {'alpha': 1.5931277221002813, 'batch_size': 96, 'beta_1': 0.9841927132362873, 'beta_2': 0.992822828377291, 'epsilon': 1.3756565978930612e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.002763680048217018, 'tol': 0.0011891201282430738, 'validation_fraction': 0.6483945237368173}
observation time 0.000006, current best 44.800242 at iter 8
suggestion time taken 11.850169 iter 9 next_points [{'alpha': 0.00026669717187646313, 'batch_size': 52, 'beta_1': 0.5951115029737686, 'beta_2': 0.9268697920432064, 'epsilon': 4.494015250194242e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.021587108442895867, 'tol': 0.00014666606796584524, 'validation_fraction': 0.13306665709741844}]
function_evaluation time 0.500494 value 44.099592 suggestion {'alpha': 0.00026669717187646313, 'batch_size': 52, 'beta_1': 0.5951115029737686, 'beta_2': 0.9268697920432064, 'epsilon': 4.494015250194242e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.021587108442895867, 'tol': 0.00014666606796584524, 'validation_fraction': 0.13306665709741844}
observation time 0.000005, current best 44.099592 at iter 9
suggestion time taken 12.125663 iter 10 next_points [{'alpha': 2.578027149137243, 'batch_size': 93, 'beta_1': 0.7475319287085741, 'beta_2': 0.9983615072423382, 'epsilon': 3.12310742543424e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.002133330208670543, 'tol': 0.00765602875362597, 'validation_fraction': 0.6296994543228324}]
function_evaluation time 0.056936 value 151.063745 suggestion {'alpha': 2.578027149137243, 'batch_size': 93, 'beta_1': 0.7475319287085741, 'beta_2': 0.9983615072423382, 'epsilon': 3.12310742543424e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.002133330208670543, 'tol': 0.00765602875362597, 'validation_fraction': 0.6296994543228324}
observation time 0.000006, current best 44.099592 at iter 10
suggestion time taken 11.997605 iter 11 next_points [{'alpha': 0.5407282547320257, 'batch_size': 94, 'beta_1': 0.532741467170612, 'beta_2': 0.999923220815948, 'epsilon': 7.328044208338617e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.0019995368352568933, 'tol': 0.08282972820213876, 'validation_fraction': 0.1120731985998203}]
function_evaluation time 0.120915 value 149.724327 suggestion {'alpha': 0.5407282547320257, 'batch_size': 94, 'beta_1': 0.532741467170612, 'beta_2': 0.999923220815948, 'epsilon': 7.328044208338617e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.0019995368352568933, 'tol': 0.08282972820213876, 'validation_fraction': 0.1120731985998203}
observation time 0.000005, current best 44.099592 at iter 11
suggestion time taken 11.926481 iter 12 next_points [{'alpha': 0.006191356264221856, 'batch_size': 158, 'beta_1': 0.5906023537366848, 'beta_2': 0.996787373847648, 'epsilon': 2.9762278728266108e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.01316152730488683, 'tol': 0.016002104204408, 'validation_fraction': 0.11166867966105051}]
function_evaluation time 0.376899 value 51.280305 suggestion {'alpha': 0.006191356264221856, 'batch_size': 158, 'beta_1': 0.5906023537366848, 'beta_2': 0.996787373847648, 'epsilon': 2.9762278728266108e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.01316152730488683, 'tol': 0.016002104204408, 'validation_fraction': 0.11166867966105051}
observation time 0.000006, current best 44.099592 at iter 12
suggestion time taken 12.180896 iter 13 next_points [{'alpha': 0.00715231025709474, 'batch_size': 92, 'beta_1': 0.9201658524105384, 'beta_2': 0.9966190569524064, 'epsilon': 5.969780613697017e-07, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.0018406332089048686, 'tol': 6.886046524665654e-05, 'validation_fraction': 0.4508847418131491}]
/home/ryedida/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 1.077474 value 91.521644 suggestion {'alpha': 0.00715231025709474, 'batch_size': 92, 'beta_1': 0.9201658524105384, 'beta_2': 0.9966190569524064, 'epsilon': 5.969780613697017e-07, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.0018406332089048686, 'tol': 6.886046524665654e-05, 'validation_fraction': 0.4508847418131491}
observation time 0.000005, current best 44.099592 at iter 13
suggestion time taken 12.184392 iter 14 next_points [{'alpha': 0.0026228901165864806, 'batch_size': 32, 'beta_1': 0.8908750404879284, 'beta_2': 0.9999932278485665, 'epsilon': 5.2193739695905776e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.006092434128179372, 'tol': 9.85165758366205e-05, 'validation_fraction': 0.24688802642019675}]
function_evaluation time 1.229048 value 44.214125 suggestion {'alpha': 0.0026228901165864806, 'batch_size': 32, 'beta_1': 0.8908750404879284, 'beta_2': 0.9999932278485665, 'epsilon': 5.2193739695905776e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.006092434128179372, 'tol': 9.85165758366205e-05, 'validation_fraction': 0.24688802642019675}
observation time 0.000005, current best 44.099592 at iter 14
saving meta data: {'args': {'--uuid': 'f9e4832831105d1694dc4e2b783b4036', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20230426_000722', '--opt': 'smoothness', '--data': 'diabetes', '--classifier': 'MLP-adam', '--metric': 'mae', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [151.4971925380264, 151.42763539278994, 151.47026299046811, 136.86202504264318, 75.2055865763391])}
saving results
saving timing
saving suggest log
done
